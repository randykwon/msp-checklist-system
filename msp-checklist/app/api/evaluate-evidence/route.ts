import { NextRequest, NextResponse } from 'next/server';
import { createLLMService, LLMVisionMessage } from '@/lib/llm-service';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { 
      itemId, 
      title, 
      description, 
      evidenceRequired, 
      advice,
      files, 
      language = 'en' 
    } = body;

    // LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    const llmService = createLLMService();

    // ë”ë¯¸ ì‘ë‹µ ì²˜ë¦¬ (API í‚¤ê°€ ì—†ì„ ë•Œ)
    if (!process.env.OPENAI_API_KEY && !process.env.GEMINI_API_KEY && !process.env.CLAUDE_API_KEY && !process.env.AWS_ACCESS_KEY_ID) {
      console.log('No LLM API key found, using dummy response');
      return NextResponse.json({
        evaluation: {
          score: 85,
          feedback: language === 'ko' ? 
            'ğŸ¯ **ì¢…í•© í‰ê°€**: ì œì¶œëœ ì¦ë¹™ ìë£Œê°€ ìš”êµ¬ì‚¬í•­ì„ ì˜ ì¶©ì¡±í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n\nğŸ“Š **ì„¸ë¶€ í‰ê°€**:\nâ€¢ ë¬¸ì„œ ì™„ì„±ë„: 90ì  - í•„ìš”í•œ ì •ë³´ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆìŒ\nâ€¢ í’ˆì§ˆ ë° ëª…í™•ì„±: 85ì  - ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ì›€\nâ€¢ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„: 80ì  - ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•¨\n\nğŸ’¡ **ê°œì„  ì œì•ˆ**:\nâ€¢ ì¼ë¶€ ì„¸ë¶€ ì‚¬í•­ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤\nâ€¢ ì¶”ê°€ ë©”íŠ¸ë¦­ì´ë‚˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë”ìš± ê°•ë ¥í•œ ì¦ë¹™ì´ ë  ê²ƒì…ë‹ˆë‹¤\n\nâœ… **ê²°ë¡ **: í˜„ì¬ ìˆ˜ì¤€ìœ¼ë¡œë„ ì¶©ë¶„íˆ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ë©°, ì œì•ˆëœ ê°œì„ ì‚¬í•­ì„ ë°˜ì˜í•˜ë©´ ë”ìš± ì™„ë²½í•œ ì¦ë¹™ì´ ë  ê²ƒì…ë‹ˆë‹¤.' :
            'ğŸ¯ **Overall Assessment**: The submitted evidence documents meet the requirements well.\n\nğŸ“Š **Detailed Evaluation**:\nâ€¢ Document Completeness: 90 points - All necessary information is included\nâ€¢ Quality & Clarity: 85 points - Content is clear and easy to understand\nâ€¢ Requirement Fulfillment: 80 points - Most requirements are satisfied\n\nğŸ’¡ **Improvement Suggestions**:\nâ€¢ Some details could be described more specifically\nâ€¢ Additional metrics or data would make the evidence even stronger\n\nâœ… **Conclusion**: The current level sufficiently meets the requirements, and implementing the suggested improvements would make the evidence even more comprehensive.',
          evaluatedAt: new Date(),
          criteria: [
            {
              name: 'Document Completeness',
              nameKo: 'ë¬¸ì„œ ì™„ì„±ë„',
              score: 90,
              comment: language === 'ko' ? 'í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.' : 'All necessary information is included.',
              commentKo: 'í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
            },
            {
              name: 'Quality & Clarity',
              nameKo: 'í’ˆì§ˆ ë° ëª…í™•ì„±',
              score: 85,
              comment: language === 'ko' ? 'ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.' : 'Content is clear and easy to understand.',
              commentKo: 'ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.'
            },
            {
              name: 'Requirement Fulfillment',
              nameKo: 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„',
              score: 80,
              comment: language === 'ko' ? 'ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•©ë‹ˆë‹¤.' : 'Most requirements are satisfied.',
              commentKo: 'ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•©ë‹ˆë‹¤.'
            }
          ]
        },
        provider: llmService.getProviderName(),
        isDummy: true
      });
    }

    // íŒŒì¼ ë°ì´í„° ì¤€ë¹„ (ì´ë¯¸ì§€ì™€ PDF ëª¨ë‘ ì²˜ë¦¬)
    const contentParts: any[] = [];
    
    // ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì²˜ë¦¬
    const imageFiles = files.filter((file: any) => file.fileType === 'image');
    imageFiles.forEach((img: any) => {
      contentParts.push({
        type: "image_url" as const,
        image_url: {
          url: `data:${img.mimeType};base64,${img.base64Data}`
        }
      });
    });
    
    // PDF íŒŒì¼ë“¤ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ë¡œ ë³€í™˜)
    const pdfFiles = files.filter((file: any) => file.fileType === 'pdf');
    let pdfTexts = '';
    if (pdfFiles.length > 0) {
      pdfTexts = pdfFiles.map((pdf: any, index: number) => 
        `\n\n--- PDF ë¬¸ì„œ ${index + 1}: ${pdf.fileName} ---\n${pdf.extractedText || 'í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨'}`
      ).join('');
    }

    // í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
    const evaluationPrompt = language === 'ko' ? 
      `ë‹¤ìŒ AWS MSP ìš”êµ¬ì‚¬í•­ì— ëŒ€í•œ ì¦ë¹™ ìë£Œë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”:

**í‰ê°€ í•­ëª©**: ${title}
**ì„¤ëª…**: ${description}
**ì¦ë¹™ ìš”êµ¬ì‚¬í•­**: ${evidenceRequired}
**ì¡°ì–¸**: ${advice}

**ì œì¶œëœ ì¦ë¹™ ìë£Œ**:
- ì´ë¯¸ì§€ íŒŒì¼: ${imageFiles.length}ê°œ
- PDF ë¬¸ì„œ: ${pdfFiles.length}ê°œ${pdfTexts}

**í‰ê°€ ê¸°ì¤€**:
1. ë¬¸ì„œ ì™„ì„±ë„ (0-100ì ): í•„ìš”í•œ ì •ë³´ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?
2. í’ˆì§ˆ ë° ëª…í™•ì„± (0-100ì ): ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
3. ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ (0-100ì ): ëª…ì‹œëœ ìš”êµ¬ì‚¬í•­ì„ ì–¼ë§ˆë‚˜ ì˜ ì¶©ì¡±í•˜ëŠ”ê°€?

**ì‘ë‹µ í˜•ì‹**:
ğŸ¯ **ì¢…í•© í‰ê°€**: [ì „ì²´ì ì¸ í‰ê°€ ìš”ì•½]

ğŸ“Š **ì„¸ë¶€ í‰ê°€**:
â€¢ ë¬¸ì„œ ì™„ì„±ë„: [ì ìˆ˜]ì  - [í‰ê°€ ë‚´ìš©]
â€¢ í’ˆì§ˆ ë° ëª…í™•ì„±: [ì ìˆ˜]ì  - [í‰ê°€ ë‚´ìš©]  
â€¢ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„: [ì ìˆ˜]ì  - [í‰ê°€ ë‚´ìš©]

ğŸ’¡ **ê°œì„  ì œì•ˆ**:
â€¢ [êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆë“¤]

âœ… **ê²°ë¡ **: [ìµœì¢… ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­]

ì¢…í•© ì ìˆ˜ëŠ” ì„¸ ê¸°ì¤€ì˜ í‰ê· ìœ¼ë¡œ ê³„ì‚°í•˜ê³ , ê°ê´€ì ì´ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.` :
      `Please evaluate the evidence documents for the following AWS MSP requirement:

**Assessment Item**: ${title}
**Description**: ${description}
**Evidence Required**: ${evidenceRequired}
**Advice**: ${advice}

**Submitted Evidence**:
- Image files: ${imageFiles.length}
- PDF documents: ${pdfFiles.length}${pdfTexts}

**Evaluation Criteria**:
1. Document Completeness (0-100 points): Are all necessary information included?
2. Quality & Clarity (0-100 points): Is the content clear and easy to understand?
3. Requirement Fulfillment (0-100 points): How well does it meet the specified requirements?

**Response Format**:
ğŸ¯ **Overall Assessment**: [Overall evaluation summary]

ğŸ“Š **Detailed Evaluation**:
â€¢ Document Completeness: [score] points - [evaluation content]
â€¢ Quality & Clarity: [score] points - [evaluation content]
â€¢ Requirement Fulfillment: [score] points - [evaluation content]

ğŸ’¡ **Improvement Suggestions**:
â€¢ [Specific improvement recommendations]

âœ… **Conclusion**: [Final conclusion and recommendations]

Calculate the overall score as the average of the three criteria and provide objective, constructive feedback.`;

    const systemMessage = language === 'ko' ? 
      "ë‹¹ì‹ ì€ AWS MSP(Managed Service Provider) í”„ë¡œê·¸ë¨ì˜ ì „ë¬¸ í‰ê°€ìì…ë‹ˆë‹¤. ì œì¶œëœ ì¦ë¹™ ìë£Œë¥¼ ê°ê´€ì ì´ê³  ê±´ì„¤ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ íŒŒíŠ¸ë„ˆê°€ ìš”êµ¬ì‚¬í•­ì„ ë” ì˜ ì¶©ì¡±í•  ìˆ˜ ìˆë„ë¡ ë„ì›€ì„ ì œê³µí•©ë‹ˆë‹¤." :
      "You are an expert evaluator for the AWS MSP (Managed Service Provider) program. You objectively and constructively evaluate submitted evidence documents to help partners better meet the requirements.";

    // ë©”ì‹œì§€ êµ¬ì„±
    const messages: LLMVisionMessage[] = [
      {
        role: 'system',
        content: [{ type: 'text', text: systemMessage }]
      },
      {
        role: 'user',
        content: [
          { type: 'text', text: evaluationPrompt },
          ...contentParts
        ]
      }
    ];

    // LLM ì„œë¹„ìŠ¤ë¥¼ í†µí•´ í‰ê°€ ìƒì„±
    const result = await llmService.generateVision(messages, {
      temperature: 0.3,
      maxTokens: 1500
    });

    const evaluationText = result.content;
    
    // ì ìˆ˜ ì¶”ì¶œ (ì •ê·œì‹ìœ¼ë¡œ ì ìˆ˜ë“¤ì„ ì°¾ì•„ì„œ í‰ê·  ê³„ì‚°)
    const scoreMatches = evaluationText.match(/(\d+)ì /g) || [];
    const scores = scoreMatches.map(match => parseInt(match.replace('ì ', '')));
    const averageScore = scores.length > 0 ? Math.round(scores.reduce((a, b) => a + b, 0) / scores.length) : 75;

    // í‰ê°€ ê¸°ì¤€ë³„ ì ìˆ˜ íŒŒì‹± (ê°„ë‹¨í•œ íŒŒì‹±)
    const criteria = [
      {
        name: 'Document Completeness',
        nameKo: 'ë¬¸ì„œ ì™„ì„±ë„',
        score: scores[0] || 75,
        comment: language === 'ko' ? 'ë¬¸ì„œ ì™„ì„±ë„ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.' : 'Document completeness evaluation result.',
        commentKo: 'ë¬¸ì„œ ì™„ì„±ë„ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.'
      },
      {
        name: 'Quality & Clarity',
        nameKo: 'í’ˆì§ˆ ë° ëª…í™•ì„±',
        score: scores[1] || 75,
        comment: language === 'ko' ? 'í’ˆì§ˆ ë° ëª…í™•ì„± í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.' : 'Quality and clarity evaluation result.',
        commentKo: 'í’ˆì§ˆ ë° ëª…í™•ì„± í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.'
      },
      {
        name: 'Requirement Fulfillment',
        nameKo: 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„',
        score: scores[2] || 75,
        comment: language === 'ko' ? 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.' : 'Requirement fulfillment evaluation result.',
        commentKo: 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.'
      }
    ];

    return NextResponse.json({
      evaluation: {
        score: averageScore,
        feedback: evaluationText,
        feedbackKo: language === 'ko' ? evaluationText : undefined,
        evaluatedAt: new Date(),
        criteria
      },
      provider: llmService.getProviderName(),
      usage: result.usage,
      isDummy: false
    });

  } catch (error: any) {
    console.error('Error evaluating evidence:', error);
    
    return NextResponse.json(
      { 
        error: 'Failed to evaluate evidence',
        details: error.message 
      },
      { status: 500 }
    );
  }
}