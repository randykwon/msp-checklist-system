import { NextRequest, NextResponse } from 'next/server';
import { cookies } from 'next/headers';
import { verifyToken } from '@/lib/auth';
import { createLLMService, LLMVisionMessage } from '@/lib/llm-service';
import Database from 'better-sqlite3';
import path from 'path';
import fs from 'fs';

// í‰ê°€ ê²°ê³¼ ì €ìž¥ í•¨ìˆ˜
function saveEvaluationToDb(
  userId: number,
  itemId: string,
  assessmentType: string,
  score: number,
  feedback: string,
  llmProvider: string,
  llmModel: string,
  fileCount: number,
  totalFileSize: number
) {
  try {
    const dbPath = path.join(process.cwd(), 'msp-assessment.db');
    if (!fs.existsSync(dbPath)) return;
    
    const db = new Database(dbPath);
    
    // í…Œì´ë¸” ìƒì„±
    db.exec(`
      CREATE TABLE IF NOT EXISTS evidence_evaluations (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER NOT NULL,
        item_id TEXT NOT NULL,
        assessment_type TEXT DEFAULT 'unknown',
        score INTEGER NOT NULL,
        feedback TEXT NOT NULL,
        llm_provider TEXT,
        llm_model TEXT,
        file_count INTEGER DEFAULT 1,
        total_file_size INTEGER DEFAULT 0,
        evaluated_at TEXT NOT NULL,
        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
        UNIQUE(user_id, item_id)
      )
    `);
    
    // í‰ê°€ ê²°ê³¼ ì €ìž¥ (ê¸°ì¡´ ê²°ê³¼ ì—…ë°ì´íŠ¸)
    const stmt = db.prepare(`
      INSERT OR REPLACE INTO evidence_evaluations 
      (user_id, item_id, assessment_type, score, feedback, llm_provider, llm_model, file_count, total_file_size, evaluated_at)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    `);
    
    stmt.run(
      userId,
      itemId,
      assessmentType,
      score,
      feedback,
      llmProvider,
      llmModel,
      fileCount,
      totalFileSize,
      new Date().toISOString()
    );
    
    db.close();
    console.log(`Evaluation saved for user ${userId}, item ${itemId}`);
  } catch (error) {
    console.error('Failed to save evaluation to DB:', error);
  }
}

export async function POST(request: NextRequest) {
  try {
    // ì‚¬ìš©ìž ì¸ì¦ í™•ì¸
    const cookieStore = await cookies();
    const token = cookieStore.get('msp_auth_token')?.value;
    let currentUserId = 0;
    
    if (token) {
      const user = verifyToken(token);
      if (user) {
        currentUserId = user.id;
      }
    }

    const body = await request.json();
    const { 
      itemId, 
      title, 
      description, 
      evidenceRequired, 
      advice,
      virtualEvidence,
      files, 
      language = 'en',
      assessmentType = 'unknown'
    } = body;

    // íŒŒì¼ í†µê³„ ê³„ì‚°
    const fileCount = files?.length || 0;
    const totalFileSize = files?.reduce((sum: number, f: any) => sum + (f.fileSize || 0), 0) || 0;

    // LLM ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    const llmService = createLLMService();

    // ë”ë¯¸ ì‘ë‹µ ì²˜ë¦¬ (API í‚¤ê°€ ì—†ì„ ë•Œ)
    if (!process.env.OPENAI_API_KEY && !process.env.GEMINI_API_KEY && !process.env.CLAUDE_API_KEY && !process.env.AWS_ACCESS_KEY_ID) {
      console.log('No LLM API key found, using dummy response');
      return NextResponse.json({
        evaluation: {
          score: 85,
          feedback: language === 'ko' ? 
            'ðŸŽ¯ **ì¢…í•© í‰ê°€**: ì œì¶œëœ ì¦ë¹™ ìžë£Œê°€ ìš”êµ¬ì‚¬í•­ì„ ìž˜ ì¶©ì¡±í•˜ê³  ìžˆìŠµë‹ˆë‹¤.\n\nðŸ“Š **ì„¸ë¶€ í‰ê°€**:\nâ€¢ ë¬¸ì„œ ì™„ì„±ë„: 90ì  - í•„ìš”í•œ ì •ë³´ê°€ ëª¨ë‘ í¬í•¨ë˜ì–´ ìžˆìŒ\nâ€¢ í’ˆì§ˆ ë° ëª…í™•ì„±: 85ì  - ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ì›€\nâ€¢ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„: 80ì  - ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•¨\n\nðŸ’¡ **ê°œì„  ì œì•ˆ**:\nâ€¢ ì¼ë¶€ ì„¸ë¶€ ì‚¬í•­ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ë©´ ì¢‹ê² ìŠµë‹ˆë‹¤\nâ€¢ ì¶”ê°€ ë©”íŠ¸ë¦­ì´ë‚˜ ë°ì´í„°ê°€ ìžˆë‹¤ë©´ ë”ìš± ê°•ë ¥í•œ ì¦ë¹™ì´ ë  ê²ƒìž…ë‹ˆë‹¤\n\nâœ… **ê²°ë¡ **: í˜„ìž¬ ìˆ˜ì¤€ìœ¼ë¡œë„ ì¶©ë¶„ížˆ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ë©°, ì œì•ˆëœ ê°œì„ ì‚¬í•­ì„ ë°˜ì˜í•˜ë©´ ë”ìš± ì™„ë²½í•œ ì¦ë¹™ì´ ë  ê²ƒìž…ë‹ˆë‹¤.' :
            'ðŸŽ¯ **Overall Assessment**: The submitted evidence documents meet the requirements well.\n\nðŸ“Š **Detailed Evaluation**:\nâ€¢ Document Completeness: 90 points - All necessary information is included\nâ€¢ Quality & Clarity: 85 points - Content is clear and easy to understand\nâ€¢ Requirement Fulfillment: 80 points - Most requirements are satisfied\n\nðŸ’¡ **Improvement Suggestions**:\nâ€¢ Some details could be described more specifically\nâ€¢ Additional metrics or data would make the evidence even stronger\n\nâœ… **Conclusion**: The current level sufficiently meets the requirements, and implementing the suggested improvements would make the evidence even more comprehensive.',
          evaluatedAt: new Date(),
          criteria: [
            {
              name: 'Document Completeness',
              nameKo: 'ë¬¸ì„œ ì™„ì„±ë„',
              score: 90,
              comment: language === 'ko' ? 'í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.' : 'All necessary information is included.',
              commentKo: 'í•„ìš”í•œ ëª¨ë“  ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.'
            },
            {
              name: 'Quality & Clarity',
              nameKo: 'í’ˆì§ˆ ë° ëª…í™•ì„±',
              score: 85,
              comment: language === 'ko' ? 'ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.' : 'Content is clear and easy to understand.',
              commentKo: 'ë‚´ìš©ì´ ëª…í™•í•˜ê³  ì´í•´í•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.'
            },
            {
              name: 'Requirement Fulfillment',
              nameKo: 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„',
              score: 80,
              comment: language === 'ko' ? 'ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•©ë‹ˆë‹¤.' : 'Most requirements are satisfied.',
              commentKo: 'ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•©ë‹ˆë‹¤.'
            }
          ]
        },
        provider: llmService.getProviderName(),
        isDummy: true
      });
    }

    // íŒŒì¼ ë°ì´í„° ì¤€ë¹„ (ì´ë¯¸ì§€ì™€ PDF ëª¨ë‘ ì²˜ë¦¬)
    const contentParts: any[] = [];
    
    // ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì²˜ë¦¬
    const imageFiles = files.filter((file: any) => file.fileType === 'image');
    imageFiles.forEach((img: any) => {
      contentParts.push({
        type: "image_url" as const,
        image_url: {
          url: `data:${img.mimeType};base64,${img.base64Data}`
        }
      });
    });
    
    // PDF íŒŒì¼ë“¤ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ë¡œ ë³€í™˜)
    const pdfFiles = files.filter((file: any) => file.fileType === 'pdf');
    let pdfTexts = '';
    if (pdfFiles.length > 0) {
      pdfTexts = pdfFiles.map((pdf: any, index: number) => 
        `\n\n--- PDF ë¬¸ì„œ ${index + 1}: ${pdf.fileName} ---\n${pdf.extractedText || 'í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨'}`
      ).join('');
    }

    // ê°€ìƒì¦ë¹™ì˜ˆì œ ì„¹ì…˜ (ìžˆëŠ” ê²½ìš°ì—ë§Œ)
    const virtualEvidenceSection = virtualEvidence ? 
      (language === 'ko' ? 
        `\n\n**ðŸ” ì°¸ê³ ìš© ê°€ìƒì¦ë¹™ì˜ˆì œ** (ì´ ìˆ˜ì¤€ì˜ ì¦ë¹™ì´ ê¸°ëŒ€ë©ë‹ˆë‹¤):\n${virtualEvidence}` :
        `\n\n**ðŸ” Reference Virtual Evidence Example** (This level of evidence is expected):\n${virtualEvidence}`) : '';

    // ì¡°ì–¸ ì„¹ì…˜ (ìžˆëŠ” ê²½ìš°ì—ë§Œ)
    const adviceSection = advice ? 
      (language === 'ko' ? 
        `\n\n**ðŸ’¡ ì „ë¬¸ê°€ ì¡°ì–¸** (ì´ ì¡°ì–¸ì„ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”):\n${advice}` :
        `\n\n**ðŸ’¡ Expert Advice** (Evaluate based on this advice):\n${advice}`) : '';

    // í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ë” ì—„ê²©í•œ ë²„ì „)
    const evaluationPrompt = language === 'ko' ? 
      `ë‹¹ì‹ ì€ AWS MSP í”„ë¡œê·¸ëž¨ì˜ **ì—„ê²©í•œ** ì‹¬ì‚¬ê´€ìž…ë‹ˆë‹¤. ì œì¶œëœ ì¦ë¹™ ìžë£Œë¥¼ ì•„ëž˜ ê¸°ì¤€ì— ë”°ë¼ **ê°ê´€ì ì´ê³  ì—„ê²©í•˜ê²Œ** í‰ê°€í•´ì£¼ì„¸ìš”.

## í‰ê°€ ëŒ€ìƒ í•­ëª©
- **í•­ëª© ID**: ${itemId}
- **í•­ëª©ëª…**: ${title}
- **ì„¤ëª…**: ${description}
- **ì¦ë¹™ ìš”êµ¬ì‚¬í•­**: ${evidenceRequired}
${adviceSection}
${virtualEvidenceSection}

## ì œì¶œëœ ì¦ë¹™ ìžë£Œ
- ì´ë¯¸ì§€ íŒŒì¼: ${imageFiles.length}ê°œ
- PDF ë¬¸ì„œ: ${pdfFiles.length}ê°œ${pdfTexts}

## ì—„ê²©í•œ í‰ê°€ ê¸°ì¤€ (ê° í•­ëª© 0-100ì )

### 1. ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ (ê°€ìž¥ ì¤‘ìš”)
- ì¦ë¹™ ìš”êµ¬ì‚¬í•­ì— ëª…ì‹œëœ ëª¨ë“  í•­ëª©ì´ í¬í•¨ë˜ì–´ ìžˆëŠ”ê°€?
- ê°€ìƒì¦ë¹™ì˜ˆì œì—ì„œ ì œì‹œí•œ ìˆ˜ì¤€ì˜ ìƒì„¸í•¨ì„ ê°–ì¶”ê³  ìžˆëŠ”ê°€?
- ëˆ„ë½ëœ í•„ìˆ˜ ìš”ì†Œê°€ ìžˆìœ¼ë©´ **ëŒ€í­ ê°ì ** (ê° ëˆ„ë½ í•­ëª©ë‹¹ -15ì )

### 2. ë¬¸ì„œ ì™„ì„±ë„
- ì „ë¬¸ê°€ ì¡°ì–¸ì—ì„œ ê¶Œìž¥í•œ ë‚´ìš©ì´ ë°˜ì˜ë˜ì–´ ìžˆëŠ”ê°€?
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ë‚ ì§œ, ë‹´ë‹¹ìž ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìžˆëŠ”ê°€?
- ìŠ¤í¬ë¦°ìƒ·ì´ë‚˜ ë¬¸ì„œê°€ ì‹¤ì œ ìš´ì˜ í™˜ê²½ì˜ ê²ƒì¸ê°€?
- ëª¨í˜¸í•˜ê±°ë‚˜ ì¼ë°˜ì ì¸ ë‚´ìš©ë§Œ ìžˆìœ¼ë©´ **ê°ì **

### 3. í’ˆì§ˆ ë° ì‹ ë¢°ì„±
- ë¬¸ì„œì˜ ì§„ìœ„ì„±ê³¼ ì‹ ë¢°ì„±ì´ í™•ì¸ë˜ëŠ”ê°€?
- ì´ë¯¸ì§€ê°€ ì„ ëª…í•˜ê³  ë‚´ìš©ì´ ì½ì„ ìˆ˜ ìžˆëŠ”ê°€?
- ë‚ ì§œì™€ ë²„ì „ ì •ë³´ê°€ ìµœì‹ ì¸ê°€?

## í‰ê°€ ì‹œ ì£¼ì˜ì‚¬í•­
âš ï¸ **ì—„ê²©í•˜ê²Œ í‰ê°€í•˜ì„¸ìš”**:
- 80ì  ì´ìƒ: ìš”êµ¬ì‚¬í•­ì„ ì™„ë²½ížˆ ì¶©ì¡±í•˜ê³  ê°€ìƒì¦ë¹™ì˜ˆì œ ìˆ˜ì¤€ ì´ìƒ
- 60-79ì : ëŒ€ë¶€ë¶„ ì¶©ì¡±í•˜ë‚˜ ì¼ë¶€ ë³´ì™„ í•„ìš”
- 40-59ì : ê¸°ë³¸ ìš”êµ¬ì‚¬í•­ë§Œ ì¶©ì¡±, ìƒë‹¹í•œ ë³´ì™„ í•„ìš”
- 40ì  ë¯¸ë§Œ: ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±, ìž¬ì œì¶œ í•„ìš”

## ì‘ë‹µ í˜•ì‹
ðŸŽ¯ **ì¢…í•© í‰ê°€**: [í•©ê²©/ì¡°ê±´ë¶€ í•©ê²©/ë³´ì™„ í•„ìš”/ìž¬ì œì¶œ í•„ìš”] - [í•œ ì¤„ ìš”ì•½]

ðŸ“Š **ì„¸ë¶€ í‰ê°€**:
â€¢ ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„: [ì ìˆ˜]ì  - [êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš©ê³¼ ê·¼ê±°]
â€¢ ë¬¸ì„œ ì™„ì„±ë„: [ì ìˆ˜]ì  - [êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš©ê³¼ ê·¼ê±°]
â€¢ í’ˆì§ˆ ë° ì‹ ë¢°ì„±: [ì ìˆ˜]ì  - [êµ¬ì²´ì ì¸ í‰ê°€ ë‚´ìš©ê³¼ ê·¼ê±°]

âŒ **ë¶€ì¡±í•œ ì ** (ìžˆëŠ” ê²½ìš°):
â€¢ [ëˆ„ë½ë˜ê±°ë‚˜ ë¶€ì¡±í•œ êµ¬ì²´ì ì¸ í•­ëª©ë“¤]

ðŸ’¡ **ê°œì„  ì œì•ˆ**:
â€¢ [êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ë°©ì•ˆ]

âœ… **ê²°ë¡ **: [ìµœì¢… íŒì •ê³¼ ë‹¤ìŒ ë‹¨ê³„ ê¶Œìž¥ì‚¬í•­]` :

      `You are a **strict** auditor for the AWS MSP program. Evaluate the submitted evidence **objectively and rigorously** based on the criteria below.

## Assessment Item
- **Item ID**: ${itemId}
- **Title**: ${title}
- **Description**: ${description}
- **Evidence Required**: ${evidenceRequired}
${adviceSection}
${virtualEvidenceSection}

## Submitted Evidence
- Image files: ${imageFiles.length}
- PDF documents: ${pdfFiles.length}${pdfTexts}

## Strict Evaluation Criteria (0-100 points each)

### 1. Requirement Fulfillment (Most Important)
- Are all items specified in the evidence requirements included?
- Does it meet the level of detail shown in the virtual evidence example?
- **Significant deduction** for missing required elements (-15 points per missing item)

### 2. Document Completeness
- Are the recommendations from expert advice reflected?
- Are specific numbers, dates, and responsible parties included?
- Are screenshots/documents from actual production environment?
- **Deduct points** for vague or generic content

### 3. Quality & Reliability
- Can the authenticity and reliability of documents be verified?
- Are images clear and readable?
- Are dates and version information current?

## Evaluation Guidelines
âš ï¸ **Be strict**:
- 80+ points: Fully meets requirements, exceeds virtual evidence example level
- 60-79 points: Mostly meets requirements, some improvements needed
- 40-59 points: Only basic requirements met, significant improvements needed
- Below 40: Requirements not met, resubmission required

## Response Format
ðŸŽ¯ **Overall Assessment**: [Pass/Conditional Pass/Needs Improvement/Resubmit Required] - [One-line summary]

ðŸ“Š **Detailed Evaluation**:
â€¢ Requirement Fulfillment: [score] points - [Specific evaluation with evidence]
â€¢ Document Completeness: [score] points - [Specific evaluation with evidence]
â€¢ Quality & Reliability: [score] points - [Specific evaluation with evidence]

âŒ **Deficiencies** (if any):
â€¢ [Specific missing or insufficient items]

ðŸ’¡ **Improvement Suggestions**:
â€¢ [Specific and actionable improvement recommendations]

âœ… **Conclusion**: [Final verdict and recommended next steps]`;

    const systemMessage = language === 'ko' ? 
      "ë‹¹ì‹ ì€ AWS MSP(Managed Service Provider) í”„ë¡œê·¸ëž¨ì˜ ì—„ê²©í•œ ì‹¬ì‚¬ê´€ìž…ë‹ˆë‹¤. ì œì¶œëœ ì¦ë¹™ ìžë£Œê°€ AWSì˜ ë†’ì€ ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ ê°ê´€ì ì´ê³  ë¹„íŒì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ê´€ëŒ€í•œ í‰ê°€ëŠ” íŒŒíŠ¸ë„ˆì—ê²Œ ë„ì›€ì´ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¶€ì¡±í•œ ì ì„ ëª…í™•ížˆ ì§€ì í•˜ì—¬ ì‹¤ì œ ì‹¬ì‚¬ì—ì„œ í†µê³¼í•  ìˆ˜ ìžˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”." :
      "You are a strict auditor for the AWS MSP (Managed Service Provider) program. You objectively and critically evaluate whether submitted evidence meets AWS's high standards. Lenient evaluation does not help partners. Clearly point out deficiencies to help them pass the actual audit.";

    // ë©”ì‹œì§€ êµ¬ì„±
    const messages: LLMVisionMessage[] = [
      {
        role: 'system',
        content: [{ type: 'text', text: systemMessage }]
      },
      {
        role: 'user',
        content: [
          { type: 'text', text: evaluationPrompt },
          ...contentParts
        ]
      }
    ];

    // LLM ì„œë¹„ìŠ¤ë¥¼ í†µí•´ í‰ê°€ ìƒì„±
    const result = await llmService.generateVision(messages, {
      temperature: 0.3,
      maxTokens: 1500
    });

    const evaluationText = result.content;
    
    // ì ìˆ˜ ì¶”ì¶œ (ì •ê·œì‹ìœ¼ë¡œ ì ìˆ˜ë“¤ì„ ì°¾ì•„ì„œ í‰ê·  ê³„ì‚°)
    const scoreMatches = evaluationText.match(/(\d+)ì /g) || [];
    const scores = scoreMatches.map(match => parseInt(match.replace('ì ', '')));
    const averageScore = scores.length > 0 ? Math.round(scores.reduce((a, b) => a + b, 0) / scores.length) : 75;

    // í‰ê°€ ê¸°ì¤€ë³„ ì ìˆ˜ íŒŒì‹± (ê°„ë‹¨í•œ íŒŒì‹±)
    const criteria = [
      {
        name: 'Document Completeness',
        nameKo: 'ë¬¸ì„œ ì™„ì„±ë„',
        score: scores[0] || 75,
        comment: language === 'ko' ? 'ë¬¸ì„œ ì™„ì„±ë„ í‰ê°€ ê²°ê³¼ìž…ë‹ˆë‹¤.' : 'Document completeness evaluation result.',
        commentKo: 'ë¬¸ì„œ ì™„ì„±ë„ í‰ê°€ ê²°ê³¼ìž…ë‹ˆë‹¤.'
      },
      {
        name: 'Quality & Clarity',
        nameKo: 'í’ˆì§ˆ ë° ëª…í™•ì„±',
        score: scores[1] || 75,
        comment: language === 'ko' ? 'í’ˆì§ˆ ë° ëª…í™•ì„± í‰ê°€ ê²°ê³¼ìž…ë‹ˆë‹¤.' : 'Quality and clarity evaluation result.',
        commentKo: 'í’ˆì§ˆ ë° ëª…í™•ì„± í‰ê°€ ê²°ê³¼ìž…ë‹ˆë‹¤.'
      },
      {
        name: 'Requirement Fulfillment',
        nameKo: 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„',
        score: scores[2] || 75,
        comment: language === 'ko' ? 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ í‰ê°€ ê²°ê³¼ìž…ë‹ˆë‹¤.' : 'Requirement fulfillment evaluation result.',
        commentKo: 'ìš”êµ¬ì‚¬í•­ ì¶©ì¡±ë„ í‰ê°€ ê²°ê³¼ìž…ë‹ˆë‹¤.'
      }
    ];

    // í‰ê°€ ê²°ê³¼ë¥¼ DBì— ì €ìž¥
    if (currentUserId > 0) {
      saveEvaluationToDb(
        currentUserId,
        itemId,
        assessmentType,
        averageScore,
        evaluationText,
        llmService.getProviderName(),
        llmService.getModelName?.() || 'unknown',
        fileCount,
        totalFileSize
      );
    }

    return NextResponse.json({
      evaluation: {
        score: averageScore,
        feedback: evaluationText,
        feedbackKo: language === 'ko' ? evaluationText : undefined,
        evaluatedAt: new Date(),
        criteria
      },
      provider: llmService.getProviderName(),
      usage: result.usage,
      isDummy: false
    });

  } catch (error: any) {
    console.error('Error evaluating evidence:', error);
    
    return NextResponse.json(
      { 
        error: 'Failed to evaluate evidence',
        details: error.message 
      },
      { status: 500 }
    );
  }
}