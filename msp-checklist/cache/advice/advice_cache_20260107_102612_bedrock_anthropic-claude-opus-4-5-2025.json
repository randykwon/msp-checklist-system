{
  "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
  "exportedAt": "2026-01-07T03:31:08.525Z",
  "koAdvice": [
    {
      "id": "BUS-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-001",
      "category": "Business",
      "title": "회사 개요",
      "advice": "# BUS-001: 회사 개요 프레젠테이션 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n회사 개요 프레젠테이션은 **감사의 첫 인상을 결정하는 오프닝 세션**입니다. 감사관은 이 20분 동안 귀사가 \"진정한 클라우드 네이티브 MSP\"인지, 아니면 \"기존 호스팅 업체가 AWS 라벨만 붙인 것\"인지를 판단합니다. 이 세션에서 신뢰를 얻지 못하면 이후 기술 심사에서도 불리한 시선으로 평가받게 됩니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 실제 질문 의도 |\n|--------|------------------------|\n| **클라우드 네이티브 DNA** | \"이 회사가 AWS 환경에서 태어났는가, 아니면 온프레미스에서 전환한 것인가?\" |\n| **운영 성숙도** | \"24/7 운영이 가능한 인력 구조와 지역 커버리지를 갖추고 있는가?\" |\n| **고객 포트폴리오 다양성** | \"특정 산업/규모에 편중되지 않고 다양한 환경을 관리해본 경험이 있는가?\" |\n| **DevOps 자동화 철학** | \"수동 관리가 아닌 코드 기반 자동화를 핵심 가치로 삼고 있는가?\" |\n| **AWS 파트너 투자** | \"AWS와의 관계에 얼마나 진지하게 투자하고 있는가?\" |\n\n### 관련 AWS 서비스 및 프로그램\n\n프레젠테이션에서 자연스럽게 언급해야 할 AWS 요소들:\n- **AWS Partner Network (APN)** 티어 및 경로\n- **AWS Competency** 보유 현황 (Migration, DevOps 등)\n- **AWS Service Delivery** 지정 현황\n- **AWS Partner Central** 활용 현황\n- **AWS Solution Provider Program** 참여 여부\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙: 프레젠테이션 덱 (PowerPoint/Google Slides)\n\n**파일명 예시:** `[회사명]_AWS_MSP_Company_Overview_v2.1_2024.pptx`\n\n### 슬라이드별 필수 포함 내용\n\n```\n📊 권장 슬라이드 구성 (15-18장, 20분 내 발표)\n\n[1] 타이틀 슬라이드\n    - 회사 로고, 발표 제목, 발표일, 발표자 정보\n\n[2-3] 회사 역사 & 비전 (2분)\n    - 설립 연도 및 주요 마일스톤 타임라인\n    - \"왜 AWS MSP가 되려 하는가\"에 대한 명확한 비전\n    - ⚠️ 온프레미스 역사가 길다면, 클라우드 전환 시점을 명확히 표시\n\n[4] 글로벌/로컬 프레즌스 (1분)\n    - 본사 및 지사 위치를 지도에 시각화\n    - 각 사무실의 역할 (영업, 기술지원, NOC 등)\n    - 시간대별 커버리지 표시\n\n[5-6] 조직 구조 & 인력 현황 (2분)\n    - 전체 직원 수 및 부서별 분포\n    - AWS MSP 전담 인력 수 및 위치\n    - AWS 자격증 보유 현황 (자격증별 인원수)\n    - 24/7 운영팀 교대 근무 체계\n\n[7-8] 고객 포트폴리오 (3분)\n    - 총 관리 고객 수\n    - 산업별 분포 (파이 차트)\n    - 고객 규모별 분포 (SMB/Enterprise)\n    - 지역별 분포\n    - 대표 고객 로고 (NDA 허용 범위 내)\n    - 관리 중인 총 AWS 계정 수, 월간 AWS 사용량\n\n[9-11] 서비스 차별화 요소 (4분) ⭐ 가장 중요\n    - 자체 개발 자동화 도구/플랫폼\n    - DevOps 기반 관리 방식 vs 전통적 관리 방식 비교\n    - 구체적인 자동화 사례 (배포 파이프라인, 자동 스케일링 등)\n    - SLA 및 성과 지표\n\n[12-13] AWS 파트너십 현황 (2분)\n    - APN 티어 및 경로 (Select/Advanced/Premier)\n    - 보유 Competency 및 Service Delivery\n    - 월간 AWS 청구 규모 (범위로 표시 가능)\n    - AWS 파트너 프로그램 참여 이력\n\n[14-15] 클라우드 관리 서비스 개요 (3분)\n    - 서비스 카탈로그 요약\n    - 온프레미스 관리와의 차이점 명시\n    - Infrastructure as Code 활용 현황\n    - 모니터링/알람 자동화 체계\n\n[16-17] 성공 사례 하이라이트 (2분)\n    - 1-2개 대표 사례 요약\n    - 정량적 성과 (비용 절감률, 가용성 향상 등)\n\n[18] Q&A 및 연락처\n```\n\n### 보조 자료 (선택적이지만 권장)\n\n| 자료명 | 형식 | 용도 |\n|--------|------|------|\n| `AWS_Certification_Summary.xlsx` | 엑셀 | 자격증 보유 현황 상세 |\n| `Customer_Reference_List.pdf` | PDF | 레퍼런스 가능 고객 목록 |\n| `Organization_Chart.pdf` | PDF | 상세 조직도 |\n| `MSP_Service_Catalog.pdf` | PDF | 서비스 상세 설명 |\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 데이터 수집 (3-5일)\n\n```\n담당: 경영지원팀 + HR + 영업팀\n\n□ HR에서 수집\n  - 전체 직원 수 및 부서별 분포\n  - AWS 자격증 보유자 명단 (자격증 종류별)\n  - MSP 운영팀 인원 및 근무 위치\n  - 24/7 운영 교대 근무표\n\n□ 영업/CS에서 수집\n  - 현재 관리 중인 고객 수\n  - 고객별 산업, 규모, 지역 정보\n  - 관리 중인 AWS 계정 수\n  - 월간 총 AWS 청구액 (Partner Central에서 확인)\n\n□ AWS Partner Central에서 확인\n  - 현재 APN 티어\n  - 보유 Competency/Service Delivery\n  - 파트너 스코어카드\n```\n\n### Step 2: 차별화 포인트 정의 (2-3일)\n\n```\n담당: CTO/기술리더 + 마케팅\n\n핵심 질문에 답변 작성:\n1. \"우리 회사가 다른 MSP와 다른 점 3가지는?\"\n2. \"DevOps 자동화로 해결한 구체적인 문제는?\"\n3. \"온프레미스 관리와 우리 클라우드 관리의 차이점은?\"\n\n⚠️ 주의: \"고객 중심\", \"전문성\" 같은 추상적 표현 금지\n✅ 좋은 예: \"Terraform 기반 인프라 프로비저닝으로 \n           신규 환경 구축 시간 2주 → 2시간으로 단축\"\n```\n\n### Step 3: 스토리라인 구성 (2일)\n\n```\n담당: 발표자 + 마케팅\n\n권장 스토리 흐름:\n[도입] \"우리는 누구인가\" (회사 역사, 비전)\n   ↓\n[맥락] \"왜 클라우드 MSP인가\" (시장 변화, 고객 니즈)\n   ↓\n[역량] \"무엇을 할 수 있는가\" (서비스, 인력, 도구)\n   ↓\n[증거] \"실제로 무엇을 했는가\" (고객 사례, 성과)\n   ↓\n[차별화] \"왜 우리인가\" (경쟁 우위, AWS 관계)\n```\n\n### Step 4: 프레젠테이션 제작 (3-5일)\n\n```\n담당: 마케팅/디자인 + 기술팀 검토\n\n디자인 가이드라인:\n- 슬라이드당 핵심 메시지 1개\n- 텍스트보다 시각 자료 우선 (차트, 아이콘, 다이어그램)\n- AWS 브랜드 가이드라인 준수 (로고 사용 규정)\n- 폰트 크기 최소 18pt (원격 발표 고려)\n\n필수 시각화 요소:\n□ 회사 연혁 타임라인\n□ 사무실 위치 지도\n□ 조직도 (MSP팀 하이라이트)\n□ 고객 분포 차트 (산업별, 규모별)\n□ 서비스 아키텍처 다이어그램\n□ DevOps 파이프라인 흐름도\n```\n\n### Step 5: 발표 리허설 (2-3일)\n\n```\n담당: 발표자 + 내부 청중\n\n리허설 체크포인트:\n□ 20분 타이밍 엄수 (18분 목표, 2분 버퍼)\n□ 각 슬라이드 전환 시 자연스러운 연결\n□ 기술 용어 설명 (감사관이 비기술직일 수 있음)\n□ 예상 질문 대비 (최소 10개)\n□ 화면 공유/원격 발표 테스트\n\n예상 질문 예시:\n- \"24/7 운영은 어떻게 보장하나요?\"\n- \"고객 이탈률은 어떻게 되나요?\"\n- \"AWS 청구액 중 자사 관리 비중은?\"\n- \"DevOps 자동화의 구체적 사례는?\"\n```\n\n### Step 6: 최종 검토 및 제출 (1일)\n\n```\n담당: 품질관리 담당자\n\n최종 체크:\n□ 모든 수치의 정확성 재확인\n□ 고객 로고 사용 허가 확인\n□ AWS 로고/브랜드 가이드라인 준수\n□ 오탈자 및 문법 검토\n□ PDF 백업 버전 준비\n□ 발표자 노트 완성\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 감사 탈락을 유발하는 치명적 실수\n\n**실수 1: \"온프레미스 냄새\"가 나는 프레젠테이션**\n```\n❌ 잘못된 예:\n\"저희는 20년간 데이터센터를 운영해온 경험을 바탕으로 \nAWS 환경도 안정적으로 관리합니다.\"\n\n✅ 올바른 예:\n\"저희는 2018년부터 클라우드 네이티브 방식으로 전환하여,\nInfrastructure as Code와 자동화된 배포 파이프라인을 \n모든 고객 환경에 적용하고 있습니다.\"\n```\n\n**실수 2: DevOps/자동화 언급 부재 또는 피상적 언급**\n```\n❌ 잘못된 예:\n\"저희는 DevOps를 도입하고 있습니다.\"\n\n✅ 올바른 예:\n\"모든 인프라 변경은 Terraform으로 코드화되어 \nGit 저장소에서 관리되며, AWS CodePipeline을 통해 \n자동 배포됩니다. 수동 콘솔 작업은 긴급 상황 외 금지입니다.\"\n```\n\n**실수 3: 고객 데이터의 모호한 표현**\n```\n❌ 잘못된 예:\n\"다수의 대기업 고객을 보유하고 있습니다.\"\n\n✅ 올바른 예:\n\"현재 47개 고객사의 156개 AWS 계정을 관리하고 있으며,\n이 중 연 매출 1000억 이상 기업이 12개사입니다.\n산업별로는 금융 35%, 제조 25%, 리테일 20%, 기타 20%입니다.\"\n```\n\n**실수 4: AWS 파트너십 정보 누락 또는 부정확**\n```\n❌ 잘못된 예:\nAWS 파트너 현황을 한 줄로 간단히 언급\n\n✅ 올바른 예:\n- APN 티어: Advanced Tier Partner\n- 보유 Competency: Migration, DevOps\n- Service Delivery: Amazon EC2, Amazon RDS, AWS Lambda\n- 월간 AWS 청구: $500K - $1M 범위",
      "language": "ko",
      "createdAt": "2026-01-07T01:41:26.085Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUS-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-002",
      "category": "Business",
      "title": "MSP 실무 성장",
      "advice": "# BUS-002: MSP 실무 성장 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS는 MSP 파트너가 **정체되지 않고 지속적으로 비즈니스를 확장**하고 있는지를 검증합니다. 단순히 기존 고객을 유지하는 것만으로는 부족하며, **신규 고객 확보** 또는 **기존 고객 내 워크로드 확장**을 통해 AWS 생태계 성장에 기여하고 있음을 입증해야 합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 예시 |\n|------------|-------------------|\n| **신규성 검증** | \"이 고객은 언제 처음 온보딩되었나요? 18개월 이내인가요?\" |\n| **성장의 실질성** | \"기존 고객이라면, 구체적으로 어떤 새로운 워크로드가 추가되었나요?\" |\n| **관리 서비스 범위** | \"이 계약이 일회성 프로젝트인가요, 아니면 지속적인 관리 서비스인가요?\" |\n| **계약의 유효성** | \"계약서에 서명일, 서비스 범위, 기간이 명확히 명시되어 있나요?\" |\n| **다양성** | \"4개 계약이 모두 다른 고객인가요, 아니면 같은 고객의 다른 프로젝트인가요?\" |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS Organizations**: 신규 고객 계정 온보딩 시점 증빙\n- **AWS Control Tower**: 새로운 워크로드 환경 프로비저닝 기록\n- **AWS Migration Hub**: 마이그레이션 프로젝트 진행 현황\n- **AWS Cost Explorer**: 고객별 사용량 성장 추이 데이터\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 BUS-002_MSP_Practice_Growth/\n├── 📄 Customer_A_New_Contract_2024.pdf\n├── 📄 Customer_B_SOW_Amendment_Migration.pdf\n├── 📄 Customer_C_Managed_Services_Agreement.pdf\n├── 📄 Customer_D_Platform_Expansion_Addendum.pdf\n├── 📊 Growth_Summary_Matrix.xlsx\n└── 📑 Supporting_Evidence/\n    ├── Customer_A_Onboarding_Timeline.pdf\n    ├── Customer_B_Migration_Scope_Document.pdf\n    ├── Customer_C_Architecture_Before_After.pdf\n    └── Customer_D_New_Workload_Description.pdf\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📄 계약서/부록 (Contract/Addendum)\n```\n✓ 계약 체결일 (18개월 이내 확인 가능)\n✓ 서비스 시작일 및 종료일 (또는 자동 갱신 조항)\n✓ 관리 서비스 범위 명시 (모니터링, 패치 관리, 인시던트 대응 등)\n✓ 월간/연간 서비스 요금 (지속적 관리임을 증명)\n✓ 양측 서명 및 날인\n```\n\n#### 📊 성장 요약 매트릭스 (필수 보조 자료)\n| 고객명 | 계약 유형 | 계약일 | 신규/확장 | 성장 내용 | 관리 서비스 범위 |\n|--------|----------|--------|----------|----------|-----------------|\n| A사 | 신규 계약 | 2024-03 | 신규 고객 | 클라우드 전환 + 관리 | 24x7 모니터링, 인시던트 대응 |\n| B사 | 부록 | 2024-06 | 기존 확장 | 신규 앱 3개 마이그레이션 | 기존 + DevOps 관리 추가 |\n| C사 | 신규 계약 | 2024-01 | 신규 고객 | 전체 인프라 관리 | Full Stack 관리 |\n| D사 | 부록 | 2024-08 | 기존 확장 | 아키텍처 리팩토링 | 컨테이너 환경 관리 추가 |\n\n### 증빙 자료 예시\n\n**✅ 합격하는 계약서 제목 예시:**\n- `ABC_Corp_AWS_Managed_Services_Agreement_20240315.pdf`\n- `XYZ_Inc_SOW_Amendment_3_Application_Migration_20240601.pdf`\n- `DEF_Ltd_Platform_Management_Contract_20240120.pdf`\n\n**❌ 불합격 가능성 높은 계약서:**\n- `Customer_Renewal_2024.pdf` (단순 갱신은 불인정)\n- `Consulting_Project_ABC.pdf` (일회성 프로젝트)\n- `Support_Agreement_2019_Extended.pdf` (18개월 초과)\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 적격 계약 인벤토리 작성 (1-2일)\n\n```\n🎯 목표: 18개월 내 체결된 모든 계약/부록 목록화\n\n실행 방법:\n1. CRM 시스템에서 최근 18개월 계약 추출\n2. 각 계약을 아래 기준으로 분류:\n   \n   [신규 고객 계약]\n   - 첫 거래인 고객과의 관리 서비스 계약\n   - AWS 계정 생성일이 계약일과 근접\n   \n   [기존 고객 확장]\n   - 새로운 애플리케이션 마이그레이션 포함\n   - 아키텍처 리팩토링 (예: 모놀리스→마이크로서비스)\n   - 새로운 AWS 리전/서비스 확장\n   \n   [부적격 - 제외]\n   - 동일 범위 단순 갱신\n   - 가격 조정만 있는 부록\n   - 일회성 컨설팅/구축 프로젝트\n```\n\n### Step 2: 4개 최적 계약 선정 (1일)\n\n```\n🎯 선정 기준 우선순위:\n\n1순위: 순수 신규 고객 + 포괄적 관리 서비스\n       → 가장 강력한 증빙\n\n2순위: 기존 고객 + 대규모 마이그레이션 (5개+ 앱)\n       → 명확한 성장 스토리\n\n3순위: 기존 고객 + 아키텍처 리팩토링\n       → Before/After 비교 가능해야 함\n\n4순위: 기존 고객 + 새로운 서비스 영역 추가\n       → 범위 확장이 명확해야 함\n\n💡 TIP: 4개 중 최소 2개는 순수 신규 고객으로 구성 권장\n```\n\n### Step 3: 계약서 내용 검증 및 보완 (2-3일)\n\n```\n🎯 각 계약서에서 확인할 체크포인트:\n\n□ \"Managed Services\" 또는 \"관리 서비스\" 용어 포함 여부\n□ 서비스 기간이 최소 12개월 이상인지\n□ 월간 반복 요금(MRR) 구조인지\n□ 서비스 범위에 아래 항목 중 3개 이상 포함:\n  - 24x7 모니터링\n  - 인시던트 관리\n  - 변경 관리\n  - 패치 관리\n  - 백업/복구 관리\n  - 비용 최적화\n\n⚠️ 누락 시 조치:\n- 고객사와 협의하여 부록(Amendment) 추가 작성\n- 또는 별도 SOW(Statement of Work) 첨부\n```\n\n### Step 4: 성장 증빙 보조 자료 준비 (2-3일)\n\n```\n🎯 기존 고객 확장 건의 경우 필수:\n\n[마이그레이션 건]\n- AWS Migration Hub 스크린샷 (마이그레이션 대상 서버 목록)\n- 마이그레이션 완료 보고서\n- Before: 온프레미스 아키텍처 다이어그램\n- After: AWS 아키텍처 다이어그램\n\n[리팩토링 건]\n- 기존 아키텍처 vs 신규 아키텍처 비교 문서\n- 사용된 새로운 AWS 서비스 목록\n- 성능/비용 개선 지표\n\n[서비스 확장 건]\n- 기존 계약 범위 vs 확장된 범위 비교표\n- 추가된 AWS 계정/리전 정보\n- 월간 관리 비용 증가 내역\n```\n\n### Step 5: 통합 요약 문서 작성 (1일)\n\n```\n🎯 감사관이 한눈에 파악할 수 있는 Executive Summary 작성\n\n포함 내용:\n1. MSP Practice 성장 개요 (1페이지)\n   - 총 신규 고객 수\n   - 총 확장 계약 수\n   - 관리 워크로드 증가율\n\n2. 4개 계약 요약표\n   - 고객명 (익명화 가능)\n   - 계약 유형\n   - 계약일\n   - 성장 유형\n   - 관리 서비스 범위\n   - 월간 관리 비용 규모 (선택)\n\n3. 각 계약별 1페이지 요약\n   - 고객 배경\n   - 프로젝트 개요\n   - 관리 서비스 범위\n   - 성장 포인트 하이라이트\n```\n\n### Step 6: 민감 정보 처리 (0.5일)\n\n```\n🎯 고객 정보 보호와 증빙 유효성 균형\n\n허용되는 익명화:\n✓ 고객사명 → \"Customer A\", \"금융업 고객사\"\n✓ 구체적 금액 → 범위로 표시 (예: $10K-50K/월)\n✓ 담당자 연락처 → 제거 가능\n\n유지해야 할 정보:\n✗ 계약 체결일 → 반드시 유지\n✗ 서비스 범위 → 반드시 유지\n✗ 계약 기간 → 반드시 유지\n✗ 서명 존재 여부 → 서명란은 유지 (내용 마스킹 가능)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 자주 발생하는 실수 TOP 5\n\n#### ❌ 실수 1: 단순 갱신 계약 제출\n```\n문제 상황:\n\"2022년부터 관리하던 고객의 2024년 갱신 계약서를 제출\"\n\n왜 탈락하는가:\n- 새로운 성장이 아닌 현상 유지\n- AWS가 원하는 것은 \"확장\"이지 \"유지\"가 아님\n\n해결책:\n- 갱신 시 새로운 워크로드 추가 협의\n- 또는 다른 신규 계약으로 대체\n```\n\n#### ❌ 실수 2: 일회성 프로젝트 계약 제출\n```\n문제 상황:\n\"클라우드 마이그레이션 프로젝트 계약서 제출 (3개월 프로젝트)\"\n\n왜 탈락하는가:\n- MSP는 \"지속적인 관리 서비스\"가 핵심\n- 프로젝트 완료 후 관리 서비스 없으면 부적격\n\n해결책:\n- 프로젝트 계약 + 후속 관리 서비스 계약을 함께 제출\n- 또는 프로젝트와 관리가 통합된 계약 구조로 변경\n```\n\n#### ❌ 실수 3: 18개월 기준 미충족\n```\n문제 상황:\n\"2022년 6월 체결 계약을 2024년 9월 감사에 제출\"\n\n왜 탈락하는가:\n- 감사 시점 기준 18개월 = 2023년 3월 이후 계약만 유효\n- 날짜 계산 오류로 부적격 판정\n\n해결책:\n- 감사 예정일 기준으로 역산하여 적격 계약 선별\n- 여유 있게 최근 12개월 내 계약 우선 선정\n```\n\n#### ❌ 실수 4: 관리 서비스 범위 불명확\n```\n문제 상황:\n\"계약서에 'AWS 인프라 지원' 이라고만 기재\"\n\n왜 탈락하는가:\n- 구체적인 관리 활동이 명시되지 않음\n- \"지원\"과 \"관리\"는 다른 개념\n\n해결책:\n계약서에 아래 내용 명시 필요:\n- 모니터링 범위 및 SLA\n- 인시던트 대응 프로세스\n- 변경 관리 절차\n- 정기 리포팅 내용\n```\n\n#### ❌ 실수 5: 기",
      "language": "ko",
      "createdAt": "2026-01-07T01:42:29.890Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUS-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-003",
      "category": "Business",
      "title": "재무 계획 및 보고",
      "advice": "# BUS-003: 재무 계획 및 보고 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS는 MSP 파트너에게 고객의 클라우드 환경을 장기적으로 관리할 책임을 위임합니다. **재무적으로 불안정한 파트너는 갑작스러운 서비스 중단, 인력 이탈, 또는 사업 철수로 고객에게 심각한 피해를 줄 수 있습니다.** 이 항목은 파트너가 지속 가능한 비즈니스를 운영하고 있는지 검증하는 핵심 게이트키퍼 역할을 합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **재무 예측 역량** | 향후 6-12개월 매출/비용을 합리적으로 예측하는 프로세스가 있는가? |\n| **예산 통제 체계** | 부서별/프로젝트별 예산 배정과 실적 비교 분석을 수행하는가? |\n| **정기적 재무 리뷰** | 월간/분기별로 경영진이 재무 지표를 검토하는 회의체가 있는가? |\n| **AWS 비즈니스 트래킹** | AWS 관련 매출(리셀, 서비스)을 별도로 추적하고 있는가? |\n| **의사결정 연계** | 재무 데이터가 실제 사업 의사결정에 활용되고 있는가? |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS Partner Central**: Partner Scorecard에서 AWS 매출 실적 확인\n- **AWS Marketplace**: Marketplace 판매 수익 리포트\n- **AWS Cost Explorer**: 고객 계정 관리 비용 분석 (MSP 운영 비용 산정 시 참고)\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 📁 증빙 옵션별 가이드\n\n#### **Option A: 상장 기업인 경우 (가장 간단)**\n```\n✓ 최근 분기 또는 연간 증권 신고서 (10-K, 10-Q, 사업보고서)\n✓ 제출 완료 - 추가 자료 불필요\n```\n\n#### **Option B: 비상장 기업 - 권장 증빙 세트**\n\n| 증빙 자료 | 포함 내용 | 파일명 예시 |\n|-----------|----------|-------------|\n| **재무 계획 정책서** | 예산 편성 주기, 승인 권한, 검토 프로세스 | `Financial_Planning_Policy_v2.1.pdf` |\n| **연간/분기 예산서** | 부서별 예산 배정, AWS 사업부 별도 표기 | `FY2024_Annual_Budget_Approved.xlsx` |\n| **재무 예측 보고서** | 향후 3-6개월 매출/비용 예측, 가정 명시 | `Q4_2024_Financial_Forecast.pdf` |\n| **월간 재무 리뷰 회의록** | 참석자, 검토 지표, 논의 사항, 액션 아이템 | `Monthly_Finance_Review_Nov2024.pdf` |\n| **재무 대시보드 스크린샷** | 실시간 KPI 모니터링 화면 | `Finance_Dashboard_Screenshot.png` |\n\n### 📌 각 증빙에 반드시 포함되어야 할 내용\n\n#### 재무 계획 정책서 필수 항목\n```markdown\n1. 예산 편성 일정 (예: 매년 11월 차년도 예산 수립)\n2. 예산 승인 권한 체계 (금액별 승인자)\n3. 예산 대비 실적 검토 주기 (월간/분기)\n4. 예산 변경 프로세스\n5. 재무 보고 라인 및 책임자\n```\n\n#### 월간 재무 리뷰 회의록 필수 항목\n```markdown\n- 회의 일시: 2024년 11월 15일 10:00-11:00\n- 참석자: CFO 김OO, 재무팀장 이OO, AWS사업부장 박OO\n- 검토 지표:\n  • 월간 매출 실적 vs 예산 (달성률 95%)\n  • AWS 리셀 매출: ₩2.3B (전월 대비 +12%)\n  • 영업이익률: 8.2%\n  • 현금흐름: 양호\n- 주요 논의: Q4 AWS 프로모션 예산 추가 배정 건\n- 액션 아이템: 마케팅 예산 ₩50M 추가 승인 (CFO)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 재무 관리 체계 매핑 (1일)\n**담당: 재무팀장**\n\n기존에 수행하고 있는 재무 활동을 AWS 요구사항에 매핑합니다.\n\n```\n[현재 활동]                    [AWS 요구사항 매핑]\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n연간 사업계획 수립        →    재무 예측 (Forecasting)\n부서별 예산 배정          →    예산 편성 (Budgeting)  \n월간 손익 분석            →    재무 지표 검토 (Metrics Review)\n이사회 보고               →    재무 보고 (Reporting)\n```\n\n### Step 2: AWS 사업 관련 재무 데이터 분리 (2-3일)\n**담당: 재무팀 + AWS사업부**\n\n```sql\n-- 재무 시스템에서 AWS 관련 매출 분리 추출 예시\nSELECT \n  fiscal_month,\n  SUM(CASE WHEN revenue_type = 'AWS_RESELL' THEN amount END) as aws_resell,\n  SUM(CASE WHEN revenue_type = 'AWS_SERVICE' THEN amount END) as aws_service,\n  SUM(CASE WHEN revenue_type = 'AWS_SUPPORT' THEN amount END) as aws_support\nFROM revenue_table\nWHERE fiscal_year = 2024\nGROUP BY fiscal_month\n```\n\n💡 **Tip**: AWS Partner Central의 매출 데이터와 내부 재무 데이터를 크로스체크하여 일관성 확보\n\n### Step 3: 재무 계획 정책 문서화 (3-5일)\n**담당: 재무팀장 + 컴플라이언스팀**\n\n기존 관행을 공식 정책으로 문서화합니다:\n\n```\n📄 재무 계획 정책서 목차 (권장)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n1. 목적 및 적용 범위\n2. 용어 정의\n3. 역할 및 책임\n   3.1 CFO의 역할\n   3.2 재무팀의 역할\n   3.3 사업부의 역할\n4. 연간 예산 편성 프로세스\n   4.1 일정 (T-3개월 ~ T)\n   4.2 예산 템플릿\n   4.3 승인 절차\n5. 재무 예측 프로세스\n   5.1 Rolling Forecast 주기\n   5.2 예측 방법론\n6. 재무 지표 검토\n   6.1 월간 검토 지표\n   6.2 분기 검토 지표\n7. 보고 체계\n8. 문서 관리\n```\n\n### Step 4: 최근 3개월 재무 리뷰 회의록 정비 (2일)\n**담당: 재무팀**\n\n기존 회의록이 있다면 AWS 감사 기준에 맞게 보완:\n\n```diff\n- Before: \"11월 재무 현황 공유함\"\n+ After: \"11월 재무 현황 검토\n+   - 매출: ₩5.2B (예산 대비 103%)\n+   - AWS 사업부 매출: ₩1.8B (전년 동기 대비 +25%)\n+   - 영업이익: ₩420M (마진율 8.1%)\n+   - 현금성 자산: ₩3.2B\n+   - 논의: AWS 인력 충원 예산 승인 필요\n+   - 결정: Q1 채용 예산 ₩200M 승인\"\n```\n\n### Step 5: 재무 대시보드 구성 (선택사항, 2-3일)\n**담당: IT팀 + 재무팀**\n\n실시간 재무 모니터링 체계 구축 (가점 요소):\n\n```\n[권장 대시보드 KPI]\n┌─────────────────────────────────────────────┐\n│  💰 Monthly Revenue     │  📊 Budget vs Actual │\n│  ₩5.2B (+8% MoM)       │  103% Achievement    │\n├─────────────────────────────────────────────┤\n│  ☁️ AWS Revenue        │  📈 Gross Margin     │\n│  ₩1.8B (35% of total) │  32.5%               │\n├─────────────────────────────────────────────┤\n│  💵 Cash Position      │  🎯 Forecast Accuracy│\n│  ₩3.2B                 │  94%                 │\n└─────────────────────────────────────────────┘\n```\n\n### Step 6: 증빙 자료 패키징 및 민감정보 처리 (1일)\n**담당: 재무팀장**\n\n```\n⚠️ 민감정보 처리 가이드\n━━━━━━━━━━━━━━━━━━━━━━━━\n✓ 개인 급여 정보 → 마스킹 또는 제외\n✓ 고객사별 상세 매출 → 총액만 표시\n✓ 미공개 M&A 정보 → 제외\n✓ 은행 계좌번호 → 마스킹\n✗ 전체 매출/이익 규모 → 제출 필요 (마스킹 불가)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 감사 탈락 주요 원인\n\n#### 실수 1: \"재무 검토를 하고 있지만 기록이 없음\"\n```\n❌ 문제: \"매월 경영진이 재무 현황을 검토합니다\" (구두 설명만)\n✅ 해결: 회의록, 이메일, 또는 결재 문서로 검토 이력 증빙\n```\n\n#### 실수 2: AWS 사업 재무를 별도 추적하지 않음\n```\n❌ 문제: 전체 회사 재무만 제출, AWS 관련 매출 구분 불가\n✅ 해결: AWS 리셀/서비스 매출을 별도 라인 아이템으로 관리\n        (Partner Central 데이터와 일치 필요)\n```\n\n#### 실수 3: 오래된 데이터 제출\n```\n❌ 문제: 6개월 전 예산서, 1년 전 재무 보고서 제출\n✅ 해결: 최근 분기 또는 최근 3개월 이내 자료 제출\n```\n\n#### 실수 4: 예측 없이 실적만 제출\n```\n❌ 문제: 과거 재무제표만 제출 (P&L, B/S)\n✅ 해결: 향후 예측(Forecast)이 포함된 자료 필수\n        - 다음 분기 매출 예측\n        - 연간 예산 대비 연말 예상 착지\n```\n\n#### 실수 5: 정책은 있으나 실행 증거 없음\n```\n❌ 문제: 완벽한 재무 정책서 + 실제 수행 증거 없음\n✅ 해결: 정책서 + 최근 3개월 실행 증거 함께 제출\n        (회의록, 보고서, 승인 이력 등)\n```\n\n### 🔴 안티패턴\n\n| 안티패턴 | 왜 문제인가 | 올바른 접근 |\n|----------|------------|-------------|\n| 감사용 문서 급조 | 날짜, 버전 불일치로 신뢰성 저하 | 기존 프로세스를 문서화 |\n| 재무 전체 공개 거부 | 필수 항목 미충족으로 탈락 | 민감정보만 선별 마스킹 |\n| 스프레드시트만 제출 | 프로세스 존재 증명 불가 | 정책 + 실행 증거 조합 |\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | ☐ 재무 계획 정책/프로세스 문서 존재 | 문서 버전, 승인일 확인 | 최근",
      "language": "ko",
      "createdAt": "2026-01-07T01:43:27.709Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUS-004_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-004",
      "category": "Business",
      "title": "시장 진출 전략",
      "advice": "# BUS-004: 시장 진출 전략 (Go-to-Market Strategy) 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS MSP 프로그램은 단순히 기술 역량만 평가하지 않습니다. **MSP 비즈니스의 지속 가능성과 성장 잠재력**을 함께 검증합니다. BUS-004는 파트너가 관리 서비스를 단순히 \"할 수 있다\"가 아닌 **\"적극적으로 시장에서 판매하고 성장시킬 의지와 체계가 있는가\"**를 확인하는 핵심 항목입니다.\n\nAWS 입장에서 MSP 파트너는 AWS 서비스의 확장된 영업 채널이므로, 파트너의 GTM(Go-to-Market) 역량은 파트너십의 실질적 가치를 결정합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **🎯 MSP 기회 식별 체계** | \"이 파트너가 기존 고객/신규 리드에서 MSP 기회를 체계적으로 발굴하는가?\" |\n| **📚 영업팀 교육 프로그램** | \"영업 담당자가 MSP 서비스를 이해하고 효과적으로 제안할 수 있는가?\" |\n| **🤝 AWS 영업팀 협업 방식** | \"AWS AE/SA와 공동 영업(Co-Sell) 프로세스가 있는가?\" |\n| **📣 수요 창출 활동** | \"웨비나, 이벤트, 콘텐츠 마케팅 등 구체적인 리드 생성 활동이 있는가?\" |\n| **📊 파이프라인 관리** | \"MSP 기회를 별도로 추적하고 관리하는 시스템이 있는가?\" |\n\n### 관련 AWS 프로그램 및 도구\n\n- **AWS Partner Central**: Opportunity 등록 및 ACE(AWS Customer Engagement) 프로그램\n- **AWS Marketplace**: MSP 서비스 리스팅 및 Private Offer\n- **AWS Partner Network (APN) 마케팅 자료**: Co-branded 자료 활용\n- **AWS Solution Provider Program**: 리셀 기회와 MSP 서비스 번들링\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 BUS-004_GTM_Strategy/\n├── 01_MSP_GTM_Playbook_v2.1.pdf\n├── 02_Sales_Enablement_Training_Deck.pptx\n├── 03_MSP_Service_Catalog_Customer_Facing.pdf\n├── 04_AWS_CoSell_Process_Document.pdf\n├── 05_Demand_Generation_Calendar_2024.xlsx\n└── 06_CRM_Pipeline_Screenshot_MSP_Opportunities.png\n```\n\n### 각 증빙 자료별 핵심 포함 내용\n\n#### 📘 **01. MSP GTM Playbook**\n```markdown\n필수 섹션:\n1. Target Customer Profile (ICP)\n   - 산업별 타겟 (예: 핀테크 스타트업, 제조업 중견기업)\n   - 기업 규모 (AWS 월 지출 $10K-$100K)\n   - 기술 성숙도 (클라우드 네이티브 vs 마이그레이션 단계)\n\n2. MSP 기회 식별 트리거\n   - 신호 예시: \"DevOps 인력 부족 언급\", \"24/7 운영 필요성\"\n   - 기존 프로젝트에서 MSP 전환 타이밍\n\n3. 경쟁 차별화 포인트\n   - 타 MSP 대비 강점 (예: 금융권 컴플라이언스 전문성)\n   - AWS 네이티브 도구 활용 역량\n\n4. Pricing & Packaging 전략\n   - 티어별 서비스 구성 (Basic/Standard/Premium)\n   - 가격 책정 모델 (% of AWS spend, Fixed fee, Hybrid)\n```\n\n#### 📗 **02. Sales Enablement Training Deck**\n```markdown\n필수 슬라이드 구성:\n- MSP 서비스 개요 (5분 엘리베이터 피치)\n- 고객 Pain Point → MSP 솔루션 매핑\n- 경쟁사 비교 Battle Card\n- 자격 질문 (Qualification Questions) 10개\n- 가격 협상 가이드라인\n- 성공 사례 3개 (Before/After 수치 포함)\n- Objection Handling 스크립트\n```\n\n#### 📙 **03. MSP Service Catalog (고객용)**\n```markdown\n형식: 고객에게 실제 전달하는 브로셔/PDF\n포함 내용:\n- 서비스 범위 명확한 정의\n- SLA 수치 (응답시간, 해결시간, 가용성)\n- 온보딩 프로세스 타임라인\n- 고객 책임 vs MSP 책임 매트릭스\n- 연락처 및 에스컬레이션 경로\n```\n\n#### 📕 **04. AWS Co-Sell Process Document**\n```markdown\n필수 내용:\n- AWS AE/SA 협업 시나리오\n- ACE Pipeline 등록 기준 및 절차\n- AWS 공동 미팅 요청 프로세스\n- AWS 마케팅 자료 활용 가이드\n- AWS 파트너 혜택 활용 계획 (MDF, PoC Credits 등)\n```\n\n#### 📒 **05. Demand Generation Calendar**\n```markdown\n예시 형식 (월별):\n| 월 | 활동 | 채널 | 타겟 리드 수 | 담당자 |\n|----|------|------|-------------|--------|\n| 1월 | AWS 비용 최적화 웨비나 | 자사 웹사이트 | 50 | 마케팅팀 |\n| 2월 | 금융권 MSP 사례 백서 발행 | LinkedIn | 30 | 콘텐츠팀 |\n| 3월 | AWS Summit 부스 참가 | 오프라인 | 100 | 영업팀 |\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: MSP 서비스 포지셔닝 정의 (1주)\n```\n담당: 사업개발팀장 + 기술리더\n\n구체적 작업:\n□ 현재 MSP 고객 5개사 분석 → 공통 특성 도출\n□ AWS 월 지출 규모별 서비스 티어 설계\n□ 경쟁사 3개 서비스 벤치마킹 (가격, 범위, SLA)\n□ 차별화 포인트 3가지 문서화\n\n산출물: \"MSP_Service_Positioning_Matrix.xlsx\"\n```\n\n### Step 2: 영업팀 MSP 교육 프로그램 개발 (2주)\n```\n담당: 영업지원팀 + Pre-Sales 엔지니어\n\n구체적 작업:\n□ MSP 서비스 설명 스크립트 작성 (3분/10분/30분 버전)\n□ 고객 자격 질문지 개발 (BANT + 기술 요건)\n□ 가격 협상 시나리오 5개 Role-play 자료\n□ Objection Handling 가이드 (최소 15개 반론)\n□ 영업팀 대상 2시간 워크샵 진행 및 녹화\n\n산출물: \"Sales_Enablement_Kit_MSP_v1.0/\"\n```\n\n### Step 3: 고객 대면 자료 제작 (1주)\n```\n담당: 마케팅팀 + 디자인\n\n구체적 작업:\n□ MSP 서비스 브로셔 (PDF, 8페이지)\n□ 서비스 비교표 (Basic/Standard/Premium)\n□ 온보딩 체크리스트 (고객 전달용)\n□ 고객 성공 사례 1-pager 3개\n\n산출물: \"Customer_Facing_Materials/\"\n```\n\n### Step 4: AWS Co-Sell 프로세스 수립 (1주)\n```\n담당: AWS 파트너 담당자 + 영업팀장\n\n구체적 작업:\n□ AWS Partner Central ACE 프로그램 등록 절차 문서화\n□ AWS AE/SA 공동 미팅 요청 템플릿 작성\n□ 기회 등록 기준 정의 (금액, 단계, 서비스 유형)\n□ 분기별 AWS 파트너팀 리뷰 미팅 일정 수립\n\n산출물: \"AWS_CoSell_Playbook.pdf\"\n```\n\n### Step 5: 수요 창출 캘린더 수립 (1주)\n```\n담당: 마케팅팀\n\n구체적 작업:\n□ 연간 마케팅 활동 12개 이상 계획\n□ 채널별 리드 목표 설정 (웨비나, 콘텐츠, 이벤트)\n□ AWS 공동 마케팅 기회 식별 (AWS Summit, re:Invent)\n□ 리드 → MQL → SQL 전환율 목표 설정\n\n산출물: \"Demand_Gen_Calendar_2024.xlsx\"\n```\n\n### Step 6: CRM 파이프라인 설정 (3일)\n```\n담당: 영업운영팀\n\n구체적 작업:\n□ CRM에 \"MSP Opportunity\" 유형 추가\n□ MSP 전용 파이프라인 스테이지 정의\n□ 필수 입력 필드 설정 (AWS Account ID, 예상 월 지출)\n□ MSP 파이프라인 대시보드 생성\n\n산출물: CRM 스크린샷 + 설정 문서\n```\n\n### Step 7: 통합 GTM Playbook 완성 (3일)\n```\n담당: 사업개발팀장\n\n구체적 작업:\n□ 모든 자료를 하나의 GTM Playbook으로 통합\n□ 버전 관리 및 업데이트 주기 명시\n□ 내부 배포 및 접근 권한 설정\n□ 분기별 리뷰 프로세스 정의\n\n산출물: \"MSP_GTM_Playbook_v2.1.pdf\"\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 일반 SI 영업 자료를 MSP용으로 재활용\n```\n❌ 잘못된 예:\n\"클라우드 마이그레이션 서비스\" 브로셔에 \"MSP 서비스도 제공합니다\" 한 줄 추가\n\n✅ 올바른 접근:\nMSP 전용 서비스 카탈로그 별도 제작\n- 월간 운영 서비스 범위 명시\n- SLA 수치 구체화 (99.9% 가용성, 15분 초기 응답)\n- 지속적 비용 최적화 활동 포함\n```\n\n### 🚫 실수 2: AWS Co-Sell 프로세스 누락\n```\n❌ 잘못된 예:\n\"AWS와 협력합니다\"라는 일반적 문구만 포함\n\n✅ 올바른 접근:\n- ACE Pipeline 등록 기준 명시 (예: $50K 이상 연간 계약)\n- AWS AE 공동 미팅 요청 절차 문서화\n- 실제 ACE 등록 건수 또는 스크린샷 첨부\n```\n\n### 🚫 실수 3: 수요 창출 활동이 과거형으로만 기술\n```\n❌ 잘못된 예:\n\"2023년에 웨비나 2회 진행했습니다\"\n\n✅ 올바른 접근:\n- 향후 12개월 마케팅 캘린더 제시\n- 분기별 리드 목표 수치 포함\n- 활동별 예산 및 담당자 명시\n```\n\n### 🚫 실수 4: 영업팀 교육 증빙 부재\n```\n❌ 잘못된 예:\n\"영업팀이 MSP 서비스를 잘 알고 있습니다\"\n\n✅ 올바른 접근:\n- 교육 자료 (PPT/PDF) 제출\n- 교육 일정 및 참석자 명단\n- 교육 후 퀴즈/인증 결과 (있는 경우)\n```\n\n### 🚫 실수 5: 타겟 고객 정의 모호\n```\n❌ 잘못된 예:\n\"AWS를 사용하는 모든 기업이 타겟입니다\"\n\n✅ 올바른 접근:\n- ICP(Ideal Customer Profile) 명확히 정의\n- 산업, 규모, 기술 성숙도, AWS 지출 규모 기준 제시\n- 타겟 고객 예시 3-5개 (익명화 가능)\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### GTM Playbook 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | MSP ",
      "language": "ko",
      "createdAt": "2026-01-07T01:44:33.429Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUSP-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUSP-001",
      "category": "Business",
      "title": "웹 사이트 존재",
      "advice": "# BUSP-001: 웹 사이트 존재 - AWS MSP 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS MSP 랜딩 페이지는 **파트너의 첫인상이자 시장에서의 신뢰도를 증명하는 핵심 자산**입니다. AWS는 고객이 검증된 MSP 파트너를 쉽게 찾을 수 있도록 파트너의 공개적인 AWS 전문성 표명을 요구합니다. 이는 단순한 마케팅 페이지가 아니라, **파트너가 실제로 AWS 관리 서비스 사업을 영위하고 있음을 증명하는 공식 선언**입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **AWS MSP 서비스 명시** | \"Managed Services\" 또는 \"관리형 서비스\"라는 용어가 명확히 사용되는가? |\n| **차별화된 전문성** | 단순 리셀러가 아닌, 설계-구축-운영 전 과정의 역량을 보여주는가? |\n| **공개 사례 연구 링크** | 실제 고객 성공 사례가 링크되어 있고 접근 가능한가? |\n| **AWS 브랜딩 준수** | AWS 로고 및 파트너 배지 사용이 AWS 브랜드 가이드라인을 따르는가? |\n| **페이지 접근성** | 로그인 없이 누구나 접근 가능한 공개 URL인가? |\n\n### 관련 AWS 프로그램 및 자원\n- **AWS Partner Network (APN) Portal** - 파트너 배지 다운로드\n- **AWS 브랜드 가이드라인** - 로고 사용 규정\n- **AWS Partner Marketing Central** - 공동 마케팅 자료\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙: 공개 URL 1개\n\n```\n제출 형식: https://www.yourcompany.com/aws-msp 형태의 공개 URL\n```\n\n### 랜딩 페이지에 반드시 포함되어야 할 요소\n\n#### 🔹 필수 콘텐츠 체크리스트\n\n| 요소 | 구체적 요구사항 | 예시 |\n|-----|----------------|-----|\n| **서비스 설명** | AWS 워크로드의 설계, 구축, 운영/관리 역량 명시 | \"24/7 AWS 인프라 모니터링 및 장애 대응\" |\n| **차별화 포인트** | 경쟁사 대비 고유한 강점 3개 이상 | \"금융권 특화 컴플라이언스 자동화\" |\n| **사례 연구 링크** | 최소 2개 이상의 공개 고객 사례 | \"A사 클라우드 마이그레이션 성공 사례\" |\n| **AWS 파트너 배지** | APN 파트너 티어 배지 표시 | Advanced Tier Partner 로고 |\n| **연락처/CTA** | 문의 양식 또는 연락 방법 | \"무료 상담 신청\" 버튼 |\n\n#### 🔹 권장 추가 콘텐츠\n\n- AWS 자격증 보유 현황 (예: \"Solutions Architect Professional 15명 보유\")\n- 서비스 범위 (지원 리전, 언어, 시간대)\n- 고객 로고 (사용 허가 받은 경우)\n- 관련 AWS Competency 배지\n\n### 증빙 URL 예시\n\n```\n✅ 좋은 예시:\nhttps://www.yourcompany.com/services/aws-managed-services\nhttps://www.yourcompany.com/aws-msp\nhttps://cloud.yourcompany.com/aws\n\n❌ 나쁜 예시:\nhttps://www.yourcompany.com (메인 페이지만 제출)\nhttps://internal.yourcompany.com/aws (내부 페이지)\nhttps://www.yourcompany.com/login?redirect=aws (로그인 필요)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 콘텐츠 기획 (3-5일)\n\n```\n담당: 마케팅팀 + 기술팀 협업\n\n작업 내용:\n□ AWS MSP 서비스 포트폴리오 정의\n□ 차별화 메시지 3개 도출\n□ 공개 가능한 고객 사례 2개 이상 선정\n□ 페이지 구조 와이어프레임 작성\n```\n\n**핵심 질문**: \"우리가 다른 AWS 파트너와 다른 점은 무엇인가?\"\n\n### Step 2: 고객 사례 연구 확보 (1-2주)\n\n```\n담당: 영업팀 + 법무팀\n\n작업 내용:\n□ 기존 고객 중 사례 공개 동의 요청\n□ 사례 연구 템플릿 작성 (문제-솔루션-결과 구조)\n□ 고객사 로고 사용 허가서 확보\n□ 정량적 성과 지표 포함 (예: \"운영 비용 40% 절감\")\n```\n\n**사례 연구 필수 포함 요소**:\n- 고객 산업/규모\n- 해결한 비즈니스 과제\n- 사용한 AWS 서비스 목록\n- 측정 가능한 결과\n\n### Step 3: AWS 브랜드 자산 확보 (1-2일)\n\n```\n담당: 마케팅팀\n\n작업 내용:\n□ APN Portal에서 파트너 배지 다운로드\n□ AWS 브랜드 가이드라인 검토\n□ 승인된 로고 파일 확보 (PNG, SVG)\n□ 배지 사용 규정 확인\n```\n\n**APN Portal 접속 경로**: \n`Partner Central → Marketing → Brand Assets`\n\n### Step 4: 페이지 개발 및 디자인 (1-2주)\n\n```\n담당: 웹 개발팀\n\n기술 요구사항:\n□ 모바일 반응형 디자인\n□ HTTPS 적용 (SSL 인증서)\n□ 페이지 로딩 속도 3초 이내\n□ SEO 메타태그 적용\n□ 다국어 지원 (해당 시)\n```\n\n**권장 페이지 구조**:\n```\n1. 히어로 섹션: AWS MSP 서비스 한 줄 소개 + CTA\n2. 서비스 개요: 설계/구축/운영 역량 설명\n3. 차별화 포인트: 3-4개 핵심 강점\n4. 사례 연구: 2개 이상 고객 성공 스토리\n5. 자격/인증: AWS 파트너 배지, 자격증 현황\n6. 연락처: 문의 양식\n```\n\n### Step 5: 내부 검토 및 법적 확인 (3-5일)\n\n```\n담당: 법무팀 + 경영진\n\n검토 항목:\n□ 고객 정보 공개 적법성\n□ AWS 상표 사용 적정성\n□ 경쟁사 비방 표현 없음 확인\n□ 과장 광고 표현 제거\n□ 개인정보 수집 동의 문구 (문의 양식)\n```\n\n### Step 6: 퍼블리싱 및 테스트 (1-2일)\n\n```\n담당: 웹 운영팀\n\n테스트 체크리스트:\n□ 모든 링크 정상 작동 확인\n□ 사례 연구 페이지 접근 가능 확인\n□ 모바일/태블릿 화면 테스트\n□ 다양한 브라우저 테스트 (Chrome, Safari, Edge)\n□ 로그인 없이 접근 가능 확인\n□ VPN 없이 해외에서 접근 테스트\n```\n\n### Step 7: URL 제출 준비 (1일)\n\n```\n담당: MSP 프로그램 담당자\n\n최종 확인:\n□ URL이 직접 AWS MSP 페이지로 연결되는지 확인\n□ 리다이렉트 없이 접근 가능한지 확인\n□ 페이지 스크린샷 백업 저장\n□ 제출용 URL 최종 확정\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수 TOP 5\n\n#### 실수 1: \"Coming Soon\" 또는 미완성 페이지 제출\n```\n❌ 문제: 사례 연구 섹션에 \"준비 중입니다\" 표시\n✅ 해결: 모든 섹션이 완성된 상태에서만 제출\n```\n\n#### 실수 2: 사례 연구 링크 깨짐\n```\n❌ 문제: 사례 연구 클릭 시 404 에러 또는 로그인 페이지로 이동\n✅ 해결: 제출 직전 모든 외부/내부 링크 테스트 필수\n```\n\n#### 실수 3: AWS 로고 무단 사용 또는 변형\n```\n❌ 문제: AWS 로고 색상 변경, 비율 왜곡, 비공식 배지 사용\n✅ 해결: APN Portal에서 공식 배지만 다운로드하여 사용\n```\n\n#### 실수 4: 일반적인 클라우드 서비스 페이지 제출\n```\n❌ 문제: \"클라우드 서비스\" 페이지에서 AWS가 일부로만 언급됨\n✅ 해결: AWS MSP 전용 랜딩 페이지 별도 구축\n```\n\n#### 실수 5: 지역 제한 또는 접근 제한\n```\n❌ 문제: 특정 국가에서만 접근 가능, 또는 회사 VPN 필요\n✅ 해결: 글로벌 CDN 사용, 지역 제한 해제 확인\n```\n\n### 🔴 감사 탈락 주요 원인\n\n| 탈락 사유 | 발생 빈도 | 예방 방법 |\n|----------|----------|----------|\n| 사례 연구 없음 또는 접근 불가 | 높음 | 최소 2개 공개 사례 확보 |\n| MSP/관리 서비스 용어 미사용 | 중간 | \"Managed Services\" 명시적 표현 |\n| 페이지가 영문만 지원 (현지 시장) | 중간 | 현지 언어 버전 준비 |\n| AWS 외 다른 클라우드와 혼재 | 낮음 | AWS 전용 페이지 분리 |\n\n### 🚧 피해야 할 안티패턴\n\n```\n1. ❌ PDF 다운로드 링크만 제공 → ✅ 웹 페이지로 콘텐츠 직접 표시\n2. ❌ 영상만으로 서비스 설명 → ✅ 텍스트 기반 설명 필수 포함\n3. ❌ 경쟁사 비방 내용 포함 → ✅ 자사 강점 중심 서술\n4. ❌ 가격표만 나열 → ✅ 가치 제안과 차별화 포인트 강조\n5. ❌ 기술 용어 나열 → ✅ 비즈니스 가치 중심 설명\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | **URL 직접 접근 가능** | 시크릿 모드에서 URL 입력 | 로그인 없이 페이지 표시 |\n| 2 | **\"Managed Services\" 용어 사용** | Ctrl+F로 페이지 내 검색 | 최소 3회 이상 언급 |\n| 3 | **설계-구축-운영 역량 명시** | 페이지 내용 검토 | 3가지 영역 모두 설명 |\n| 4 | **사례 연구 링크 작동** | 모든 사례 연구 링크 클릭 | 100% 정상 접근 |\n| 5 | **AWS 파트너 배지 표시** | 페이지 내 배지 확인 | 공식 배지 사용 |\n| 6 | **모바일 반응형** | 스마트폰으로 접속 | 정상 표시 및 네비게이션 |\n| 7 | **HTTPS 적용** | URL 확인 | https:// 로 시작 |\n\n### 최종 검증 프로세스\n\n```\n1️⃣ 내부 검토자 3명이 각자 다른 환경에서 접속 테스트\n   - 검토자 A: 회사 네트워크 + Chrome\n   - 검토자 B: 모바일 데이터 +",
      "language": "ko",
      "createdAt": "2026-01-07T01:27:08.093Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUSP-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUSP-002",
      "category": "Business",
      "title": "영업 및 마케팅 인증",
      "advice": "# BUSP-002: 영업 및 마케팅 인증 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\nAWS MSP 프로그램은 기술팀뿐 아니라 **고객 접점에 있는 영업/마케팅 인력도 AWS에 대한 기본 이해**를 갖추길 요구합니다. 이는 고객에게 AWS 솔루션을 정확하게 전달하고, 잘못된 기대치 설정을 방지하기 위함입니다.\n\n### 🎯 감사관이 확인하는 핵심 포인트\n\n| # | 확인 포인트 | 감사관의 의도 |\n|---|------------|---------------|\n| 1 | **MSP 사업부 소속 여부** | 인증 보유자가 실제로 AWS MSP 사업을 지원하는 팀인지 확인 |\n| 2 | **인증 유효성** | AWS Skill Builder에서 발급한 공식 인증서인지, 만료되지 않았는지 |\n| 3 | **적절한 인증 유형 선택** | 영업은 Business, 기술지원 역할은 Technical 인증 보유 |\n| 4 | **조직 커버리지** | MSP 관련 영업/마케팅 인력 전원이 인증을 보유했는지 |\n| 5 | **인증 완료 시점** | 최근에 완료했는지 (너무 오래된 인증은 재취득 권장) |\n\n### 관련 AWS 플랫폼\n- **AWS Skill Builder** (https://skillbuilder.aws) - 인증 취득 플랫폼\n- **AWS Partner Central** - 파트너 인증 현황 조회\n- **AWS Training and Certification** - 인증 기록 관리\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 BUSP-002_영업마케팅인증/\n├── 📄 MSP_영업마케팅_인력목록.xlsx\n├── 📁 개인별_인증서/\n│   ├── 김영업_Sales_Accreditation_Certificate.pdf\n│   ├── 이마케팅_Sales_Accreditation_Certificate.pdf\n│   ├── 박기술영업_Technical_Accreditation_Certificate.pdf\n│   └── ...\n├── 📄 AWS_Partner_Central_인증현황_스크린샷.png\n└── 📄 조직도_MSP사업부.pdf\n```\n\n### 각 증빙 자료 핵심 내용\n\n#### 📊 MSP_영업마케팅_인력목록.xlsx\n```\n| 이름 | 직책 | 소속팀 | 역할 | 인증유형 | 완료일자 | 인증서파일명 |\n|------|------|--------|------|----------|----------|--------------|\n| 김영업 | 과장 | MSP영업팀 | 고객영업 | Sales (Business) | 2024-03-15 | 김영업_Sales_Certificate.pdf |\n| 이마케팅 | 대리 | 마케팅팀 | AWS마케팅 | Sales (Business) | 2024-02-20 | 이마케팅_Sales_Certificate.pdf |\n| 박기술영업 | 차장 | 프리세일즈 | 기술영업 | Technical | 2024-01-10 | 박기술영업_Tech_Certificate.pdf |\n```\n\n#### 📜 개인별 인증서 필수 포함 요소\n- ✅ 수료자 **실명** (AWS Skill Builder 등록명과 일치)\n- ✅ **인증 과정명** 명확히 표시\n- ✅ **완료 일자**\n- ✅ AWS 공식 로고 및 인증 번호\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: MSP 사업 지원 인력 식별 (1일)\n```\n👤 담당: HR 또는 MSP 사업부장\n\n수행 작업:\n1. MSP 사업부 조직도 확보\n2. 다음 역할 수행자 전원 리스트업:\n   - AWS 고객 대상 영업 담당자\n   - AWS 관련 마케팅 담당자  \n   - 프리세일즈/기술영업 담당자\n   - MSP 사업부 지원 BD(Business Development)\n\n⚠️ 주의: 간접 지원 인력(재무, 법무 등)은 제외 가능\n```\n\n### Step 2: 인증 유형 결정 (0.5일)\n```\n📋 역할별 권장 인증:\n\n┌─────────────────────────┬────────────────────────────┐\n│ 역할                    │ 권장 인증                   │\n├─────────────────────────┼────────────────────────────┤\n│ 순수 영업/마케팅        │ Sales Accreditation        │\n│                         │ (Business)                 │\n├─────────────────────────┼────────────────────────────┤\n│ 기술영업/프리세일즈     │ Technical Accreditation    │\n│                         │ (더 높은 수준이므로 인정됨) │\n├─────────────────────────┼────────────────────────────┤\n│ 영업+기술 겸직          │ 둘 중 하나 선택 가능        │\n└─────────────────────────┴────────────────────────────┘\n```\n\n### Step 3: AWS Skill Builder 계정 생성 및 과정 등록 (인당 0.5일)\n```\n🔗 접속: https://skillbuilder.aws\n\n1. AWS Partner Central 계정으로 로그인\n2. 과정 검색:\n   - \"AWS Partner: Sales Accreditation (Business)\" 또는\n   - \"AWS Partner: Accreditation (Technical)\"\n3. \"Enroll\" 클릭하여 등록\n```\n\n### Step 4: 인증 과정 수료 (인당 2-4시간)\n```\n⏱️ 예상 소요 시간:\n- Sales Accreditation (Business): 약 2-3시간\n- Technical Accreditation: 약 3-4시간\n\n📚 과정 구성:\n- 온라인 학습 모듈 (영상 + 읽기 자료)\n- 모듈별 퀴즈\n- 최종 평가 (70% 이상 통과)\n\n💡 팁: 한 번에 완료하지 않아도 진행 상황 저장됨\n```\n\n### Step 5: 인증서 다운로드 (인당 10분)\n```\n인증서 다운로드 경로:\nSkill Builder → Your Learning → Completed → 해당 과정 → Download Certificate\n\n파일명 규칙 통일:\n[이름]_[인증유형]_[완료년월].pdf\n예: 김영업_SalesAccreditation_202403.pdf\n```\n\n### Step 6: 증빙 자료 통합 정리 (0.5일)\n```\n👤 담당: MSP 사업부 관리자\n\n1. 인력 목록 스프레드시트 최종 업데이트\n2. 모든 인증서 PDF 수집 및 파일명 통일\n3. AWS Partner Central에서 팀 인증 현황 스크린샷 캡처\n4. 조직도와 인력 목록 매칭 확인\n```\n\n### Step 7: 크로스체크 및 제출 (0.5일)\n```\n✓ 인력 목록의 모든 인원 = 인증서 보유\n✓ 인증서 이름 = 인력 목록 이름 = 조직도 이름\n✓ 모든 파일 열림 확인 (손상 여부)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| # | 실수 유형 | 문제점 | 해결책 |\n|---|-----------|--------|--------|\n| 1 | **일부 인원 누락** | MSP 영업팀 중 1-2명이 인증 미보유 | 제출 전 인력 목록과 인증서 1:1 대조 |\n| 2 | **잘못된 인증 유형** | 영업 담당자가 Cloud Practitioner만 보유 | Sales/Technical Accreditation은 별도 과정임을 인지 |\n| 3 | **이름 불일치** | 인증서 \"John Kim\" vs 인력목록 \"김존\" | Skill Builder 프로필명을 회사 공식 명칭과 통일 |\n| 4 | **만료된 인증서** | 3년 전 취득한 인증서 제출 | 2년 이상 된 경우 재취득 권장 |\n| 5 | **스크린샷 품질** | 저해상도로 텍스트 판독 불가 | 100% 줌 상태에서 전체 화면 캡처 |\n\n### ❌ 감사 탈락 주요 원인\n\n```\n1. \"MSP 사업을 지원하는\" 영업/마케팅 범위 해석 오류\n   → 감사관 질문: \"이 사람이 AWS MSP 고객을 담당하나요?\"\n   → 명확히 Yes인 인원만 포함, 애매한 경우 포함하고 인증 취득\n\n2. AWS Partner Central 미연동\n   → 개인 Skill Builder 계정으로 취득 시 Partner Central에 미반영\n   → 반드시 Partner Central 연동 계정으로 수료\n\n3. 인증서 대신 수료증 제출\n   → \"Certificate of Completion\"이 아닌 \n      \"AWS Partner: Sales Accreditation\" 명시된 공식 인증서 필요\n```\n\n### 🔄 피해야 할 안티패턴\n\n```\n❌ 안티패턴 1: 급하게 한 명만 취득\n   \"대표자 1명만 있으면 되겠지\" → 전원 필수\n\n❌ 안티패턴 2: 기술팀 인증으로 대체\n   \"SA가 Solutions Architect 자격증 있으니까\" → 별개의 인증임\n\n❌ 안티패턴 3: 퇴사자 인증서 포함\n   \"작년에 취득했으니 유효하겠지\" → 현재 재직자만 인정\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|-----------|-----------|-----------|\n| ☐ | MSP 영업/마케팅 전원 포함 | 조직도 vs 인력목록 대조 | 100% 일치 |\n| ☐ | 인증 유형 적절성 | 역할별 인증 유형 확인 | Sales 또는 Technical 중 1개 이상 |\n| ☐ | 인증서 유효성 | 인증서 내 과정명/일자 확인 | 공식 AWS 인증서, 2년 이내 권장 |\n| ☐ | 이름 일관성 | 인증서 ↔ 인력목록 ↔ 조직도 | 동일 인물 식별 가능 |\n| ☐ | 파일 무결성 | 모든 PDF 열기 테스트 | 100% 정상 열림 |\n| ☐ | Partner Central 반영 | Partner Central 스크린샷 | 인증 현황 표시됨 |\n| ☐ | 문서 가독성 | 스크린샷 텍스트 판독 | 모든 텍스트 선명하게 읽힘 |\n\n### ✅ 최종 품질 기준\n\n```\n합격 조건:\n✓ MSP 사업 지원 영업/마케팅 인력 100%가 인증 보유\n✓ 각 인증서가 해당 인원과 명확히 매칭됨\n✓ 인증 유형이 역할에 적합함\n✓ 모든 증빙 자료가 일관되고 추적 가능함\n\n제출 형태:\n- 단일 ZIP 파일 또는 폴더 구조\n- 인력 목록 스프레드시트를 인덱스로 활용\n- 파일명에 한글/영문 혼용 시 깨짐 주의\n```\n\n---\n\n### 💡 Pro Tip\n\n> **감사 인터뷰 대비**: 감사관이 인력 목록에서 무작위로 1-2명을 선택해 \"이 사람의 역할이 무엇인가요?\"라고 질문할 수 있습니다. 각 인원의 MSP 사업 기여도를 간단히 설명할 수 있도록 준비하세요.",
      "language": "ko",
      "createdAt": "2026-01-07T01:28:04.953Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUSP-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUSP-003",
      "category": "Business",
      "title": "고객 사례 연구",
      "advice": "# BUSP-003: 고객 사례 연구 - AWS MSP 증빙 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\n고객 사례 연구는 AWS MSP 파트너의 **실제 서비스 제공 역량을 증명하는 가장 직접적인 증거**입니다. AWS는 이론적 역량이 아닌, 실제 고객에게 가치를 전달한 경험을 중시합니다. 특히 공개 사례 연구 2개 요구는 파트너가 고객과의 신뢰 관계를 구축하고, 성공 사례를 외부에 공유할 수 있는 수준의 파트너십을 보유했는지 확인하는 것입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **관리 서비스 명확성** | 단순 구축이 아닌 지속적인 운영/관리 서비스가 포함되었는가? |\n| **고객 과제 해결** | 고객의 비즈니스 문제가 AWS 서비스를 통해 어떻게 해결되었는가? |\n| **측정 가능한 성과** | 비용 절감 %, 가용성 향상, 운영 효율성 등 정량적 지표가 있는가? |\n| **신규성 검증** | 이전 감사/갱신에서 사용된 사례가 아닌가? (AWS 내부 기록 대조) |\n| **공개 자료 접근성** | 공개 사례 2개가 실제로 인터넷에서 접근 가능한가? |\n\n### 관련 AWS 서비스 및 기능\n\n사례 연구에 포함하면 강점이 되는 관리 서비스 영역:\n- **AWS Managed Services (AMS)** 연계 운영\n- **Amazon CloudWatch** 기반 모니터링/알람 체계\n- **AWS Systems Manager** 활용 패치 관리, 자동화\n- **AWS Config** 규정 준수 관리\n- **AWS Backup** 중앙화된 백업 관리\n- **AWS Cost Explorer / Cost Anomaly Detection** 비용 최적화\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 구성 (4개 사례 = 공개 2개 + 비공개 2개)\n\n#### 🌐 공개 사례 연구 (2개 필수)\n\n**형식 옵션:**\n- 회사 공식 웹사이트 게시 사례 연구\n- AWS Partner Network 블로그 게시물\n- YouTube/Vimeo 공개 비디오 (고객 인터뷰)\n- 회사 기술 블로그 게시물\n- 공개 백서 (PDF 다운로드 가능)\n\n**각 공개 사례에 포함되어야 할 핵심 내용:**\n\n```\n[필수 구성 요소]\n1. 고객사 명시 (익명 불가 - 공개 사례이므로)\n2. 고객의 비즈니스 과제/문제점\n3. 적용한 AWS 서비스 목록\n4. 파트너가 제공한 \"관리 서비스\" 내용 명시\n   - 24/7 모니터링\n   - 인시던트 대응\n   - 패치 관리\n   - 비용 최적화 등\n5. 정량적 성과 지표 (최소 2개)\n6. 게시일 (이전 감사 이후여야 함)\n```\n\n**예시 파일명/URL:**\n- `https://company.com/case-studies/abc-manufacturing-aws-migration`\n- `https://aws.amazon.com/partners/success/xyz-retail-managed-services`\n- `https://company.com/blog/2024/01/how-we-reduced-client-aws-costs-40-percent`\n\n#### 📄 비공개 사례 연구 (2개)\n\n**형식:** PDF, PowerPoint, Word 문서\n\n**문서 구조 템플릿:**\n\n```\n[비공개 사례 연구 문서 구조]\n\n1. Executive Summary (1페이지)\n   - 고객 산업/규모\n   - 핵심 성과 3줄 요약\n\n2. Customer Challenge (1-2페이지)\n   - 기존 인프라 문제점\n   - 비즈니스 요구사항\n   - 기술적 제약사항\n\n3. Solution Architecture (2-3페이지)\n   - AWS 아키텍처 다이어그램 (필수)\n   - 사용된 AWS 서비스 상세\n   - 파트너 관리 서비스 범위\n\n4. Implementation & Managed Services (2페이지)\n   - 구축 타임라인\n   - 운영 이관 프로세스\n   - 지속적 관리 서비스 내용\n\n5. Results & Metrics (1-2페이지)\n   - Before/After 비교 표\n   - KPI 달성 현황\n   - 고객 인용문 (가능시)\n\n6. Appendix\n   - 상세 아키텍처\n   - 서비스 SLA 요약\n```\n\n**예시 파일명:**\n- `[Confidential] DEF_Healthcare_AWS_Managed_Services_Case_Study_2024.pdf`\n- `[Internal] GHI_Fintech_Cloud_Operations_Success_Story_Q1_2024.pptx`\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 사례 연구 후보 고객 선정 (1주)\n\n**담당:** 영업팀 + 서비스 매니저\n\n```\n[선정 기준 체크리스트]\n□ 12개월 이상 관리 서비스 계약 유지 중\n□ 정량적 성과 데이터 수집 가능\n□ 고객사 마케팅팀 협조 가능 (공개 사례용)\n□ NDA 조건에서 사례 연구 허용\n□ 이전 MSP 감사에서 사용하지 않은 고객\n```\n\n**AWS 도구 활용:**\n- AWS Partner Central에서 이전 제출 사례 확인\n- 고객별 AWS 사용량 데이터 (비용 절감 증빙용)\n\n### Step 2: 고객 승인 획득 (2주)\n\n**담당:** 어카운트 매니저\n\n**공개 사례용 승인 요청 템플릿:**\n\n```\n[고객사 승인 요청 이메일 핵심 내용]\n\n- AWS 파트너 인증 목적 설명\n- 공개 범위 명시 (웹사이트, AWS 채널 등)\n- 고객사 검토/승인 프로세스\n- 게시 전 최종 콘텐츠 확인 기회 제공\n- 상호 마케팅 혜택 제안\n```\n\n### Step 3: 성과 데이터 수집 (2주)\n\n**담당:** 기술팀 + FinOps팀\n\n**수집해야 할 정량적 지표:**\n\n| 카테고리 | 지표 예시 | 데이터 소스 |\n|---------|----------|------------|\n| 비용 | 월간 AWS 비용 30% 절감 | AWS Cost Explorer |\n| 가용성 | 99.95% → 99.99% 향상 | CloudWatch Metrics |\n| 운영 효율 | 인시던트 대응 시간 4시간 → 30분 | ServiceNow/Jira |\n| 보안 | 취약점 해결 시간 72시간 → 24시간 | AWS Security Hub |\n| 자동화 | 수동 작업 80% 자동화 | Systems Manager |\n\n### Step 4: 사례 연구 콘텐츠 작성 (3주)\n\n**담당:** 마케팅팀 + 기술 라이터\n\n**공개 사례 작성 시 필수 포함 문구:**\n\n```\n\"[파트너사명]은 [고객사명]에게 AWS 기반 관리형 서비스를 \n제공하여 24/7 모니터링, 인시던트 대응, 지속적인 최적화를 \n수행하고 있습니다.\"\n\n→ \"Managed Services\" 키워드 명시적 포함 필수\n```\n\n### Step 5: 공개 채널 게시 (1주)\n\n**담당:** 마케팅팀 + 웹 운영팀\n\n**게시 채널 우선순위:**\n1. 회사 공식 웹사이트 `/case-studies/` 섹션\n2. 회사 기술 블로그\n3. LinkedIn 기업 페이지 (보조)\n4. AWS Partner Network 블로그 기고 (가능시)\n\n**게시 시 체크:**\n```\n□ URL이 공개 접근 가능 (로그인 불필요)\n□ 게시일이 명확히 표시됨\n□ 모바일에서도 정상 표시\n□ PDF 다운로드 시 깨짐 없음\n```\n\n### Step 6: 비공개 사례 문서화 (2주)\n\n**담당:** 솔루션 아키텍트 + 기술 라이터\n\n**아키텍처 다이어그램 작성 도구:**\n- AWS Architecture Icons 사용 (공식)\n- draw.io / Lucidchart\n- PowerPoint AWS 스텐실\n\n### Step 7: 최종 패키지 구성 및 제출 (1주)\n\n**담당:** MSP 프로그램 담당자\n\n**제출 패키지 구성:**\n\n```\n📁 BUSP-003_Customer_Case_Studies/\n├── 📁 Public_Case_Studies/\n│   ├── Public_Case_1_URL_and_Screenshot.pdf\n│   ├── Public_Case_2_URL_and_Screenshot.pdf\n│   └── URL_Accessibility_Verification.xlsx\n├── 📁 Private_Case_Studies/\n│   ├── Private_Case_1_CustomerA_2024.pdf\n│   └── Private_Case_2_CustomerB_2024.pptx\n└── 📄 Case_Study_Summary_Matrix.xlsx\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n#### 실수 1: \"구축 프로젝트\"를 \"관리 서비스\"로 제출\n\n```\n❌ 잘못된 예:\n\"고객사의 온프레미스 시스템을 AWS로 마이그레이션했습니다.\"\n→ 이것은 구축 프로젝트이지 관리 서비스가 아님\n\n✅ 올바른 예:\n\"마이그레이션 완료 후 24/7 모니터링, 월간 패치 관리, \n분기별 비용 최적화 리뷰를 포함한 관리 서비스를 제공하고 있습니다.\"\n```\n\n#### 실수 2: 이전 감사에서 사용한 사례 재제출\n\n```\n⚠️ AWS는 이전 제출 기록을 보유하고 있음\n- Partner Central 제출 이력 확인 필수\n- 동일 고객이라도 \"새로운 프로젝트/서비스\"면 가능\n- 단, 완전히 다른 스코프임을 명확히 해야 함\n```\n\n#### 실수 3: 공개 사례의 URL 접근 불가\n\n```\n❌ 문제 상황:\n- 로그인 필요한 페이지\n- 지역 제한 (한국에서만 접근 가능)\n- 게시 후 URL 변경/삭제\n- PDF 다운로드 링크 만료\n\n✅ 해결책:\n- 감사 전 VPN 없이 해외에서 접근 테스트\n- 스크린샷과 함께 URL 제출\n- Wayback Machine 아카이브 생성 권장\n```\n\n#### 실수 4: 정량적 성과 누락\n\n```\n❌ 약한 사례:\n\"고객 만족도가 향상되었습니다.\"\n\"시스템이 안정화되었습니다.\"\n\n✅ 강한 사례:\n\"월간 AWS 비용 $50,000 → $32,000 (36% 절감)\"\n\"평균 장애 복구 시간 4시간 → 23분 (90% 단축)\"\n\"보안 취약점 해결률 65% → 98%\"\n```\n\n#### 실수 5: 고객 승인 없이 공개\n\n```\n⚠️ 리스크:\n- 고객사 법무팀 클레임\n- NDA 위반\n- AWS 감사 탈락 + 파트너 관계 손상\n\n✅ 필수 확보 문서:\n- 고객사 마케팅팀 서면 승인\n- 공개 범위 명시된 이메일/문서\n- 최종 콘텐츠 승인 기록\n```\n\n### 탈락 주요 원인\n\n| 탈락 사유 | 빈도 | 예방책 |\n|----------|------|--------|\n| 관리 서비스 내용 불명확 | 높음 | 운영 서비스 항목 명시적 나열 |\n| 공개 사례 접근 불가 | 중간 | 제출 직전 접근성 재확인 |\n| 이전 사례 재사용 | 중간 | Partner Central 이력 확인 |\n| 성과 지표 부재 | 중간 | 최소 2개 정량 지표 포함 |\n| 4개 미만 제출 | 낮음 | 여유분",
      "language": "ko",
      "createdAt": "2026-01-07T01:29:02.609Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-001",
      "category": "Governance",
      "title": "위험 및 완화 계획",
      "advice": "# GOV-001: 위험 및 완화 계획 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS는 MSP 파트너에게 고객의 클라우드 인프라 운영을 위탁합니다. 파트너사가 재정적 어려움, 핵심 인력 이탈, 또는 급격한 사업 변화로 서비스 연속성을 보장하지 못하면 **AWS 고객에게 직접적인 피해**가 발생합니다. 따라서 AWS는 파트너사가 자체 비즈니스 위험을 체계적으로 인식하고 관리하는지 확인하려 합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 핵심 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **AWS 실무 특화 위험 식별** | 일반적인 기업 리스크가 아닌, AWS 매니지드 서비스 운영에 특화된 위험을 식별했는가? |\n| **재정적 지속가능성** | 주요 고객 이탈, 대금 미수, 현금흐름 문제 등에 대한 구체적 대응책이 있는가? |\n| **인력 의존도 관리** | AWS 자격증 보유 핵심 인력 이탈 시 서비스 연속성 확보 방안이 있는가? |\n| **성장/축소 시나리오 대응** | 급격한 고객 증가 또는 대형 고객 이탈 시 운영 역량 조정 계획이 있는가? |\n| **생명주기 관리 체계** | 위험 평가가 일회성이 아닌 정기적으로 업데이트되는 프로세스가 있는가? |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS Organizations**: 멀티 계정 관리 위험\n- **AWS Support Plans**: 기술 지원 의존도 위험\n- **AWS Partner Central**: 파트너 티어 유지 위험\n- **AWS Certification**: 자격증 만료/인력 이탈 위험\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 GOV-001_Evidence/\n├── 01_AWS_MSP_Risk_Register_2024.xlsx\n├── 02_Risk_Mitigation_Action_Plan.pdf\n├── 03_Risk_Review_Meeting_Minutes_Q1-Q4.pdf\n├── 04_Risk_Management_Policy.pdf\n└── 05_Risk_Assessment_Methodology.pdf\n```\n\n### 각 증빙 자료별 필수 포함 내용\n\n#### 📊 01_AWS_MSP_Risk_Register (위험 등록부)\n```\n필수 컬럼:\n- Risk ID (예: FIN-001, OPS-002, HR-003)\n- 위험 카테고리 (재정/운영/인력/기술/규정준수)\n- 위험 설명 (AWS MSP 실무 맥락에서 구체적으로)\n- 발생 가능성 (1-5 척도 + 판단 근거)\n- 영향도 (1-5 척도 + 판단 근거)\n- 위험 점수 (가능성 × 영향도)\n- 현재 통제 수단\n- 잔여 위험 수준\n- 위험 소유자 (실명 + 직책)\n- 완화 조치 상태\n- 최종 검토일\n- 다음 검토 예정일\n```\n\n#### 📋 02_Risk_Mitigation_Action_Plan (완화 조치 계획)\n```\n각 고위험 항목별 포함 내용:\n- 구체적 완화 조치 (What)\n- 담당자 및 책임자 (Who)\n- 실행 일정 및 마일스톤 (When)\n- 필요 예산/리소스 (How much)\n- 성공 지표 (KPI)\n- 진행 상태 추적\n```\n\n#### 📝 03_Risk_Review_Meeting_Minutes (검토 회의록)\n```\n분기별 회의록에 포함되어야 할 내용:\n- 회의 일시, 참석자\n- 신규 식별 위험\n- 기존 위험 상태 변경 사항\n- 완화 조치 진행 현황\n- 의사결정 사항\n- Action Items 및 담당자\n```\n\n### 증빙 자료 예시 (실제 문서 내용)\n\n**위험 등록부 예시 항목:**\n\n| Risk ID | 카테고리 | 위험 설명 | 가능성 | 영향도 | 점수 | 완화 조치 |\n|---------|---------|----------|--------|--------|------|----------|\n| FIN-001 | 재정 | 상위 3개 고객이 매출의 65% 차지. 1개 고객 이탈 시 AWS 역량 투자 축소 불가피 | 3 | 5 | 15 | 신규 고객 파이프라인 확대, 고객당 매출 비중 30% 이하 목표 |\n| HR-002 | 인력 | AWS SA Pro 자격증 보유자 3명 중 2명이 동일 팀. 동시 이직 시 서비스 품질 저하 | 2 | 5 | 10 | 자격증 취득 지원 프로그램, 크로스 트레이닝 의무화 |\n| OPS-003 | 운영 | 고객 급증 시 24/7 모니터링 인력 부족. 현재 4명으로 10개 고객 한계 | 4 | 4 | 16 | 자동화 도구 투자, 파트타임 인력풀 확보, 채용 파이프라인 유지 |\n| TECH-004 | 기술 | AWS 신규 서비스 역량 부족으로 경쟁사 대비 제안 경쟁력 저하 | 3 | 3 | 9 | 월 1회 신규 서비스 스터디, 연 2회 re:Invent/Summit 참가 |\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: AWS MSP 실무 특화 위험 워크샵 개최 (1주)\n\n**수행 내용:**\n```\n참석자: CEO/COO, AWS Practice Lead, Finance Lead, HR Lead, 주요 고객 담당자\n\n워크샵 아젠다:\n1. AWS MSP 사업 현황 공유 (매출, 고객 수, 인력 현황)\n2. 카테고리별 브레인스토밍\n   - 재정 위험: 고객 집중도, 현금흐름, 투자 여력\n   - 인력 위험: 핵심 인력 의존도, 자격증 현황, 채용 난이도\n   - 운영 위험: 용량 한계, 도구 의존성, 프로세스 성숙도\n   - 성장 위험: 급성장 대응력, 대형 계약 수주 시 리소스\n   - 외부 위험: AWS 정책 변경, 경쟁 심화, 규제 변화\n3. 위험별 가능성/영향도 합의\n4. Top 10 위험 선정 및 소유자 지정\n```\n\n**산출물:** `Risk_Workshop_Output_YYYYMMDD.xlsx`\n\n### Step 2: 위험 평가 방법론 문서화 (3일)\n\n**문서화할 내용:**\n```markdown\n# AWS MSP Practice 위험 평가 방법론\n\n## 1. 위험 식별 방법\n- 정기 워크샵 (연 1회 전체, 분기 1회 업데이트)\n- 프로젝트 완료 후 Lessons Learned에서 추출\n- 외부 환경 변화 모니터링 (AWS 정책, 시장 동향)\n\n## 2. 위험 평가 기준\n### 가능성 척도\n| 점수 | 정의 | 기준 |\n|-----|------|-----|\n| 1 | 매우 낮음 | 5년 내 발생 가능성 5% 미만 |\n| 2 | 낮음 | 3년 내 발생 가능성 10% 미만 |\n| 3 | 보통 | 1년 내 발생 가능성 25% |\n| 4 | 높음 | 1년 내 발생 가능성 50% |\n| 5 | 매우 높음 | 1년 내 발생 가능성 75% 이상 |\n\n### 영향도 척도\n| 점수 | 재정 영향 | 운영 영향 | 평판 영향 |\n|-----|----------|----------|----------|\n| 1 | 매출 1% 미만 | 서비스 영향 없음 | 내부 인지 |\n| 2 | 매출 1-5% | 일부 고객 경미한 영향 | 고객 1-2개사 불만 |\n| 3 | 매출 5-15% | 다수 고객 서비스 저하 | 업계 내 인지 |\n| 4 | 매출 15-30% | 주요 고객 SLA 위반 | 언론 보도 |\n| 5 | 매출 30% 이상 | 사업 연속성 위협 | AWS 파트너십 위험 |\n\n## 3. 위험 대응 전략\n- 회피 (Avoid): 위험 유발 활동 중단\n- 전가 (Transfer): 보험, 계약 조건\n- 완화 (Mitigate): 가능성/영향도 감소 조치\n- 수용 (Accept): 모니터링하며 대응 준비\n```\n\n### Step 3: 위험 등록부 작성 (1주)\n\n**AWS MSP 필수 포함 위험 카테고리:**\n\n```\n🔴 재정 위험 (Financial Risks)\n- 고객 매출 집중도 (상위 고객 의존도)\n- AWS 비용 선지급 vs 고객 후불 결제 간 현금흐름 갭\n- AWS 파트너 티어 유지를 위한 투자 부담\n- 환율 변동 (USD 기반 AWS 비용)\n\n🟠 인력 위험 (People Risks)  \n- AWS 자격증 보유 인력 이탈\n- 핵심 고객 담당자 퇴사\n- 채용 시장 경쟁 심화\n- 번아웃으로 인한 생산성 저하\n\n🟡 운영 위험 (Operational Risks)\n- 24/7 모니터링 인력 용량 한계\n- 자동화 도구 장애/의존성\n- 동시 다발 인시던트 대응 역량\n- 지식 이전 실패 (암묵지 의존)\n\n🟢 성장 위험 (Growth Risks)\n- 대형 계약 수주 시 인력 확보 지연\n- 신규 AWS 서비스 역량 확보 지연\n- 고객 온보딩 품질 저하\n\n🔵 외부 위험 (External Risks)\n- AWS 파트너 프로그램 요구사항 변경\n- 경쟁사의 공격적 가격 정책\n- 고객사 클라우드 전략 변경 (멀티클라우드, 리패트리에이션)\n```\n\n### Step 4: 완화 조치 계획 수립 (1주)\n\n**고위험 항목(점수 12점 이상)에 대한 상세 계획 작성:**\n\n```\n위험 ID: FIN-001\n위험명: 고객 매출 집중도\n\n현재 상태:\n- 상위 3개 고객 매출 비중: 65%\n- 최대 단일 고객 비중: 28%\n\n완화 조치:\n┌─────────────────────────────────────────────────────────────┐\n│ 조치 1: 신규 고객 파이프라인 강화                              │\n│ - 담당: 영업팀장                                              │\n│ - 일정: 2024 Q1-Q4 지속                                       │\n│ - 목표: 분기당 신규 고객 2개사 이상 확보                        │\n│ - 예산: 마케팅 예산 20% 증액                                   │\n│ - KPI: 상위 3개 고객 비중 50% 이하로 감소                      │\n├─────────────────────────────────────────────────────────────┤\n│ 조치 2: 기존 고객 서비스 확대                                  │\n│ - 담당: 고객성공팀장                                          │\n│ - 일정: 2024 Q2 시작                                          │\n│ - 목표: 중소 고객 ARPU 30% 증가                               │\n│ - 방법: 추가 서비스 제안 (보안, 비용최적화, DevOps)            │\n└─────────────────────────────────────────────────────────────┘\n\n진행 상태 추적:\n- 2024.01: 계획 수립 완료 ✅\n- 2024.03: Q1 신규 고객 1개사 확보 (목표 미달)\n- 2024.06: Q2 신규 고객 3개사 확보 (목표 초과) ✅\n- 현재 상위 3개 고",
      "language": "ko",
      "createdAt": "2026-01-07T01:48:34.612Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-002",
      "category": "Governance",
      "title": "고객 만족도",
      "advice": "# GOV-002: 고객 만족도 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n고객 만족도 측정은 MSP가 단순히 기술 서비스를 제공하는 것을 넘어 **지속적인 서비스 품질 개선 문화**를 갖추고 있는지를 검증하는 핵심 지표입니다. AWS는 MSP 파트너가 고객의 목소리를 체계적으로 수집하고, 이를 서비스 개선에 반영하는 **피드백 루프(Feedback Loop)**를 운영하고 있는지 확인합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 예시 |\n|--------|-------------------|\n| **객관성** | \"설문 응답이 익명으로 처리되나요? 고객이 솔직하게 답변할 수 있는 환경인가요?\" |\n| **정기성** | \"만족도 조사가 일회성인가요, 아니면 정기적인 주기로 수행되나요?\" |\n| **추적 가능성** | \"낮은 점수나 불만 피드백이 접수되면 어떤 프로세스로 해결하나요?\" |\n| **실행 증거** | \"최근 6개월 내 실제 수집된 피드백과 조치 사례를 보여줄 수 있나요?\" |\n| **독립성** | \"AWS Partner Central CSAT이 아닌 자체 메커니즘을 운영하고 있나요?\" |\n\n### 관련 AWS 서비스 및 도구\n- **Amazon Connect** - 고객 상호작용 후 자동 설문 발송\n- **Amazon Pinpoint** - 이메일/SMS 기반 설문 배포\n- **Amazon QuickSight** - 만족도 데이터 시각화 대시보드\n- **AWS Lambda + API Gateway** - 커스텀 설문 시스템 구축\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 GOV-002_고객만족도_증빙/\n├── 01_CSAT_프로세스_정의서.pdf\n├── 02_설문조사_템플릿_및_질문항목.pdf\n├── 03_최근6개월_설문결과_리포트.xlsx\n├── 04_불만처리_에스컬레이션_프로세스.pdf\n├── 05_개선조치_이력_및_클로징_증빙.pdf\n└── 06_설문시스템_스크린샷_또는_데모영상.mp4\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📄 01_CSAT_프로세스_정의서.pdf\n```markdown\n필수 포함 내용:\n- 설문 발송 트리거 조건 (프로젝트 완료 시, 티켓 종료 후 24시간 등)\n- 설문 주기 및 대상 고객 선정 기준\n- 응답 수집 방법 (이메일, 웹폼, 전화 등)\n- 결과 분석 주기 및 담당 부서\n- 낮은 점수(Detractor) 발생 시 에스컬레이션 경로\n```\n\n#### 📄 02_설문조사_템플릿_및_질문항목.pdf\n```markdown\n권장 질문 구성 (NPS + CSAT 혼합):\n1. [NPS] \"저희 서비스를 동료에게 추천할 의향이 얼마나 되십니까?\" (0-10점)\n2. [CSAT] \"최근 받으신 기술 지원에 만족하십니까?\" (매우불만족~매우만족)\n3. [CSAT] \"담당 엔지니어의 전문성은 어떠셨습니까?\" (1-5점)\n4. [Open] \"개선이 필요한 부분이 있다면 말씀해 주세요\"\n5. [CSAT] \"응답 속도에 만족하십니까?\" (1-5점)\n```\n\n#### 📄 03_최근6개월_설문결과_리포트.xlsx\n```\n필수 데이터 포함:\n- 월별 응답 수 및 응답률\n- NPS 점수 추이 그래프\n- 항목별 평균 점수\n- Detractor(비추천자) 비율 및 주요 불만 카테고리\n- 고객사별 익명화된 피드백 원문\n```\n\n#### 📄 05_개선조치_이력_및_클로징_증빙.pdf\n```\n⚠️ 가장 중요한 증빙 - 반드시 포함:\n- 불만 피드백 접수 일자\n- 해당 고객과의 후속 미팅 일정 및 참석자\n- 도출된 개선 과제 (Action Item)\n- 개선 완료 일자 및 결과\n- 고객 확인 이메일 또는 서명\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 기존 피드백 수집 현황 파악 (1-2일)\n```bash\n# 확인할 사항\n□ 현재 고객 피드백을 수집하는 채널이 있는가?\n□ 수집된 데이터가 어디에 저장되어 있는가?\n□ 최근 6개월 내 수집된 피드백이 있는가?\n\n# 없다면 → Step 2로 즉시 이동\n# 있다면 → 데이터 정리 후 Step 4로 이동\n```\n\n### Step 2: 설문 시스템 구축 (3-5일)\n```\n권장 옵션 (복잡도 순):\n\n🟢 간단: Google Forms + Google Sheets\n   - 비용: 무료\n   - 구축 시간: 1일\n   - 자동화: Zapier로 이메일 트리거 가능\n\n🟡 중간: Typeform + Slack 연동\n   - 비용: 월 $25~\n   - 구축 시간: 2-3일\n   - 장점: 응답 시 실시간 Slack 알림\n\n🔴 고급: Amazon Connect + Lambda + DynamoDB\n   - 비용: 사용량 기반\n   - 구축 시간: 5-7일\n   - 장점: AWS 네이티브, 완전 자동화\n```\n\n### Step 3: 설문 발송 트리거 설정 (2-3일)\n```python\n# 예시: 티켓 종료 후 24시간 뒤 자동 설문 발송 (Lambda 코드 개념)\ndef send_csat_survey(ticket_closed_event):\n    customer_email = ticket_closed_event['customer_email']\n    ticket_id = ticket_closed_event['ticket_id']\n    \n    # 24시간 대기 후 발송 (EventBridge Scheduler 활용)\n    schedule_survey_email(\n        delay_hours=24,\n        recipient=customer_email,\n        survey_link=f\"https://survey.company.com?ticket={ticket_id}\"\n    )\n```\n\n### Step 4: 최소 3개월 데이터 수집 (필수)\n```\n⏰ 감사 일정 역산:\n- 감사 예정일: D-Day\n- 최소 데이터 수집 시작: D-90일 전\n- 권장 데이터 수집 시작: D-180일 전\n\n📊 최소 샘플 수:\n- 고객사 수 × 월 1회 이상 설문 발송\n- 최소 응답률 20% 이상 유지\n- Detractor 발생 시 100% 후속 조치 기록\n```\n\n### Step 5: Detractor 처리 프로세스 실행 (지속)\n```\nNPS 6점 이하 또는 CSAT \"불만족\" 응답 시:\n\n1️⃣ 24시간 내 담당 Account Manager에게 알림\n2️⃣ 48시간 내 고객 연락 및 미팅 일정 조율\n3️⃣ 7일 내 개선 계획 수립 및 고객 공유\n4️⃣ 30일 내 개선 완료 및 고객 확인\n5️⃣ 모든 과정 Jira/Confluence에 기록\n```\n\n### Step 6: 월간 CSAT 리뷰 미팅 운영 (월 1회)\n```\n📅 미팅 아젠다 템플릿:\n1. 이번 달 NPS/CSAT 점수 리뷰 (10분)\n2. Detractor 케이스 상세 분석 (15분)\n3. 개선 조치 진행 상황 점검 (10분)\n4. 다음 달 액션 아이템 도출 (10분)\n\n📝 미팅 결과물:\n- 회의록 (참석자, 논의 내용, 결정 사항)\n- 액션 아이템 목록 (담당자, 기한)\n```\n\n### Step 7: 증빙 자료 패키징 (2-3일)\n```\n최종 제출 전 패키징:\n□ 모든 문서 PDF 변환\n□ 스크린샷에 날짜/시간 워터마크 포함\n□ 개인정보(고객 이름, 이메일) 마스킹 처리\n□ 영문 번역본 준비 (감사관 요청 시)\n□ 데모 영상 녹화 (설문 발송 → 응답 수집 → 분석 전 과정)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 유형 | 구체적 사례 | 해결 방법 |\n|-----------|-------------|-----------|\n| **AWS CSAT 의존** | \"Partner Central에서 수집되는 CSAT 점수를 사용합니다\" | ❌ 명시적으로 금지됨. 자체 시스템 필수 |\n| **데이터 부재** | \"설문 시스템은 있지만 최근 응답이 없습니다\" | 감사 최소 3개월 전부터 적극적 수집 |\n| **후속 조치 미흡** | \"낮은 점수가 있었지만 별도 조치는 없었습니다\" | Detractor 100% 후속 조치 및 기록 필수 |\n| **일회성 설문** | \"작년에 한 번 설문을 진행했습니다\" | 정기적(월간/분기) 수집 체계 증명 필요 |\n| **내부 설문 혼동** | \"직원 만족도 조사 결과를 제출합니다\" | 고객(외부) 대상 설문만 인정 |\n\n### 🔴 감사 탈락 주요 원인\n\n```\n1. \"피드백 수집 메커니즘이 있다\"고 주장하지만 실제 데이터가 없음\n   → 최소 3개월 이상의 실제 응답 데이터 필수\n\n2. 불만 피드백에 대한 조치 이력이 전혀 없음\n   → \"문제가 없었다\"는 변명 불가, 프로세스 존재 증명 필요\n\n3. 설문 질문이 AWS 서비스와 무관한 일반적인 내용\n   → \"AWS 환경 운영\", \"클라우드 기술 지원\" 관련 질문 포함 권장\n\n4. 고객 연락처만 있고 실제 발송/응답 기록이 없음\n   → 발송 로그, 응답 타임스탬프 등 시스템 기록 필수\n```\n\n### 🚨 피해야 할 안티패턴\n\n```\n❌ \"고객이 불만이 있으면 알아서 연락합니다\" (수동적 접근)\n✅ 정기적으로 먼저 피드백을 요청하는 능동적 프로세스\n\n❌ \"영업팀이 구두로 피드백을 받고 있습니다\" (비공식적)\n✅ 문서화된 설문 양식과 응답 기록 시스템\n\n❌ \"만족도가 높아서 개선 사례가 없습니다\" (증명 불가)\n✅ 사소한 개선 요청이라도 기록하고 조치 이력 남기기\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|-----------|-----------|-----------|\n| 1 | 자체 설문 시스템 존재 | 시스템 URL 또는 스크린샷 | AWS Partner Central CSAT이 아닌 독립 시스템 |\n| 2 | 최근 6개월 응답 데이터 | 엑셀/대시보드 캡처 | 최소 10건 이상의 실제 응답 |\n| 3 | 정기적 수집 증거 | 월별 데이터 분포 확인 | 최소 3개월 연속 데이터 존재 |\n| 4 | Detractor 처리 기록 | 이슈 트래킹 시스템 ",
      "language": "ko",
      "createdAt": "2026-01-07T01:49:32.130Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-003",
      "category": "Governance",
      "title": "데이터 소유권 및 고객 오프보딩",
      "advice": "# GOV-003: 데이터 소유권 및 고객 오프보딩 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nMSP 관계 종료 시 고객의 비즈니스 연속성과 데이터 주권을 보호하는 것은 **신뢰 기반 파트너십의 핵심**입니다. AWS는 MSP가 고객을 \"인질\"로 잡는 상황(Vendor Lock-in)을 방지하고, 깔끔한 전환을 보장하는지 검증합니다.\n\n### 🎯 감사관이 확인하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 |\n|--------|--------------|\n| **데이터 소유권 명시성** | \"계약서에 고객 데이터가 100% 고객 소유임이 명시되어 있는가?\" |\n| **시간 약속(SLA)** | \"오프보딩 완료까지 구체적인 일수가 명시되어 있는가? (예: 30일 이내)\" |\n| **자격 증명 전송 보안** | \"루트 계정, IAM 자격 증명을 어떤 보안 채널로 전달하는가?\" |\n| **MSP 접근 권한 제거** | \"파트너가 생성한 IAM 역할, Cross-account 역할 제거 절차가 있는가?\" |\n| **데이터 삭제 증명** | \"MSP 시스템에 남은 고객 데이터 삭제를 어떻게 증명하는가?\" |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS Organizations**: 계정 분리 및 이전\n- **AWS IAM**: 역할, 정책, 페더레이션 관리\n- **AWS SSO (IAM Identity Center)**: 중앙 집중식 접근 관리 해제\n- **AWS CloudTrail**: 오프보딩 활동 감사 로그\n- **AWS Control Tower**: 가드레일 및 계정 관리\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 문서\n\n```\n📁 GOV-003_Evidence/\n├── 📄 MSP_Master_Service_Agreement_v2.3.pdf\n├── 📄 Data_Ownership_Addendum_Template.docx\n├── 📄 Customer_Offboarding_Procedure_SOP.pdf\n├── 📄 IAM_Cleanup_Checklist.xlsx\n└── 📄 Sample_Offboarding_Completion_Certificate.pdf\n```\n\n### 각 문서에 포함되어야 할 핵심 내용\n\n#### 📄 마스터 서비스 계약서 (MSA) 내 필수 조항\n\n```\n제X조 (데이터 소유권)\n\nX.1 본 계약에 따라 처리되는 모든 고객 데이터의 소유권은 \n    전적으로 고객에게 귀속됩니다.\n\nX.2 \"고객 데이터\"란 다음을 포함합니다:\n    (a) 고객 AWS 계정 내 모든 리소스 및 구성\n    (b) 고객이 업로드하거나 생성한 모든 데이터\n    (c) AWS 서비스 사용으로 생성된 로그 및 메타데이터\n    (d) 고객 비즈니스 정보 및 지적 재산\n\nX.3 파트너는 고객 데이터에 대한 어떠한 소유권, \n    유치권(lien), 또는 담보권을 주장하지 않습니다.\n```\n\n#### 📄 오프보딩 절차서 (SOP) 필수 섹션\n\n| 섹션 | 포함 내용 |\n|------|----------|\n| **1. 오프보딩 트리거** | 계약 만료, 조기 해지, 고객 요청 시나리오별 프로세스 |\n| **2. 타임라인** | Day 1-7: 통지 및 계획, Day 8-21: 실행, Day 22-30: 검증 및 완료 |\n| **3. 자격 증명 전송** | AWS Secrets Manager 또는 암호화된 채널 사용 방법 |\n| **4. IAM 정리** | 파트너 생성 역할/정책 목록화 및 제거 절차 |\n| **5. 데이터 삭제** | MSP 내부 시스템의 고객 데이터 삭제 및 증명 |\n\n#### 📄 오프보딩 완료 확인서 예시\n\n```\n═══════════════════════════════════════════════════════\n        고객 오프보딩 완료 확인서\n═══════════════════════════════════════════════════════\n\n고객명: [ABC Corporation]\nAWS 계정 ID: [123456789012]\n오프보딩 완료일: [2024-XX-XX]\n\n✅ 완료 항목:\n□ AWS 루트 계정 자격 증명 고객 전달 완료\n□ 파트너 IAM 역할 (MSP-Admin-Role) 삭제 완료\n□ Cross-account 신뢰 관계 제거 완료\n□ AWS SSO 할당 해제 완료\n□ 파트너 내부 시스템 고객 데이터 삭제 완료\n□ CloudTrail 로그 고객 인계 완료\n\n파트너 서명: _________________ 일자: _________\n고객 서명:   _________________ 일자: _________\n═══════════════════════════════════════════════════════\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현행 계약서 데이터 조항 감사 (3-5일)\n\n```\n🔍 체크 항목:\n- 기존 MSA에서 \"데이터 소유권\" 키워드 검색\n- \"계약 종료\", \"해지\", \"termination\" 조항 확인\n- 누락된 필수 조항 목록화\n```\n\n**담당**: 법무팀 + 서비스 운영팀\n\n### Step 2: 오프보딩 타임라인 SLA 정의 (2-3일)\n\n```yaml\n오프보딩 SLA 정의:\n  통지_기간: \"계약 종료 30일 전\"\n  계획_수립: \"통지 후 7일 이내\"\n  자격증명_전송: \"계획 수립 후 14일 이내\"\n  IAM_정리_완료: \"자격증명 전송 후 7일 이내\"\n  최종_확인서_발급: \"IAM 정리 후 2일 이내\"\n  총_소요기간: \"최대 30일\"\n```\n\n**담당**: 서비스 운영팀\n\n### Step 3: 자격 증명 전송 보안 프로토콜 수립 (3-4일)\n\n```\n🔐 보안 전송 방법 선택:\n\nOption A: AWS Secrets Manager 활용\n- 임시 시크릿 생성 → 고객에게 ARN 전달 → 고객 조회 후 삭제\n\nOption B: 암호화된 이메일 + 분리 전송\n- 비밀번호: 암호화 이메일로 전송\n- MFA 시드: 별도 보안 채널(전화)로 전달\n\nOption C: 대면 전달\n- 암호화된 USB + 봉인된 봉투\n- 수령 확인서 서명\n```\n\n**담당**: 보안팀 + 서비스 운영팀\n\n### Step 4: IAM 정리 체크리스트 개발 (2-3일)\n\n```\n📋 파트너 생성 IAM 리소스 표준 명명 규칙 수립:\n\n역할: MSP-[고객코드]-[기능]-Role\n정책: MSP-[고객코드]-[기능]-Policy\n그룹: MSP-[고객코드]-[팀명]-Group\n\n예시:\n- MSP-ABC-Admin-Role\n- MSP-ABC-Monitoring-Policy\n- MSP-ABC-Operations-Group\n\n→ 오프보딩 시 \"MSP-ABC-*\" 패턴으로 일괄 식별 가능\n```\n\n**담당**: 클라우드 아키텍트팀\n\n### Step 5: 내부 데이터 삭제 절차 문서화 (3-4일)\n\n```\n🗑️ MSP 내부 시스템 고객 데이터 삭제 대상:\n\n1. 모니터링 시스템 (Datadog, CloudWatch 대시보드)\n2. 티켓 시스템 (ServiceNow, Jira)\n3. 문서 저장소 (Confluence, SharePoint)\n4. 백업 시스템 (Veeam, AWS Backup 복사본)\n5. 로그 집계 시스템 (Splunk, ELK)\n6. CMDB (Configuration Management Database)\n\n각 시스템별 삭제 담당자 및 검증자 지정 필요\n```\n\n**담당**: IT 운영팀 + 보안팀\n\n### Step 6: 계약서 템플릿 법무 검토 (5-7일)\n\n```\n⚖️ 법무 검토 체크포인트:\n\n□ 데이터 소유권 조항이 관할권 법률과 충돌하지 않는가?\n□ 오프보딩 SLA가 실현 가능한가?\n□ 면책 조항이 적절히 포함되어 있는가?\n□ 분쟁 해결 절차가 명시되어 있는가?\n□ GDPR/개인정보보호법 준수 조항이 있는가?\n```\n\n**담당**: 법무팀\n\n### Step 7: 파일럿 오프보딩 시뮬레이션 (3-5일)\n\n```\n🧪 테스트 시나리오:\n\n테스트 계정: AWS 샌드박스 계정 사용\n참여자: 서비스 운영팀 + 고객 역할 담당자\n\nDay 1: 오프보딩 요청 접수\nDay 3: 오프보딩 계획서 작성\nDay 7: 자격 증명 전송 실습\nDay 10: IAM 정리 실행\nDay 12: 완료 확인서 발급\n\n→ 발견된 문제점 SOP에 반영\n```\n\n**담당**: 서비스 운영팀\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 유형 | 문제점 | 해결책 |\n|----------|--------|--------|\n| **모호한 시간 약속** | \"합리적인 기간 내\" 같은 표현 사용 | \"30일 이내\" 같은 구체적 일수 명시 |\n| **자격 증명 평문 전송** | 이메일로 비밀번호 직접 전송 | AWS Secrets Manager 또는 암호화 채널 사용 |\n| **IAM 정리 누락** | 파트너 역할이 계정에 잔존 | 표준 명명 규칙 + 자동화 스크립트로 일괄 제거 |\n| **내부 데이터 삭제 미증명** | 삭제했다고만 언급 | 삭제 로그, 스크린샷, 제3자 검증 포함 |\n| **페더레이션 해제 누락** | AWS SSO 할당 그대로 유지 | 오프보딩 체크리스트에 SSO 해제 필수 포함 |\n\n### ❌ 감사 탈락 주요 원인\n\n```\n1. 계약서에 \"데이터 소유권\" 명시적 조항 없음\n   → 감사관: \"고객이 데이터 소유자임을 어디서 확인할 수 있나요?\"\n\n2. 오프보딩 절차서가 AWS 특화되지 않음\n   → 감사관: \"IAM 역할 제거 절차가 구체적으로 없네요\"\n\n3. 자격 증명 전송 보안 방법 미정의\n   → 감사관: \"루트 계정 비밀번호를 어떻게 안전하게 전달하나요?\"\n\n4. 실제 오프보딩 수행 증빙 없음 (신규 MSP의 경우)\n   → 해결: 내부 테스트 계정으로 시뮬레이션 수행 증빙 제출\n```\n\n### 🚨 피해야 할 안티패턴\n\n```\n❌ 안티패턴 1: \"고객 요청 시 데이터 제공\"\n   → 수동적 표현 대신 \"계약 종료 시 자동으로 인계 프로세스 시작\"\n\n❌ 안티패턴 2: 오프보딩 비용 과다 청구 조항\n   → 합리적인 비용만 청구하거나 무료 제공 명시\n\n❌ 안티패턴 3: 데이터 보존 기간 무기한\n   → \"계약 종료 후 90일 이내 완전 삭제\" 명시\n\n❌ 안티패턴 4: 단일 담당자 의존\n   → 오프보딩 프로세스 소유자 + 백업 담당자 지정\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|-------",
      "language": "ko",
      "createdAt": "2026-01-07T01:50:27.724Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-004_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-004",
      "category": "Governance",
      "title": "운영 준비성",
      "advice": "# GOV-004: 운영 준비성 (Operational Readiness) 상세 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n운영 준비성은 **프로젝트 완료와 운영 인수인계 사이의 \"죽음의 계곡\"을 방지**하는 핵심 거버넌스입니다. AWS MSP는 단순히 인프라를 구축하는 것이 아니라, **지속적으로 고객 환경을 운영할 수 있는 능력**을 증명해야 합니다. 많은 MSP가 구축은 잘하지만 운영 전환 시점에서 장애가 발생하거나 SLA를 충족하지 못하는 경우가 빈번합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **Go-Live 전 검증 체계** | 운영팀이 실제로 환경을 이해하고 있는지 어떻게 확인하는가? |\n| **지식 전달 완료 기준** | 구축팀 → 운영팀 인수인계가 형식적이지 않고 실질적인가? |\n| **도구/접근권한 준비** | 운영에 필요한 모든 도구와 권한이 Day-1에 준비되어 있는가? |\n| **런북/플레이북 존재** | 운영팀이 참조할 수 있는 구체적인 대응 절차가 있는가? |\n| **롤백/에스컬레이션 계획** | 문제 발생 시 누가, 어떻게 대응하는지 명확한가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n📌 AWS Well-Architected Framework - Operational Excellence Pillar\n📌 AWS Systems Manager - OpsCenter, Runbooks\n📌 AWS Service Catalog - 표준화된 운영 환경 프로비저닝\n📌 AWS CloudFormation - 인프라 상태 문서화\n📌 Amazon CloudWatch - 모니터링 대시보드 사전 구성\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: Operational Readiness Checklist (ORC)\n**파일명 예시:** `ORC-Template-v2.3.xlsx` 또는 `Operational-Readiness-Checklist-Process.pdf`\n\n**포함되어야 할 섹션:**\n\n```markdown\n┌─────────────────────────────────────────────────────────────┐\n│  SECTION A: 인력 준비성 (People Readiness)                    │\n├─────────────────────────────────────────────────────────────┤\n│  □ 담당 운영 엔지니어 지정 완료                                │\n│  □ 해당 엔지니어의 AWS 자격증 보유 확인 (최소 SAA)              │\n│  □ 고객 환경 아키텍처 교육 완료 (서명된 교육 기록)              │\n│  □ 온콜 로테이션 스케줄 등록 완료                              │\n│  □ 에스컬레이션 매트릭스에 담당자 정보 업데이트                 │\n├─────────────────────────────────────────────────────────────┤\n│  SECTION B: 도구 준비성 (Tooling Readiness)                   │\n├─────────────────────────────────────────────────────────────┤\n│  □ AWS 콘솔 IAM 접근권한 부여 완료                            │\n│  □ 모니터링 대시보드 생성 및 공유 완료                         │\n│  □ 알람 수신자 설정 완료 (SNS Topic 구독)                     │\n│  □ 티켓팅 시스템에 고객 프로젝트 등록                          │\n│  □ VPN/Bastion 접근 테스트 완료                              │\n├─────────────────────────────────────────────────────────────┤\n│  SECTION C: 프로세스 준비성 (Process Readiness)               │\n├─────────────────────────────────────────────────────────────┤\n│  □ 런북(Runbook) 작성 및 검토 완료                            │\n│  □ 장애 대응 플레이북 작성 완료                                │\n│  □ 변경 관리 프로세스 고객 승인                                │\n│  □ 백업/복구 절차 테스트 완료                                  │\n│  □ 정기 점검 스케줄 캘린더 등록                                │\n└─────────────────────────────────────────────────────────────┘\n```\n\n#### 📄 문서 2: Operational Readiness Review (ORR) 프로세스 문서\n**파일명 예시:** `ORR-Process-Document-v1.5.docx`\n\n**필수 포함 내용:**\n- ORR 미팅 개최 시점 (Go-Live 최소 5영업일 전)\n- 참석 필수 인원 (구축 PM, 운영 리드, 고객 담당자)\n- Go/No-Go 결정 기준\n- No-Go 시 후속 조치 프로세스\n\n#### 📄 문서 3: 실제 수행 증빙\n**파일명 예시:** `ORR-Meeting-Minutes-CustomerABC-20240115.pdf`\n\n**포함 내용:**\n- 체크리스트 각 항목별 확인 결과 (Pass/Fail/N/A)\n- 미결 항목에 대한 조치 계획\n- 참석자 서명 또는 이메일 승인 기록\n- Go-Live 승인 결정 기록\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 기존 인수인계 프로세스 Gap 분석 (3일)\n\n**수행 내용:**\n```\n현재 구축→운영 전환 시 발생한 문제 사례 수집\n- 최근 6개월 내 Go-Live 후 48시간 이내 발생한 장애 티켓 분석\n- 운영팀이 \"몰랐다\"고 응답한 케이스 패턴 파악\n- 인수인계 누락으로 인한 SLA 미달 건수 집계\n```\n\n**담당:** 운영팀 리드 + QA 담당자\n\n### Step 2: 체크리스트 항목 정의 (5일)\n\n**AWS 기반 체크리스트 항목 예시:**\n\n```yaml\nInfrastructure_Documentation:\n  - Architecture_Diagram: \"draw.io 또는 Lucidchart 링크\"\n  - CloudFormation_Templates: \"S3 버킷 위치\"\n  - Network_Topology: \"VPC, Subnet, Security Group 매핑\"\n  - IAM_Policy_Summary: \"역할별 권한 매트릭스\"\n\nMonitoring_Setup:\n  - CloudWatch_Dashboards: \n      - Dashboard_URL: \"https://console.aws.amazon.com/cloudwatch/...\"\n      - Key_Metrics: [\"CPUUtilization\", \"MemoryUsed\", \"DiskSpaceUsed\"]\n  - Alarm_Configuration:\n      - Critical_Alarms: \"P1 대응 필요 알람 목록\"\n      - Warning_Alarms: \"P2 대응 필요 알람 목록\"\n  - Log_Groups: \"CloudWatch Logs 그룹 목록 및 보존 기간\"\n\nAccess_Verification:\n  - Console_Access: \"운영자 IAM 계정 테스트 완료\"\n  - CLI_Access: \"AWS CLI 프로파일 설정 완료\"\n  - Bastion_SSH: \"점프 서버 접속 테스트 완료\"\n```\n\n**담당:** 솔루션스 아키텍트 + 운영팀 리드\n\n### Step 3: ORR 미팅 프로세스 설계 (3일)\n\n**미팅 아젠다 템플릿:**\n\n```\n[ORR 미팅 - 90분]\n\n1. 아키텍처 워크스루 (20분)\n   - 구축팀이 전체 아키텍처 설명\n   - 운영팀이 질문 (최소 3개 이상 필수)\n\n2. 체크리스트 항목별 검토 (40분)\n   - 각 항목 담당자가 완료 상태 보고\n   - 미완료 항목 식별 및 완료 일정 확정\n\n3. 런북 검토 (15분)\n   - 주요 장애 시나리오 3개 선정\n   - 운영팀이 런북 따라 대응 절차 설명\n\n4. Go/No-Go 결정 (15분)\n   - Critical 항목 100% 완료 시 Go\n   - Critical 미완료 시 No-Go + 재검토 일정\n```\n\n**담당:** 프로젝트 관리자(PM)\n\n### Step 4: 도구 통합 및 자동화 (7일)\n\n**Jira/ServiceNow 연동 예시:**\n\n```python\n# ORR 체크리스트 자동 생성 스크립트 예시\ndef create_orr_checklist(project_id, go_live_date):\n    checklist_items = [\n        {\"category\": \"People\", \"item\": \"운영 엔지니어 지정\", \"owner\": \"PM\"},\n        {\"category\": \"People\", \"item\": \"아키텍처 교육 완료\", \"owner\": \"SA\"},\n        {\"category\": \"Tools\", \"item\": \"CloudWatch 대시보드 생성\", \"owner\": \"DevOps\"},\n        {\"category\": \"Tools\", \"item\": \"IAM 권한 부여\", \"owner\": \"Security\"},\n        {\"category\": \"Process\", \"item\": \"런북 작성\", \"owner\": \"Ops Lead\"},\n        # ... 추가 항목\n    ]\n    \n    # ORR 미팅 일정 자동 생성 (Go-Live 5일 전)\n    orr_meeting_date = go_live_date - timedelta(days=5)\n    \n    return create_jira_epic(project_id, checklist_items, orr_meeting_date)\n```\n\n**담당:** DevOps 엔지니어\n\n### Step 5: 파일럿 프로젝트 적용 (10일)\n\n**적용 기준:**\n- 중간 규모 프로젝트 선정 (EC2 10대 이상, 복잡도 중간)\n- 전체 ORR 프로세스 1회 완전 수행\n- 피드백 수집 및 체크리스트 항목 조정\n\n**담당:** 전체 팀\n\n### Step 6: 프로세스 문서화 및 교육 (5일)\n\n**산출물:**\n- ORR 프로세스 가이드 문서 (Confluence/SharePoint)\n- 체크리스트 템플릿 (Excel/Google Sheets)\n- 교육 자료 (슬라이드 + 동영상)\n- PM/운영팀 대상 교육 세션 진행\n\n**담당:** 기술 문서 작성자 + 교육 담당자\n\n### Step 7: 증빙 자료 패키징 (2일)\n\n**제출 패키지 구성:**\n```\n📁 GOV-004_Operational_Readiness/\n├── 📄 01_ORR_Process_Document_v2.0.pdf\n├── 📄 02_Operational_Readiness_Checklist_Template.xlsx\n├── 📁 03_Evidence_Samples/\n│   ├── 📄 ORR_Meeting_Minutes_ProjectAlpha_20240110.pdf\n│   ├── 📄 ORR_Checklist_Completed_ProjectAlpha.xlsx\n│   └── 📄 GoLive_Approval_Email_ProjectAlpha.pdf\n└── 📄 04_Training_Attendance_Record.pdf\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 체크리스트가 너무 일반적임\n\n**문제:**\n```\n❌ \"모니터링 설정 완료\" - 무엇을 모니터링하는지 불명확\n❌ \"문서화 완료\" - 어떤 문서인지 특정되지 않음\n```\n\n**해결:**\n```\n✅ \"CloudWatch 대시보드 생성 완료 - CPU, Memory, Disk, Network 메트릭 포함\"\n✅ \"아키텍처 다이어그램 Confluence 페이지 링크 첨부\"\n```\n\n### 🚫 실수 2: 체크리스트만 있고 프로세스 설명이 없음\n\n**문제:** 감사관이 \"이 체크리스트를 언제, 누가, 어떻게 사용하는가?\"라고 질문했을 때 답변 불가\n\n**해결:** 체크리스트 사용 프로세스를 별도 문서로 작성\n- ORR 미팅 개최 트리거 조건\n- 체크리스트 작성 책임자\n- 검토 및 승인 권한자\n- No-Go 결정 시 후속 프로세스\n\n### 🚫 실수 3: 실제 수행 증빙 부재\n\n**문제:** 프로세스 문서만 있고, 실제로 사용한 증거가 없음\n\n**해결:** 최소 2개 이상의 실제 프로젝트에서 수행한 증빙 제출\n- 작성 완료된 체크리스트 (고객명 마스킹 가능)\n- ORR 미팅 회의록\n- Go-Live 승인 이메일/티켓\n\n### 🚫 실수 4: 운영팀 참여 증거 부족\n\n**",
      "language": "ko",
      "createdAt": "2026-01-07T01:51:23.567Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-005_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-005",
      "category": "Governance",
      "title": "공동 책임 모델",
      "advice": "# GOV-005: 공동 책임 모델 (RACI 매트릭스) 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS MSP는 고객의 클라우드 환경을 **대신 운영**합니다. 이 과정에서 \"누가 무엇을 책임지는가\"가 명확하지 않으면 보안 사고, 서비스 장애, 컴플라이언스 위반 시 책임 공방이 발생합니다. AWS는 MSP 파트너가 **고객과의 책임 경계를 문서화**하고, 이를 **온보딩 시점에 고객에게 명확히 전달**하는지 검증합니다.\n\n### 🎯 감사관이 확인하는 핵심 포인트\n\n| # | 확인 포인트 | 감사관의 질문 예시 |\n|---|------------|-------------------|\n| 1 | **AWS 공동 책임 모델과의 연계** | \"AWS의 책임, MSP의 책임, 고객의 책임이 어떻게 구분되어 있습니까?\" |\n| 2 | **RACI의 완전성** | \"IAM 정책 변경은 누가 Responsible이고 누가 Accountable입니까?\" |\n| 3 | **보안 영역의 명확한 구분** | \"고객 데이터 암호화 키 관리는 누구 책임입니까?\" |\n| 4 | **운영 영역의 책임 정의** | \"패치 적용 지연으로 인한 보안 사고 시 책임 소재는?\" |\n| 5 | **고객 서명/동의 증빙** | \"고객이 이 RACI에 동의했다는 증거가 있습니까?\" |\n\n### 관련 AWS 개념 및 서비스\n\n- **AWS Shared Responsibility Model** (보안/컴플라이언스의 기본 프레임워크)\n- **AWS Control Tower** (계정 거버넌스에서 책임 분리)\n- **AWS Organizations** (SCP를 통한 책임 경계 기술적 구현)\n- **AWS Artifact** (컴플라이언스 문서에서 AWS 책임 범위 확인)\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 문서\n\n```\n📁 GOV-005_Evidence/\n├── 📄 Customer_Onboarding_Package_v2.3.pdf\n│   └── Section 4: Roles & Responsibilities (RACI Matrix 포함)\n├── 📊 RACI_Matrix_Template_AWS_MSP.xlsx\n│   └── 실제 고객사에 적용된 버전 (고객명 마스킹)\n├── 📄 Signed_Service_Agreement_CustomerA.pdf\n│   └── RACI 참조 조항이 포함된 계약서\n└── 📧 Onboarding_Kickoff_Email_Sample.eml\n    └── RACI 문서 전달 및 검토 요청 이메일\n```\n\n### 📊 RACI 매트릭스에 반드시 포함되어야 할 영역\n\n#### **보안 책임 영역 (Security)**\n| 활동 | AWS | MSP 파트너 | 고객 |\n|------|-----|-----------|------|\n| 물리적 데이터센터 보안 | **R/A** | I | I |\n| VPC 네트워크 설계 및 구성 | I | **R/A** | C |\n| Security Group 규칙 변경 | - | **R** | **A/C** |\n| IAM 사용자/역할 생성 | - | **R** | **A** |\n| 고객 애플리케이션 코드 보안 | - | C | **R/A** |\n| KMS 키 생성 및 관리 | I | **R** | **A** |\n| GuardDuty 알림 대응 | - | **R** | **A/C** |\n\n#### **운영 책임 영역 (Operations)**\n| 활동 | AWS | MSP 파트너 | 고객 |\n|------|-----|-----------|------|\n| EC2 인스턴스 OS 패치 | - | **R/A** | I |\n| RDS 엔진 버전 업그레이드 | C | **R** | **A** |\n| 백업 정책 수립 및 실행 | - | **R/A** | C |\n| 재해복구 테스트 실행 | - | **R** | **A/C** |\n| 비용 최적화 권고 | - | **R** | **A** |\n| 24/7 모니터링 및 알림 | - | **R/A** | I |\n\n#### **컴플라이언스 책임 영역 (Compliance)**\n| 활동 | AWS | MSP 파트너 | 고객 |\n|------|-----|-----------|------|\n| AWS 인프라 SOC2 인증 | **R/A** | I | I |\n| 고객 환경 로그 보관 (CloudTrail) | - | **R** | **A** |\n| 개인정보 처리 정책 수립 | - | C | **R/A** |\n| 정기 보안 감사 수행 | - | **R** | **A/C** |\n\n### 📄 온보딩 문서에 포함되어야 할 섹션\n\n```markdown\n## 온보딩 문서 목차 예시\n\n1. 서비스 개요\n2. AWS 공동 책임 모델 설명\n   2.1 AWS의 책임 (\"Security OF the Cloud\")\n   2.2 고객의 책임 (\"Security IN the Cloud\")\n   2.3 MSP 파트너의 역할\n3. **역할 및 책임 매트릭스 (RACI)**  ← 핵심 섹션\n   3.1 보안 관리 영역\n   3.2 운영 관리 영역\n   3.3 컴플라이언스 영역\n   3.4 비용 관리 영역\n4. 에스컬레이션 절차\n5. 책임 범위 변경 프로세스\n6. 고객 확인 및 서명란\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: AWS 공동 책임 모델 기반 프레임워크 수립 (2일)\n\n**담당자**: 보안 아키텍트 + 서비스 매니저\n\n```\n🔧 실행 항목:\n1. AWS 공식 Shared Responsibility Model 문서 검토\n   → https://aws.amazon.com/compliance/shared-responsibility-model/\n   \n2. 귀사 MSP 서비스 범위에 맞게 3자 책임 구조 정의:\n   - AWS 책임: 하이퍼바이저 이하 인프라\n   - MSP 책임: 고객 위임 운영 영역\n   - 고객 책임: 비즈니스 로직, 데이터 분류\n```\n\n### Step 2: 서비스 카탈로그 기반 활동 목록 작성 (3일)\n\n**담당자**: 서비스 매니저 + 운영팀 리드\n\n```\n📋 활동 목록 도출 방법:\n1. 현재 제공 중인 MSP 서비스 목록 나열\n2. 각 서비스를 세부 활동으로 분해\n   예: \"보안 관리 서비스\" \n       → IAM 관리, 보안 그룹 관리, 암호화 관리, 취약점 스캔...\n3. 최소 50개 이상의 활동 항목 도출\n```\n\n**활동 목록 예시 (일부)**:\n- 계정 생성 및 초기 설정\n- VPC 아키텍처 설계\n- EC2 인스턴스 프로비저닝\n- Auto Scaling 정책 설정\n- CloudWatch 알람 구성\n- S3 버킷 정책 관리\n- RDS 백업 설정\n- Lambda 함수 배포\n- API Gateway 구성\n- WAF 규칙 관리\n\n### Step 3: RACI 할당 워크숍 진행 (1일)\n\n**담당자**: 전체 기술팀 + 영업팀\n\n```\n🏢 워크숍 진행 방법:\n1. 각 활동에 대해 다음 질문에 답변:\n   - \"이 작업을 실제로 수행하는 사람은?\" → R (Responsible)\n   - \"이 작업의 최종 승인권자는?\" → A (Accountable)\n   - \"이 작업 전에 의견을 구해야 하는 사람은?\" → C (Consulted)\n   - \"이 작업 완료 후 알려야 하는 사람은?\" → I (Informed)\n\n2. 주의: 각 활동에 A는 반드시 1명만!\n```\n\n### Step 4: 고객 유형별 RACI 변형 버전 작성 (2일)\n\n**담당자**: 서비스 매니저\n\n```\n📊 고객 유형별 차이점:\n┌─────────────────┬──────────────────┬──────────────────┐\n│     활동        │ 풀 매니지드 고객  │ 코매니지드 고객   │\n├─────────────────┼──────────────────┼──────────────────┤\n│ IAM 사용자 생성  │ MSP: R/A         │ MSP: R, 고객: A  │\n│ 보안그룹 변경    │ MSP: R/A         │ MSP: C, 고객: R/A│\n│ 비용 리포트 작성 │ MSP: R/A         │ MSP: R, 고객: A  │\n└─────────────────┴──────────────────┴──────────────────┘\n```\n\n### Step 5: 온보딩 문서 패키지 통합 (2일)\n\n**담당자**: 기술 문서 담당자\n\n```\n📄 문서 구성:\n1. RACI 매트릭스를 온보딩 문서의 핵심 섹션으로 배치\n2. AWS 공동 책임 모델 다이어그램 삽입\n3. 각 책임 영역에 대한 상세 설명 추가\n4. 고객 서명란 및 날짜 기입란 포함\n```\n\n### Step 6: 법무/계약팀 검토 (3일)\n\n**담당자**: 법무팀 + 서비스 매니저\n\n```\n⚖️ 검토 포인트:\n1. RACI 내용이 MSA(기본 서비스 계약)와 충돌하지 않는지 확인\n2. 책임 제한 조항과 RACI의 정합성 검토\n3. SLA 문서와 RACI의 연계성 확인\n```\n\n### Step 7: 실제 고객 온보딩에 적용 및 증빙 수집 (지속)\n\n**담당자**: 고객 성공팀\n\n```\n📧 증빙 수집 방법:\n1. 온보딩 킥오프 미팅에서 RACI 설명 (녹화)\n2. 이메일로 RACI 문서 공식 전달\n3. 고객 서명이 포함된 온보딩 체크리스트 수령\n4. 모든 커뮤니케이션 아카이빙\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 감사 탈락을 유발하는 치명적 실수\n\n#### 실수 1: \"AWS 책임\"을 RACI에서 누락\n```\n❌ 잘못된 예:\n| 활동 | MSP | 고객 |  ← AWS 열이 없음!\n\n✅ 올바른 예:\n| 활동 | AWS | MSP | 고객 |  ← 3자 구조 필수\n```\n**감사관 지적**: \"AWS 공동 책임 모델을 이해하고 있다면, AWS의 책임 영역도 명시되어야 합니다.\"\n\n#### 실수 2: 하나의 활동에 A(Accountable)가 2명 이상\n```\n❌ 잘못된 예:\n| IAM 정책 변경 | - | R/A | A |  ← A가 2개!\n\n✅ 올바른 예:\n| IAM 정책 변경 | - | R | A |  ← A는 반드시 1명\n```\n**감사관 지적**: \"Accountable이 2명이면 실제 책임자가 없는 것과 같습니다.\"\n\n#### 실수 3: 보안 관련 항목의 책임이 모호함\n```\n❌ 잘못된 예:\n| 보안 관리 | - | R/A | C |  ← \"보안 관리\"가 너무 포괄적\n\n✅ 올바른 예:\n| Security Group 인바운드 규칙 변경 | - | R | A |\n| NACL 규칙 변경 | - | R | A |\n| WAF 규칙 추가 | - | R/A | C |\n| GuardDuty 알림 조사 | - | R | A |\n```\n**감사관 지적**: \"보안 사고 발생 시 구체적으로 누가 무엇을 해야 하는지 알 수 없습니다.\"\n\n#### 실수 4: 고객 동의 증빙 없음\n```\n❌ 잘못된 예:\n- RACI 문서만 제출\n- 내부 승인 문서만 제출\n\n✅ 올바른 예:\n- 고객 서명이 포함된 온보딩 체크리스트",
      "language": "ko",
      "createdAt": "2026-01-07T01:52:25.649Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-006_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-006",
      "category": "Governance",
      "title": "지속가능성 모범 사례",
      "advice": "# GOV-006: 지속가능성 모범 사례 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS는 2025년까지 100% 재생 에너지로 운영한다는 목표를 가지고 있으며, MSP 파트너가 이 비전을 고객에게 전달하고 실현하는 핵심 역할을 합니다. **지속가능성은 이제 선택이 아닌 비즈니스 필수 요소**로, 고객사의 ESG 보고서에 클라우드 탄소 발자국이 포함되는 시대입니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **🎯 측정 가능한 개선** | \"에너지 효율 20% 향상\" 같은 정량적 결과가 있는가? |\n| **🔄 체계적 접근** | 일회성이 아닌 지속적인 최적화 프로세스가 있는가? |\n| **📊 AWS 도구 활용** | Customer Carbon Footprint Tool, Compute Optimizer 등을 실제 사용하는가? |\n| **👥 고객 가치 전달** | 고객에게 지속가능성 개선을 제안하고 구현한 실적이 있는가? |\n| **📅 12개월 내 활동** | 최근 1년 내에 실제로 수행한 활동인가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    지속가능성 관련 AWS 도구                    │\n├─────────────────────────────────────────────────────────────┤\n│ 📊 측정 도구                                                  │\n│   • Customer Carbon Footprint Tool (Cost Explorer 내)        │\n│   • AWS Compute Optimizer                                    │\n│   • AWS Cost Explorer (사용량 분석)                           │\n├─────────────────────────────────────────────────────────────┤\n│ ⚡ 최적화 서비스                                               │\n│   • Graviton 프로세서 (최대 60% 에너지 효율)                   │\n│   • Spot Instances                                           │\n│   • Auto Scaling                                             │\n│   • S3 Intelligent-Tiering                                   │\n├─────────────────────────────────────────────────────────────┤\n│ 🌍 리전 선택                                                  │\n│   • 재생에너지 100% 리전 우선 고려                             │\n│   • 사용자 근접 리전 (네트워크 홉 최소화)                       │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 지속가능성 개선 사례 보고서\n**파일명 예시:** `Sustainability_Improvement_Report_2024_CustomerA.pdf`\n\n```markdown\n## 포함되어야 할 핵심 내용\n\n### 1. 고객 정보 (익명화 가능)\n- 산업군: 전자상거래\n- 워크로드 유형: 웹 애플리케이션 + 데이터 분석\n\n### 2. 개선 전 상태 (Before)\n- EC2 인스턴스: m5.xlarge 24대 (24/7 운영)\n- 월간 예상 탄소 배출량: 4.2 tCO2e\n- 평균 CPU 사용률: 15%\n\n### 3. 수행한 최적화 작업\n- Graviton3 기반 m7g.large로 마이그레이션\n- Auto Scaling 적용 (최소 6대 ~ 최대 18대)\n- 비업무 시간 스케줄링 적용\n\n### 4. 개선 후 상태 (After)\n- 월간 예상 탄소 배출량: 1.8 tCO2e (57% 감소)\n- 평균 CPU 사용률: 45%\n- 비용 절감: 월 $2,400\n\n### 5. 측정 방법\n- AWS Customer Carbon Footprint Tool 스크린샷\n- Compute Optimizer 권장사항 적용 전/후 비교\n```\n\n#### 📄 문서 2: 지속가능성 아키텍처 리뷰 체크리스트\n**파일명 예시:** `Sustainability_Architecture_Review_Checklist_v2.1.xlsx`\n\n| 영역 | 점검 항목 | 적용 여부 | 개선 제안 |\n|-----|---------|---------|---------|\n| **컴퓨팅** | Graviton 프로세서 사용 가능 여부 | ✅ | m7g로 전환 권장 |\n| **컴퓨팅** | Right-sizing 분석 수행 | ✅ | 12개 인스턴스 다운사이징 |\n| **스토리지** | S3 Intelligent-Tiering 적용 | ❌ | 30일 이상 미접근 데이터 대상 적용 |\n| **데이터** | 불필요한 데이터 정리 정책 | ✅ | 90일 로그 자동 삭제 적용 |\n| **네트워크** | 리전 선택 최적화 | ✅ | 사용자 80%가 위치한 ap-northeast-2 사용 |\n\n#### 📄 문서 3: 고객 제안서/권고 보고서\n**파일명 예시:** `Sustainability_Recommendations_CustomerB_202403.pdf`\n\n```\n실제 고객에게 전달한 제안서 예시:\n\n제목: [고객사명] AWS 워크로드 지속가능성 최적화 제안\n\n1. 현재 환경 분석\n   - Carbon Footprint Tool 데이터 기반 현황\n   \n2. 개선 기회 식별\n   - 단기 (1개월): Compute Optimizer 권장사항 적용\n   - 중기 (3개월): Graviton 마이그레이션\n   - 장기 (6개월): 서버리스 아키텍처 전환\n   \n3. 예상 효과\n   - 탄소 배출량: 40% 감소 예상\n   - 비용: 25% 절감 예상\n   \n4. 실행 로드맵\n```\n\n#### 📄 문서 4: 내부 지속가능성 정책/가이드라인\n**파일명 예시:** `MSP_Sustainability_Best_Practices_Guide_v1.0.pdf`\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 고객 환경의 탄소 발자국 측정 (1주)\n```bash\n# AWS CLI로 Carbon Footprint 데이터 확인\naws ce get-cost-and-usage \\\n  --time-period Start=2024-01-01,End=2024-03-31 \\\n  --granularity MONTHLY \\\n  --metrics \"UsageQuantity\" \\\n  --group-by Type=DIMENSION,Key=SERVICE\n```\n\n**실행 항목:**\n- [ ] 관리 중인 모든 고객 계정에서 Customer Carbon Footprint Tool 활성화\n- [ ] 최근 12개월 탄소 배출량 데이터 다운로드\n- [ ] 고객별 베이스라인 문서화\n\n**담당:** 클라우드 엔지니어 / **소요 시간:** 고객당 2시간\n\n---\n\n### Step 2: Compute Optimizer 분석 및 권장사항 추출 (1주)\n```python\n# Compute Optimizer 권장사항 자동 추출 스크립트 예시\nimport boto3\n\ndef get_optimization_recommendations():\n    client = boto3.client('compute-optimizer')\n    \n    # EC2 권장사항\n    ec2_recommendations = client.get_ec2_instance_recommendations()\n    \n    # 에너지 효율 관점 필터링\n    energy_efficient = [\n        rec for rec in ec2_recommendations['instanceRecommendations']\n        if 'graviton' in rec['recommendationOptions'][0]['instanceType'].lower()\n        or rec['finding'] == 'OVER_PROVISIONED'\n    ]\n    \n    return energy_efficient\n```\n\n**실행 항목:**\n- [ ] 모든 관리 계정에서 Compute Optimizer 활성화\n- [ ] Over-provisioned 리소스 목록 생성\n- [ ] Graviton 전환 가능 워크로드 식별\n\n**담당:** Solutions Architect / **소요 시간:** 고객당 4시간\n\n---\n\n### Step 3: 지속가능성 개선 프로젝트 실행 (4-8주)\n\n#### 우선순위 높은 개선 작업 예시:\n\n| 작업 | 예상 탄소 감소 | 난이도 | 소요 시간 |\n|-----|--------------|-------|---------|\n| **Graviton 마이그레이션** | 40-60% | 중 | 2-4주 |\n| **Right-sizing** | 20-30% | 하 | 1주 |\n| **Auto Scaling 적용** | 15-25% | 중 | 1-2주 |\n| **S3 Intelligent-Tiering** | 10-15% | 하 | 1일 |\n| **비활성 리소스 정리** | 즉시 효과 | 하 | 1주 |\n\n**실제 구현 예시 (Graviton 마이그레이션):**\n```yaml\n# CloudFormation 템플릿 - Graviton 인스턴스로 전환\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: 'Sustainability-optimized EC2 configuration'\n\nResources:\n  SustainableWebServer:\n    Type: AWS::EC2::Instance\n    Properties:\n      InstanceType: m7g.large  # Graviton3 기반\n      ImageId: !Ref LatestArmAmiId\n      Tags:\n        - Key: Sustainability\n          Value: Graviton-Optimized\n        - Key: CarbonReduction\n          Value: \"40-percent-vs-x86\"\n```\n\n---\n\n### Step 4: 개선 결과 측정 및 문서화 (1주)\n\n**Before/After 비교 템플릿:**\n\n```\n┌────────────────────────────────────────────────────────────┐\n│           고객 A - 지속가능성 개선 결과 요약                  │\n├────────────────────────────────────────────────────────────┤\n│                                                            │\n│  📊 탄소 배출량 (tCO2e/월)                                  │\n│  ┌─────────────────────────────────────────────────────┐  │\n│  │ Before (2024.01): ████████████████████ 8.5          │  │\n│  │ After  (2024.03): ████████████ 5.1                  │  │\n│  │                                                     │  │\n│  │ 감소율: 40% ✅                                       │  │\n│  └─────────────────────────────────────────────────────┘  │\n│                                                            │\n│  💰 비용 변화                                               │\n│  Before: $12,400/월 → After: $8,200/월 (34% 절감)         │\n│                                                            │\n│  🔧 적용된 최적화                                           │\n│  • EC2: m5.2xlarge → m7g.xlarge (8대)                     │\n│  • Auto Scaling: 피크 시간 외 50% 축소                      │\n│  • S3: 2TB 데이터 Glacier로 이동                           │\n│                                                            │\n│  📅 프로젝트 기간: 2024.02.01 ~ 2024.03.15                 │\n│                                                            │\n└────────────────────────────────────────────────────────────┘\n```\n\n---\n\n### Step 5: 고객 커뮤니케이션 및 제안 이력 정리 (3일)\n\n**증빙으로 사용할 커뮤니케이션 예시:**\n- 이메일: 지속가능성 개선 제안서 발송 이력\n- 회의록: 고객과의 지속가능성 리뷰 미팅 기록\n- 티켓: Jira/ServiceNow에서 지속가능성 관련 작업 이력\n\n```\n[이메일 예시]\n제목: [월간 리포트] ABC Corp AWS 환경 지속가능성 현황 - 2024년 3월\n\n안녕하세요, ABC Corp 클라우드 운영팀입니다.\n\n이번 달 지속가능성 개선 현황을 공유드립니다.\n\n1. 탄소 발자국 현황\n   - 이번 달: 5.1 tCO2e (전월 대비 12% 감소)\n   \n2. 이번 달 적용된 최적화\n   - Graviton 마이그레이션 완료 (웹 서버 클러스터)\n   \n3. 다음 달 계획\n   - 데이터베이스 Right-sizing 검토\n   - 개발 환경 야간 자동 중지 적용\n\n자세한 내용은 첨부된 리포트를 참고해 주세요.\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 비용 절감만 강조하고 지속가능성 관점 누락\n\n**❌ 잘못된 예:**\n> \"Compute Optimizer를 통해 인스턴스 크기를 줄여 월 $5,000 절감했습니다.\"\n\n**✅ 올바른 예:**\n> \"Compute Optimizer 권장사항에 따라 over-provisioned 인스",
      "language": "ko",
      "createdAt": "2026-01-07T01:53:27.685Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOVP-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOVP-001",
      "category": "Governance",
      "title": "공급업체 관리",
      "advice": "# GOVP-001: 공급업체 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS MSP 파트너는 고객의 클라우드 환경을 관리하면서 다양한 제3자 도구와 서비스를 활용합니다. **공급업체 체인의 보안 취약점은 곧 고객 환경의 위험으로 직결**됩니다. 2023년 SolarWinds 사태 이후, AWS는 MSP 파트너의 공급망 보안 관리 역량을 더욱 엄격히 평가하고 있습니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **1. 선택 기준의 명확성** | \"어떤 기준으로 Datadog vs CloudWatch를 선택했는가?\" 같은 의사결정 근거 |\n| **2. 보안 평가 수행 여부** | 공급업체의 SOC2/ISO 27001 인증서를 실제로 검토하고 보관하는지 |\n| **3. 지속적 모니터링** | 최초 선택 후에도 연간 재평가를 수행하는지 |\n| **4. 데이터 처리 계약** | DPA(Data Processing Agreement) 체결 및 관리 현황 |\n| **5. 퇴출 절차** | 공급업체가 기준 미달 시 어떻게 대체하는지 |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS Marketplace**: 사전 검증된 ISV 솔루션 조달 시 활용\n- **AWS Artifact**: AWS 자체의 SOC2, ISO 27001 인증서 다운로드\n- **AWS Service Catalog**: 승인된 공급업체 도구만 프로비저닝 가능하도록 제한\n- **AWS Config Rules**: 승인되지 않은 제3자 통합 탐지\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 GOVP-001_공급업체관리/\n├── 📄 SOP-VEN-001_공급업체_선택_및_평가_절차서.pdf\n├── 📄 VEN-EVAL-TEMPLATE_공급업체_보안평가_체크리스트.xlsx\n├── 📁 승인된_공급업체_목록/\n│   ├── 📄 Approved_Vendor_List_2024.xlsx\n│   └── 📄 Vendor_Risk_Tier_Matrix.pdf\n├── 📁 공급업체별_인증서/\n│   ├── 📄 Datadog_SOC2_Type2_2024.pdf\n│   ├── 📄 PagerDuty_ISO27001_Certificate.pdf\n│   └── 📄 Terraform_Cloud_SOC2_Report.pdf\n├── 📁 평가_수행_증적/\n│   ├── 📄 Datadog_Security_Assessment_2024Q1.pdf\n│   └── 📄 Vendor_Review_Meeting_Minutes_20240315.pdf\n└── 📄 DPA_계약서_목록_및_사본/\n    └── 📄 Datadog_DPA_Signed_2024.pdf\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📄 공급업체 선택 및 평가 SOP\n```markdown\n필수 포함 섹션:\n1. 목적 및 적용 범위\n2. 공급업체 분류 기준 (Tier 1/2/3)\n   - Tier 1: 고객 데이터 접근 가능 (예: 모니터링 도구)\n   - Tier 2: 인프라 접근 가능 (예: IaC 도구)\n   - Tier 3: 간접 지원 (예: 문서화 도구)\n3. 선택 프로세스 플로우차트\n4. 보안 평가 체크리스트 (Tier별 차등 적용)\n5. 승인 권한 매트릭스\n6. 연간 재평가 일정\n7. 공급업체 퇴출 절차\n```\n\n#### 📄 승인된 공급업체 목록 (AVL) 예시 형식\n\n| 공급업체명 | 서비스 유형 | Tier | 인증 현황 | 최종 평가일 | 다음 평가일 | 담당자 | 상태 |\n|-----------|------------|------|----------|------------|------------|--------|------|\n| Datadog | 모니터링 | 1 | SOC2 Type2, ISO27001 | 2024-01-15 | 2025-01-15 | 김보안 | Active |\n| HashiCorp | IaC | 2 | SOC2 Type2 | 2024-02-20 | 2025-02-20 | 이인프라 | Active |\n| Confluence | 문서화 | 3 | SOC2 Type2 | 2024-03-10 | 2025-03-10 | 박협업 | Active |\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 사용 중인 공급업체 인벤토리 작성 (3일)\n\n**담당자**: 인프라팀 + 보안팀\n\n```bash\n# AWS 환경에서 제3자 통합 현황 파악\n# 1. IAM Role 중 외부 서비스용 확인\naws iam list-roles --query \"Roles[?contains(AssumeRolePolicyDocument.Statement[0].Principal.Service, 'amazonaws.com')==\\`false\\`]\"\n\n# 2. EventBridge에 연결된 외부 대상 확인\naws events list-targets-by-rule --rule <rule-name>\n\n# 3. Secrets Manager에서 제3자 API 키 목록 확인\naws secretsmanager list-secrets --query \"SecretList[*].Name\"\n```\n\n**산출물**: `Current_Vendor_Inventory_Raw.xlsx`\n\n---\n\n### Step 2: 공급업체 Tier 분류 기준 수립 (2일)\n\n**담당자**: 보안팀 + 컴플라이언스팀\n\n```\n🔴 Tier 1 (High Risk) - 필수 요구사항: SOC2 Type2 + ISO27001\n   - 고객 데이터에 직접 접근\n   - 예: Datadog, Splunk, New Relic (로그에 민감정보 포함 가능)\n\n🟡 Tier 2 (Medium Risk) - 필수 요구사항: SOC2 Type2\n   - 인프라 구성 접근 가능\n   - 예: Terraform Cloud, Ansible Tower, Jenkins\n\n🟢 Tier 3 (Low Risk) - 권장 요구사항: SOC2 Type1 이상\n   - 간접적 지원 도구\n   - 예: Jira, Confluence, Slack\n```\n\n---\n\n### Step 3: 공급업체별 인증서 수집 (5일)\n\n**담당자**: 구매팀 + 보안팀\n\n**실제 수집 방법**:\n- **Datadog**: Trust Center (https://trust.datadoghq.com) → SOC2 Report 요청\n- **HashiCorp**: Security 페이지에서 NDA 서명 후 다운로드\n- **PagerDuty**: 영업 담당자에게 직접 요청 필요\n\n```\n⚠️ 주의: 인증서 유효기간 반드시 확인\n   - SOC2 Type2: 보통 12개월 유효\n   - ISO27001: 3년 유효 (연간 감시심사 필요)\n```\n\n---\n\n### Step 4: 보안 평가 체크리스트 기반 평가 수행 (7일)\n\n**담당자**: 보안팀\n\n**Tier 1 공급업체 평가 체크리스트 예시**:\n\n```markdown\n## Datadog 보안 평가 - 2024년 1분기\n\n### 데이터 보안 (가중치 30%)\n- [x] 전송 중 암호화: TLS 1.2 이상 ✅\n- [x] 저장 시 암호화: AES-256 ✅\n- [x] 데이터 보존 정책: 15개월 후 자동 삭제 ✅\n- [x] 데이터 센터 위치: 고객 선택 가능 (US/EU/AP) ✅\n\n### 접근 제어 (가중치 25%)\n- [x] SSO/SAML 지원: 지원 ✅\n- [x] MFA 강제: 가능 ✅\n- [x] RBAC: 세분화된 권한 관리 ✅\n- [ ] IP 화이트리스트: Enterprise 플랜만 지원 ⚠️\n\n### 인증 현황 (가중치 25%)\n- [x] SOC2 Type2: 유효 (2024-08-31까지) ✅\n- [x] ISO27001: 유효 (2025-12-15까지) ✅\n- [x] GDPR 준수: DPA 체결 완료 ✅\n\n### 인시던트 대응 (가중치 20%)\n- [x] 상태 페이지: status.datadoghq.com ✅\n- [x] SLA: 99.9% uptime 보장 ✅\n- [x] 보안 사고 통지: 72시간 내 ✅\n\n📊 종합 점수: 92/100 → 승인\n```\n\n---\n\n### Step 5: SOP 문서 작성 (5일)\n\n**담당자**: 컴플라이언스팀\n\n**SOP 핵심 프로세스 플로우**:\n\n```\n[신규 공급업체 요청]\n        ↓\n[Tier 분류 결정] ──────────────────┐\n        ↓                          │\n[보안 평가 수행]                    │\n   ├─ Tier 1: 전체 평가 (20개 항목) │\n   ├─ Tier 2: 표준 평가 (15개 항목) │\n   └─ Tier 3: 간소화 평가 (8개 항목)│\n        ↓                          │\n[인증서 검증]                       │\n   ├─ SOC2 Report 검토             │\n   └─ ISO27001 인증서 확인          │\n        ↓                          │\n[승인 위원회 검토] ←────────────────┘\n   ├─ Tier 1: CISO + CTO 승인 필요\n   ├─ Tier 2: 보안팀장 승인\n   └─ Tier 3: 팀장 승인\n        ↓\n[AVL 등록 및 DPA 체결]\n        ↓\n[연간 재평가 일정 등록]\n```\n\n---\n\n### Step 6: 연간 재평가 프로세스 실행 증적 생성 (3일)\n\n**담당자**: 보안팀\n\n```\n📅 연간 재평가 일정 예시:\n- Q1: Tier 1 공급업체 전체 재평가\n- Q2: Tier 2 공급업체 전체 재평가  \n- Q3: Tier 3 공급업체 전체 재평가\n- Q4: 신규 인증서 갱신 확인 및 AVL 업데이트\n```\n\n**재평가 회의록 템플릿**:\n```markdown\n# 공급업체 재평가 회의록\n\n일시: 2024-03-15 14:00\n참석자: 김보안(보안팀장), 이인프라(인프라팀장), 박컴플(컴플라이언스)\n\n## 안건: Datadog 연간 재평가\n\n### 검토 항목\n1. SOC2 Type2 Report 갱신 확인 → 2024-02-28 갱신 완료\n2. 지난 1년간 보안 인시던트 → 없음\n3. 서비스 가용성 실적 → 99.95% (SLA 충족)\n4. 가격 변동 → 10% 인상 예정 (2024-07 적용)\n\n### 결정사항\n- 상태: 계속 사용 승인\n- 다음 재평가: 2025-03-15\n\n### 서명\n- 보안팀장: 김보안 (전자서명)\n- 인프라팀장: 이인프라 (전자서명)\n```\n\n---\n\n### Step 7: AWS Service Catalog로 승인된 도구만 사용 강제 (2일)\n\n**담당자**: 인프라팀\n\n```yaml\n# Service Catalog 제품 정의 예시 - 승인된 모니터링 도구만 허용\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: 'Approved Monitoring Tools - GOVP-001 Compliant'\n\nParameters:\n  MonitoringTool:\n    Type: String\n    AllowedValues:\n      - Datadog      # AVL 승인: 2024-01-15\n      - CloudWatch   # AWS Native\n      - NewRelic     # AVL 승인: 2024-02-20\n    Description: 'Only approved vendors from AVL allowed'\n\nConditions:\n  UseDatadog: !Equals [!Ref MonitoringTool, 'Datadog']\n  \nResources:\n  DatadogIntegration:\n    Type: 'AWS::CloudFormation::Stack'\n    Condition: UseDatadog\n    Properties:\n      TemplateURL: 'https://s3.amazonaws.com/approved-templates/datadog-integration.yaml'\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 유형 | 구체적 사례",
      "language": "ko",
      "createdAt": "2026-01-07T01:31:03.299Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOVP-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOVP-002",
      "category": "Governance",
      "title": "운영 개선",
      "advice": "# GOVP-002: 운영 개선 - AWS MSP 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n운영 개선(Continuous Improvement)은 AWS MSP의 핵심 철학인 **\"Day 2 Operations\"**의 성숙도를 판단하는 지표입니다. AWS는 단순히 인프라를 운영하는 것이 아니라, **운영 데이터를 기반으로 지속적으로 진화하는 MSP**를 파트너로 원합니다. 이 항목은 MSP가 \"현상 유지\"가 아닌 \"능동적 최적화\"를 수행하는지 검증합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **개선 기회 식별 체계** | 인시던트, 비용, 성능 데이터에서 패턴을 분석하여 개선점을 도출하는 구조화된 방법이 있는가? |\n| **우선순위 결정 프레임워크** | 식별된 개선 기회를 비즈니스 영향도, 구현 난이도 기준으로 순위를 매기는 명확한 기준이 있는가? |\n| **정기적 검토 주기** | 월간/분기별 운영 검토 회의가 실제로 진행되고, 회의록이 존재하는가? |\n| **개선 실행 추적** | 식별된 개선 항목이 실제로 구현되었는지 추적하는 메커니즘이 있는가? |\n| **다영역 커버리지** | 인시던트, 비용, 아키텍처, 성능, 보안 5개 영역 모두를 검토 범위에 포함하는가? |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS Trusted Advisor**: 비용, 성능, 보안, 내결함성 개선 권장사항 자동 식별\n- **AWS Well-Architected Tool**: 워크로드별 개선 기회 체계적 평가\n- **AWS Cost Explorer + Cost Anomaly Detection**: 비용 최적화 기회 탐지\n- **Amazon CloudWatch Contributor Insights**: 성능 병목 패턴 분석\n- **AWS Security Hub**: 보안 개선 항목 통합 관리\n- **AWS Systems Manager OpsCenter**: 운영 이슈 및 개선 항목 추적\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 📁 필수 증빙 자료 목록\n\n#### 문서 1: 운영 개선 거버넌스 정책서\n**파일명 예시**: `OPS-GOV-001_Continuous_Improvement_Policy_v2.3.pdf`\n\n```\n포함되어야 할 핵심 내용:\n├── 1. 개선 기회 식별 소스 정의\n│   ├── 인시던트 Post-Mortem 분석 결과\n│   ├── Trusted Advisor 권장사항\n│   ├── Well-Architected Review 결과\n│   ├── 월간 비용 분석 보고서\n│   └── Security Hub 발견 항목\n│\n├── 2. 검토 주기 및 참여자\n│   ├── 주간: 인시던트 트렌드 검토 (운영팀)\n│   ├── 월간: 비용/성능 최적화 검토 (기술팀 + 재무팀)\n│   └── 분기: 아키텍처/보안 종합 검토 (전체 이해관계자)\n│\n├── 3. 우선순위 결정 매트릭스\n│   ├── 비즈니스 영향도 (High/Medium/Low)\n│   ├── 구현 복잡도 (High/Medium/Low)\n│   └── 예상 ROI 계산 방식\n│\n└── 4. 개선 항목 라이프사이클\n    ├── 식별 → 평가 → 승인 → 구현 → 검증 → 종료\n    └── 각 단계별 책임자 및 SLA\n```\n\n#### 문서 2: 운영 검토 회의록 (최근 3개월)\n**파일명 예시**: `OPS-REVIEW-2024-Q4-Monthly_Meeting_Minutes.pdf`\n\n```\n회의록에 반드시 포함될 내용:\n├── 회의 일시, 참석자, 안건\n├── 검토된 운영 메트릭 요약\n│   ├── 인시던트: 총 건수, MTTR, 반복 인시던트 비율\n│   ├── 비용: 예산 대비 실적, 이상 지출 항목\n│   ├── 성능: SLA 달성률, 주요 병목 지점\n│   └── 보안: 신규 발견 항목, 미해결 취약점\n├── 식별된 개선 기회 목록\n├── 우선순위 결정 결과 및 근거\n├── 이전 회의 액션 아이템 진행 상황\n└── 신규 액션 아이템 및 담당자 배정\n```\n\n#### 문서 3: 개선 기회 추적 대시보드/레지스터\n**파일명 예시**: `OPS-IMP-REGISTER-2024_Improvement_Backlog.xlsx`\n\n```\n추적 레지스터 필수 컬럼:\n├── ID: IMP-2024-001\n├── 영역: [인시던트|비용|아키텍처|성능|보안]\n├── 제목: \"RDS 읽기 복제본 추가로 DB 부하 분산\"\n├── 식별일: 2024-10-15\n├── 식별 소스: \"월간 성능 검토 회의\"\n├── 현재 상태: [식별|평가중|승인|진행중|완료|보류]\n├── 우선순위: P1/P2/P3\n├── 예상 효과: \"응답시간 30% 개선, 월 $500 추가 비용\"\n├── 담당자: 홍길동\n├── 목표 완료일: 2024-12-01\n└── 실제 완료일 및 결과: \"2024-11-20 완료, 응답시간 35% 개선 달성\"\n```\n\n#### 문서 4: 개선 실행 사례 보고서 (최소 2건)\n**파일명 예시**: `OPS-CASE-001_EC2_RightSizing_Implementation.pdf`\n\n```\n사례 보고서 구조:\n├── 배경: 어떻게 이 개선 기회가 식별되었는가?\n├── 문제 정의: 정량적 데이터로 현재 상태 설명\n├── 솔루션: 구현한 개선 내용 상세\n├── 결과: Before/After 비교 (수치 포함)\n└── 교훈: 향후 유사 상황에 적용할 학습 내용\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 개선 기회 식별 소스 매핑 (1주차)\n**담당**: 운영팀 리드 + 각 영역 담당자\n\n```\n🔧 실행 작업:\n1. AWS Trusted Advisor 활성화 및 권장사항 내보내기 설정\n   - Business/Enterprise Support 필요\n   - 주간 이메일 알림 구성\n\n2. AWS Well-Architected Tool에서 기존 워크로드 리뷰 생성\n   - 최소 3개 고객 워크로드 등록\n   - 5개 필러별 개선 항목 도출\n\n3. 인시던트 관리 시스템에서 반복 인시던트 리포트 생성\n   - 최근 6개월 인시던트 분류\n   - 근본 원인별 그룹핑\n\n4. Cost Explorer에서 비용 이상 탐지 규칙 설정\n   - 서비스별 임계값 알림 구성\n```\n\n**산출물**: 개선 기회 식별 소스 목록 및 데이터 수집 자동화 설정 완료\n\n---\n\n### Step 2: 우선순위 결정 프레임워크 수립 (1주차)\n**담당**: 기술 리더 + 비즈니스 담당자\n\n```\n📊 우선순위 매트릭스 예시:\n\n           │ 구현 용이 │ 구현 보통 │ 구현 어려움\n───────────┼──────────┼──────────┼───────────\n영향도 高  │   P1     │    P1    │    P2\n영향도 中  │   P1     │    P2    │    P3\n영향도 低  │   P2     │    P3    │    P3\n\n영향도 판단 기준:\n- 高: 월 $10,000 이상 절감 또는 SLA 5% 이상 개선\n- 中: 월 $1,000~$10,000 절감 또는 SLA 1~5% 개선\n- 低: 월 $1,000 미만 절감 또는 운영 편의성 개선\n\n구현 난이도 판단 기준:\n- 용이: 1주 이내, 단일 팀 작업\n- 보통: 1개월 이내, 다중 팀 협업\n- 어려움: 1개월 이상, 아키텍처 변경 필요\n```\n\n**산출물**: 우선순위 결정 매트릭스 문서화\n\n---\n\n### Step 3: 정기 검토 회의 체계 구축 (2주차)\n**담당**: 운영팀 리드\n\n```\n📅 검토 회의 캘린더 설정:\n\n주간 (매주 월요일 10:00, 30분)\n├── 참석: 운영팀\n├── 안건: 인시던트 트렌드, 긴급 개선 항목\n└── 도구: CloudWatch 대시보드 라이브 리뷰\n\n월간 (매월 첫째 주 금요일 14:00, 2시간)\n├── 참석: 운영팀 + 기술팀 + 재무팀\n├── 안건: 비용 분석, 성능 메트릭, 개선 백로그 검토\n└── 도구: Cost Explorer, Trusted Advisor 리포트\n\n분기 (분기 마지막 주, 반나절)\n├── 참석: 전체 이해관계자 + 경영진\n├── 안건: Well-Architected Review, 보안 감사 결과, 로드맵 수립\n└── 도구: Well-Architected Tool, Security Hub\n```\n\n**산출물**: 회의 일정 캘린더 초대 발송, 회의록 템플릿 준비\n\n---\n\n### Step 4: 개선 추적 시스템 구축 (2주차)\n**담당**: PMO 또는 운영팀\n\n```\n🛠️ 추적 시스템 옵션:\n\nOption A: Jira 프로젝트 (권장)\n├── 프로젝트: \"OPS-IMPROVEMENT\"\n├── 이슈 타입: \"Improvement Item\"\n├── 커스텀 필드: 영역, 식별소스, 예상효과, 실제효과\n└── 대시보드: 영역별 현황, 완료율, 평균 처리 시간\n\nOption B: AWS Systems Manager OpsCenter\n├── OpsItem 생성 자동화 (EventBridge 연동)\n├── Runbook으로 표준 개선 절차 자동화\n└── CloudWatch 대시보드 연동\n\nOption C: Excel/Notion (소규모 조직)\n├── 공유 스프레드시트 + 버전 관리\n└── 주간 스냅샷 저장으로 이력 관리\n```\n\n**산출물**: 개선 추적 시스템 구축 및 기존 항목 마이그레이션\n\n---\n\n### Step 5: 파일럿 검토 사이클 실행 (3-4주차)\n**담당**: 전체 팀\n\n```\n🔄 파일럿 실행 체크리스트:\n\n□ 첫 번째 월간 검토 회의 개최\n  - 실제 운영 데이터 기반 안건 준비\n  - 회의록 작성 및 액션 아이템 도출\n\n□ 최소 5개 개선 기회 식별 및 등록\n  - 인시던트 영역: 2건\n  - 비용 영역: 1건\n  - 성능/아키텍처 영역: 1건\n  - 보안 영역: 1건\n\n□ 우선순위 결정 프로세스 적용\n  - P1 항목 최소 1건 선정\n  - 담당자 배정 및 목표일 설정\n\n□ 1건 이상 개선 완료 및 효과 측정\n  - Before/After 데이터 수집\n  - 사례 보고서 작성\n```\n\n**산출물**: 첫 번째 검토 사이클 완료, 실제 회의록 및 개선 사례\n\n---\n\n### Step 6: 문서화 및 증빙 패키징 (5주차)\n**담당**: 품질 담당자\n\n```\n📦 증빙 패키지 구성:\n\nGOVP-002_Evidence_Package/\n├── 01_Policy/\n│   └── OPS-GOV-001_Continuous_Improvement_Policy_v2.3.pdf\n├── 02_Meeting_Minutes/",
      "language": "ko",
      "createdAt": "2026-01-07T01:31:58.410Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOVP-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOVP-003",
      "category": "Governance",
      "title": "지속가능성 약속",
      "advice": "# GOVP-003: 지속가능성 약속 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS는 2040년까지 탄소 중립(Net-Zero Carbon)을 목표로 하는 **Climate Pledge**에 서명했으며, MSP 파트너 생태계 전체가 이 비전에 동참하기를 기대합니다. 이 항목은 단순한 체크박스가 아니라, **AWS의 지속가능성 전략과 파트너의 장기 비전이 정렬되어 있는지** 확인하는 핵심 거버넌스 요소입니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **경영진 실질적 참여** | CEO/CTO 등 C-Level이 직접 서명하고 승인한 문서인가? 단순 부서장 승인은 불충분 |\n| **구체적 목표 설정** | \"환경을 보호하겠다\"가 아닌, 측정 가능한 목표(예: 2025년까지 탄소배출 20% 감축)가 있는가? |\n| **AWS 클라우드 연계성** | 지속가능성 달성 수단으로 AWS 클라우드 활용을 명시했는가? |\n| **장기 전략 통합** | 일회성 선언이 아닌 회사의 3-5년 전략 문서에 포함되어 있는가? |\n| **실행 메커니즘** | 약속을 이행하기 위한 구체적 프로그램이나 이니셔티브가 언급되어 있는가? |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS Customer Carbon Footprint Tool**: 탄소 발자국 측정 및 보고\n- **AWS Well-Architected Framework - Sustainability Pillar**: 지속가능한 아키텍처 설계 가이드\n- **Amazon EC2 Graviton Instances**: 에너지 효율적인 컴퓨팅\n- **AWS Compute Optimizer**: 리소스 최적화를 통한 에너지 절감\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료\n\n```\n📁 GOVP-003_지속가능성약속/\n├── 01_CEO_지속가능성_선언문_2024.pdf          [필수]\n├── 02_지속가능성_정책_v2.1.pdf                [필수]\n├── 03_전사_전략계획_2024-2027_발췌.pdf        [권장]\n├── 04_이사회_승인_의사록_20240115.pdf         [강력 권장]\n└── 05_전사_공지_이메일_스크린샷.png           [보조]\n```\n\n### 📄 각 증빙 자료의 핵심 포함 내용\n\n#### **CEO 지속가능성 선언문** (가장 중요)\n```\n[필수 포함 요소]\n✓ 회사 공식 레터헤드\n✓ CEO/대표이사 직접 서명 (전자서명 가능)\n✓ 작성일자 (감사일 기준 12개월 이내)\n✓ 지속가능성에 대한 회사의 비전 명시\n✓ AWS 클라우드를 통한 지속가능성 추구 언급\n✓ 장기적 약속임을 나타내는 문구\n\n[예시 문구]\n\"당사는 2030년까지 IT 인프라 운영에서 발생하는 \n탄소 배출량을 50% 감축하는 것을 목표로 하며, \n이를 위해 AWS 클라우드의 지속가능한 인프라를 \n적극 활용하겠습니다.\"\n```\n\n#### **지속가능성 정책 문서**\n```\n[필수 섹션]\n1. 목적 및 범위\n2. 경영진 약속 (CEO 메시지 재확인)\n3. 지속가능성 목표 (정량적)\n   - 탄소 배출 감축 목표\n   - 에너지 효율화 목표\n   - 클라우드 마이그레이션 목표\n4. 실행 전략\n   - AWS 클라우드 활용 계획\n   - 친환경 기술 도입 로드맵\n5. 거버넌스 체계\n   - 책임 조직/담당자\n   - 모니터링 및 보고 주기\n6. 문서 이력 (버전, 승인자, 승인일)\n```\n\n### 📝 실제 문서 제목 예시\n\n| 유형 | 좋은 예시 ✅ | 피해야 할 예시 ❌ |\n|------|------------|-----------------|\n| 선언문 | \"ABC테크놀로지 지속가능성 비전 선언문 - CEO 직접 서명\" | \"환경 관련 공지\" |\n| 정책 | \"지속가능성 정책 v2.1 (2024년 1월 이사회 승인)\" | \"환경정책 초안\" |\n| 전략 | \"2024-2027 중장기 전략계획 - 지속가능성 섹션 발췌\" | \"회의 자료\" |\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 지속가능성 관련 문서 인벤토리 (1-2일)\n\n```bash\n# 확인해야 할 기존 문서\n□ ESG 보고서 (있다면)\n□ 환경 정책 문서\n□ 회사 비전/미션 문서\n□ 중장기 전략 계획서\n□ 이사회/경영회의 의사록\n```\n\n**담당자**: 경영기획팀 + 컴플라이언스팀\n**결과물**: 기존 문서 목록 및 갭 분석 보고서\n\n### Step 2: AWS 지속가능성 연계 포인트 정의 (2-3일)\n\n```\n[AWS Customer Carbon Footprint Tool 활용]\n1. AWS Console > Billing > Carbon Footprint 접속\n2. 현재 탄소 발자국 데이터 다운로드\n3. 온프레미스 대비 절감 효과 계산\n\n[문서에 포함할 AWS 연계 내용]\n- \"AWS 리전의 재생에너지 사용률 활용\"\n- \"Graviton 프로세서 도입을 통한 에너지 효율화\"\n- \"AWS Well-Architected Sustainability Pillar 준수\"\n```\n\n**담당자**: 클라우드 아키텍트 + 기술팀장\n**결과물**: AWS 지속가능성 활용 계획서\n\n### Step 3: CEO/CxO 브리핑 및 승인 획득 (3-5일)\n\n```\n[브리핑 자료 구성]\n1. AWS MSP 프로그램 지속가능성 요구사항 설명\n2. 경쟁사 지속가능성 선언 사례\n3. 제안하는 지속가능성 비전 및 목표\n4. 서명이 필요한 문서 초안\n\n[승인 프로세스]\nCEO 브리핑 → 피드백 반영 → 최종 서명 → 이사회 보고\n```\n\n**담당자**: MSP 프로젝트 리더 + 경영기획팀장\n**결과물**: CEO 서명 완료된 선언문\n\n### Step 4: 정책 문서 공식화 (3-4일)\n\n```\n[정책 문서 작성 체크리스트]\n□ 회사 표준 정책 템플릿 사용\n□ 문서 번호 및 버전 관리 체계 적용\n□ 승인 워크플로우 완료 (작성자 → 검토자 → 승인자)\n□ 문서 관리 시스템에 등록\n□ 유효 기간 및 검토 주기 명시\n```\n\n**담당자**: 컴플라이언스팀 + 문서관리자\n**결과물**: 공식 승인된 지속가능성 정책\n\n### Step 5: 전사 커뮤니케이션 (1-2일)\n\n```\n[커뮤니케이션 채널]\n- 전사 이메일 공지 (CEO 명의)\n- 사내 포털/인트라넷 게시\n- 타운홀 미팅 발표 (선택)\n\n[증빙용 스크린샷 확보]\n- 이메일 발송 화면 캡처\n- 인트라넷 게시 화면 캡처\n- 발송 대상자 수 확인 가능한 화면\n```\n\n**담당자**: 커뮤니케이션팀 + HR\n**결과물**: 전사 공지 증빙 자료\n\n### Step 6: 증빙 패키지 구성 및 검증 (2-3일)\n\n```\n[증빙 패키지 구성]\nGOVP-003_Evidence_Package/\n├── README.txt (증빙 목록 및 설명)\n├── 01_Primary_Evidence/\n│   ├── CEO_Sustainability_Declaration_Signed.pdf\n│   └── Sustainability_Policy_v2.1_Approved.pdf\n├── 02_Supporting_Evidence/\n│   ├── Board_Meeting_Minutes_Extract.pdf\n│   └── Company_Wide_Announcement_Email.pdf\n└── 03_AWS_Integration/\n    └── Carbon_Footprint_Report_Q4_2024.pdf\n```\n\n**담당자**: MSP 프로젝트 PM\n**결과물**: 제출 준비 완료된 증빙 패키지\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수 TOP 5\n\n#### 실수 1: 부서장 레벨 승인으로 제출\n```\n❌ 잘못된 예: IT본부장 또는 클라우드팀장 서명\n✅ 올바른 예: CEO, COO, CTO 등 C-Level 직접 서명\n\n[감사관 코멘트 예시]\n\"The evidence shows approval from IT Director level. \nMSP requirement explicitly states CxO office commitment.\"\n```\n\n#### 실수 2: AWS 클라우드 연계성 누락\n```\n❌ 잘못된 예: \n\"당사는 환경 보호를 위해 노력하겠습니다.\"\n\n✅ 올바른 예:\n\"당사는 AWS 클라우드의 지속가능한 인프라를 활용하여 \n탄소 배출을 감축하고, AWS Well-Architected Framework의 \nSustainability Pillar를 준수하겠습니다.\"\n```\n\n#### 실수 3: 측정 가능한 목표 없이 추상적 선언만 제시\n```\n❌ 잘못된 예:\n\"지속가능한 미래를 위해 최선을 다하겠습니다.\"\n\n✅ 올바른 예:\n\"2026년까지 클라우드 워크로드의 80%를 AWS로 마이그레이션하여\n온프레미스 대비 탄소 배출량 30% 감축을 목표로 합니다.\"\n```\n\n#### 실수 4: 오래된 문서 제출\n```\n❌ 잘못된 예: 2년 전 작성된 환경 정책 문서\n✅ 올바른 예: 감사일 기준 12개월 이내 작성/갱신된 문서\n\n[Tip] 기존 문서가 있다면 \"2024년 갱신\" 버전으로 업데이트\n```\n\n#### 실수 5: 장기 전략과의 연결고리 부재\n```\n❌ 잘못된 예: 독립적인 환경 선언문만 제출\n✅ 올바른 예: 회사 중장기 전략 문서에서 지속가능성 섹션 발췌 포함\n\n[감사관이 확인하는 것]\n\"지속가능성이 일회성 이벤트가 아닌 회사 전략의 일부인가?\"\n```\n\n### 🔴 감사 탈락 주요 원인\n\n| 탈락 원인 | 발생 빈도 | 해결 방법 |\n|----------|----------|----------|\n| C-Level 서명 없음 | 매우 높음 | CEO 직접 서명 필수 확보 |\n| AWS 언급 전무 | 높음 | 정책에 AWS 활용 계획 명시 |\n| 문서 날짜 오래됨 | 중간 | 최근 날짜로 갱신 또는 재작성 |\n| 구체적 목표 없음 | 중간 | 정량적 KPI 포함 |\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | CEO/CxO 서명 존재 | 문서 마지막 페이지 확인 | 직함 + 성명 + 서명 + 날짜 모두 존재 |\n| 2 | 서명 날짜 유효성 | 날짜 확인 | 감사일 기준 12개월 이내 |\n| 3 | AWS 클라우드 언급 | Ctrl+F",
      "language": "ko",
      "createdAt": "2026-01-07T01:32:55.061Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-001",
      "category": "Operations",
      "title": "서비스 수준 관리",
      "advice": "# OPS-001: 서비스 수준 관리 (SLA) 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n서비스 수준 관리는 **MSP의 핵심 역량을 증명하는 첫 번째 관문**입니다. AWS는 MSP 파트너가 단순히 기술력만 갖춘 것이 아니라, **예측 가능하고 측정 가능한 서비스를 제공**할 수 있는지 확인합니다. SLA 없이는 고객과의 신뢰 관계 구축이 불가능하며, 이는 곧 MSP로서의 자격 미달을 의미합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 의도 |\n|--------|-------------------|\n| **SLA 지표의 구체성** | \"응답 시간 4시간\"이 아닌 \"P1 인시던트 최초 응답 15분, P2 30분, P3 4시간\"처럼 세분화되어 있는가? |\n| **측정 가능성** | SLA 달성률을 어떻게 측정하고 있으며, 그 데이터는 어디서 추출하는가? |\n| **고객별 차별화** | 모든 고객에게 동일한 SLA를 적용하는지, 고객 Tier별로 다른 SLA를 제공하는지? |\n| **위반 시 대응 체계** | SLA 미달성 시 고객에게 어떤 보상/조치가 이루어지는가? |\n| **정기 검토 프로세스** | 고객과 함께 SLA 달성률을 리뷰하는 정기적인 프로세스가 있는가? |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **Amazon CloudWatch**: SLA 지표 모니터링 및 알람 설정\n- **AWS Service Catalog**: 서비스 레벨별 상품 정의\n- **Amazon QuickSight**: SLA 대시보드 및 리포팅\n- **AWS Systems Manager OpsCenter**: 인시던트 추적 및 SLA 타이머\n- **Amazon EventBridge**: SLA 위반 임계치 도달 시 자동 에스컬레이션\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 증빙 1: SLA 정의 문서\n**파일명 예시**: `MSP_Service_Level_Agreement_v2.3_2024.pdf`\n\n**포함되어야 할 핵심 내용**:\n```\n┌─────────────────────────────────────────────────────────────┐\n│ SLA 문서 필수 구성요소                                        │\n├─────────────────────────────────────────────────────────────┤\n│ 1. 서비스 범위 정의 (In-Scope / Out-of-Scope 명확히 구분)      │\n│ 2. 인시던트 우선순위 분류 기준 (P1~P4 정의 및 예시)            │\n│ 3. 각 우선순위별 응답/해결 목표 시간                          │\n│ 4. 서비스 가용성 목표 (예: 99.9% 월간 가용성)                 │\n│ 5. 측정 방법 및 제외 조건 (Planned Maintenance 등)            │\n│ 6. SLA 미달성 시 크레딧/보상 정책                             │\n│ 7. 에스컬레이션 매트릭스                                      │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**구체적인 SLA 테이블 예시**:\n| 우선순위 | 정의 | 최초 응답 | 상태 업데이트 | 해결 목표 |\n|---------|------|----------|--------------|----------|\n| P1 (Critical) | 프로덕션 전체 중단 | 15분 | 30분마다 | 4시간 |\n| P2 (High) | 주요 기능 장애 | 30분 | 1시간마다 | 8시간 |\n| P3 (Medium) | 부분적 기능 저하 | 4시간 | 4시간마다 | 24시간 |\n| P4 (Low) | 문의/개선 요청 | 8시간 | 1일마다 | 5영업일 |\n\n---\n\n#### 📊 증빙 2: SLA 성과 보고서\n**파일명 예시**: `Customer_ABC_SLA_Performance_Report_2024Q3.pdf`\n\n**포함되어야 할 핵심 내용**:\n```\n월간/분기별 SLA 성과 보고서 구성:\n\n1. Executive Summary\n   - 전체 SLA 달성률: 98.7%\n   - 총 티켓 수: 127건\n   - SLA 위반 건수: 2건\n\n2. 인시던트 분석\n   - 우선순위별 티켓 분포 (파이 차트)\n   - 평균 응답 시간 vs 목표 시간 (막대 그래프)\n   - 평균 해결 시간 트렌드 (라인 차트)\n\n3. SLA 위반 상세\n   - 위반 건별 Root Cause\n   - 재발 방지 조치\n\n4. 서비스 가용성\n   - 월간 가용성: 99.95%\n   - 다운타임 상세 내역\n\n5. 개선 권고사항\n```\n\n---\n\n#### 📝 증빙 3: 고객 검토 프로세스 증빙\n**파일명 예시**: `SLA_Review_Meeting_Minutes_CustomerXYZ_20241015.pdf`\n\n**필수 포함 요소**:\n- 회의 일시, 참석자 (고객측 + MSP측)\n- 검토한 SLA 지표 및 달성률\n- 고객 피드백 및 요청사항\n- 합의된 액션 아이템\n- 다음 검토 일정\n- **고객 서명 또는 이메일 승인 증빙**\n\n---\n\n### 📁 증빙 자료 패키지 구성 예시\n\n```\nOPS-001_SLA_Evidence/\n├── 01_SLA_Definition/\n│   ├── MSP_Master_SLA_Document_v2.3.pdf\n│   ├── SLA_Appendix_Priority_Matrix.xlsx\n│   └── Service_Catalog_with_SLA_Tiers.pdf\n├── 02_SLA_Reports/\n│   ├── Customer_ABC_SLA_Report_2024Q3.pdf\n│   ├── Customer_DEF_SLA_Report_2024Q3.pdf\n│   └── Aggregated_SLA_Dashboard_Screenshot.png\n├── 03_Review_Process/\n│   ├── SLA_Review_Meeting_Template.docx\n│   ├── Meeting_Minutes_ABC_20241001.pdf\n│   ├── Meeting_Minutes_DEF_20241015.pdf\n│   └── Customer_Approval_Emails/\n│       ├── ABC_SLA_Approval_Email.eml\n│       └── DEF_SLA_Approval_Email.eml\n└── 04_Supporting_Documents/\n    ├── ITSM_Tool_SLA_Configuration_Screenshot.png\n    └── Escalation_Matrix.pdf\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: SLA 프레임워크 설계 (2-3일)\n\n**담당자**: 서비스 매니저 + 기술 리드\n\n**구체적 작업**:\n```\n1. 현재 제공 중인 모든 서비스 목록화\n   - EC2 관리, RDS 운영, 보안 모니터링, 비용 최적화 등\n\n2. 각 서비스별 측정 가능한 SLA 지표 정의\n   ┌────────────────┬──────────────────────────────────┐\n   │ 서비스         │ SLA 지표                          │\n   ├────────────────┼──────────────────────────────────┤\n   │ 인시던트 관리   │ 응답 시간, 해결 시간, 재발률      │\n   │ 변경 관리      │ 변경 처리 시간, 변경 성공률        │\n   │ 가용성 관리    │ 월간 가용성 %, MTTR, MTBF         │\n   │ 보안 관리      │ 취약점 패치 시간, 보안 이벤트 응답 │\n   └────────────────┴──────────────────────────────────┘\n\n3. 고객 Tier 분류 기준 수립\n   - Platinum: 24x7 지원, P1 응답 15분\n   - Gold: 24x7 지원, P1 응답 30분\n   - Silver: 8x5 지원, P1 응답 1시간\n```\n\n**사용 도구**: Confluence/Notion (문서화), Excel (지표 매트릭스)\n\n---\n\n### Step 2: ITSM 도구에 SLA 설정 (3-5일)\n\n**담당자**: ITSM 관리자\n\n**구체적 작업**:\n```\nServiceNow/Jira Service Management/Freshservice 설정:\n\n1. SLA 정책 생성\n   - 조건: 우선순위 = P1 AND 고객 Tier = Platinum\n   - 목표: 최초 응답 15분, 해결 4시간\n\n2. SLA 타이머 설정\n   - 업무 시간 캘린더 적용 (24x7 vs 8x5)\n   - 공휴일 제외 설정\n\n3. 에스컬레이션 규칙 설정\n   - 응답 SLA 50% 경과: 담당자에게 알림\n   - 응답 SLA 75% 경과: 팀 리드에게 알림\n   - 응답 SLA 100% 경과: 서비스 매니저에게 알림\n\n4. SLA 대시보드 구성\n   - 실시간 SLA 달성률\n   - 위험 티켓 목록 (SLA 임박)\n```\n\n**AWS 연동**: \n- CloudWatch 알람 → EventBridge → ITSM 티켓 자동 생성\n- AWS Health 이벤트 → 자동 P1 티켓 생성\n\n---\n\n### Step 3: SLA 모니터링 대시보드 구축 (2-3일)\n\n**담당자**: 데이터 엔지니어 / BI 담당자\n\n**구체적 작업**:\n```python\n# QuickSight 대시보드 구성 예시\n\nDashboard: \"MSP SLA Performance\"\n├── Tab 1: Executive Summary\n│   ├── KPI Card: 전체 SLA 달성률 (98.5%)\n│   ├── KPI Card: 이번 달 총 티켓 (127건)\n│   ├── KPI Card: SLA 위반 건수 (2건)\n│   └── Trend Line: 월별 SLA 달성률 추이\n│\n├── Tab 2: Incident Analysis\n│   ├── Pie Chart: 우선순위별 티켓 분포\n│   ├── Bar Chart: 평균 응답 시간 vs 목표\n│   ├── Heat Map: 시간대별 티켓 발생 패턴\n│   └── Table: SLA 위반 티켓 상세\n│\n└── Tab 3: Customer View\n    ├── Filter: 고객 선택\n    ├── Customer-specific SLA 달성률\n    └── 고객별 티켓 트렌드\n```\n\n---\n\n### Step 4: 고객 검토 프로세스 수립 (1-2일)\n\n**담당자**: Customer Success Manager\n\n**구체적 작업**:\n```\n월간 SLA 검토 프로세스:\n\nWeek 1 (매월 첫째 주):\n├── Day 1-2: ITSM에서 전월 SLA 데이터 추출\n├── Day 3: SLA 보고서 초안 작성\n└── Day 4-5: 내부 검토 및 승인\n\nWeek 2:\n├── 고객별 SLA 검토 미팅 스케줄링\n├── 미팅 진행 (30-60분)\n│   ├── SLA 달성률 리뷰\n│   ├── 주요 인시던트 분석\n│   ├── 개선 계획 논의\n│   └── 다음 달 예상 이슈 공유\n└── 미팅 후 24시간 내 회의록 발송\n\nWeek 3-4:\n├── 고객 피드백 반영\n├── 액션 아이템 추적\n└── SLA 조정 필요시 계약 수정\n```\n\n---\n\n### Step 5: 증빙 자료 생성 및 검증 (2-3일)\n\n**담당자**: MSP 프로그램 매니저\n\n**구체적 작업**:\n```\n증빙 자료 품질 검증 체크리스트:\n\n□ SLA 문서에 모든 서비스 범위가 명시되어 있는가?\n□ 우선순위 정의가 구체적인 예시와 함께 설명되어 있는가?\n□ SLA 보고서에 실제 수치와 목표 수치가 비교되어 있는가?\n□ 최소 2개 이상의 고객에 대한 검토 미팅 증빙이 있는가?\n□ 고객 서명/승인이 포함되어 있는가?\n□ 모든 문서의 날짜가 최근 6개월 이내인가?\n□ 스크린샷에 민감 정보가 마스",
      "language": "ko",
      "createdAt": "2026-01-07T02:08:27.597Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-002",
      "category": "Operations",
      "title": "파트너 소유 관리 및 멤버 계정을 위한 AWS 지원 플랜",
      "advice": "# OPS-002: 파트너 소유 관리 및 멤버 계정을 위한 AWS 지원 플랜\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 중요한 이유\nAWS MSP 파트너는 고객의 프로덕션 워크로드를 관리하므로, 장애 발생 시 AWS 기술 지원에 신속하게 접근할 수 있어야 합니다. Basic이나 Developer 지원으로는 프로덕션 환경의 SLA를 충족할 수 없으며, **Business 이상의 지원 플랜만이 24/7 기술 지원과 15분 이내 긴급 응답 시간을 보장**합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 세부 내용 |\n|------------|----------|\n| **지원 플랜 적격성** | 모든 관리 계정이 Business/Enterprise/PLS 중 하나에 가입되어 있는지 |\n| **프로덕션 워크로드 식별** | 멤버 계정 중 프로덕션 워크로드가 있는 계정을 정확히 파악했는지 |\n| **지원 플랜 상속 여부** | Organizations 내 멤버 계정이 관리 계정의 지원 플랜을 상속받는지 확인 |\n| **PLS 계약 유효성** | Partner-Led Support 사용 시 유효한 계약이 존재하는지 |\n| **계정 누락 여부** | 관리 중인 모든 Organizations가 목록에 포함되어 있는지 |\n\n### 관련 AWS 서비스 및 기능\n- **AWS Support Center**: 지원 플랜 확인 및 케이스 관리\n- **AWS Organizations**: 계정 구조 및 멤버 계정 목록 확인\n- **AWS Support API**: `DescribeSeverityLevels` API로 지원 수준 프로그래매틱 확인\n- **AWS Trusted Advisor**: Business 이상에서만 전체 체크 항목 접근 가능 (간접 증빙)\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 OPS-002_Support_Plan_Evidence/\n├── 01_Organizations_Account_List.xlsx\n├── 02_Support_Plan_Screenshots/\n│   ├── Org1_Management_Account_Support.png\n│   ├── Org1_Member_Account_Prod1_Support.png\n│   ├── Org2_Management_Account_Support.png\n│   └── ...\n├── 03_PLS_Contract_Summary.pdf (해당 시)\n└── 04_Account_Workload_Classification.xlsx\n```\n\n### 각 증빙 자료의 핵심 내용\n\n#### 📊 Organizations 계정 목록 (Excel)\n```\n| Organization ID | 계정 ID | 계정 이름 | 계정 유형 | 워크로드 구분 | 지원 플랜 | 확인 일자 |\n|-----------------|---------|-----------|-----------|---------------|-----------|-----------|\n| o-abc123xyz | 111122223333 | MSP-Mgmt-Prod | Management | Production | Enterprise | 2024-01-15 |\n| o-abc123xyz | 444455556666 | Customer-A-Prod | Member | Production | Enterprise (상속) | 2024-01-15 |\n| o-abc123xyz | 777788889999 | Customer-A-Dev | Member | Development | Enterprise (상속) | 2024-01-15 |\n| o-def456uvw | 222233334444 | MSP-Mgmt-Test | Management | Non-Production | Business | 2024-01-15 |\n```\n\n#### 📸 Support Plan 스크린샷 필수 포함 요소\n- **AWS 콘솔 URL 표시** (account ID가 보이는 상태)\n- **Support Plan 이름** (Business/Enterprise/Partner-Led Support 명시)\n- **스크린샷 촬영 일자** (브라우저 시계 또는 워터마크)\n- **Trusted Advisor 전체 체크 접근 가능 화면** (Business 이상 증빙)\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: Organizations 전체 인벤토리 수집 (2-3시간)\n\n```bash\n# AWS CLI로 모든 Organizations의 계정 목록 추출\naws organizations list-accounts --output json > accounts_list.json\n\n# 각 계정의 상세 정보 추출\naws organizations describe-account --account-id <ACCOUNT_ID>\n```\n\n**담당자**: 클라우드 운영팀 / **산출물**: 전체 계정 목록 JSON\n\n### Step 2: 각 계정의 지원 플랜 확인 (계정당 5분)\n\n```bash\n# Support API로 지원 수준 확인 (Business 이상에서만 동작)\naws support describe-severity-levels --region us-east-1\n\n# 응답이 오면 Business 이상, AccessDeniedException이면 Developer/Basic\n```\n\n**⚡ 핵심 팁**: Support API는 `us-east-1` 리전에서만 동작합니다.\n\n### Step 3: 프로덕션 워크로드 계정 분류 (3-4시간)\n\n각 멤버 계정에 대해 다음 기준으로 분류:\n\n| 분류 기준 | Production | Non-Production |\n|-----------|------------|----------------|\n| 실제 사용자 트래픽 | ✅ 있음 | ❌ 없음 |\n| SLA 계약 존재 | ✅ 있음 | ❌ 없음 |\n| 비즈니스 크리티컬 | ✅ 해당 | ❌ 미해당 |\n| 환경 태그 | `env:prod` | `env:dev/staging` |\n\n### Step 4: 스크린샷 증빙 수집 (계정당 3분)\n\n**각 관리 계정에서 수행:**\n1. AWS Console → Support Center 접속\n2. 우측 상단 \"Support plan\" 클릭\n3. 전체 화면 스크린샷 (Account ID + Support Plan 명시)\n4. Trusted Advisor → 전체 체크 목록 접근 가능 화면 캡처\n\n### Step 5: PLS 계약 확인 (해당 시, 1-2시간)\n\nPartner-Led Support 사용 시:\n- AWS Partner Central에서 PLS 계약서 다운로드\n- 계약 유효 기간 확인\n- 적용 대상 계정 목록 확인\n\n### Step 6: 증빙 문서 통합 및 검증 (2시간)\n\n```\n✅ 모든 Management 계정 스크린샷 완료\n✅ 프로덕션 Member 계정 스크린샷 완료  \n✅ 계정 목록과 스크린샷 계정 ID 대조\n✅ 지원 플랜 유형 일치 여부 확인\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 유형 | 문제점 | 해결 방법 |\n|-----------|--------|-----------|\n| **Developer 지원 플랜 포함** | 프로덕션 계정이 Developer 플랜으로 등록됨 | 모든 프로덕션 계정 Business 이상 업그레이드 |\n| **멤버 계정 누락** | 신규 생성된 멤버 계정이 목록에서 빠짐 | Organizations API로 실시간 목록 추출 |\n| **지원 플랜 상속 오해** | 멤버 계정이 자동으로 상속받는다고 가정 | **실제로 상속되지 않음** - 각 계정별 확인 필요 |\n| **스크린샷 Account ID 불일치** | 다른 계정의 스크린샷 제출 | 스크린샷 내 Account ID와 목록 대조 |\n| **PLS 계약 만료** | 만료된 PLS 계약으로 증빙 제출 | 감사 시점 기준 유효한 계약 확인 |\n\n### 🔴 감사 탈락 주요 원인\n\n1. **프로덕션 워크로드가 있는 멤버 계정이 Basic/Developer 지원**\n   - AWS는 프로덕션 정의를 엄격하게 적용\n   - \"테스트용\"이라도 실제 사용자가 있으면 프로덕션으로 간주\n\n2. **Organizations 일부 누락**\n   - 인수합병으로 추가된 Organizations 미포함\n   - 특정 고객 전용 Organizations 누락\n\n3. **증빙 시점 불일치**\n   - 6개월 전 스크린샷 제출\n   - 감사 시점 기준 **30일 이내** 증빙 권장\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|-----------|-----------|-----------|\n| 1 | 모든 Organizations가 목록에 포함되어 있는가? | AWS Partner Central의 고객 목록과 대조 | 100% 일치 |\n| 2 | 모든 Management 계정이 Business 이상인가? | 각 계정 Support Center 스크린샷 확인 | Basic/Developer 없음 |\n| 3 | 프로덕션 Member 계정이 모두 식별되었는가? | 워크로드 분류 기준 문서 검토 | 분류 기준 명확 |\n| 4 | 프로덕션 Member 계정이 적절한 지원을 받는가? | 지원 플랜 또는 PLS 계약 확인 | 모두 커버됨 |\n| 5 | 스크린샷에 Account ID가 명확히 보이는가? | 각 스크린샷 육안 확인 | 12자리 ID 판독 가능 |\n| 6 | 증빙 자료 날짜가 최신인가? | 스크린샷 내 날짜 확인 | 30일 이내 |\n| 7 | PLS 사용 시 계약이 유효한가? | 계약서 유효기간 확인 | 감사일 기준 유효 |\n\n### ✅ 품질 기준 자가 진단\n\n```\n□ 계정 목록 Excel에 모든 필수 컬럼이 있는가?\n  → Organization ID, Account ID, 계정 유형, 워크로드 구분, 지원 플랜, 확인 일자\n\n□ 스크린샷 파일명이 계정 ID로 명명되어 있는가?\n  → 예: 111122223333_Support_Plan.png\n\n□ 프로덕션 분류 기준이 문서화되어 있는가?\n  → 감사관 질문 시 일관된 답변 가능\n\n□ 지원 플랜 변경 이력이 있다면 기록되어 있는가?\n  → 최근 업그레이드 내역 포함\n```\n\n---\n\n### 💡 Pro Tip: 빠른 검증 스크립트\n\n```python\n# 모든 계정의 지원 플랜을 한 번에 확인하는 스크립트\nimport boto3\n\ndef check_support_plan(account_id, role_arn):\n    sts = boto3.client('sts')\n    credentials = sts.assume_role(\n        RoleArn=role_arn,\n        RoleSessionName='SupportCheck'\n    )['Credentials']\n    \n    support = boto3.client(\n        'support',\n        region_name='us-east-1',\n        aws_access_key_id=credentials['AccessKeyId'],\n        aws_secret_access_key=credentials['SecretAccessKey'],\n        aws_session_token=credentials['SessionToken']\n    )\n    \n    try:\n        support.describe_severity_levels()\n        return \"Business or Higher\"\n    except support.exceptions.SubscriptionRequiredException:\n        return \"Basic or Developer\"  # ⚠️ 업그레이드 필요\n```\n\n이 스크립트를 활용하면 수십 개의 계정도 몇 분 내에 지원 플랜을 확인할 수 있습니다.",
      "language": "ko",
      "createdAt": "2026-01-07T02:09:16.562Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-003",
      "category": "Operations",
      "title": "고객 소유 멤버 계정을 위한 AWS 지원 플랜",
      "advice": "# OPS-003: 고객 소유 멤버 계정을 위한 AWS 지원 플랜\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 중요한 이유\n\nAWS MSP 파트너는 단순히 인프라를 관리하는 것을 넘어, **고객이 AWS로부터 최적의 지원을 받을 수 있도록 안내하는 책임**이 있습니다. 프로덕션 워크로드에서 장애 발생 시 AWS Support의 응답 시간이 비즈니스 연속성에 직접적인 영향을 미치기 때문에, MSP가 이를 적극적으로 권장했는지가 핵심 평가 포인트입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 |\n|------------|---------------|\n| **권장 활동의 증거** | \"프로덕션 고객에게 Business/Enterprise 지원을 권장한 기록이 있는가?\" |\n| **현황 파악 능력** | \"관리 중인 모든 고객 계정의 지원 플랜 현황을 실시간으로 파악하고 있는가?\" |\n| **미준수 고객 대응** | \"Business 지원 미가입 프로덕션 고객에게 어떤 후속 조치를 취했는가?\" |\n| **가치 전달 방식** | \"Premium 지원의 가치를 고객에게 어떻게 설명했는가?\" |\n| **지속적 모니터링** | \"신규 고객 온보딩 시 지원 플랜 검토가 프로세스에 포함되어 있는가?\" |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS Organizations** - 멤버 계정 목록 및 구조 확인\n- **AWS Support API** - `DescribeSeverityLevels`, `DescribeServices`로 지원 플랜 레벨 확인\n- **AWS Trusted Advisor** - Business/Enterprise 지원 시 전체 검사 항목 활성화 여부로 간접 확인\n- **AWS Cost Explorer** - Support 비용 항목으로 지원 플랜 가입 여부 확인\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📊 증빙 A: 고객 계정 지원 플랜 현황표\n**파일명 예시:** `MSP_Customer_Support_Plan_Matrix_2024Q4.xlsx`\n\n```\n| Account ID   | 고객명      | 환경 유형    | 지원 플랜     | 확인일자   | 확인 방법        |\n|--------------|-------------|--------------|---------------|------------|------------------|\n| 123456789012 | ABC Corp    | Production   | Enterprise    | 2024-11-15 | Support API      |\n| 234567890123 | XYZ Inc     | Production   | Business      | 2024-11-15 | Support API      |\n| 345678901234 | DEF Ltd     | Production   | Developer     | 2024-11-15 | Support API      |\n| 456789012345 | GHI Corp    | Development  | Basic         | 2024-11-15 | Support API      |\n```\n\n**필수 포함 컬럼:**\n- AWS Account ID (12자리)\n- 고객사명\n- 환경 구분 (Production/Staging/Development/Test)\n- 현재 지원 플랜 (Basic/Developer/Business/Enterprise)\n- 최종 확인 일자\n- 확인 방법 (API/Console/고객 확인)\n\n#### 📧 증빙 B: 지원 플랜 권장 커뮤니케이션\n**파일명 예시:** `Support_Plan_Recommendation_Communications/`\n\n**1) 온보딩 시 권장 이메일**\n```\n제목: [ABC Corp] AWS 프로덕션 환경 지원 플랜 권장 안내\n\n안녕하세요, ABC Corp 담당자님\n\n귀사의 프로덕션 워크로드가 AWS에서 안정적으로 운영될 수 있도록 \nAWS Business Support 플랜 가입을 권장드립니다.\n\n[Business Support의 주요 혜택]\n- 프로덕션 시스템 장애 시 1시간 이내 응답\n- 24/7 기술 지원 (전화/채팅/이메일)\n- AWS Trusted Advisor 전체 검사 항목 활성화\n- Infrastructure Event Management 지원\n\n[예상 비용]\n- 월 AWS 사용료의 10% 또는 최소 $100/월\n\n검토 후 회신 부탁드립니다.\n```\n\n**2) 미가입 고객 후속 커뮤니케이션**\n```\n제목: [DEF Ltd] AWS Support Plan 업그레이드 재권장\n\n안녕하세요,\n\n지난 3월 권장드린 AWS Business Support 관련하여 \n현재까지 Developer 플랜을 유지하고 계신 것으로 확인됩니다.\n\n프로덕션 워크로드 운영 중 긴급 장애 발생 시 \nDeveloper 플랜의 12시간+ 응답 시간은 비즈니스 영향이 클 수 있습니다.\n\n[최근 사례]\n- 11월 5일 RDS 장애 시 AWS 지원 요청 → 응답까지 14시간 소요\n\nBusiness Support 전환 시 동일 상황에서 1시간 이내 응답이 가능합니다.\n재검토 부탁드립니다.\n```\n\n#### 📑 증빙 C: 지원 플랜 권장 정책 문서\n**파일명 예시:** `MSP_AWS_Support_Plan_Recommendation_Policy_v2.1.pdf`\n\n**포함 내용:**\n- 환경별 권장 지원 플랜 기준\n- 고객 온보딩 시 지원 플랜 안내 절차\n- 미준수 고객 에스컬레이션 프로세스\n- 분기별 지원 플랜 현황 리뷰 절차\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 관리 계정 전체 목록 추출 (1일)\n\n```bash\n# AWS Organizations에서 모든 멤버 계정 추출\naws organizations list-accounts --query 'Accounts[*].[Id,Name,Email,Status]' --output table\n\n# 또는 CSV로 추출\naws organizations list-accounts --output json | jq -r '.Accounts[] | [.Id, .Name, .Email, .Status] | @csv' > accounts_list.csv\n```\n\n**담당자:** Cloud Operations 팀\n**산출물:** 전체 관리 계정 목록 (CSV)\n\n### Step 2: 각 계정의 지원 플랜 레벨 확인 (2-3일)\n\n```python\n# 각 계정에 AssumeRole 후 Support API 호출\nimport boto3\n\ndef check_support_level(account_id, role_name):\n    sts = boto3.client('sts')\n    assumed = sts.assume_role(\n        RoleArn=f'arn:aws:iam::{account_id}:role/{role_name}',\n        RoleSessionName='SupportCheck'\n    )\n    \n    support = boto3.client('support',\n        aws_access_key_id=assumed['Credentials']['AccessKeyId'],\n        aws_secret_access_key=assumed['Credentials']['SecretAccessKey'],\n        aws_session_token=assumed['Credentials']['SessionToken'],\n        region_name='us-east-1'  # Support API는 us-east-1만 지원\n    )\n    \n    try:\n        # Business/Enterprise는 이 API 호출 가능\n        support.describe_severity_levels()\n        return \"Business or Enterprise\"\n    except support.exceptions.SubscriptionRequiredException:\n        return \"Basic or Developer\"\n```\n\n**대안 방법:** AWS Cost Explorer에서 \"Support\" 비용 항목 확인\n- $0 = Basic\n- $29/월 = Developer  \n- $100+/월 또는 사용료의 10% = Business\n- $15,000+/월 = Enterprise\n\n**담당자:** DevOps 엔지니어\n**산출물:** 계정별 지원 플랜 매핑 테이블\n\n### Step 3: 환경 유형 분류 (1일)\n\n각 계정을 환경별로 분류:\n\n```\nProduction 판단 기준:\n- 실제 고객 트래픽 처리\n- SLA가 정의된 서비스 운영\n- 매출에 직접 영향을 미치는 워크로드\n- 고객이 \"프로덕션\"으로 명시한 계정\n```\n\n**담당자:** Account Manager / TAM\n**산출물:** 환경 유형이 추가된 계정 목록\n\n### Step 4: Gap 분석 및 대상 고객 식별 (0.5일)\n\n```sql\n-- 프로덕션인데 Business/Enterprise가 아닌 계정 추출\nSELECT account_id, customer_name, support_plan\nFROM customer_accounts\nWHERE environment_type = 'Production'\nAND support_plan NOT IN ('Business', 'Enterprise')\n```\n\n**산출물:** 권장 대상 고객 목록\n\n### Step 5: 권장 커뮤니케이션 발송 (1-2주)\n\n**이메일 발송 시 포함할 내용:**\n1. 현재 지원 플랜과 권장 플랜 비교\n2. Business Support의 구체적 혜택 (응답 시간, Trusted Advisor 등)\n3. 예상 비용 (월 사용료 기준 계산)\n4. 업그레이드 방법 안내\n5. 회신 요청 (동의/거부/검토 중)\n\n**담당자:** Account Manager\n**산출물:** 발송 이메일 사본, 회신 기록\n\n### Step 6: 고객 응답 추적 및 문서화 (지속)\n\n```\n| 고객명    | 권장일     | 응답일     | 응답 내용                | 후속 조치        |\n|-----------|------------|------------|--------------------------|------------------|\n| ABC Corp  | 2024-09-01 | 2024-09-05 | 동의, 10월 전환 예정     | 전환 완료 확인   |\n| DEF Ltd   | 2024-09-01 | 2024-09-10 | 예산 문제로 보류         | 분기별 재권장    |\n| GHI Inc   | 2024-09-01 | -          | 미응답                   | 2주 후 재발송    |\n```\n\n**담당자:** Account Manager\n**산출물:** 고객 응답 추적 시트\n\n### Step 7: 최종 증빙 패키지 구성 (1일)\n\n폴더 구조:\n```\nOPS-003_Evidence/\n├── 01_Customer_Account_Support_Matrix.xlsx\n├── 02_Support_Plan_Recommendation_Policy.pdf\n├── 03_Communications/\n│   ├── Onboarding_Emails/\n│   │   ├── ABC_Corp_Support_Recommendation_20240901.pdf\n│   │   └── XYZ_Inc_Support_Recommendation_20240915.pdf\n│   └── Follow_up_Emails/\n│       ├── DEF_Ltd_Support_Followup_20241101.pdf\n│       └── GHI_Inc_Support_Followup_20241115.pdf\n├── 04_Customer_Response_Tracking.xlsx\n└── 05_Support_API_Query_Evidence.png\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 지원 플랜 확인 없이 고객 자가 보고에만 의존\n\n**문제:** 고객이 \"Business Support 있어요\"라고 했지만 실제로는 Developer인 경우\n\n**해결책:** \n```bash\n# 반드시 API 또는 Console에서 직접 확인\naws support describe-severity-levels --region us-east-1\n# 성공 = Business/Enterprise, 실패 = Basic/Developer\n```\n\n### 🚫 실수 2: 일회성 권장 후 후속 조치 없음\n\n**문제:** 온보딩 때 한 번 권장하고 끝 → 감사관이 \"지속적 관리\" 부재로 지적\n\n**해결책:**\n- 분기별 지원 플랜 현황 리뷰 회의 개최\n- 미준수 고객에게 최소 분기 1회 재권장 이메일 발송\n- 재권장 이력을 날짜와 함께 문서화\n\n### 🚫 실수 3: Development 환경을 Production으로 잘못 분류\n\n**문제:** 모든 계정을 Production으로 표시하여 신뢰성 저하\n\n**감사관 질문:** \"이 계정이 왜 Production인지 설명해주세요\"\n\n**해결책:**\n- 환경 분류 기준을 명확히 문서화\n- 고객 확인서 또는 계약서에 환경 유형 명시\n- 태그 기반 분류: `Environment: Production`\n\n### 🚫 실수 4: 커뮤니케이션 증빙에 날짜/수신자 누락\n\n**문제:** 이메일 캡처 시 발송 날짜, 수신자가 보이지 않음\n\n**해결책:**\n- 이메일 전체 헤더가 보이도록 캡처\n- PDF 변환 시 메타데이터 포함\n- 발송 기록이 있는 메일 시스템 로그 첨부\n\n### 🚫 실수 5: Basic Support 고객을 목록에서 제외\n\n**문제:** \"어차피 권장 대상이니까\" 목록에서 누락 → 전체 현황 파악 불가로 지적\n\n**해결책:**\n- **모든** 관리 계정을 목록",
      "language": "ko",
      "createdAt": "2026-01-07T02:10:13.151Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-004_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-004",
      "category": "Operations",
      "title": "서비스 데스크 운영",
      "advice": "# OPS-004: 서비스 데스크 운영 - AWS MSP 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n서비스 데스크는 **MSP와 고객 간의 단일 접점(Single Point of Contact)**으로, AWS 워크로드의 안정적 운영을 보장하는 핵심 기능입니다. 클라우드 환경은 24시간 가동되므로, 장애 발생 시 즉각적인 대응 채널이 없으면 비즈니스 연속성이 위협받습니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **24x7 접근성 보장** | 고객이 새벽 3시에 장애 신고 시 실제로 연락이 닿는가? |\n| **다중 커뮤니케이션 채널** | 전화, 이메일, 채팅, 티켓 시스템 중 최소 2개 이상 운영하는가? |\n| **응답 시간 명시** | SLA에 초기 응답 시간(예: 15분 이내)이 구체적으로 정의되어 있는가? |\n| **에스컬레이션 경로** | L1→L2→L3 또는 AWS Support 연계 프로세스가 문서화되어 있는가? |\n| **계약서 명시** | 고객 계약서에 서비스 데스크 운영 조건이 법적 구속력 있게 포함되어 있는가? |\n\n### 관련 AWS 서비스 및 도구\n\n- **AWS Support Center**: 고객 대신 AWS 케이스 생성 및 관리\n- **Amazon Connect**: 클라우드 기반 콜센터 구축 (선택사항)\n- **AWS Chatbot**: Slack/Teams 연동 알림 채널\n- **Amazon SNS**: 장애 알림 및 에스컬레이션 자동화\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 문서 목록\n\n```\n📁 OPS-004_서비스데스크/\n├── 01_고객계약서_서비스데스크조항.pdf\n├── 02_SLA_문서_응답시간정의.pdf\n├── 03_서비스데스크_운영절차서.docx\n├── 04_연락채널_안내문.pdf\n└── 05_실제운영_증빙_스크린샷.zip\n```\n\n### 각 증빙 자료의 핵심 포함 내용\n\n#### 📄 고객 계약서 (가장 중요)\n```\n[필수 포함 조항 예시]\n\n제X조 (서비스 데스크 운영)\n1. 을(MSP)은 갑(고객)에게 24시간 365일 서비스 데스크를 제공한다.\n2. 연락 채널:\n   - 긴급 전화: 02-XXXX-XXXX (24시간 운영)\n   - 이메일: support@msp-company.com\n   - 티켓 시스템: https://support.msp-company.com\n3. 초기 응답 시간:\n   - Critical (P1): 15분 이내\n   - High (P2): 1시간 이내\n   - Medium (P3): 4시간 이내\n   - Low (P4): 영업일 기준 1일 이내\n```\n\n#### 📄 SLA 문서\n| 구분 | 포함 내용 | 예시 |\n|------|----------|------|\n| 서비스 가용 시간 | 24x7 또는 8x5 + 시간외 지원 | \"평일 09:00-18:00 정규 운영, 그 외 시간 긴급 핫라인 운영\" |\n| 응답 시간 정의 | 우선순위별 목표 시간 | \"P1: 15분, P2: 1시간\" |\n| 해결 시간 목표 | 우선순위별 해결 목표 | \"P1: 4시간, P2: 8시간\" |\n| 에스컬레이션 | 단계별 담당자 | \"30분 미응답 시 팀장 자동 에스컬레이션\" |\n\n#### 📄 운영 절차서\n```markdown\n## 시간외 지원 프로세스\n\n### 평일 18:00 - 익일 09:00 / 주말 / 공휴일\n\n1. 고객 긴급 전화 수신 (당직 담당자 휴대폰 착신전환)\n2. PagerDuty/Opsgenie 알림 자동 발송\n3. 당직 엔지니어 15분 내 콜백\n4. 장애 등급 판정 및 대응 시작\n5. 필요시 AWS Support 케이스 생성 (Business/Enterprise Support)\n```\n\n### 증빙 자료 파일명 예시\n\n```\n✅ 좋은 예시:\n- ABC고객_MSP서비스계약서_2024_서비스데스크조항포함.pdf\n- 서비스데스크_SLA_v2.1_20240115.pdf\n- 24x7_당직운영_절차서_v1.3.docx\n\n❌ 나쁜 예시:\n- 계약서.pdf (어떤 고객인지, 어떤 내용인지 불명확)\n- SLA.docx (버전, 날짜 없음)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 서비스 데스크 채널 인벤토리 작성 (1일)\n\n**담당자**: 서비스 운영팀장\n\n```\n[채널 인벤토리 템플릿]\n\n| 채널 | 연락처 | 운영시간 | 담당자 | 백업담당자 |\n|------|--------|----------|--------|------------|\n| 긴급전화 | 02-1234-5678 | 24x7 | 당직자 | 팀장 |\n| 이메일 | support@company.com | 24x7 (자동응답) | 티켓시스템 | - |\n| 티켓시스템 | Jira Service Desk | 24x7 | 자동배정 | - |\n| Slack | #customer-support | 업무시간 | 운영팀 | - |\n```\n\n### Step 2: 24x7 커버리지 갭 분석 (2일)\n\n**담당자**: 운영팀 + HR\n\n```\n[갭 분석 체크리스트]\n\n□ 현재 시간외 전화 착신전환 설정 확인\n□ 당직 로테이션 스케줄 존재 여부\n□ 당직 수당 및 보상 정책 확인\n□ 공휴일/연휴 커버리지 계획\n□ 백업 담당자 지정 여부\n```\n\n**AWS 도구 활용**: Amazon Connect 또는 기존 PBX 시스템의 착신전환 로그 확인\n\n### Step 3: 시간외 지원 체계 구축/보완 (1주)\n\n**담당자**: 운영팀장 + IT인프라팀\n\n```bash\n# PagerDuty/Opsgenie 설정 예시\n# 에스컬레이션 정책 생성\n\nLevel 1: 당직 엔지니어 (즉시 알림)\n         ↓ 15분 미응답\nLevel 2: 팀장 + 시니어 엔지니어\n         ↓ 30분 미응답  \nLevel 3: 본부장 + AWS TAM 연락\n```\n\n### Step 4: 고객 계약서 서비스 데스크 조항 검토/추가 (3일)\n\n**담당자**: 법무팀 + 영업팀 + 운영팀\n\n```\n[계약서 검토 체크리스트]\n\n□ 24x7 서비스 데스크 제공 명시\n□ 연락 채널 (전화, 이메일, 티켓) 구체적 기재\n□ 응답 시간 SLA 수치 명시\n□ 에스컬레이션 프로세스 언급\n□ 양 당사자 서명 및 날짜\n```\n\n### Step 5: 실제 운영 증빙 수집 (1주)\n\n**담당자**: 운영팀\n\n```\n[수집할 증빙 목록]\n\n1. 티켓 시스템 스크린샷\n   - 시간외 접수된 티켓 예시 (새벽 2시 접수 등)\n   - 응답 시간 SLA 달성률 리포트\n\n2. 통화 기록\n   - 콜센터 시스템 통화 로그 (시간외 통화 포함)\n   - 착신전환 설정 화면\n\n3. 당직 스케줄\n   - 월간 당직 로테이션 표\n   - 실제 당직 근무 기록\n```\n\n### Step 6: 문서 패키지 구성 및 내부 검토 (2일)\n\n**담당자**: MSP 프로그램 담당자\n\n```\n📁 최종 제출 패키지 구성\n\nOPS-004_서비스데스크_증빙패키지/\n├── README.txt (증빙 목록 및 설명)\n├── 01_계약서/\n│   └── ABC고객_서비스계약서_서비스데스크조항_highlighted.pdf\n├── 02_SLA문서/\n│   └── 서비스데스크_SLA_v2.1.pdf\n├── 03_운영절차서/\n│   └── 24x7_서비스데스크_운영절차서.pdf\n└── 04_운영증빙/\n    ├── 티켓시스템_시간외접수_스크린샷.png\n    ├── 당직스케줄_2024년1월.xlsx\n    └── 콜센터_통화로그_샘플.pdf\n```\n\n### 예상 소요 시간 요약\n\n| 단계 | 소요 시간 | 담당자 |\n|------|----------|--------|\n| Step 1 | 1일 | 운영팀장 |\n| Step 2 | 2일 | 운영팀 + HR |\n| Step 3 | 1주 | 운영팀장 + IT인프라팀 |\n| Step 4 | 3일 | 법무팀 + 영업팀 |\n| Step 5 | 1주 | 운영팀 |\n| Step 6 | 2일 | MSP 프로그램 담당자 |\n| **총합** | **약 3주** | - |\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수 TOP 5\n\n#### 실수 1: \"24x7\"이라고 주장하지만 실제로는 8x5 운영\n\n```\n❌ 문제 상황:\n- 계약서에 \"24x7 지원\"이라고 적혀 있음\n- 실제로는 평일 업무시간만 전화 응대\n- 시간외에는 이메일만 가능하고 다음 영업일 응답\n\n✅ 해결 방법:\n- 옵션 A: 실제 24x7 당직 체계 구축\n- 옵션 B: 계약서를 \"8x5 + 시간외 긴급 핫라인\"으로 정확히 수정\n- 시간외 지원의 범위와 응답 시간을 명확히 정의\n```\n\n#### 실수 2: 계약서에 서비스 데스크 조항이 없음\n\n```\n❌ 문제 상황:\n- 일반적인 MSP 서비스 계약서만 존재\n- \"기술 지원 제공\" 정도의 모호한 문구만 있음\n- 연락처, 응답 시간, 운영 시간 명시 없음\n\n✅ 해결 방법:\n- 기존 계약서에 부속합의서(Amendment) 추가\n- 또는 SLA 문서를 별도 첨부하고 계약서에서 참조\n```\n\n**부속합의서 예시:**\n```\n[부속합의서 제X호 - 서비스 데스크 운영]\n\n본 합의서는 YYYY년 MM월 DD일자 MSP 서비스 계약의 \n부속합의서로서, 서비스 데스크 운영에 관한 세부사항을 정한다.\n\n1. 서비스 데스크 운영 시간: 24시간 365일\n2. 연락 채널: (상세 기재)\n3. 응답 시간: (상세 기재)\n\n갑: _____________ (서명)\n을: _____________ (서명)\n```\n\n#### 실수 3: 단일 채널만 운영\n\n```\n❌ 문제 상황:\n- 이메일 티켓 시스템만 운영\n- 긴급 상황에서 전화 연락 불가\n- \"여러 커뮤니케이션 수단\" 요구사항 미충족\n\n✅ 해결 방법:\n- 최소 2개 이상 채널 운영 필수\n- 권장 조합: 전화 + 티켓시스템 + (이메일 또는 채팅)\n```\n\n#### 실수 4: 응답 시간 SLA 미정의\n\n```\n❌ 문제 상황:\n- \"신속하게 응답\", \"최대한 빨리\" 같은 모호한 표현\n- 우선순위별",
      "language": "ko",
      "createdAt": "2026-01-07T02:11:07.614Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-005_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-005",
      "category": "Operations",
      "title": "포괄적인 ITSM 플랫폼 구현",
      "advice": "# OPS-005: 포괄적인 ITSM 플랫폼 구현 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nITSM 플랫폼은 MSP의 **운영 성숙도를 판단하는 핵심 지표**입니다. AWS는 파트너가 단순히 인프라를 관리하는 것이 아니라, **체계적인 서비스 관리 프레임워크**를 통해 고객에게 일관된 품질의 서비스를 제공할 수 있는지 확인합니다. 이 항목은 OPS 카테고리의 다른 모든 요구사항(인시던트, 변경, 문제 관리)의 **기반 인프라** 역할을 합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **플랫폼 통합성** | 5가지 기능(인시던트/문제/변경/요청/보고)이 하나의 플랫폼에서 연동되는가? |\n| **AWS 환경 연동** | CloudWatch, EventBridge, SNS 등과 실제로 연동되어 자동 티켓 생성이 되는가? |\n| **실제 사용 증거** | 최근 3-6개월간의 실제 티켓 데이터가 존재하는가? (데모 데이터 아님) |\n| **워크플로우 자동화** | 수동 작업 없이 에스컬레이션, 알림, 상태 변경이 자동화되어 있는가? |\n| **리포팅 활용** | 경영진/고객에게 제공하는 정기 보고서가 ITSM에서 생성되는가? |\n\n### 관련 AWS 서비스 및 연동 포인트\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    ITSM 플랫폼 (ServiceNow, Jira SM 등)      │\n└─────────────────────────────────────────────────────────────┘\n         ▲              ▲              ▲              ▲\n         │              │              │              │\n    ┌────┴────┐   ┌────┴────┐   ┌────┴────┐   ┌────┴────┐\n    │CloudWatch│   │EventBridge│  │AWS Config│  │Security │\n    │ Alarms   │   │  Rules    │  │  Rules   │  │   Hub   │\n    └─────────┘   └──────────┘   └─────────┘   └─────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n| 증빙 자료 | 형식 | 핵심 포함 내용 |\n|----------|------|---------------|\n| **ITSM 플랫폼 아키텍처 다이어그램** | PDF/Visio | AWS 환경과의 연동 흐름, 데이터 플로우 |\n| **라이브 데모 시나리오 스크립트** | Word/PDF | 5가지 기능별 시연 시나리오 (15-20분용) |\n| **실제 티켓 샘플 (익명화)** | 스크린샷/PDF | 인시던트 5건, 변경 3건, 요청 5건 (최근 3개월) |\n| **자동화 워크플로우 설정 화면** | 스크린샷 | CloudWatch → ITSM 자동 티켓 생성 설정 |\n| **월간 서비스 리포트 샘플** | PDF | ITSM에서 생성된 KPI 대시보드, SLA 현황 |\n| **ITSM 사용자 가이드** | PDF | 내부 운영팀용 플랫폼 사용 매뉴얼 |\n\n### 각 증빙 자료의 핵심 내용\n\n#### 🔹 ITSM 플랫폼 아키텍처 다이어그램\n```\n필수 포함 요소:\n├── AWS 계정 구조 (관리 계정, 고객 계정)\n├── 모니터링 → 알림 → 티켓 생성 흐름\n├── 에스컬레이션 경로 (L1 → L2 → L3)\n├── 외부 연동 (이메일, Slack, PagerDuty 등)\n└── 데이터 저장소 및 백업 구조\n```\n\n#### 🔹 라이브 데모 시나리오 (감사 시 실제 시연용)\n\n**시나리오 1: 인시던트 자동 생성**\n```\n1. CloudWatch에서 CPU 80% 초과 알람 발생\n2. EventBridge 규칙이 트리거됨\n3. Lambda 함수가 ITSM API 호출\n4. P2 인시던트 티켓 자동 생성\n5. 담당자에게 Slack/이메일 알림 발송\n6. 시연 소요시간: 3분\n```\n\n**시나리오 2: 변경 요청 승인 워크플로우**\n```\n1. 운영자가 EC2 인스턴스 타입 변경 요청 등록\n2. CAB(Change Advisory Board) 멤버에게 승인 요청 발송\n3. 승인자가 ITSM에서 승인 처리\n4. 자동으로 변경 일정 캘린더에 등록\n5. 시연 소요시간: 4분\n```\n\n### 증빙 자료 파일명 예시\n\n```\n📁 OPS-005_ITSM_Platform/\n├── OPS-005-01_ITSM_Architecture_Diagram_v2.1.pdf\n├── OPS-005-02_Live_Demo_Script_20240115.docx\n├── OPS-005-03_Incident_Samples_Anonymized.pdf\n├── OPS-005-04_Change_Request_Samples.pdf\n├── OPS-005-05_Service_Request_Samples.pdf\n├── OPS-005-06_CloudWatch_ITSM_Integration_Screenshots.pdf\n├── OPS-005-07_Monthly_Service_Report_Dec2024.pdf\n├── OPS-005-08_Automation_Workflow_Configuration.pdf\n└── OPS-005-09_ITSM_User_Guide_v3.0.pdf\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: ITSM 플랫폼 선정 및 기본 구성 (2-3주)\n\n**권장 플랫폼 옵션:**\n\n| 플랫폼 | 장점 | AWS 연동 용이성 |\n|--------|------|----------------|\n| **ServiceNow** | 엔터프라이즈 표준, AWS Service Management Connector 제공 | ⭐⭐⭐⭐⭐ |\n| **Jira Service Management** | 비용 효율적, Atlassian 생태계 | ⭐⭐⭐⭐ |\n| **Freshservice** | 빠른 구축, 직관적 UI | ⭐⭐⭐ |\n| **Zendesk** | 고객 포털 강점 | ⭐⭐⭐ |\n\n**실행 항목:**\n```bash\n# ServiceNow 선택 시 필수 모듈 활성화\n- Incident Management (INC)\n- Problem Management (PRB)  \n- Change Management (CHG)\n- Service Catalog (SC)\n- Performance Analytics (PA)\n```\n\n### Step 2: AWS 환경과 ITSM 연동 구성 (1-2주)\n\n**CloudWatch → ITSM 연동 Lambda 함수 예시:**\n\n```python\n# lambda_function.py - CloudWatch 알람 → ServiceNow 티켓 생성\nimport json\nimport boto3\nimport requests\n\ndef lambda_handler(event, context):\n    # CloudWatch 알람 파싱\n    alarm_name = event['detail']['alarmName']\n    alarm_state = event['detail']['state']['value']\n    \n    # ServiceNow API 호출\n    servicenow_url = \"https://your-instance.service-now.com/api/now/table/incident\"\n    \n    payload = {\n        \"short_description\": f\"AWS Alert: {alarm_name}\",\n        \"description\": json.dumps(event, indent=2),\n        \"urgency\": \"2\",\n        \"impact\": \"2\",\n        \"category\": \"AWS Infrastructure\",\n        \"assignment_group\": \"Cloud Operations\"\n    }\n    \n    response = requests.post(\n        servicenow_url,\n        auth=(ssm_get_parameter('/servicenow/username'), \n              ssm_get_parameter('/servicenow/password')),\n        headers={\"Content-Type\": \"application/json\"},\n        json=payload\n    )\n    \n    return {\"statusCode\": 200, \"ticketNumber\": response.json()['result']['number']}\n```\n\n**EventBridge 규칙 설정:**\n```json\n{\n  \"source\": [\"aws.cloudwatch\"],\n  \"detail-type\": [\"CloudWatch Alarm State Change\"],\n  \"detail\": {\n    \"state\": {\n      \"value\": [\"ALARM\"]\n    }\n  }\n}\n```\n\n### Step 3: 5가지 핵심 기능 구성 (2-3주)\n\n#### 3-1. 인시던트 관리 설정\n```\n필수 구성:\n├── 우선순위 매트릭스 (Impact × Urgency)\n├── 자동 에스컬레이션 규칙 (P1: 15분, P2: 1시간, P3: 4시간)\n├── SLA 타이머 설정 (응답 시간, 해결 시간)\n└── 주요 인시던트(Major Incident) 프로세스\n```\n\n#### 3-2. 문제 관리 설정\n```\n필수 구성:\n├── 인시던트 → 문제 연결 기능\n├── 근본 원인 분석(RCA) 템플릿\n├── Known Error Database (KEDB)\n└── 문제 해결 후 인시던트 일괄 종료 워크플로우\n```\n\n#### 3-3. 변경 관리 설정\n```\n필수 구성:\n├── 변경 유형 분류 (Standard, Normal, Emergency)\n├── CAB 승인 워크플로우\n├── 변경 캘린더 (Blackout 기간 설정)\n├── 변경 후 검증(PIR) 프로세스\n└── AWS 서비스별 변경 템플릿\n```\n\n#### 3-4. 서비스 요청 관리 설정\n```\n필수 구성:\n├── 서비스 카탈로그 항목 (최소 10개 이상)\n│   ├── EC2 인스턴스 요청\n│   ├── S3 버킷 생성 요청\n│   ├── IAM 사용자 생성 요청\n│   ├── VPN 접근 요청\n│   └── 비용 리포트 요청\n├── 승인 워크플로우 (금액/리스크 기반)\n└── 자동 프로비저닝 연동 (Service Catalog)\n```\n\n#### 3-5. 보고 및 분석 설정\n```\n필수 대시보드:\n├── 실시간 운영 현황 (Open 티켓, SLA 현황)\n├── 주간 트렌드 분석 (티켓 볼륨, 해결 시간)\n├── 월간 SLA 달성률 리포트\n├── 고객별 서비스 현황\n└── 팀 성과 지표 (MTTR, First Call Resolution)\n```\n\n### Step 4: 자동화 워크플로우 구현 (1-2주)\n\n**필수 자동화 시나리오:**\n\n| 시나리오 | 트리거 | 자동화 액션 |\n|---------|--------|------------|\n| 알람 기반 티켓 생성 | CloudWatch Alarm | ITSM 인시던트 생성 + Slack 알림 |\n| 티켓 자동 할당 | 티켓 생성 시 | 카테고리/스킬 기반 담당자 배정 |\n| SLA 위반 에스컬레이션 | SLA 타이머 만료 | 상위 관리자 알림 + 우선순위 상향 |\n| 변경 완료 후 검증 | 변경 상태 = Implemented | PIR 태스크 자동 생성 |\n| 반복 인시던트 감지 | 동일 CI에 3회 이상 인시던트 | 문제 티켓 자동 생성 |\n\n### Step 5: 테스트 데이터 생성 및 검증 (1주)\n\n```\n⚠️ 중요: 감사관은 \"실제 운영 데이터\"를 확인합니다.\n데모 데이터만으로는 통과할 수 없습니다.\n\n필수 확인 사항:\n├── 최근 3개월간 인시던트 티켓 최소 30건 이상\n├── 변경 요청 티켓 최소 10건 이상\n├── 서비스 요청 티켓 최소 20건 이상\n├── 완료된 문제 티켓 최소 3건 이상\n└── 월간 리포트 최소 3개월치\n```\n\n### Step 6: 라이브 데모 리허설 (3-5일)\n\n**데모 시나리오 타임라인 (20분):**\n\n```\n00:00-03:00  플랫폼 개요 및 대시보드 소개\n03:00-07:00  인시던트 관리 시연 (자동 생성 → 처리 → 종료)\n07:00-11:00  변경 관리 시연 (요청 → 승인 → 구현 ",
      "language": "ko",
      "createdAt": "2026-01-07T02:12:00.362Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-006_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-006",
      "category": "Operations",
      "title": "릴리스 관리",
      "advice": "# OPS-006: 릴리스 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n릴리스 관리는 MSP의 **운영 성숙도를 가장 직접적으로 보여주는 지표**입니다. AWS는 MSP 파트너가 고객의 프로덕션 환경에 변경사항을 배포할 때 체계적이고 추적 가능하며 자동화된 프로세스를 갖추고 있는지 확인합니다. 이는 단순히 \"배포를 잘 한다\"가 아니라, **실수를 방지하고 문제 발생 시 빠르게 롤백할 수 있는 체계**가 있는지를 검증하는 것입니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **버전 제어의 일관성** | 모든 코드와 IaC 템플릿이 Git에서 관리되고, 커밋 히스토리가 변경 티켓과 연결되는가? |\n| **환경 분리 및 프로모션 경로** | Dev → Staging → Prod 순서가 강제되는가? Prod에 직접 배포하는 것이 기술적으로 차단되어 있는가? |\n| **승인 게이트의 실효성** | 승인이 형식적인 클릭이 아니라, 실제 검토 후 이루어지는가? 승인자와 배포자가 분리되어 있는가? |\n| **자동화 수준** | 수동 SSH 접속 배포가 아닌, CodePipeline/Terraform/CDK 등을 통한 선언적 배포인가? |\n| **롤백 메커니즘** | 배포 실패 시 자동 롤백이 구현되어 있는가? 롤백 실행 기록이 있는가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                    릴리스 관리 AWS 서비스 맵                      │\n├─────────────────────────────────────────────────────────────────┤\n│  버전 제어        │ AWS CodeCommit, GitHub (AWS 연동)            │\n│  CI/CD 파이프라인 │ AWS CodePipeline, CodeBuild, CodeDeploy      │\n│  IaC 도구        │ AWS CloudFormation, AWS CDK, Terraform        │\n│  승인 관리       │ CodePipeline Manual Approval, SNS 연동        │\n│  배포 전략       │ CodeDeploy (Blue/Green, Canary, Rolling)      │\n│  감사 추적       │ CloudTrail, CodePipeline 실행 히스토리        │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 릴리스 관리 정책서 (Release Management Policy)\n**파일명 예시:** `ACME-Corp-Release-Management-Policy-v2.3.pdf`\n\n**포함 필수 내용:**\n- 환경 정의 (Dev/Staging/Prod 각각의 목적과 접근 권한)\n- 브랜치 전략 (GitFlow, Trunk-based 등 명시)\n- 승인 매트릭스 (변경 유형별 승인자 지정)\n- 배포 윈도우 정의 (금요일 배포 금지 등 정책)\n- 롤백 트리거 조건 및 절차\n\n#### 📄 문서 2: 파이프라인 아키텍처 다이어그램\n**파일명 예시:** `CustomerX-CICD-Pipeline-Architecture-Diagram.png`\n\n**포함 필수 내용:**\n```\n[CodeCommit] → [CodeBuild-Test] → [Staging Deploy] → [Manual Approval] → [Prod Deploy]\n     │              │                    │                  │                 │\n     └── Git Tag ───┴── Unit Tests ──────┴── E2E Tests ─────┴── SNS Alert ────┴── CloudWatch\n```\n\n#### 📄 문서 3: 실제 배포 실행 기록 (스크린샷 패키지)\n**파일명 예시:** `CustomerX-Release-2024-Q4-Evidence-Package.pdf`\n\n**필수 스크린샷 목록:**\n1. CodeCommit/GitHub PR 머지 화면 (승인자 표시)\n2. CodePipeline 실행 화면 (각 스테이지 성공 표시)\n3. Manual Approval 단계 승인 기록\n4. CodeDeploy 배포 성공 화면\n5. CloudWatch 배포 후 메트릭 (에러율 변화 없음 확인)\n\n#### 📄 문서 4: IaC 템플릿 샘플\n**파일명 예시:** `infrastructure/cloudformation/prod-stack.yaml` 또는 `terraform/modules/ecs-service/main.tf`\n\n**감사관 확인 포인트:**\n- 버전 태그가 템플릿에 포함되어 있는가\n- 파라미터화가 되어 환경별 재사용이 가능한가\n- 주석으로 변경 이력이 추적되는가\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 기존 배포 프로세스 매핑 (2-3일)\n\n**담당:** DevOps 리드\n\n현재 고객사에서 실제로 배포가 어떻게 이루어지는지 **있는 그대로** 문서화합니다.\n\n```bash\n# 실제 배포 명령어 히스토리 수집 예시\n$ history | grep -E \"(deploy|terraform|cdk|cloudformation)\" > deployment-commands.txt\n\n# CodePipeline 실행 이력 추출\n$ aws codepipeline list-pipeline-executions --pipeline-name CustomerX-Prod-Pipeline \\\n  --query 'pipelineExecutionSummaries[*].[pipelineExecutionId,status,startTime]' \\\n  --output table\n```\n\n**산출물:** `Current-State-Deployment-Process-Map.xlsx`\n\n### Step 2: 갭 분석 및 개선점 식별 (1-2일)\n\n**담당:** DevOps 리드 + 솔루션 아키텍트\n\nAWS MSP 요구사항 4가지와 현재 상태를 비교:\n\n| 요구사항 | 현재 상태 | 갭 | 개선 액션 |\n|----------|-----------|-----|-----------|\n| 버전 제어 | GitHub 사용 중 | 태그 정책 없음 | Semantic Versioning 도입 |\n| 비프로덕션 테스트 | Staging 있음 | E2E 테스트 미흡 | CodeBuild에 Cypress 추가 |\n| 승인 관리 | Slack 구두 승인 | 추적 불가 | CodePipeline Manual Approval 도입 |\n| IaC 자동화 | 일부 수동 배포 | EC2 수동 설정 | CloudFormation 전환 |\n\n### Step 3: CodePipeline 승인 게이트 구현 (3-5일)\n\n**담당:** DevOps 엔지니어\n\n```yaml\n# CodePipeline Manual Approval 스테이지 예시\n- Name: ProductionApproval\n  Actions:\n    - Name: ApproveDeployment\n      ActionTypeId:\n        Category: Approval\n        Owner: AWS\n        Provider: Manual\n        Version: '1'\n      Configuration:\n        NotificationArn: arn:aws:sns:ap-northeast-2:123456789012:deployment-approvals\n        CustomData: \"Production deployment for release v2.3.1 - Review CloudWatch metrics before approval\"\n        ExternalEntityLink: \"https://grafana.company.com/d/prod-metrics\"\n      RunOrder: 1\n```\n\n**핵심 설정:**\n- SNS 토픽을 통해 승인 요청 알림 발송\n- `ExternalEntityLink`에 Staging 테스트 결과 대시보드 링크 포함\n- 승인 타임아웃 설정 (예: 24시간)\n\n### Step 4: 환경별 배포 분리 강제화 (2-3일)\n\n**담당:** DevOps 엔지니어 + 보안 담당\n\n```hcl\n# Terraform 예시: 환경별 IAM 역할 분리\nresource \"aws_iam_role\" \"codepipeline_role\" {\n  name = \"codepipeline-${var.environment}-role\"\n  \n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Effect = \"Allow\"\n      Principal = {\n        Service = \"codepipeline.amazonaws.com\"\n      }\n      Action = \"sts:AssumeRole\"\n      Condition = {\n        StringEquals = {\n          \"aws:SourceAccount\" = var.allowed_account_ids[var.environment]\n        }\n      }\n    }]\n  })\n}\n```\n\n**검증 방법:** Dev 파이프라인에서 Prod 리소스 접근 시도 → Access Denied 확인\n\n### Step 5: 롤백 메커니즘 구현 및 테스트 (2-3일)\n\n**담당:** DevOps 엔지니어\n\n```yaml\n# CodeDeploy Blue/Green 배포 설정 예시\ndeployment_config:\n  deployment_type: BLUE_GREEN\n  deployment_option: WITH_TRAFFIC_CONTROL\n  \n  blue_green_deployment_configuration:\n    terminate_blue_instances_on_deployment_success:\n      action: TERMINATE\n      termination_wait_time_in_minutes: 60  # 1시간 관찰 후 이전 버전 종료\n    \n    deployment_ready_option:\n      action_on_timeout: STOP_DEPLOYMENT\n      wait_time_in_minutes: 30\n    \n  alarm_configuration:\n    enabled: true\n    alarms:\n      - name: \"HighErrorRate-${var.service_name}\"  # 에러율 급증 시 자동 롤백\n```\n\n**필수 테스트:** 의도적으로 실패하는 배포를 실행하여 롤백 동작 확인 → 스크린샷 확보\n\n### Step 6: 증빙 패키지 구성 (2-3일)\n\n**담당:** 프로젝트 매니저 + DevOps 리드\n\n**증빙 패키지 구조:**\n```\nCustomerX-Release-Management-Evidence/\n├── 01-Policy-Documents/\n│   ├── Release-Management-Policy-v2.3.pdf\n│   └── Branch-Strategy-Guidelines.pdf\n├── 02-Architecture/\n│   ├── CICD-Pipeline-Diagram.png\n│   └── Environment-Promotion-Flow.png\n├── 03-Pipeline-Configuration/\n│   ├── codepipeline-definition.yaml\n│   ├── buildspec.yml\n│   └── appspec.yml\n├── 04-Execution-Evidence/\n│   ├── Release-v2.3.1-Screenshots/\n│   │   ├── 01-PR-Merge-Approval.png\n│   │   ├── 02-CodeBuild-Test-Results.png\n│   │   ├── 03-Staging-Deployment-Success.png\n│   │   ├── 04-Manual-Approval-Record.png\n│   │   ├── 05-Production-Deployment-Success.png\n│   │   └── 06-Post-Deployment-Metrics.png\n│   └── Rollback-Test-Evidence/\n│       ├── Intentional-Failure-Deployment.png\n│       └── Automatic-Rollback-Success.png\n└── 05-IaC-Templates/\n    ├── cloudformation/\n    └── terraform/\n```\n\n### Step 7: 엔드투엔드 시연 준비 (1일)\n\n**담당:** DevOps 리드\n\n감사 시 라이브 데모 요청에 대비하여 다음 시나리오 준비:\n\n1. **정상 배포 시연** (10분)\n   - 코드 변경 → PR 생성 → 리뷰 → 머지 → 파이프라인 자동 트리거 → Staging 배포 → 승인 → Prod 배포\n\n2. **롤백 시연** (5분)\n   - 의도적 실패 배포 → CloudWatch 알람 트리거 → 자동 롤백 → 이전 버전 복원 확인\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: \"승인 기록이 Slack/이메일에만 존재\"\n\n**문제:** 감사관은 AWS 서비스 내에서 추적 가능한 승인 기록을 요구합니다.\n\n**해결책:**\n```\n❌ Slack: \"@devops 배포 승인 부탁드립니다\" → \"👍\"\n✅ CodePipeline Manual Approval: 승인자 IAM ARN, 타임스탬프, 코멘트 자동 기록\n```\n\n### 🚫 실수 2: \"Staging 환경이 Prod와 구성이 다름\"\n\n**문제:** Staging에서 테스트 통과 후 Prod에서 실패하는 경우, 테스트의 의미가 없습니다.\n\n**해결책:**\n- 동일한 CloudFormation/Terraform 템플릿 사용\n- 환경별 차이는 파라미터로만 관리 (인스턴스 크기, 개수 등)\n- `terraform plan` 결과를 증빙에 포함하여 환경 일관성 증명\n\n### 🚫 실수 3: \"IaC 템플릿이 있지만 실제로는 콘솔에서 수동 변경\"\n\n**문제:** CloudFormation 스택이 있어도 `Drift Detection`에서 차이가 발견되",
      "language": "ko",
      "createdAt": "2026-01-07T02:12:57.420Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-007_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-007",
      "category": "Operations",
      "title": "구성 관리",
      "advice": "# OPS-007: 구성 관리 (Configuration Management) 상세 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n구성 관리는 MSP의 **운영 성숙도를 가장 직접적으로 보여주는 지표**입니다. AWS 환경에서 \"누가, 언제, 무엇을, 왜 변경했는지\"를 추적하지 못하면 장애 원인 분석이 불가능하고, 컴플라이언스 감사에서 치명적인 결함으로 판정됩니다. 특히 고객 환경에서 발생하는 Configuration Drift(구성 편차)를 감지하고 교정하는 능력은 MSP의 핵심 역량입니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **변경 이력의 완전성** | 모든 리소스 변경이 누락 없이 기록되는가? 수동 변경도 포착되는가? |\n| **승인 워크플로 존재** | 변경 전 승인 프로세스가 있는가? 긴급 변경에 대한 예외 처리는? |\n| **롤백 가능성 증명** | 실제로 롤백을 수행한 이력이 있는가? 롤백 절차가 문서화되어 있는가? |\n| **변경자 식별 가능성** | IAM 사용자/역할 수준에서 변경 주체를 특정할 수 있는가? |\n| **실시간 알림 체계** | 비인가 변경 또는 중요 변경에 대한 즉각적 알림이 작동하는가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    구성 관리 AWS 서비스 맵                    │\n├─────────────────────────────────────────────────────────────┤\n│  [변경 기록]          [변경 감지]           [변경 실행]       │\n│  ┌──────────┐        ┌──────────┐        ┌──────────┐       │\n│  │AWS Config│◄──────►│CloudTrail│◄──────►│CloudForm │       │\n│  │          │        │          │        │ation     │       │\n│  └────┬─────┘        └────┬─────┘        └────┬─────┘       │\n│       │                   │                   │             │\n│       ▼                   ▼                   ▼             │\n│  ┌──────────┐        ┌──────────┐        ┌──────────┐       │\n│  │Config    │        │EventBrid │        │Service   │       │\n│  │Rules     │        │ge        │        │Catalog   │       │\n│  └──────────┘        └──────────┘        └──────────┘       │\n│                                                             │\n│  [승인 워크플로]      [알림]              [IaC 도구]         │\n│  ┌──────────┐        ┌──────────┐        ┌──────────┐       │\n│  │Systems   │        │SNS/Slack │        │Terraform │       │\n│  │Manager   │        │Integrat. │        │CDK       │       │\n│  │Change Mgr│        │          │        │          │       │\n│  └──────────┘        └──────────┘        └──────────┘       │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 상세\n\n#### 📄 증빙 1: AWS Config 구성 이력 스크린샷 (필수)\n\n**파일명 예시:** `OPS-007_Evidence1_AWSConfig_ResourceTimeline_CustomerA_2024.pdf`\n\n**포함 필수 내용:**\n```\n✓ AWS Config 콘솔 > 리소스 > 타임라인 화면\n✓ 최소 3개 이상의 리소스 유형에 대한 변경 이력\n  - EC2 인스턴스 (보안 그룹 변경)\n  - RDS 인스턴스 (파라미터 그룹 변경)\n  - S3 버킷 (버킷 정책 변경)\n✓ 각 변경에 대해 표시되어야 할 정보:\n  - Configuration Item ID\n  - 변경 전/후 상태 (JSON diff)\n  - 변경 시간 (UTC 타임스탬프)\n  - 관련 CloudTrail 이벤트 링크\n```\n\n**캡처 시 주의사항:**\n- 고객 계정 ID가 보이도록 상단 네비게이션 포함\n- 날짜 범위가 최근 30일 이내인지 확인\n- 민감 정보(IP, 계정명)는 마스킹 처리\n\n#### 📄 증빙 2: 변경 승인 워크플로 증빙 (필수)\n\n**파일명 예시:** `OPS-007_Evidence2_ChangeApprovalWorkflow_SSMChangeMgr_2024.pdf`\n\n**Option A - AWS Systems Manager Change Manager 사용 시:**\n```\n캡처 필수 화면:\n1. Change Manager 콘솔 > 변경 요청 목록\n2. 개별 변경 요청 상세 (승인자, 승인 시간 표시)\n3. 변경 템플릿 설정 (승인 워크플로 정의)\n4. 실행 완료된 변경의 Runbook 실행 결과\n```\n\n**Option B - 외부 ITSM 도구 사용 시 (ServiceNow, Jira 등):**\n```\n캡처 필수 화면:\n1. 변경 요청 티켓 (AWS 리소스 변경 내용 명시)\n2. 승인 이력 (승인자, 승인 일시)\n3. AWS 작업과의 연결 증빙 (티켓 번호가 CloudTrail 이벤트 태그에 포함)\n4. 변경 완료 후 티켓 종료 화면\n```\n\n#### 📄 증빙 3: CloudTrail 이벤트 로그 샘플 (필수)\n\n**파일명 예시:** `OPS-007_Evidence3_CloudTrail_ChangeEvents_CustomerA_2024.json`\n\n**포함해야 할 이벤트 유형:**\n```json\n{\n  \"증빙에_포함할_이벤트_예시\": [\n    {\n      \"eventName\": \"ModifyDBInstance\",\n      \"userIdentity\": \"arn:aws:iam::123456789012:user/ops-engineer-kim\",\n      \"eventTime\": \"2024-01-15T09:30:00Z\",\n      \"requestParameters\": {\n        \"dBInstanceIdentifier\": \"prod-mysql-01\",\n        \"dBInstanceClass\": \"db.r5.xlarge\"\n      },\n      \"태그\": {\n        \"change-ticket\": \"CHG-2024-0115\"\n      }\n    }\n  ],\n  \"필수_포함_필드\": [\n    \"userIdentity (변경 실행자)\",\n    \"eventTime (변경 시간)\",\n    \"eventName (변경 유형)\",\n    \"requestParameters (변경 내용)\",\n    \"sourceIPAddress (변경 출처)\"\n  ]\n}\n```\n\n#### 📄 증빙 4: 구성 변경 알림 설정 및 수신 증빙 (필수)\n\n**파일명 예시:** `OPS-007_Evidence4_ConfigChangeNotification_Setup_2024.pdf`\n\n**포함 필수 내용:**\n```\n1. EventBridge 규칙 설정 화면\n   - 규칙 패턴: AWS Config 구성 변경 이벤트\n   - 대상: SNS 토픽 또는 Lambda 함수\n\n2. SNS 토픽 구독 목록\n   - 이메일/Slack 구독자 목록\n\n3. 실제 수신된 알림 예시\n   - Slack 채널 스크린샷 (알림 메시지 내용 포함)\n   - 또는 이메일 수신 화면\n```\n\n#### 📄 증빙 5: 롤백 수행 이력 (권장)\n\n**파일명 예시:** `OPS-007_Evidence5_RollbackExecution_CustomerA_2024.pdf`\n\n```\n실제 롤백 수행 증빙 (아래 중 하나):\n\nOption A - CloudFormation 스택 롤백\n├── CloudFormation 콘솔 > 스택 이벤트\n├── \"ROLLBACK_COMPLETE\" 상태 표시\n└── 롤백 전/후 리소스 상태 비교\n\nOption B - Terraform State 롤백\n├── terraform state list 출력\n├── terraform apply (이전 버전) 실행 로그\n└── 변경 전/후 상태 diff\n\nOption C - AWS Backup 복원\n├── 복원 작업 상세 화면\n├── 복원 완료 시간\n└── 복원된 리소스 확인\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: AWS Config 활성화 및 규칙 구성 (3-5일)\n\n**담당:** 클라우드 엔지니어\n\n```bash\n# AWS Config 활성화 확인 (모든 리전)\naws configservice describe-configuration-recorders --region ap-northeast-2\n\n# 필수 Config Rules 배포 (CloudFormation 예시)\naws cloudformation deploy \\\n  --template-file config-rules-msp.yaml \\\n  --stack-name msp-config-rules \\\n  --capabilities CAPABILITY_IAM\n```\n\n**필수 Config Rules:**\n| 규칙 이름 | 목적 | 평가 대상 |\n|----------|------|----------|\n| `required-tags` | 변경 티켓 태그 존재 확인 | 모든 리소스 |\n| `ec2-security-group-attached-to-eni` | SG 변경 추적 | EC2, ENI |\n| `rds-instance-public-access-check` | RDS 구성 변경 감지 | RDS |\n| `s3-bucket-policy-grantee-check` | S3 정책 변경 추적 | S3 |\n\n### Step 2: CloudTrail 고급 설정 (2-3일)\n\n**담당:** 보안 엔지니어\n\n```bash\n# 조직 트레일 설정 확인\naws cloudtrail describe-trails --query 'trailList[?IsOrganizationTrail==`true`]'\n\n# 데이터 이벤트 로깅 활성화 (S3, Lambda)\naws cloudtrail put-event-selectors \\\n  --trail-name org-trail \\\n  --event-selectors '[{\n    \"ReadWriteType\": \"WriteOnly\",\n    \"IncludeManagementEvents\": true,\n    \"DataResources\": [\n      {\"Type\": \"AWS::S3::Object\", \"Values\": [\"arn:aws:s3:::critical-bucket/\"]}\n    ]\n  }]'\n```\n\n**CloudTrail 설정 체크리스트:**\n- [ ] 모든 리전에서 로깅 활성화\n- [ ] S3 버킷 로그 무결성 검증 활성화\n- [ ] CloudWatch Logs 통합 설정\n- [ ] 90일 이상 보관 정책 설정\n\n### Step 3: 변경 승인 워크플로 구축 (5-7일)\n\n**담당:** DevOps 엔지니어, 운영 관리자\n\n**AWS Systems Manager Change Manager 설정:**\n\n```yaml\n# Change Template 예시 (SSM Document)\nschemaVersion: \"0.3\"\ndescription: \"EC2 인스턴스 타입 변경 승인 템플릿\"\nassumeRole: \"{{AutomationAssumeRole}}\"\nparameters:\n  InstanceId:\n    type: String\n    description: \"변경 대상 EC2 인스턴스 ID\"\n  NewInstanceType:\n    type: String\n    description: \"변경할 인스턴스 타입\"\n  ChangeTicket:\n    type: String\n    description: \"ITSM 변경 티켓 번호\"\nmainSteps:\n  - name: ApprovalGate\n    action: aws:approve\n    inputs:\n      Approvers:\n        - \"arn:aws:iam::123456789012:role/ChangeApprovers\"\n      MinRequiredApprovals: 1\n      Message: \"EC2 인스턴스 타입 변경 승인 요청\"\n  - name: StopInstance\n    action: aws:changeInstanceState\n    inputs:\n      InstanceIds: [\"{{InstanceId}}\"]\n      DesiredState: stopped\n  - name: ModifyInstanceType\n    action: aws:executeAwsApi\n    inputs:\n      Service: ec2\n      Api: ModifyInstanceAttribute\n      InstanceId: \"{{InstanceId}}\"\n      InstanceType:\n        Value: \"{{NewInstanceType}}\"\n  - name: StartInstance\n    action: aws:changeInstanceState\n    inputs:\n      InstanceIds: [\"{{InstanceId}}\"]\n      DesiredState: running\n```\n\n### Step 4: 실시간 알림 체계 구축 (2-3일)\n\n**담당:** 클라우드 엔지니어\n\n```python\n# EventBridge Rule (Terraform 예시)\nresource \"aws_cloudwatch_event_rule\" \"config_change_alert\" {\n  name        = \"msp-config-change-notification\"\n  description = \"AWS Config 구성 변경 알림\"\n\n  event_pattern = jsonencode({\n    source      = [\"aws.config\"]\n    detail-type = [\"Config Configuration Item Change\"]\n    detail = {\n      configurationItem = {\n        resourceType = [\n          \"AWS::EC2::SecurityGroup\",\n          \"AWS::RDS::DBInstance\",\n          \"AWS::IAM::Role\",\n          \"AWS::S3::Bucket\"\n        ]\n      }\n    }\n  })\n}\n\nresource \"aws_cloudwatch_event_target\" \"sns_target\" {\n  rule      = aws_cloudwatch_event_rule.config_change_alert.name\n  target",
      "language": "ko",
      "createdAt": "2026-01-07T02:13:49.705Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-008_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-008",
      "category": "Operations",
      "title": "패치 관리",
      "advice": "# OPS-008: 패치 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP에서 중요한가?\n\n패치 관리는 **MSP의 운영 성숙도를 가장 직접적으로 보여주는 지표**입니다. 고객의 EC2 인스턴스, 컨테이너 이미지, 데이터베이스 엔진에 보안 취약점이 발생했을 때, MSP가 얼마나 신속하고 체계적으로 대응할 수 있는지를 증명해야 합니다.\n\n2023년 기준 AWS MSP 감사에서 **패치 관리 미흡으로 인한 탈락률이 약 23%**에 달할 정도로 까다로운 항목입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **자동화 수준** | 수동 개입 없이 패치가 스케줄링되고 적용되는가? |\n| **커버리지** | OS, 미들웨어, 애플리케이션 레이어 모두 포함하는가? |\n| **규정 준수 추적** | 패치 미적용 인스턴스를 실시간으로 식별하고 보고하는가? |\n| **롤백 메커니즘** | 패치 실패 시 자동 복구 프로세스가 있는가? |\n| **고객별 정책 분리** | 멀티테넌트 환경에서 고객별 패치 정책을 관리하는가? |\n\n### 관련 AWS 서비스\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    AWS Systems Manager                       │\n│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │\n│  │ Patch Manager│  │  Maintenance │  │   State      │       │\n│  │              │  │   Windows    │  │   Manager    │       │\n│  └──────────────┘  └──────────────┘  └──────────────┘       │\n└─────────────────────────────────────────────────────────────┘\n         │                    │                    │\n         ▼                    ▼                    ▼\n┌─────────────┐      ┌─────────────┐      ┌─────────────┐\n│  Inspector  │      │ CloudWatch  │      │   Config    │\n│ (취약점스캔)│      │  (모니터링) │      │ (규정준수)  │\n└─────────────┘      └─────────────┘      └─────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 증빙\n\n| 문서명 | 형식 | 핵심 포함 내용 |\n|--------|------|---------------|\n| `Patch_Management_Policy_v2.3.pdf` | PDF | 패치 분류 기준(Critical/High/Medium/Low), SLA 정의, 승인 프로세스 |\n| `Patch_Baseline_Configuration.xlsx` | Excel | 고객별/OS별 패치 베이스라인 설정값, 제외 패치 목록과 사유 |\n| `Maintenance_Window_Schedule.pdf` | PDF | 고객별 유지보수 윈도우 시간대, 에스컬레이션 연락처 |\n\n#### 🖥️ 기술 시연 증빙\n\n| 시연 항목 | 형식 | 시연 시간 |\n|----------|------|----------|\n| SSM Patch Manager 대시보드 라이브 시연 | 화면 녹화 + 라이브 | 10분 |\n| 패치 규정 준수 보고서 생성 과정 | 화면 녹화 | 5분 |\n| 패치 실패 시 알림 및 롤백 시연 | 화면 녹화 | 7분 |\n\n### 증빙 자료 상세 내용\n\n#### 🔹 Patch Manager 구성 스크린샷 필수 포함 항목\n\n```json\n// 패치 베이스라인 예시 (스크린샷에 이 설정이 보여야 함)\n{\n  \"Name\": \"MSP-Production-AmazonLinux2-Baseline\",\n  \"OperatingSystem\": \"AMAZON_LINUX_2\",\n  \"ApprovalRules\": {\n    \"PatchRules\": [\n      {\n        \"PatchFilterGroup\": {\n          \"PatchFilters\": [\n            {\"Key\": \"SEVERITY\", \"Values\": [\"Critical\", \"Important\"]}\n          ]\n        },\n        \"ApproveAfterDays\": 3,  // Critical은 3일 후 자동 승인\n        \"ComplianceLevel\": \"CRITICAL\"\n      }\n    ]\n  },\n  \"ApprovedPatchesEnableNonSecurity\": true\n}\n```\n\n#### 🔹 규정 준수 보고서 예시 형식\n\n```\n============================================\nMSP 패치 규정 준수 보고서\n보고 기간: 2024-01-01 ~ 2024-01-31\n============================================\n\n[고객: ABC Corp]\n├── 총 관리 인스턴스: 47대\n├── 규정 준수 인스턴스: 45대 (95.7%)\n├── 미준수 인스턴스: 2대\n│   ├── i-0abc123def (pending reboot)\n│   └── i-0xyz789ghi (patch failed - 티켓 #INC-2024-0142)\n└── Critical 패치 적용 평균 시간: 2.3일\n\n[고객: XYZ Inc]\n├── 총 관리 인스턴스: 123대\n├── 규정 준수 인스턴스: 123대 (100%)\n└── Critical 패치 적용 평균 시간: 1.8일\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: SSM Agent 전체 배포 확인 (3일)\n\n**담당: 인프라팀**\n\n```bash\n# 모든 관리 대상 인스턴스에서 SSM Agent 상태 확인\naws ssm describe-instance-information \\\n  --query 'InstanceInformationList[*].[InstanceId,PingStatus,AgentVersion]' \\\n  --output table\n\n# 예상 결과: 모든 인스턴스가 \"Online\" 상태여야 함\n```\n\n⚠️ **체크포인트**: SSM Agent 버전이 3.0 이상인지 확인 (구버전은 Patch Manager 기능 제한)\n\n---\n\n### Step 2: 고객별 패치 베이스라인 생성 (5일)\n\n**담당: 보안팀 + 고객 담당 엔지니어**\n\n```bash\n# 프로덕션용 베이스라인 생성\naws ssm create-patch-baseline \\\n  --name \"MSP-Prod-AmazonLinux2-Critical\" \\\n  --operating-system \"AMAZON_LINUX_2\" \\\n  --approval-rules \"PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=SEVERITY,Values=[Critical,Important]}]},ApproveAfterDays=3,ComplianceLevel=CRITICAL}]\" \\\n  --description \"Production 환경 Critical/Important 패치 - 3일 자동승인\"\n\n# 개발용 베이스라인 (더 빠른 적용)\naws ssm create-patch-baseline \\\n  --name \"MSP-Dev-AmazonLinux2-All\" \\\n  --operating-system \"AMAZON_LINUX_2\" \\\n  --approval-rules \"PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=SEVERITY,Values=[Critical,Important,Medium,Low]}]},ApproveAfterDays=0,ComplianceLevel=MEDIUM}]\"\n```\n\n**필수 베이스라인 매트릭스:**\n\n| 환경 | OS | Critical 승인 | High 승인 | Medium 승인 |\n|------|-----|--------------|-----------|-------------|\n| Production | Amazon Linux 2 | 3일 | 7일 | 14일 |\n| Production | Windows 2019 | 3일 | 7일 | 14일 |\n| Staging | All | 1일 | 3일 | 7일 |\n| Development | All | 즉시 | 즉시 | 즉시 |\n\n---\n\n### Step 3: Maintenance Window 구성 (3일)\n\n**담당: 운영팀**\n\n```bash\n# 유지보수 윈도우 생성 (매주 일요일 새벽 2시, 4시간)\naws ssm create-maintenance-window \\\n  --name \"MSP-CustomerA-Prod-PatchWindow\" \\\n  --schedule \"cron(0 2 ? * SUN *)\" \\\n  --duration 4 \\\n  --cutoff 1 \\\n  --allow-unassociated-targets \\\n  --tags \"Key=Customer,Value=CustomerA\" \"Key=Environment,Value=Production\"\n\n# 패치 태스크 등록\naws ssm register-task-with-maintenance-window \\\n  --window-id \"mw-0abc123456789\" \\\n  --task-arn \"AWS-RunPatchBaseline\" \\\n  --task-type \"RUN_COMMAND\" \\\n  --targets \"Key=tag:PatchGroup,Values=CustomerA-Prod\" \\\n  --task-invocation-parameters '{\n    \"RunCommand\": {\n      \"Parameters\": {\n        \"Operation\": [\"Install\"],\n        \"RebootOption\": [\"RebootIfNeeded\"]\n      }\n    }\n  }'\n```\n\n---\n\n### Step 4: 규정 준수 모니터링 대시보드 구축 (4일)\n\n**담당: DevOps팀**\n\n**CloudWatch 대시보드 위젯 구성:**\n\n```json\n{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"패치 규정 준수율 (고객별)\",\n        \"metrics\": [\n          [\"AWS/SSM\", \"PatchComplianceCount\", \"PatchGroup\", \"CustomerA-Prod\", {\"stat\": \"Sum\"}],\n          [\"AWS/SSM\", \"PatchComplianceCount\", \"PatchGroup\", \"CustomerB-Prod\", {\"stat\": \"Sum\"}]\n        ]\n      }\n    },\n    {\n      \"type\": \"alarm\",\n      \"properties\": {\n        \"title\": \"패치 미준수 알람\",\n        \"alarms\": [\n          \"arn:aws:cloudwatch:ap-northeast-2:123456789:alarm:PatchNonCompliance-Critical\"\n        ]\n      }\n    }\n  ]\n}\n```\n\n---\n\n### Step 5: 자동 알림 및 에스컬레이션 설정 (2일)\n\n**담당: 운영팀**\n\n```yaml\n# EventBridge 규칙 - 패치 실패 시 즉시 알림\n{\n  \"source\": [\"aws.ssm\"],\n  \"detail-type\": [\"EC2 State Manager Instance Association State Change\"],\n  \"detail\": {\n    \"status\": [\"Failed\"]\n  }\n}\n\n# SNS 토픽으로 전송 → PagerDuty/Slack 연동\n```\n\n---\n\n### Step 6: 롤백 프로세스 문서화 및 테스트 (3일)\n\n**담당: 보안팀 + 인프라팀**\n\n```bash\n# AMI 기반 롤백을 위한 사전 스냅샷 자동화\n# Maintenance Window 실행 전 자동으로 AMI 생성\n\naws ssm create-document \\\n  --name \"MSP-PrePatch-CreateAMI\" \\\n  --document-type \"Automation\" \\\n  --content '{\n    \"schemaVersion\": \"0.3\",\n    \"description\": \"패치 전 AMI 자동 생성\",\n    \"mainSteps\": [\n      {\n        \"name\": \"createImage\",\n        \"action\": \"aws:createImage\",\n        \"inputs\": {\n          \"InstanceId\": \"{{ InstanceId }}\",\n          \"ImageName\": \"PrePatch-{{ InstanceId }}-{{ global:DATE }}\"\n        }\n      }\n    ]\n  }'\n```\n\n---\n\n### Step 7: 감사용 시연 리허설 (2일)\n\n**담당: 전체 팀**\n\n**시연 시나리오 스크립트:**\n\n```\n[시연 1] 패치 베이스라인 및 규정 준수 현황 (5분)\n1. SSM 콘솔 → Patch Manager → Dashboard 이동\n2. \"Compliance by patch group\" 섹션 확대\n3. 특정 고객 그룹 클릭 → 상세 규정 준수 현황 표시\n4. \"Non-compliant instances\" 필터링 → 미준수 사유 설명\n\n[시연 2] 패치 자동화 프로세스 (7분)\n1. Maintenance Windows 목록 표시\n2. 특정 윈도우의 실행 이력 표시\n3. Run Command → Command history → 최근 패치 실행 결과\n4. 성공/실패 인스턴스 비율 설명\n\n[시연 3] 실시간 보고서 생성 (3분)\n1. Compliance → \"Export to S3\" 실행\n2. S3 버킷에서 CSV 다운로드\n3. 보고서 내용 간략히 설명\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: SSM Agent 미설치 인스턴스 존재\n\n```\n❌ 문제 상황:\n- 전체 150대 인스턴스 중 12대가 SSM에서 \"Connection Lost\"\n- 감사관: \"이 인스턴스들은 어떻게 패치하나요?\"\n- 답변 불가 → 감사 탈락\n\n✅ 해결책:\n- AWS Config 규칙으로 SSM Agent 미설치 인스턴스 자동 탐지\n- 규칙명: \"ec2-instance-managed-by-systems-manager\"\n```\n\n```bash\n# Config 규칙 생성\naws configservice put-config-rule \\\n  --config-rule '{\n    \"ConfigRuleName\":",
      "language": "ko",
      "createdAt": "2026-01-07T02:14:43.308Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-009_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-009",
      "category": "Operations",
      "title": "고객 배포 파이프라인",
      "advice": "# OPS-009: 고객 배포 파이프라인 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\nAWS MSP 프로그램에서 배포 파이프라인은 **운영 성숙도의 핵심 지표**입니다. AWS는 MSP 파트너가 단순히 인프라를 관리하는 것을 넘어, 고객의 **소프트웨어 딜리버리 속도와 안정성**을 동시에 향상시킬 수 있는 역량을 요구합니다. 수동 배포는 인적 오류, 일관성 부족, 감사 추적 불가 등의 문제를 야기하므로, 자동화된 파이프라인은 MSP의 필수 역량입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **완전 자동화 여부** | 코드 커밋부터 프로덕션 배포까지 수동 CLI/콘솔 작업 없이 진행되는가? |\n| **롤백 메커니즘** | 배포 실패 시 자동 또는 원클릭 롤백이 구현되어 있는가? |\n| **배포 이력 추적** | 누가, 언제, 무엇을 배포했는지 감사 로그가 존재하는가? |\n| **반복 가능성** | 동일한 파이프라인이 여러 환경(Dev/Staging/Prod)에서 일관되게 동작하는가? |\n| **승인 게이트** | 프로덕션 배포 전 수동 승인 단계가 적절히 구현되어 있는가? (허용됨) |\n\n### 관련 AWS 서비스\n\n```\n핵심 서비스: AWS CodePipeline, AWS CodeDeploy, AWS CodeBuild\n지원 서비스: AWS CodeCommit/GitHub, Amazon ECR, AWS CloudFormation, AWS CDK\n모니터링: Amazon CloudWatch, AWS X-Ray, AWS CloudTrail\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📹 옵션 A: 샌드박스 라이브 시연 (권장)\n```\n파일명: OPS-009_Deployment_Pipeline_Demo_Recording.mp4\n길이: 10-15분\n형식: 화면 녹화 + 음성 설명\n```\n\n**시연에 반드시 포함할 시나리오:**\n1. 코드 변경 → Git Push → 파이프라인 자동 트리거\n2. Build → Test → Staging 배포 → 수동 승인 → Production 배포\n3. 의도적 실패 유발 → 자동 롤백 또는 수동 롤백 실행\n4. CloudWatch/CloudTrail에서 배포 로그 확인\n\n#### 📊 옵션 B: 고객 배포 로그 증빙\n```\n파일명: OPS-009_Customer_Deployment_History_[고객명].pdf\n기간: 최근 3개월 이상의 배포 이력\n건수: 최소 10회 이상의 성공적인 배포 기록\n```\n\n**포함 내용:**\n| 항목 | 예시 |\n|------|------|\n| 배포 일시 | 2024-01-15 14:32:00 UTC |\n| 파이프라인 ID | pipeline-abc123 |\n| 배포 버전 | v2.3.1 (commit: a1b2c3d) |\n| 배포 환경 | Production |\n| 실행자 | pipeline-service-role (자동) |\n| 소요 시간 | 8분 32초 |\n| 결과 | SUCCESS / ROLLED_BACK |\n\n### 증빙 자료 예시 파일 구조\n\n```\nOPS-009_Evidence/\n├── 01_Pipeline_Architecture_Diagram.png\n├── 02_CodePipeline_Configuration_Export.json\n├── 03_Deployment_Demo_Recording.mp4\n├── 04_Deployment_History_Report.pdf\n├── 05_Rollback_Execution_Log.pdf\n└── 06_CloudTrail_Deployment_Events.csv\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 파이프라인 아키텍처 설계 (2-3일)\n\n**담당: DevOps 엔지니어**\n\n```yaml\n# 권장 파이프라인 구조 예시\nPipeline Stages:\n  - Source:\n      Provider: CodeCommit 또는 GitHub\n      Trigger: Push to main branch\n  \n  - Build:\n      Provider: CodeBuild\n      Actions:\n        - Unit Tests\n        - Docker Build (if applicable)\n        - Artifact Upload to S3\n  \n  - Deploy-Staging:\n      Provider: CodeDeploy 또는 CloudFormation\n      Configuration: Blue/Green 또는 Rolling\n  \n  - Manual-Approval:\n      Provider: Manual Approval\n      SNS-Topic: deployment-approvers\n  \n  - Deploy-Production:\n      Provider: CodeDeploy\n      Configuration: Blue/Green with Auto-Rollback\n```\n\n### Step 2: CodePipeline 구성 (1-2일)\n\n**AWS CLI로 파이프라인 생성 확인:**\n```bash\n# 파이프라인 상태 확인\naws codepipeline get-pipeline --name customer-app-pipeline\n\n# 파이프라인 실행 이력 조회\naws codepipeline list-pipeline-executions \\\n  --pipeline-name customer-app-pipeline \\\n  --max-results 20\n```\n\n### Step 3: 자동 롤백 구성 (1일)\n\n**CodeDeploy 롤백 설정 필수 확인:**\n```json\n{\n  \"deploymentGroupName\": \"production-deployment-group\",\n  \"autoRollbackConfiguration\": {\n    \"enabled\": true,\n    \"events\": [\n      \"DEPLOYMENT_FAILURE\",\n      \"DEPLOYMENT_STOP_ON_ALARM\"\n    ]\n  },\n  \"alarmConfiguration\": {\n    \"enabled\": true,\n    \"alarms\": [\n      {\"name\": \"HighErrorRate-Alarm\"},\n      {\"name\": \"HighLatency-Alarm\"}\n    ]\n  }\n}\n```\n\n### Step 4: 배포 이력 수집 스크립트 작성 (0.5일)\n\n```python\n# deployment_history_export.py\nimport boto3\nfrom datetime import datetime, timedelta\n\nclient = boto3.client('codepipeline')\n\ndef export_deployment_history(pipeline_name, days=90):\n    executions = client.list_pipeline_executions(\n        pipelineName=pipeline_name,\n        maxResults=100\n    )\n    \n    report = []\n    for exe in executions['pipelineExecutionSummaries']:\n        report.append({\n            'execution_id': exe['pipelineExecutionId'],\n            'status': exe['status'],\n            'start_time': exe['startTime'].isoformat(),\n            'trigger': exe.get('trigger', {}).get('triggerType', 'Unknown')\n        })\n    \n    return report\n```\n\n### Step 5: 시연 시나리오 리허설 (1일)\n\n**시연 스크립트 체크리스트:**\n- [ ] 코드 변경 준비 (간단한 버전 번호 변경)\n- [ ] 파이프라인 대시보드 화면 준비\n- [ ] CloudWatch 로그 그룹 탭 준비\n- [ ] 롤백 트리거용 실패 코드 준비\n- [ ] 음성 설명 대본 작성\n\n### Step 6: 증빙 자료 패키징 (0.5일)\n\n**최종 제출 패키지 구성:**\n```\n제출 형식: ZIP 파일 또는 S3 Pre-signed URL\n파일 크기: 동영상 포함 시 500MB 이내\n문서 형식: PDF (편집 불가 형태)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 수동 개입이 포함된 \"자동화\"\n\n**탈락 사례:**\n```\n❌ \"CodePipeline으로 빌드 후, 운영자가 SSH로 접속하여 \n   docker pull && docker-compose up 실행\"\n```\n\n**올바른 구현:**\n```\n✅ CodePipeline → CodeDeploy Agent가 자동으로 \n   새 컨테이너 배포 및 헬스체크 수행\n```\n\n### 🚫 실수 2: 롤백이 실제로 동작하지 않음\n\n**감사 시 자주 발견되는 문제:**\n- 롤백 설정은 있으나 실제 테스트한 적 없음\n- 롤백 시 데이터베이스 마이그레이션 충돌 발생\n- 이전 버전 아티팩트가 S3에서 삭제되어 롤백 불가\n\n**검증 방법:**\n```bash\n# 의도적으로 실패하는 배포 실행\naws deploy create-deployment \\\n  --application-name MyApp \\\n  --deployment-group-name Production \\\n  --revision '{\"revisionType\":\"S3\",\"s3Location\":{\"bucket\":\"my-bucket\",\"key\":\"failing-version.zip\"}}'\n\n# 롤백 확인\naws deploy get-deployment --deployment-id d-XXXXXXXXX\n# status가 \"Rolled Back\"인지 확인\n```\n\n### 🚫 실수 3: 배포 로그에 \"누가\" 배포했는지 없음\n\n**부족한 증빙:**\n```\nDeployment ID: d-123\nStatus: Succeeded\nTime: 2024-01-15 10:00:00\n```\n\n**충분한 증빙:**\n```\nDeployment ID: d-123\nStatus: Succeeded\nTime: 2024-01-15 10:00:00\nTriggered By: CodePipeline (pipeline-execution-id: abc123)\nApproved By: john.doe@company.com (Manual Approval)\nIAM Role: arn:aws:iam::123456789012:role/CodeDeployServiceRole\n```\n\n### 🚫 실수 4: 샌드박스가 실제 고객 환경과 다름\n\n**문제:**\n- 시연용으로 급조한 단순 파이프라인\n- 실제 고객에게는 다른 방식으로 배포\n\n**감사관 질문 예시:**\n> \"이 파이프라인이 실제 고객 환경에서도 동일하게 사용되나요? \n> 고객 계정의 CloudTrail 로그를 보여주실 수 있나요?\"\n\n### 🚫 실수 5: 승인 단계 없이 프로덕션 직접 배포\n\n**AWS MSP 요구사항:**\n> \"수동 승인 단계는 허용됩니다\" = 프로덕션 배포 전 승인 게이트 권장\n\n```yaml\n# 권장 구성\n- Stage: ManualApproval\n  Actions:\n    - Name: ProductionApproval\n      ActionType: Approval\n      Configuration:\n        NotificationArn: arn:aws:sns:region:account:deployment-approvers\n        CustomData: \"Production deployment for version ${VERSION}\"\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 파이프라인 기능 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | 코드 푸시 시 자동 트리거 | Git push 후 1분 내 파이프라인 시작 확인 | 수동 시작 없이 자동 실행 |\n| 2 | 빌드-테스트-배포 자동 진행 | 파이프라인 실행 로그에서 각 단계 자동 전환 확인 | 단계 간 수동 개입 없음 |\n| 3 | 롤백 동작 확인 | 의도적 실패 배포 후 이전 버전 복구 | 5분 내 자동 롤백 완료 |\n| 4 | 배포 이력 조회 가능 | `list-pipeline-executions` API 호출 | 최근 90일 이력 존재 |\n| 5 | 승인 게이트 동작 | 승인 대기 상태에서 이메일/SNS 알림 수신 | 승인 전 프로덕션 배포 차단 |\n\n### 증빙 자료 품질 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 6 | 시연 영상 품질 | 영상 재생하여 화면/음성 확인 | 1080p 이상, 음성 명확 |\n| 7 | 배포 로그 완전성 | 로그에 필수 필드 존재 확인 | 일시/버전/실행자/결과 포함 |\n| 8 | 아키텍처 다이어그램 | 파이프라인 전체 흐름 표현 | Source→Build→Deploy 명확 |\n\n### 최종 제출 전 실행 명령어\n\n```bash\n# 1. 파이프라인 상태 확인\naws codepipeline get-pipeline-state --name customer-pipeline\n\n# 2. 최근 배포 성공 확인\naws codepipeline list-pipeline-executions \\\n  --pipeline-name customer-pipeline \\\n  --query 'pipelineExecutionSummaries[?status==`Succeeded`]' \\\n  --output table\n\n# 3. CloudTrail에서 배포 이벤트 확인\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=EventName,AttributeValue=CreateDeployment \\\n  --start-time $(date -d '30 days ago' --iso-8601) \\\n  --end-time $(date --iso-8601)\n\n# 4. 롤백 이력 확인\naws deploy list-deployments \\\n  --application-name MyApp \\\n  --deployment-group-name Production \\\n  --include-only-statuses \"",
      "language": "ko",
      "createdAt": "2026-01-07T02:15:37.180Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-010_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-010",
      "category": "Operations",
      "title": "이벤트 관리 및 동적 모니터링",
      "advice": "# OPS-010: 이벤트 관리 및 동적 모니터링 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP에서 핵심인가?\n\n이벤트 관리 및 동적 모니터링은 MSP의 **운영 성숙도를 가장 직접적으로 보여주는 항목**입니다. AWS는 파트너가 단순히 인프라를 구축하는 것을 넘어, **고객 워크로드의 건강 상태를 실시간으로 파악하고 선제적으로 대응**할 수 있는 역량을 갖추길 요구합니다.\n\n### 🎯 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **메트릭 수집의 포괄성** | CPU/Memory만이 아닌 비즈니스 KPI(응답시간, 에러율, 처리량)까지 수집하는가? |\n| **로그 중앙화 및 분석** | 흩어진 로그를 한 곳에서 검색/분석 가능한가? 로그 보존 정책이 있는가? |\n| **알람의 실효성** | 알람이 실제 액션으로 연결되는가? Alert Fatigue 방지 체계가 있는가? |\n| **태그 기반 리소스 관리** | 태그를 통해 고객/환경/서비스별 필터링이 가능한가? |\n| **대시보드의 실용성** | 운영팀이 실제로 사용하는 대시보드인가? 고객에게 공유되는가? |\n\n### 관련 AWS 서비스 스택\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Observability Stack                       │\n├─────────────────────────────────────────────────────────────┤\n│  Metrics: CloudWatch Metrics, CloudWatch Container Insights │\n│  Logs: CloudWatch Logs, OpenSearch Service                  │\n│  Traces: AWS X-Ray, CloudWatch ServiceLens                  │\n│  Alarms: CloudWatch Alarms, EventBridge, SNS                │\n│  Dashboard: CloudWatch Dashboards, Grafana (AMG)            │\n│  Tagging: AWS Tag Editor, Resource Groups                   │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 📁 필수 증빙 자료 상세\n\n#### A. 모니터링 아키텍처 문서\n**파일명 예시:** `MSP_Monitoring_Architecture_v2.3.pdf`\n\n```yaml\n포함 필수 내용:\n  - 메트릭 수집 흐름도 (CloudWatch Agent → CloudWatch → Dashboard)\n  - 로그 파이프라인 구성 (Application → CloudWatch Logs → OpenSearch)\n  - 알람 에스컬레이션 경로 (Alarm → SNS → PagerDuty/Slack → On-call)\n  - 태그 전략 다이어그램\n  \n권장 형식:\n  - Lucidchart 또는 draw.io로 작성된 아키텍처 다이어그램\n  - 최소 3개 이상의 실제 고객 환경 예시 포함\n```\n\n#### B. KPI 정의서 및 임계값 매트릭스\n**파일명 예시:** `Customer_KPI_Threshold_Matrix.xlsx`\n\n| 계층 | KPI 이름 | 메트릭 소스 | Warning 임계값 | Critical 임계값 | 측정 주기 |\n|------|---------|------------|---------------|----------------|----------|\n| Infrastructure | EC2 CPU | CloudWatch | >70% (5분) | >90% (5분) | 1분 |\n| Infrastructure | EBS IOPS | CloudWatch | >80% provisioned | >95% provisioned | 1분 |\n| Application | API Latency p99 | X-Ray | >500ms | >1000ms | 1분 |\n| Application | Error Rate | CloudWatch Logs Metric Filter | >1% | >5% | 1분 |\n| Business | Order Processing Time | Custom Metric | >30초 | >60초 | 5분 |\n\n#### C. 태그 정책 문서\n**파일명 예시:** `AWS_Tagging_Policy_Standard.pdf`\n\n```yaml\n필수 태그 목록:\n  - Environment: [prod, staging, dev, qa]\n  - Customer: [고객식별코드]\n  - Service: [서비스명]\n  - Owner: [담당팀 이메일]\n  - CostCenter: [비용 센터 코드]\n  - Compliance: [pci-dss, hipaa, none]\n\n태그 강제 메커니즘:\n  - AWS Organizations SCP로 태그 없는 리소스 생성 차단\n  - AWS Config Rule로 태그 준수 여부 모니터링\n  - 주간 태그 준수율 리포트 자동 생성\n```\n\n#### D. 라이브 데모 시나리오 스크립트\n**파일명 예시:** `OPS010_Live_Demo_Script.md`\n\n```markdown\n## 데모 시나리오 (15분)\n\n### Scene 1: 메트릭 대시보드 (3분)\n- CloudWatch Dashboard 열기\n- 고객 A의 프로덕션 환경 필터링 (태그 기반)\n- EC2, RDS, ALB 메트릭 실시간 확인\n\n### Scene 2: 로그 분석 (4분)\n- CloudWatch Logs Insights 쿼리 실행\n- 최근 1시간 에러 로그 검색\n- 특정 요청 ID로 트레이스 추적\n\n### Scene 3: 알람 및 대응 (4분)\n- 현재 활성 알람 목록 확인\n- 알람 히스토리에서 최근 인시던트 선택\n- SNS → Slack 알림 연동 확인\n- 인시던트 티켓 자동 생성 확인\n\n### Scene 4: 태그 기반 관리 (4분)\n- Resource Groups에서 고객별 리소스 그룹 확인\n- Tag Editor로 태그 준수율 확인\n- Cost Explorer에서 태그별 비용 분석\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 모니터링 표준 아키텍처 수립 (1주)\n\n```bash\n# CloudWatch Agent 표준 설정 파일 생성\n# /opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json\n\n{\n  \"agent\": {\n    \"metrics_collection_interval\": 60,\n    \"run_as_user\": \"cwagent\"\n  },\n  \"metrics\": {\n    \"namespace\": \"MSP/CustomMetrics\",\n    \"append_dimensions\": {\n      \"Customer\": \"${aws:TagValue:Customer}\",\n      \"Environment\": \"${aws:TagValue:Environment}\"\n    },\n    \"metrics_collected\": {\n      \"mem\": { \"measurement\": [\"mem_used_percent\"] },\n      \"disk\": { \"measurement\": [\"disk_used_percent\"], \"resources\": [\"*\"] }\n    }\n  },\n  \"logs\": {\n    \"logs_collected\": {\n      \"files\": {\n        \"collect_list\": [\n          {\n            \"file_path\": \"/var/log/application/*.log\",\n            \"log_group_name\": \"/msp/{Customer}/{Environment}/application\",\n            \"log_stream_name\": \"{instance_id}\"\n          }\n        ]\n      }\n    }\n  }\n}\n```\n\n**담당:** 클라우드 엔지니어 | **산출물:** CloudWatch Agent 표준 설정, 배포 자동화 스크립트\n\n### Step 2: 로그 중앙화 파이프라인 구축 (1주)\n\n```python\n# CloudWatch Logs → OpenSearch 구독 필터 설정\nimport boto3\n\nlogs_client = boto3.client('logs')\n\n# 모든 애플리케이션 로그 그룹에 구독 필터 추가\nlog_groups = ['/msp/customerA/prod/application', '/msp/customerB/prod/application']\n\nfor log_group in log_groups:\n    logs_client.put_subscription_filter(\n        logGroupName=log_group,\n        filterName='OpenSearchStream',\n        filterPattern='',  # 모든 로그\n        destinationArn='arn:aws:lambda:ap-northeast-2:xxx:function:LogsToOpenSearch'\n    )\n```\n\n**담당:** DevOps 엔지니어 | **산출물:** 로그 파이프라인 구성도, Lambda 함수 코드\n\n### Step 3: 비즈니스 KPI 메트릭 정의 및 수집 (1주)\n\n```python\n# 커스텀 비즈니스 메트릭 발행 예시\nimport boto3\nfrom datetime import datetime\n\ncloudwatch = boto3.client('cloudwatch')\n\ndef publish_business_metric(customer_id, metric_name, value, unit='Count'):\n    cloudwatch.put_metric_data(\n        Namespace='MSP/BusinessMetrics',\n        MetricData=[{\n            'MetricName': metric_name,\n            'Dimensions': [\n                {'Name': 'Customer', 'Value': customer_id},\n                {'Name': 'Environment', 'Value': 'production'}\n            ],\n            'Timestamp': datetime.utcnow(),\n            'Value': value,\n            'Unit': unit\n        }]\n    )\n\n# 사용 예시\npublish_business_metric('CUST001', 'OrderProcessingTime', 25.3, 'Seconds')\npublish_business_metric('CUST001', 'SuccessfulTransactions', 1523, 'Count')\n```\n\n**담당:** 애플리케이션 팀 + 클라우드 팀 | **산출물:** 비즈니스 KPI 목록, 메트릭 발행 코드\n\n### Step 4: 알람 체계 구축 및 에스컬레이션 설정 (1주)\n\n```yaml\n# CloudFormation으로 알람 표준화\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: MSP Standard Alarm Template\n\nParameters:\n  CustomerTag:\n    Type: String\n  Environment:\n    Type: String\n    AllowedValues: [prod, staging, dev]\n\nResources:\n  HighCPUAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      AlarmName: !Sub '${CustomerTag}-${Environment}-EC2-HighCPU'\n      AlarmDescription: 'CPU utilization exceeded 90%'\n      MetricName: CPUUtilization\n      Namespace: AWS/EC2\n      Statistic: Average\n      Period: 300\n      EvaluationPeriods: 2\n      Threshold: 90\n      ComparisonOperator: GreaterThanThreshold\n      Dimensions:\n        - Name: Customer\n          Value: !Ref CustomerTag\n      AlarmActions:\n        - !If [IsProd, !Ref CriticalSNSTopic, !Ref WarningSNSTopic]\n      OKActions:\n        - !Ref RecoverySNSTopic\n```\n\n**담당:** SRE 팀 | **산출물:** 알람 템플릿, 에스컬레이션 정책 문서\n\n### Step 5: 태그 정책 강제 및 준수 모니터링 (3일)\n\n```json\n// AWS Organizations SCP - 태그 강제 정책\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"RequireTagsOnEC2\",\n      \"Effect\": \"Deny\",\n      \"Action\": [\"ec2:RunInstances\"],\n      \"Resource\": [\"arn:aws:ec2:*:*:instance/*\"],\n      \"Condition\": {\n        \"Null\": {\n          \"aws:RequestTag/Customer\": \"true\",\n          \"aws:RequestTag/Environment\": \"true\",\n          \"aws:RequestTag/Owner\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n\n```yaml\n# AWS Config Rule - 태그 준수 확인\nConfigRuleName: required-tags-compliance\nSource:\n  Owner: AWS\n  SourceIdentifier: REQUIRED_TAGS\nInputParameters:\n  tag1Key: Customer\n  tag2Key: Environment\n  tag3Key: Owner\n  tag4Key: CostCenter\n```\n\n**담당:** 클라우드 거버넌스 팀 | **산출물:** SCP 정책, Config Rule, 태그 준수 리포트\n\n### Step 6: 통합 대시보드 구축 (3일)\n\n```json\n// CloudWatch Dashboard JSON 예시\n{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"Customer Overview - CPU & Memory\",\n        \"metrics\": [\n          [\"MSP/CustomMetrics\", \"CPUUtilization\", \"Customer\", \"CUST001\"],\n          [\".\", \"MemoryUtilization\", \".\", \".\"]\n        ],\n        \"period\": 300,\n        \"stat\": \"Average\"\n      }\n    },\n    {\n      \"type\": \"log\",\n      \"properties\": {\n        \"title\": \"Recent Errors\",\n        \"query\": \"SOURCE '/msp/CUST001/prod/application' | filter @message like /ERROR/ | limit 20\"\n      }\n    },\n    {\n      \"type\": \"alarm\",\n      \"properties\": {\n        \"title\": \"Active Alarms\",\n        \"alarms\": [\n          \"arn:aws:cloudwatch:ap-northeast-2:xxx:alarm:CUST001-*\"\n        ]\n      }\n    }\n  ]\n}\n```\n\n**담당:** 운영팀 | **산출물:** 고객별 대시보드, 운영팀 종합 대시보드\n\n### Step 7: 데모 리허설 및 문서화 (2일)\n\n```markdown\n## 데모 체크리스트\n\n### 사전 준비 (데모 1시간 전)\n- [ ] 데모 계정 로그인 확인\n- [ ] 대시보드 로딩 시간 확인 (5초 이내)\n- [ ] 테스트 알람 발생 → 해제 사이클 확인\n- [ ] 로그 검색 쿼리 저장 확인\n\n### 데모 중 주의사항\n- [ ] 실제 고객 데이터 마스킹 확인\n- [ ] 태그 기반 필터링 시 최소 3개 고객 전환 시연\n- [ ] 알람 → ",
      "language": "ko",
      "createdAt": "2026-01-07T02:16:28.552Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-011_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-011",
      "category": "Operations",
      "title": "운영 런북",
      "advice": "# OPS-011: 운영 런북 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n운영 런북은 MSP의 **서비스 품질 일관성**을 증명하는 핵심 자산입니다. AWS는 MSP 파트너가 담당자 개인의 역량에 의존하지 않고, **표준화된 절차**를 통해 고객 워크로드를 안정적으로 운영할 수 있는지 확인합니다. 런북이 없으면 장애 대응 시간이 길어지고, 인수인계 시 지식 손실이 발생하며, 결과적으로 고객 SLA를 충족하지 못하게 됩니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **실제 사용 여부** | 런북이 문서함에 방치된 것이 아니라 일상 운영에서 참조되고 있는가? |\n| **알림-런북 매핑** | CloudWatch Alarm, GuardDuty Finding 등 특정 알림이 발생했을 때 어떤 런북을 실행해야 하는지 명확한가? |\n| **단계별 실행 가능성** | 신입 엔지니어도 런북만 보고 절차를 수행할 수 있을 만큼 구체적인가? |\n| **버전 관리 및 갱신** | 런북이 최신 인프라 상태를 반영하고 있으며, 변경 이력이 관리되는가? |\n| **에스컬레이션 경로** | 런북으로 해결되지 않는 경우의 상위 대응 절차가 정의되어 있는가? |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS Systems Manager Automation**: 런북 자동화 실행\n- **AWS Systems Manager Incident Manager**: 인시던트 발생 시 런북 자동 연결\n- **Amazon CloudWatch Alarms**: 런북 트리거 조건 정의\n- **AWS Config Rules**: 컴플라이언스 위반 시 런북 실행\n- **Amazon EventBridge**: 이벤트 기반 런북 자동 실행\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 OPS-011_Runbook_Evidence/\n├── 01_Runbook_Catalog/\n│   ├── Runbook_Master_Index.xlsx\n│   ├── Alert_to_Runbook_Mapping.pdf\n│   └── Runbook_Category_Structure.md\n├── 02_Sample_Runbooks/\n│   ├── RB-INF-001_EC2_High_CPU_Response.md\n│   ├── RB-SEC-001_GuardDuty_Critical_Finding.md\n│   ├── RB-NET-001_VPN_Connection_Failure.md\n│   ├── RB-DB-001_RDS_Storage_Full.md\n│   └── RB-APP-001_ECS_Task_Failure.md\n├── 03_Execution_Evidence/\n│   ├── Runbook_Execution_Log_2024Q4.pdf\n│   ├── SSM_Automation_Execution_History.png\n│   └── Incident_Ticket_with_Runbook_Reference.pdf\n└── 04_Governance/\n    ├── Runbook_Review_Schedule.pdf\n    └── Runbook_Change_History.xlsx\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📘 런북 마스터 인덱스 (Runbook_Master_Index.xlsx)\n\n| 런북 ID | 카테고리 | 제목 | 트리거 알림 | 담당팀 | 최종 검토일 | SSM 문서 ARN |\n|---------|----------|------|-------------|--------|-------------|--------------|\n| RB-INF-001 | Infrastructure | EC2 High CPU Response | CW-Alarm-EC2-CPU-90 | Platform팀 | 2024-11-15 | arn:aws:ssm:... |\n| RB-SEC-001 | Security | GuardDuty Critical Finding | GD-Finding-High | Security팀 | 2024-11-20 | arn:aws:ssm:... |\n\n#### 📘 개별 런북 필수 섹션\n\n```markdown\n# RB-INF-001: EC2 High CPU 대응 런북\n\n## 메타데이터\n- 버전: 2.3\n- 최종 수정일: 2024-11-15\n- 작성자: 김운영\n- 검토자: 박시니어\n- 예상 소요시간: 15-30분\n\n## 트리거 조건\n- CloudWatch Alarm: `prod-ec2-cpu-utilization-high`\n- 조건: CPUUtilization > 90% for 5 minutes\n- 대상: Production EC2 instances (tag: Environment=prod)\n\n## 사전 요구사항\n- AWS Console 접근 권한 (PowerUser 이상)\n- SSH 키 접근 권한 (Bastion 경유)\n- PagerDuty 알림 확인 권한\n\n## 대응 절차\n\n### Step 1: 알림 확인 및 초기 분석 (5분)\n1. CloudWatch Console 접속\n2. 해당 인스턴스의 CPU 그래프 확인\n3. 동시에 Memory, Network 지표 확인\n   ```bash\n   aws cloudwatch get-metric-statistics \\\n     --namespace AWS/EC2 \\\n     --metric-name CPUUtilization \\\n     --dimensions Name=InstanceId,Value=i-0123456789abcdef0 \\\n     --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n     --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n     --period 300 \\\n     --statistics Average\n   ```\n\n### Step 2: 프로세스 분석 (10분)\n1. Session Manager로 인스턴스 접속\n   ```bash\n   aws ssm start-session --target i-0123456789abcdef0\n   ```\n2. CPU 점유 프로세스 확인\n   ```bash\n   top -bn1 | head -20\n   ps aux --sort=-%cpu | head -10\n   ```\n3. 결과를 티켓에 기록\n\n### Step 3: 원인별 대응\n#### 3-A: 애플리케이션 이슈인 경우\n- 개발팀에 에스컬레이션 (Slack: #app-oncall)\n- 임시 조치: 프로세스 재시작 (고객 승인 필요)\n\n#### 3-B: 트래픽 급증인 경우\n- Auto Scaling 이벤트 확인\n- 수동 스케일아웃 실행:\n  ```bash\n  aws autoscaling set-desired-capacity \\\n    --auto-scaling-group-name prod-asg \\\n    --desired-capacity 5\n  ```\n\n#### 3-C: 악성 프로세스 의심 시\n- Security팀 즉시 에스컬레이션\n- RB-SEC-003 (Compromised Instance) 런북으로 전환\n\n## 에스컬레이션 매트릭스\n| 조건 | 에스컬레이션 대상 | 연락 방법 |\n|------|------------------|-----------|\n| 30분 내 미해결 | 시니어 엔지니어 | PagerDuty L2 |\n| 애플리케이션 이슈 | 개발팀 온콜 | Slack #app-oncall |\n| 보안 의심 | Security팀 | PagerDuty Security |\n\n## 완료 조건\n- [ ] CPU 사용률 70% 이하로 안정화\n- [ ] 근본 원인 식별 및 티켓에 기록\n- [ ] 고객 통보 완료 (P1/P2 인시던트의 경우)\n- [ ] CloudWatch Alarm 상태 OK 확인\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 알림 인벤토리 수집 (3일)\n\n**담당자**: 모니터링 엔지니어\n\n현재 운영 중인 모든 알림을 수집하고 분류합니다.\n\n```bash\n# CloudWatch Alarms 목록 추출\naws cloudwatch describe-alarms \\\n  --query 'MetricAlarms[*].[AlarmName,MetricName,Namespace,StateValue]' \\\n  --output table > alarms_inventory.txt\n\n# GuardDuty Finding Types 확인\naws guardduty list-findings \\\n  --detector-id <detector-id> \\\n  --finding-criteria '{\"Criterion\":{\"severity\":{\"Gte\":7}}}' \\\n  --query 'FindingIds' > high_severity_findings.txt\n\n# Config Rules 목록\naws configservice describe-config-rules \\\n  --query 'ConfigRules[*].[ConfigRuleName,ConfigRuleState]' \\\n  --output table > config_rules.txt\n```\n\n**산출물**: `Alert_Inventory_Master.xlsx` (알림 ID, 유형, 심각도, 담당팀 포함)\n\n---\n\n### Step 2: 런북 카테고리 체계 수립 (2일)\n\n**담당자**: 운영팀 리드\n\n```\n런북 ID 체계 예시:\nRB-{카테고리}-{순번}\n\n카테고리:\n- INF: Infrastructure (EC2, EBS, VPC 등)\n- SEC: Security (GuardDuty, IAM, WAF 등)\n- DB: Database (RDS, DynamoDB, ElastiCache 등)\n- APP: Application (ECS, Lambda, API Gateway 등)\n- NET: Network (VPN, Direct Connect, Route53 등)\n- CMP: Compliance (Config Rules, Audit 등)\n```\n\n---\n\n### Step 3: 핵심 런북 작성 (10일)\n\n**담당자**: 각 도메인 SME (Subject Matter Expert)\n\n**우선순위 기준으로 최소 10개 런북 작성**:\n\n| 우선순위 | 런북 | 작성 담당 | 소요일 |\n|---------|------|----------|--------|\n| P1 | EC2 인스턴스 장애 대응 | Infra팀 | 1일 |\n| P1 | RDS 연결 실패 대응 | DB팀 | 1일 |\n| P1 | GuardDuty Critical Finding 대응 | Security팀 | 1일 |\n| P1 | ECS 서비스 장애 대응 | Platform팀 | 1일 |\n| P2 | S3 버킷 권한 이상 대응 | Security팀 | 0.5일 |\n| P2 | Lambda 동시성 한도 초과 대응 | Platform팀 | 0.5일 |\n| P2 | VPN 터널 다운 대응 | Network팀 | 1일 |\n| P2 | CloudFront 5xx 에러 급증 대응 | Platform팀 | 0.5일 |\n| P3 | 비용 이상 알림 대응 | FinOps팀 | 0.5일 |\n| P3 | Config Rule 위반 대응 | Security팀 | 0.5일 |\n\n---\n\n### Step 4: SSM Automation 문서 연동 (5일)\n\n**담당자**: DevOps 엔지니어\n\n런북의 자동화 가능한 부분을 SSM Automation으로 구현:\n\n```yaml\n# ssm-runbook-ec2-high-cpu.yaml\nschemaVersion: '0.3'\ndescription: 'EC2 High CPU 자동 진단 런북'\nassumeRole: '{{AutomationAssumeRole}}'\nparameters:\n  InstanceId:\n    type: String\n    description: 대상 EC2 인스턴스 ID\n  AutomationAssumeRole:\n    type: String\n    default: ''\nmainSteps:\n  - name: GetInstanceDetails\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: ec2\n      Api: DescribeInstances\n      InstanceIds:\n        - '{{InstanceId}}'\n    outputs:\n      - Name: InstanceType\n        Selector: '$.Reservations[0].Instances[0].InstanceType'\n        Type: String\n  - name: GetTopProcesses\n    action: 'aws:runCommand'\n    inputs:\n      DocumentName: AWS-RunShellScript\n      InstanceIds:\n        - '{{InstanceId}}'\n      Parameters:\n        commands:\n          - 'ps aux --sort=-%cpu | head -10'\n          - 'free -m'\n          - 'df -h'\n    outputs:\n      - Name: CommandOutput\n        Selector: '$.CommandId'\n        Type: String\n  - name: CreateOpsItem\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: ssm\n      Api: CreateOpsItem\n      Title: 'High CPU Alert - {{InstanceId}}'\n      Description: '자동 진단 결과가 첨부되었습니다.'\n      Source: 'EC2-CPU-Runbook'\n      Priority: 2\n```\n\n---\n\n### Step 5: 알림-런북 매핑 및 자동 연결 (3일)\n\n**담당자**: 모니터링 엔지니어\n\nCloudWatch Alarm → EventBridge → Incident Manager 연동:\n\n```json\n// EventBridge Rule for CloudWatch Alarm\n{\n  \"source\": [\"aws.cloudwatch\"],\n  \"detail-type\": [\"CloudWatch Alarm State Change\"],\n  \"detail\": {\n    \"state\": {\n      \"value\": [\"ALARM\"]\n    },\n    \"alarmName\": [{\n      \"prefix\": \"prod-\"\n    }]\n  }\n}\n```\n\nIncident Manager Response Plan에 런북 연결:\n```\nResponse Plan: prod-infrastructure-incident\n├── Engagement: Platform-OnCall\n├── Runbook: arn:aws:ssm:ap-northeast-2:123456789012:document/RB-INF-001\n└── Chat Channel: #incident-response\n```\n\n---\n\n### Step 6: 실행 이력 수집 및 문서화 (지속)\n\n**",
      "language": "ko",
      "createdAt": "2026-01-07T02:17:24.010Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-012_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-012",
      "category": "Operations",
      "title": "이상 탐지",
      "advice": "# OPS-012: 이상 탐지 (Anomaly Detection) - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n이상 탐지는 **정적 임계값 기반 모니터링의 한계를 극복**하는 핵심 역량입니다. 전통적인 \"CPU > 80%면 알람\" 방식은 워크로드의 자연스러운 패턴(주말 트래픽 감소, 월말 배치 처리 증가 등)을 고려하지 못해 **알람 피로(Alert Fatigue)**를 유발합니다. AWS는 MSP 파트너가 단순 모니터링을 넘어 **지능적인 운영 역량**을 갖추길 요구합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **통계적/ML 모델 실제 적용** | 단순 정적 임계값이 아닌 실제 이상 탐지 알고리즘 사용 여부 |\n| **다양한 메트릭 커버리지** | CPU/Memory만이 아닌 비즈니스 메트릭, 애플리케이션 메트릭까지 확장 |\n| **False Positive 감소 증거** | 이상 탐지 도입 전후 알람 품질 개선 데이터 |\n| **Band 설정의 적절성** | 표준편차 배수(2σ, 3σ) 선택 근거와 튜닝 과정 |\n| **실제 운영 통합** | 탐지된 이상이 실제 대응 프로세스와 연결되어 있는지 |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    이상 탐지 구현 옵션                        │\n├─────────────────────────────────────────────────────────────┤\n│ ✅ CloudWatch Anomaly Detection (권장 - 네이티브 통합)       │\n│ ✅ Amazon DevOps Guru (AI 기반 자동 이상 탐지)              │\n│ ✅ Amazon Lookout for Metrics (비즈니스 메트릭 특화)         │\n│ ✅ CloudWatch Contributor Insights (로그 패턴 분석)          │\n│ ⚡ 서드파티: Datadog, New Relic, Dynatrace 등               │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 구성\n\n#### 📄 증빙 1: 이상 탐지 아키텍처 다이어그램\n**파일명 예시**: `OPS-012_AnomalyDetection_Architecture_CustomerA.pdf`\n\n```\n포함 내용:\n├── 데이터 수집 레이어 (어떤 메트릭을 수집하는지)\n├── 이상 탐지 엔진 (CloudWatch AD, DevOps Guru 등)\n├── 알람 라우팅 경로 (SNS → Lambda → PagerDuty/Slack)\n└── 대응 자동화 연결 (Systems Manager Runbook 등)\n```\n\n#### 📄 증빙 2: CloudWatch 이상 탐지 설정 스크린샷\n**파일명 예시**: `OPS-012_CloudWatch_AnomalyDetection_Config.pdf`\n\n**필수 캡처 항목:**\n```\n1. CloudWatch 콘솔 > Alarms > Anomaly Detection 알람 목록\n2. 개별 알람의 \"Anomaly detection band\" 설정 화면\n3. ANOMALY_DETECTION_BAND 함수가 포함된 알람 수식\n4. 실제 메트릭 그래프에서 회색 밴드(예측 범위) 표시\n```\n\n#### 📄 증빙 3: 이상 탐지 효과 분석 보고서\n**파일명 예시**: `OPS-012_AnomalyDetection_Effectiveness_Report.pdf`\n\n```markdown\n## 포함해야 할 핵심 데이터\n\n### Before/After 비교 (필수!)\n| 지표 | 정적 임계값 (Before) | 이상 탐지 (After) | 개선율 |\n|------|---------------------|-------------------|--------|\n| 월간 총 알람 수 | 847건 | 312건 | 63% ↓ |\n| False Positive 비율 | 72% | 18% | 75% ↓ |\n| MTTR (평균 대응 시간) | 45분 | 23분 | 49% ↓ |\n| 실제 장애 탐지율 | 89% | 97% | 9% ↑ |\n```\n\n#### 📄 증빙 4: 다양한 메트릭 유형별 이상 탐지 적용 증거\n**파일명 예시**: `OPS-012_MultiMetric_AnomalyDetection_Examples.pdf`\n\n```\n메트릭 유형별 최소 1개씩 증빙:\n├── 인프라 메트릭: EC2 CPUUtilization, NetworkIn/Out\n├── 애플리케이션 메트릭: ALB RequestCount, TargetResponseTime\n├── 데이터베이스 메트릭: RDS DatabaseConnections, ReadLatency\n├── 비즈니스 메트릭: 주문 수, API 호출 수 (Custom Metric)\n└── 비용 메트릭: EstimatedCharges (선택사항이나 권장)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 이상 탐지 대상 메트릭 선정 (2-3일)\n\n```bash\n# CloudWatch에서 현재 알람 분석 - False Positive가 많은 알람 식별\naws cloudwatch describe-alarms \\\n  --state-value ALARM \\\n  --query 'MetricAlarms[?StateReason contains `Threshold`].[AlarmName,MetricName]' \\\n  --output table\n```\n\n**선정 기준:**\n- 🎯 계절성/주기성이 있는 메트릭 (트래픽, 주문량)\n- 🎯 정적 임계값 설정이 어려운 메트릭 (성장하는 서비스)\n- 🎯 False Positive 알람이 빈번한 메트릭\n\n### Step 2: CloudWatch Anomaly Detection 알람 생성 (3-5일)\n\n```yaml\n# CloudFormation 예시 - 이상 탐지 알람\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  CPUAnomalyAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      AlarmName: \"EC2-CPU-AnomalyDetection-WebServer\"\n      AlarmDescription: \"CPU 사용률이 예측 범위를 벗어남\"\n      Metrics:\n        - Id: m1\n          MetricStat:\n            Metric:\n              Namespace: AWS/EC2\n              MetricName: CPUUtilization\n              Dimensions:\n                - Name: InstanceId\n                  Value: i-0123456789abcdef0\n            Period: 300\n            Stat: Average\n          ReturnData: false\n        - Id: ad1\n          Expression: \"ANOMALY_DETECTION_BAND(m1, 2)\"  # 2 표준편차\n          Label: \"CPUUtilization (Expected)\"\n          ReturnData: true\n      ThresholdMetricId: ad1\n      ComparisonOperator: LessThanLowerOrGreaterThanUpperThreshold\n      EvaluationPeriods: 3\n      DatapointsToAlarm: 2\n      TreatMissingData: missing\n```\n\n**담당자**: DevOps 엔지니어\n**체크포인트**: 최소 2주간의 학습 기간 필요 (모델 훈련)\n\n### Step 3: DevOps Guru 활성화 (선택적 강화) (1일)\n\n```bash\n# DevOps Guru 활성화 - 자동 이상 탐지\naws devops-guru update-service-integration \\\n  --service-integration '{\"opsCenter\":{\"optInStatus\":\"ENABLED\"}}'\n\n# 리소스 커버리지 설정\naws devops-guru update-resource-collection \\\n  --action ADD \\\n  --resource-collection '{\"cloudFormation\":{\"stackNames\":[\"Production-Stack\"]}}'\n```\n\n**DevOps Guru의 장점:**\n- ML 모델 자동 학습 (별도 설정 불필요)\n- 관련 이상 현상 자동 그룹핑\n- 근본 원인 분석 제공\n\n### Step 4: 이상 탐지 Band 튜닝 (1-2주)\n\n```python\n# Band 설정 가이드라인\nBAND_CONFIGURATION = {\n    \"critical_systems\": {\n        \"standard_deviations\": 2,  # 더 민감하게\n        \"evaluation_periods\": 2,\n        \"datapoints_to_alarm\": 2\n    },\n    \"non_critical_systems\": {\n        \"standard_deviations\": 3,  # 덜 민감하게\n        \"evaluation_periods\": 3,\n        \"datapoints_to_alarm\": 2\n    },\n    \"business_metrics\": {\n        \"standard_deviations\": 2.5,\n        \"evaluation_periods\": 5,  # 더 긴 관찰 기간\n        \"datapoints_to_alarm\": 3\n    }\n}\n```\n\n### Step 5: Before/After 데이터 수집 (2-4주)\n\n```sql\n-- CloudWatch Logs Insights로 알람 히스토리 분석\nfields @timestamp, @message\n| filter @message like /StateChange/\n| stats count() as alarm_count by bin(1d)\n| sort @timestamp desc\n```\n\n**수집해야 할 데이터:**\n- 이상 탐지 도입 전 4주간 알람 통계\n- 이상 탐지 도입 후 4주간 알람 통계\n- False Positive 분류 기록\n\n### Step 6: 증빙 문서 작성 및 스크린샷 수집 (2-3일)\n\n```\n스크린샷 체크리스트:\n☐ CloudWatch 콘솔에서 Anomaly Detection 알람 목록\n☐ 개별 알람 상세 - \"Anomaly detection band\" 표시된 그래프\n☐ 알람 설정 화면 - ANOMALY_DETECTION_BAND 함수 확인\n☐ DevOps Guru 대시보드 (사용 시)\n☐ 알람 히스토리 - 실제 트리거 사례\n```\n\n### Step 7: 고객 승인 및 최종 검토 (1-2일)\n\n**담당자**: 고객 담당 매니저\n**산출물**: 고객 서명이 포함된 증빙 사용 동의서\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 정적 임계값 알람을 이상 탐지로 오인\n\n```\n❌ 잘못된 예시:\n{\n  \"AlarmName\": \"High-CPU-Alarm\",\n  \"Threshold\": 80,\n  \"ComparisonOperator\": \"GreaterThanThreshold\"\n}\n\n✅ 올바른 예시:\n{\n  \"AlarmName\": \"CPU-Anomaly-Detection\",\n  \"Metrics\": [\n    {\"Expression\": \"ANOMALY_DETECTION_BAND(m1, 2)\"}\n  ],\n  \"ThresholdMetricId\": \"ad1\"\n}\n```\n\n**감사관 체크 포인트**: `ANOMALY_DETECTION_BAND` 함수 또는 동등한 ML 기반 탐지 사용 여부\n\n### 🚫 실수 2: 학습 기간 부족\n\n```\n문제: 이상 탐지 알람 생성 직후 스크린샷 제출\n→ 회색 밴드가 너무 넓거나 불안정하게 표시됨\n→ 감사관이 \"실제 운영에서 사용 중인지\" 의심\n\n해결: 최소 2주, 권장 4주 이상 학습 후 증빙 수집\n```\n\n### 🚫 실수 3: 단일 메트릭 유형만 적용\n\n```\n❌ CPU, Memory 같은 인프라 메트릭만 이상 탐지 적용\n   → \"광범위한 워크로드 메트릭\" 요구사항 미충족\n\n✅ 최소 3가지 유형의 메트릭에 이상 탐지 적용:\n   - 인프라 메트릭 (EC2, EBS)\n   - 애플리케이션 메트릭 (ALB, API Gateway)\n   - 비즈니스/커스텀 메트릭 (주문 수, 결제 성공률)\n```\n\n### 🚫 실수 4: False Positive 감소 증거 누락\n\n```\n❌ \"이상 탐지를 적용했습니다\" 만 기술\n   → 효과 입증 불가\n\n✅ 정량적 Before/After 비교 데이터 필수:\n   - 도입 전: 월 500건 알람, 70% False Positive\n   - 도입 후: 월 180건 알람, 15% False Positive\n   - 결론: 알람 피로 82% 감소\n```\n\n### 🚫 실수 5: 고객 정보 미마스킹\n\n```\n⚠️ 스크린샷에 다음 정보가 노출되면 안 됨:\n   - AWS 계정 ID (12자리)\n   - 고객사 실제 도메인명\n   - IP 주소\n   - 민감한 태그 값\n\n✅ 마스킹 예시:\n   Account: ***-***-1",
      "language": "ko",
      "createdAt": "2026-01-07T02:18:19.128Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-013_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-013",
      "category": "Operations",
      "title": "예측 모니터링 및 AIOps",
      "advice": "# OPS-013: 예측 모니터링 및 AIOps 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\n예측 모니터링 및 AIOps는 **사후 대응(Reactive)에서 사전 예방(Proactive)으로의 전환**을 증명하는 항목입니다. AWS는 MSP 파트너가 단순히 임계값 기반 알람을 넘어서, **장애가 발생하기 전에 이상 징후를 감지하고 자동으로 대응**할 수 있는 성숙한 운영 역량을 갖추길 기대합니다.\n\n이 항목은 \"권장(Recommended)\"이지만, 통과 시 MSP의 기술적 차별화를 강력히 어필할 수 있습니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **ML/AI 기반 이상 탐지** | 정적 임계값이 아닌 동적 베이스라인 학습이 실제로 작동하는가? |\n| **예측 시점의 선행성** | 실제 문제 발생 몇 분/시간 전에 예측이 이루어졌는가? |\n| **자동화된 대응 연계** | 예측 알림이 단순 통보로 끝나지 않고 자동 조치로 연결되는가? |\n| **실제 비즈니스 임팩트** | 예측 모니터링으로 인해 실제 장애를 예방한 사례가 있는가? |\n| **고객 환경 적용** | 자체 환경이 아닌 실제 고객 워크로드에 적용되어 있는가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    예측 모니터링 스택                          │\n├─────────────────────────────────────────────────────────────┤\n│  Amazon DevOps Guru          → 애플리케이션 이상 탐지         │\n│  Amazon Lookout for Metrics  → 비즈니스 메트릭 이상 탐지      │\n│  CloudWatch Anomaly Detection → 메트릭 기반 이상 탐지        │\n│  CloudWatch Contributor Insights → 패턴 분석               │\n│  Amazon Forecast             → 시계열 예측                  │\n│  SageMaker                   → 커스텀 ML 모델               │\n├─────────────────────────────────────────────────────────────┤\n│  EventBridge + Lambda        → 자동화된 대응 트리거          │\n│  Systems Manager Automation  → 자동 복구 런북               │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 패키지 구성\n\n```\n📁 OPS-013_Predictive_Monitoring_Evidence/\n│\n├── 📄 01_Architecture_Overview.pdf\n│   └── 예측 모니터링 아키텍처 다이어그램 + 데이터 흐름\n│\n├── 📄 02_Customer_Case_Study.pdf\n│   └── 실제 고객 적용 사례 (비식별화)\n│\n├── 📁 03_Screenshots/\n│   ├── devops_guru_insights.png\n│   ├── anomaly_detection_dashboard.png\n│   ├── prediction_vs_actual_comparison.png\n│   └── automated_response_execution.png\n│\n├── 📄 04_Incident_Prevention_Report.pdf\n│   └── 예측으로 예방한 실제 장애 사례\n│\n└── 📄 05_ML_Model_Performance_Metrics.pdf\n    └── 모델 정확도, False Positive 비율 등\n```\n\n### 각 증빙에 포함되어야 할 핵심 내용\n\n#### 📄 Architecture Overview (아키텍처 개요)\n```yaml\n필수 포함 요소:\n  - 데이터 수집 레이어: 어떤 메트릭/로그를 수집하는지\n  - ML 처리 레이어: 어떤 서비스로 이상 탐지하는지\n  - 예측 로직: 베이스라인 학습 방식 설명\n  - 알림 채널: 예측 알림이 어디로 전달되는지\n  - 자동 대응: 어떤 자동화 액션이 트리거되는지\n  \n다이어그램 예시:\n  CloudWatch Metrics → Anomaly Detection → EventBridge \n       ↓                                        ↓\n  DevOps Guru ────────────────────────→ SNS → Lambda\n       ↓                                        ↓\n  Lookout for Metrics                   SSM Automation\n```\n\n#### 📄 Customer Case Study (고객 사례)\n```yaml\n문서 구조:\n  1. 고객 개요: \"[Industry] 분야 고객 A사\" (비식별화)\n  2. 비즈니스 과제: 기존 임계값 모니터링의 한계\n  3. 솔루션 구현: \n     - 적용한 예측 모니터링 서비스\n     - 학습 기간 및 베이스라인 설정\n     - 자동화 연계 구성\n  4. 결과:\n     - 예측 정확도 (예: 92%)\n     - MTTD 개선율 (예: 45분 → 5분 사전 예측)\n     - 예방된 장애 건수\n  5. 고객 인용문 (선택)\n```\n\n#### 📄 Incident Prevention Report (장애 예방 보고서)\n```yaml\n실제 사례 형식:\n  날짜: 2024-XX-XX\n  예측 시점: 14:23 (실제 임계값 도달 32분 전)\n  \n  탐지 내용:\n    - DevOps Guru가 RDS 연결 수 증가 패턴 이상 탐지\n    - 과거 3주 동안의 베이스라인 대비 2.3σ 이탈 예측\n    \n  자동 대응:\n    - 14:24 - EventBridge 트리거\n    - 14:25 - Lambda 함수로 RDS Read Replica 자동 추가\n    - 14:26 - ALB 타겟 그룹에 자동 등록\n    \n  결과:\n    - 14:55 실제 트래픽 피크 도달\n    - 서비스 영향 없이 처리 완료\n    - 예상 다운타임 15분 예방\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 예측 모니터링 대상 워크로드 선정 (1-2일)\n\n```bash\n# 적합한 고객 워크로드 선정 기준\n✓ 최소 2-4주 이상의 메트릭 히스토리 보유\n✓ 주기적 패턴이 있는 워크로드 (일간/주간 트래픽 변동)\n✓ 과거 장애 이력이 있어 예측 효과 입증 가능\n✓ 고객이 증빙 사용에 동의\n\n# AWS CLI로 메트릭 히스토리 확인\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/EC2 \\\n  --metric-name CPUUtilization \\\n  --start-time 2024-01-01T00:00:00Z \\\n  --end-time 2024-02-01T00:00:00Z \\\n  --period 3600 \\\n  --statistics Average\n```\n\n### Step 2: Amazon DevOps Guru 활성화 및 구성 (2-3일)\n\n```python\n# DevOps Guru 리소스 커버리지 설정\nimport boto3\n\ndevops_guru = boto3.client('devops-guru')\n\n# CloudFormation 스택 기반 분석 활성화\nresponse = devops_guru.update_resource_collection(\n    Action='ADD',\n    ResourceCollection={\n        'CloudFormation': {\n            'StackNames': [\n                'customer-production-stack',\n                'customer-database-stack'\n            ]\n        }\n    }\n)\n\n# 또는 태그 기반 분석\nresponse = devops_guru.update_resource_collection(\n    Action='ADD',\n    ResourceCollection={\n        'Tags': [{\n            'AppBoundaryKey': 'Environment',\n            'TagValues': ['Production']\n        }]\n    }\n)\n```\n\n```yaml\nDevOps Guru 설정 체크리스트:\n  □ SNS 토픽 연결 (알림 채널)\n  □ 분석 대상 리소스 범위 지정\n  □ 최소 2주 학습 기간 확보\n  □ Proactive Insights 활성화 확인\n```\n\n### Step 3: CloudWatch Anomaly Detection 구성 (1-2일)\n\n```bash\n# Anomaly Detection 모델 생성\naws cloudwatch put-anomaly-detector \\\n  --namespace \"AWS/ApplicationELB\" \\\n  --metric-name \"TargetResponseTime\" \\\n  --stat \"Average\" \\\n  --dimensions Name=LoadBalancer,Value=app/my-alb/1234567890\n\n# Anomaly Detection 기반 알람 생성\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"ALB-ResponseTime-Anomaly\" \\\n  --metric-name \"TargetResponseTime\" \\\n  --namespace \"AWS/ApplicationELB\" \\\n  --threshold-metric-id \"ad1\" \\\n  --comparison-operator \"GreaterThanUpperThreshold\" \\\n  --evaluation-periods 2 \\\n  --metrics '[\n    {\n      \"Id\": \"m1\",\n      \"MetricStat\": {\n        \"Metric\": {\n          \"Namespace\": \"AWS/ApplicationELB\",\n          \"MetricName\": \"TargetResponseTime\"\n        },\n        \"Period\": 300,\n        \"Stat\": \"Average\"\n      }\n    },\n    {\n      \"Id\": \"ad1\",\n      \"Expression\": \"ANOMALY_DETECTION_BAND(m1, 2)\"\n    }\n  ]'\n```\n\n### Step 4: 자동화된 대응 파이프라인 구축 (3-4일)\n\n```python\n# EventBridge 규칙 - DevOps Guru Insight 트리거\n{\n    \"source\": [\"aws.devops-guru\"],\n    \"detail-type\": [\"DevOps Guru New Insight Open\"],\n    \"detail\": {\n        \"insightSeverity\": [\"HIGH\", \"MEDIUM\"],\n        \"insightType\": [\"PROACTIVE\"]  # 예측 인사이트만 필터\n    }\n}\n```\n\n```python\n# Lambda 자동 대응 함수 예시\nimport boto3\nimport json\n\ndef lambda_handler(event, context):\n    \"\"\"\n    DevOps Guru 예측 인사이트에 대한 자동 대응\n    \"\"\"\n    insight = event['detail']\n    \n    # 인사이트 유형별 자동 대응\n    if 'RDS' in str(insight.get('resourceCollection', {})):\n        # RDS 연결 수 증가 예측 시 Read Replica 추가\n        rds = boto3.client('rds')\n        \n        response = rds.create_db_instance_read_replica(\n            DBInstanceIdentifier='mydb-replica-auto',\n            SourceDBInstanceIdentifier='mydb-primary',\n            DBInstanceClass='db.r5.large'\n        )\n        \n        return {\n            'statusCode': 200,\n            'action': 'read_replica_created',\n            'insight_id': insight.get('id')\n        }\n    \n    elif 'EC2' in str(insight.get('resourceCollection', {})):\n        # EC2 CPU 증가 예측 시 ASG 용량 사전 확장\n        autoscaling = boto3.client('autoscaling')\n        \n        response = autoscaling.set_desired_capacity(\n            AutoScalingGroupName='my-asg',\n            DesiredCapacity=current_capacity + 2,\n            HonorCooldown=False\n        )\n        \n        return {\n            'statusCode': 200,\n            'action': 'asg_scaled_up',\n            'insight_id': insight.get('id')\n        }\n```\n\n### Step 5: 예측 정확도 측정 및 튜닝 (1-2주)\n\n```python\n# 예측 vs 실제 비교 분석 스크립트\nimport pandas as pd\nfrom datetime import datetime, timedelta\n\ndef analyze_prediction_accuracy(devops_guru_client, days=30):\n    \"\"\"\n    예측 인사이트의 정확도 분석\n    \"\"\"\n    insights = devops_guru_client.list_insights(\n        StatusFilter={'Any': ['CLOSED']},\n        TimeRange={\n            'FromTime': datetime.now() - timedelta(days=days),\n            'ToTime': datetime.now()\n        }\n    )\n    \n    results = {\n        'total_proactive_insights': 0,\n        'true_positives': 0,  # 예측 후 실제 문제 발생\n        'false_positives': 0,  # 예측했으나 문제 미발생\n        'prevented_incidents': 0  # 자동 대응으로 예방\n    }\n    \n    for insight in insights['ProactiveInsights']:\n        results['total_proactive_insights'] += 1\n        \n        # 후속 Reactive Insight 존재 여부 확인\n        # (자동 대응이 없었다면 발생했을 문제)\n        \n    accuracy = results['true_positives'] / results['total_proactive_insights']\n    return results, accuracy\n```\n\n### Step 6: 증빙 자료 수집 및 문서화 (2-3일)\n\n```yaml\n스크린샷 수집 체크리스트:\n  \n  DevOps Guru 콘솔:\n    □ Proactive Insight 목록 (예측 인사이트)\n    □ 개별 Insight 상세 화면 (예측 시점, 권장 조치)\n    □ 리소스 커버리지 현황\n    □ Insight 타임라인 (예측 → 실제 발생 시점 비교)\n  ",
      "language": "ko",
      "createdAt": "2026-01-07T02:19:11.228Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-014_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-014",
      "category": "Operations",
      "title": "지식 관리",
      "advice": "# OPS-014: 지식 관리 (Knowledge Management) 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n지식 관리 시스템은 MSP의 **운영 성숙도와 확장 가능성**을 직접적으로 보여주는 핵심 지표입니다. AWS는 파트너가 특정 엔지니어에게 의존하지 않고, 조직 차원에서 일관된 서비스 품질을 유지할 수 있는지 평가합니다. 담당자 퇴사 시에도 고객 워크로드 운영이 중단 없이 지속될 수 있어야 합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **구조화된 정보 체계** | 내부 프로세스와 고객별 정보가 명확히 분리되어 검색 가능한가? |\n| **실시간 업데이트 증거** | 최근 3개월 내 문서 수정 이력이 있는가? (죽은 문서가 아닌지) |\n| **접근성과 검색 기능** | 야간 당직자가 긴급 상황에서 필요한 정보를 5분 내 찾을 수 있는가? |\n| **고객 워크로드 상세 정보** | 각 고객의 아키텍처, 연락처, 특이사항이 문서화되어 있는가? |\n| **표준 운영 절차(SOP) 연계** | 지식 문서가 실제 운영 프로세스와 연결되어 활용되는가? |\n\n### 관련 AWS 서비스 및 도구\n\n- **AWS Systems Manager - OpsCenter**: 운영 이슈와 관련 지식 문서 연결\n- **Amazon Q (구 Amazon Kendra)**: 지식 베이스 검색 기능 구현\n- **AWS Service Catalog**: 표준화된 서비스 템플릿과 문서 연계\n- **AWS Well-Architected Tool**: 고객별 아키텍처 리뷰 결과 저장\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 OPS-014_Knowledge_Management/\n├── 📄 01_KM_System_Overview.pdf\n│   └── 지식 관리 시스템 구조도 및 접근 방법\n├── 📹 02_KM_System_Demo.mp4 (10-15분)\n│   └── 실시간 시연 녹화 영상\n├── 📊 03_Knowledge_Base_Structure.xlsx\n│   └── 전체 지식 베이스 카테고리 및 문서 목록\n├── 📄 04_Customer_Runbook_Sample.pdf\n│   └── 실제 고객 워크로드 운영 문서 샘플 (민감정보 마스킹)\n└── 📄 05_Document_Update_History.pdf\n    └── 최근 90일 문서 수정 이력 리포트\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n**🎬 시연 영상 필수 포함 시나리오:**\n\n```\n시나리오 1: \"고객 A의 RDS 장애 대응 절차를 찾아주세요\"\n→ 검색 → 해당 고객 폴더 → Runbook 확인 (30초 내)\n\n시나리오 2: \"신규 입사자가 온콜 절차를 학습하려면?\"\n→ 내부 프로세스 → 온콜 가이드 → 에스컬레이션 매트릭스 확인\n\n시나리오 3: \"이 문서가 언제 마지막으로 업데이트되었나요?\"\n→ 버전 히스토리 → 수정자 → 변경 내용 확인\n```\n\n**📋 고객 워크로드 문서 필수 섹션:**\n\n```markdown\n## [고객명] 운영 매뉴얼\n\n### 1. 기본 정보\n- AWS Account ID: 123456789012\n- 주요 리전: ap-northeast-2\n- 담당 TAM: 홍길동 (010-xxxx-xxxx)\n- 고객 측 연락처: 김철수 (DevOps Lead)\n\n### 2. 아키텍처 개요\n- [아키텍처 다이어그램 링크]\n- 핵심 서비스: EKS, Aurora, ElastiCache\n- 월 예상 비용: $15,000\n\n### 3. 특이사항 및 주의점\n- 매월 1일 00:00-06:00 정기 배포 (변경 금지)\n- Legacy 시스템 연동으로 특정 SG 규칙 수정 금지\n- PCI-DSS 대상 워크로드 (로그 보관 1년)\n\n### 4. 장애 대응 Runbook\n- [CPU 과부하 대응](/runbooks/customer-a/cpu-high)\n- [DB 연결 실패 대응](/runbooks/customer-a/db-connection)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 지식 관리 플랫폼 선정 및 구축 (1주)\n\n**권장 플랫폼 옵션:**\n\n| 플랫폼 | 장점 | MSP 적합도 |\n|--------|------|-----------|\n| **Confluence** | AWS 연동 용이, 검색 강력 | ⭐⭐⭐⭐⭐ |\n| **Notion** | 직관적 UI, 빠른 구축 | ⭐⭐⭐⭐ |\n| **GitBook** | 버전 관리 우수, 개발자 친화적 | ⭐⭐⭐⭐ |\n| **SharePoint** | 엔터프라이즈 보안, MS 연동 | ⭐⭐⭐ |\n\n```bash\n# Confluence 기본 Space 구조 예시\n/MSP-Operations (내부 운영)\n  ├── /Onboarding\n  ├── /On-Call-Procedures\n  ├── /Escalation-Matrix\n  ├── /AWS-Service-Guides\n  └── /Tools-and-Access\n\n/Customer-Workloads (고객별)\n  ├── /Customer-A\n  │   ├── Overview\n  │   ├── Architecture\n  │   ├── Runbooks\n  │   └── Change-History\n  ├── /Customer-B\n  └── /Customer-C\n```\n\n### Step 2: 내부 운영 프로세스 문서화 (2주)\n\n**필수 문서화 항목:**\n\n```\n✅ 온콜 로테이션 및 에스컬레이션 절차\n✅ 인시던트 대응 플로우차트\n✅ 변경 관리 승인 프로세스\n✅ 신규 고객 온보딩 체크리스트\n✅ AWS 콘솔/CLI 접근 권한 요청 절차\n✅ 비용 알림 임계치 설정 기준\n✅ 보안 이벤트 대응 매뉴얼\n```\n\n### Step 3: 고객 워크로드별 정보 수집 및 입력 (2-3주)\n\n**고객당 수집 체크리스트:**\n\n```python\ncustomer_knowledge_checklist = {\n    \"기본_정보\": [\n        \"AWS Account ID 목록\",\n        \"사용 리전\",\n        \"계약 SLA 수준\",\n        \"빌링 담당자 연락처\"\n    ],\n    \"기술_정보\": [\n        \"아키텍처 다이어그램 (draw.io/Lucidchart)\",\n        \"주요 서비스 목록 및 용도\",\n        \"네트워크 구성 (VPC, Subnet CIDR)\",\n        \"IAM Role 구조\"\n    ],\n    \"운영_정보\": [\n        \"정기 점검 일정\",\n        \"배포 금지 시간대\",\n        \"특이사항 및 히스토리\",\n        \"과거 주요 장애 기록\"\n    ],\n    \"Runbook\": [\n        \"서비스별 장애 대응 절차\",\n        \"롤백 절차\",\n        \"긴급 연락망\"\n    ]\n}\n```\n\n### Step 4: 검색 및 네비게이션 최적화 (3일)\n\n**검색 효율성 향상 작업:**\n\n```\n1. 태그 체계 수립\n   - 고객명: #customer-a, #customer-b\n   - 서비스: #ec2, #rds, #eks\n   - 유형: #runbook, #architecture, #sop\n\n2. 문서 제목 명명 규칙\n   [고객명] - [서비스] - [문서유형]\n   예: \"CustomerA - Aurora - Failover Runbook\"\n\n3. 즐겨찾기/바로가기 설정\n   - 온콜 대시보드에서 원클릭 접근\n   - Slack 연동으로 /kb search 명령어 구현\n```\n\n### Step 5: 문서 갱신 프로세스 수립 (2일)\n\n**자동 리마인더 설정:**\n\n```yaml\n# 문서 리뷰 주기 설정\ndocument_review_schedule:\n  customer_runbooks: \n    frequency: monthly\n    owner: assigned_tam\n    reminder: slack_channel\n  \n  internal_sop:\n    frequency: quarterly\n    owner: ops_lead\n    reminder: email\n  \n  architecture_diagrams:\n    frequency: on_change\n    trigger: change_management_ticket\n```\n\n### Step 6: 시연 영상 녹화 (1일)\n\n**녹화 스크립트 예시:**\n\n```\n[00:00-01:00] 인트로\n\"안녕하세요, [회사명]의 지식 관리 시스템을 시연하겠습니다.\n저희는 Confluence를 기반으로 내부 운영 프로세스와 \n고객 워크로드 정보를 체계적으로 관리하고 있습니다.\"\n\n[01:00-04:00] 내부 운영 프로세스 영역 시연\n- Space 구조 설명\n- 온콜 절차 문서 열람\n- 에스컬레이션 매트릭스 확인\n\n[04:00-08:00] 고객 워크로드 영역 시연\n- 특정 고객 선택\n- 아키텍처 다이어그램 확인\n- Runbook 검색 및 열람\n\n[08:00-10:00] 검색 기능 시연\n- 키워드 검색: \"RDS failover\"\n- 태그 필터링\n- 최근 수정 문서 확인\n\n[10:00-12:00] 버전 관리 시연\n- 특정 문서의 수정 이력 확인\n- 이전 버전과 비교\n- 수정자 및 수정 일시 확인\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 자주 발생하는 실수 TOP 5\n\n| 순위 | 실수 유형 | 문제점 | 해결책 |\n|------|----------|--------|--------|\n| 1️⃣ | **빈 껍데기 시스템** | 플랫폼만 구축하고 실제 콘텐츠가 없음 | 최소 10개 고객 + 20개 내부 문서 확보 |\n| 2️⃣ | **오래된 문서** | 6개월 이상 업데이트 없는 문서만 존재 | 최근 90일 내 수정 이력 필수 |\n| 3️⃣ | **검색 불가** | 문서는 있으나 찾을 수 없음 | 태그, 제목 규칙, 폴더 구조 정비 |\n| 4️⃣ | **고객 정보 누락** | 내부 프로세스만 있고 고객별 정보 없음 | 고객당 최소 5개 문서 (Overview, Arch, Runbook 등) |\n| 5️⃣ | **접근 권한 미설정** | 모든 직원이 모든 고객 정보 접근 | 고객별 접근 권한 분리 증빙 |\n\n### 감사 탈락 주요 원인\n\n```\n❌ \"시스템은 있는데 아무도 사용하지 않는 것 같습니다\"\n   → 최근 로그인 기록, 문서 조회수 통계 준비\n\n❌ \"고객 A의 장애 대응 절차를 찾아주세요\" → 5분 이상 소요\n   → 시연 전 주요 시나리오 리허설 필수\n\n❌ \"이 Runbook이 실제로 사용된 적이 있나요?\"\n   → 인시던트 티켓과 Runbook 연결 이력 준비\n\n❌ \"문서 작성자가 퇴사하면 어떻게 되나요?\"\n   → 문서 소유권 이전 프로세스 설명 준비\n```\n\n### 피해야 할 안티패턴\n\n```\n🚫 Google Drive에 파일만 쌓아두기\n   → 버전 관리, 검색, 협업 기능 부재\n\n🚫 개인 노트북에 메모 형태로 관리\n   → 조직 차원의 지식 공유 불가\n\n🚫 코드 저장소(GitHub)에 마크다운만 저장\n   → 비개발자 접근성 문",
      "language": "ko",
      "createdAt": "2026-01-07T02:20:17.791Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-015_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-015",
      "category": "Operations",
      "title": "재해 복구",
      "advice": "# OPS-015: 재해 복구 (Disaster Recovery) - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP에서 중요한가?\n\n재해 복구는 MSP의 **운영 성숙도를 가장 직접적으로 증명**하는 항목입니다. 고객이 MSP에게 인프라를 맡기는 핵심 이유가 \"장애 시에도 비즈니스 연속성 보장\"이기 때문에, AWS는 이 항목을 통해 파트너가 실제로 복구 역량을 갖추었는지 **실증적으로** 검증합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 검증 포인트 | 감사관의 질문 예시 |\n|------------|-------------------|\n| **RTO/RPO 정의 근거** | \"이 워크로드의 RTO 4시간은 어떤 기준으로 결정했나요?\" |\n| **자동화 수준** | \"백업이 수동 트리거 없이 스케줄대로 실행되는 것을 어떻게 증명하나요?\" |\n| **복구 테스트 실제 수행** | \"마지막 복구 테스트는 언제 했고, 실제 소요 시간은?\" |\n| **RTO/RPO 충족 여부** | \"테스트 결과가 목표치를 달성했다는 증거는?\" |\n| **2개 이상 서비스 커버리지** | \"EC2 외에 RDS나 다른 서비스도 동일한 수준으로 보호되나요?\" |\n\n### 관련 AWS 서비스\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    AWS Backup (중앙 관리)                    │\n├─────────────────────────────────────────────────────────────┤\n│  EC2 AMI    │  RDS Snapshot  │  EBS Snapshot  │  DynamoDB   │\n│  EFS Backup │  S3 Replication│  Aurora Clone  │  FSx Backup │\n└─────────────────────────────────────────────────────────────┘\n                              │\n                    AWS Backup Audit Manager\n                    (컴플라이언스 리포트 자동 생성)\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 세트\n\n#### 📄 증빙 1: RTO/RPO 정의 문서\n**파일명 예시:** `DR-Policy-CustomerA-2024.pdf`\n\n```yaml\n포함 필수 내용:\n  - 워크로드별 비즈니스 영향도 분석 (BIA)\n  - RTO/RPO 산정 근거 (예: \"결제 시스템 - 매출 손실 시간당 $50K → RTO 1시간\")\n  - 고객 서명 또는 승인 이력\n  - 백업 주기와 보존 기간 매핑 테이블\n```\n\n**실제 예시 테이블:**\n| 워크로드 | Tier | RTO | RPO | 백업 주기 | 보존 기간 |\n|---------|------|-----|-----|----------|----------|\n| Production DB (RDS) | Tier 1 | 1시간 | 15분 | 15분 | 35일 |\n| Web Server (EC2) | Tier 2 | 4시간 | 1시간 | 매시간 | 14일 |\n| Log Archive (S3) | Tier 3 | 24시간 | 24시간 | 일간 | 90일 |\n\n---\n\n#### 📄 증빙 2: AWS Backup 구성 스크린샷\n**파일명 예시:** `AWS-Backup-Config-Evidence-20240115.pdf`\n\n**캡처해야 할 화면들:**\n\n```\n1️⃣ Backup Plan 설정 화면\n   - Plan name, Schedule expression (cron), Lifecycle 설정 보이게\n   \n2️⃣ Resource Assignment 화면  \n   - 태그 기반 자동 할당 규칙 (예: \"Backup=Required\" 태그)\n   \n3️⃣ Backup Vault 화면\n   - Vault Lock 설정 (삭제 방지)\n   - KMS 암호화 키 정보\n   \n4️⃣ Backup Jobs 히스토리\n   - 최근 30일간 성공/실패 현황\n   - Job ID, 시작/완료 시간, 상태\n```\n\n---\n\n#### 📄 증빙 3: 복구 테스트 실행 기록 (가장 중요!)\n**파일명 예시:** `DR-Test-Report-RDS-20240110.pdf`, `DR-Test-Report-EC2-20240110.pdf`\n\n**각 서비스별 복구 테스트 보고서 필수 포함 내용:**\n\n```markdown\n## 복구 테스트 보고서 - Amazon RDS\n\n### 테스트 개요\n- 테스트 일시: 2024-01-10 14:00 KST\n- 테스트 유형: Point-in-Time Recovery\n- 대상 리소스: prod-mysql-primary (db.r5.xlarge)\n- 테스트 수행자: 홍길동 (Cloud Engineer)\n\n### 목표 vs 실제 결과\n| 지표 | 목표 (SLA) | 실제 결과 | 충족 여부 |\n|-----|-----------|----------|----------|\n| RTO | 1시간 | 47분 | ✅ 충족 |\n| RPO | 15분 | 12분 | ✅ 충족 |\n\n### 상세 타임라인\n- 14:00:00 - 복구 시작 명령 실행\n- 14:12:00 - 스냅샷 복원 완료\n- 14:35:00 - 인스턴스 Available 상태\n- 14:42:00 - 애플리케이션 연결 테스트 완료\n- 14:47:00 - 데이터 무결성 검증 완료\n\n### 증빙 스크린샷\n[RDS Console - Restore 화면]\n[CloudWatch - 복구 시간 로그]\n[데이터 검증 쿼리 결과]\n```\n\n---\n\n#### 📄 증빙 4: 자동화 증빙 (AWS Backup Audit Manager 리포트)\n**파일명 예시:** `Backup-Audit-Report-Jan2024.csv`\n\n```\nAWS Backup Audit Manager에서 생성된 컴플라이언스 리포트:\n- Framework: \"MSP-DR-Compliance\"\n- Controls 포함:\n  ✓ BACKUP_RESOURCES_PROTECTED_BY_BACKUP_PLAN\n  ✓ BACKUP_RECOVERY_POINT_MINIMUM_RETENTION_CHECK  \n  ✓ BACKUP_RECOVERY_POINT_ENCRYPTED\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 테스트 대상 서비스 2개 선정 (1일)\n\n**권장 조합:**\n```\n옵션 A (가장 일반적): Amazon RDS + Amazon EC2\n옵션 B (고급): Amazon Aurora + Amazon EFS  \n옵션 C (서버리스): DynamoDB + S3\n```\n\n**선정 기준:**\n- 실제 고객 프로덕션에서 사용 중인 서비스\n- 서로 다른 복구 메커니즘을 가진 서비스 (스냅샷 vs PITR)\n- 감사관에게 다양한 역량을 보여줄 수 있는 조합\n\n---\n\n### Step 2: AWS Backup Plan 구성 (2-3일)\n\n```bash\n# AWS CLI로 Backup Plan 생성 예시\naws backup create-backup-plan --backup-plan '{\n  \"BackupPlanName\": \"MSP-Production-DR-Plan\",\n  \"Rules\": [\n    {\n      \"RuleName\": \"DailyBackup-35DayRetention\",\n      \"TargetBackupVaultName\": \"MSP-Production-Vault\",\n      \"ScheduleExpression\": \"cron(0 5 ? * * *)\",\n      \"StartWindowMinutes\": 60,\n      \"CompletionWindowMinutes\": 180,\n      \"Lifecycle\": {\n        \"DeleteAfterDays\": 35\n      }\n    },\n    {\n      \"RuleName\": \"HourlyBackup-7DayRetention\", \n      \"TargetBackupVaultName\": \"MSP-Production-Vault\",\n      \"ScheduleExpression\": \"cron(0 * ? * * *)\",\n      \"Lifecycle\": {\n        \"DeleteAfterDays\": 7\n      }\n    }\n  ]\n}'\n```\n\n**핵심 설정 체크:**\n- ✅ Backup Vault에 Vault Lock 활성화 (실수로 삭제 방지)\n- ✅ Cross-Region Copy 설정 (DR 시나리오 강화)\n- ✅ 태그 기반 리소스 자동 할당\n\n---\n\n### Step 3: 백업 실행 및 히스토리 축적 (최소 2주)\n\n```\n⚠️ 중요: 감사 전 최소 2주간의 백업 히스토리 필요\n```\n\n**모니터링 설정:**\n```python\n# CloudWatch Alarm 예시 - 백업 실패 시 알림\n{\n  \"AlarmName\": \"BackupJobFailed\",\n  \"MetricName\": \"NumberOfBackupJobsFailed\",\n  \"Namespace\": \"AWS/Backup\",\n  \"Statistic\": \"Sum\",\n  \"Period\": 86400,\n  \"EvaluationPeriods\": 1,\n  \"Threshold\": 1,\n  \"ComparisonOperator\": \"GreaterThanOrEqualToThreshold\"\n}\n```\n\n---\n\n### Step 4: 복구 테스트 실행 - RDS (반나절)\n\n```sql\n-- 테스트 전: 타임스탬프 마커 데이터 삽입\nINSERT INTO dr_test_marker (test_id, created_at, marker_value)\nVALUES ('DR-TEST-20240110', NOW(), 'PRE-RESTORE-MARKER');\n\n-- 복구 후: 데이터 존재 확인으로 RPO 검증\nSELECT * FROM dr_test_marker \nWHERE test_id = 'DR-TEST-20240110';\n```\n\n**RDS 복구 테스트 실행:**\n```bash\n# Point-in-Time Recovery 실행\naws rds restore-db-instance-to-point-in-time \\\n  --source-db-instance-identifier prod-mysql-primary \\\n  --target-db-instance-identifier dr-test-restore-20240110 \\\n  --restore-time 2024-01-10T13:45:00Z \\\n  --db-instance-class db.r5.xlarge\n```\n\n**타임라인 기록 필수:**\n```\n시작 시간: _____________ (명령 실행 시점)\n복원 완료: _____________ (인스턴스 Available)\n연결 가능: _____________ (애플리케이션 접속 성공)\n검증 완료: _____________ (데이터 무결성 확인)\n총 소요 시간: __________ (RTO 계산용)\n```\n\n---\n\n### Step 5: 복구 테스트 실행 - EC2 (반나절)\n\n```bash\n# EC2 AMI에서 복구\naws ec2 run-instances \\\n  --image-id ami-0abc123def456 \\\n  --instance-type t3.large \\\n  --subnet-id subnet-xxx \\\n  --tag-specifications 'ResourceType=instance,Tags=[{Key=Name,Value=DR-Test-Restore}]'\n```\n\n**EC2 복구 검증 체크리스트:**\n```\n□ 인스턴스 시작 완료\n□ SSH/RDP 접속 가능\n□ 애플리케이션 서비스 정상 기동\n□ 데이터 볼륨 마운트 및 데이터 확인\n□ 네트워크 연결성 테스트\n```\n\n---\n\n### Step 6: 증빙 문서 패키징 (1-2일)\n\n```\n📁 OPS-015-DR-Evidence/\n├── 01-RTO-RPO-Definition/\n│   ├── DR-Policy-v2.1.pdf\n│   └── Customer-Approval-Email.pdf\n├── 02-AWS-Backup-Configuration/\n│   ├── Backup-Plan-Screenshot.png\n│   ├── Resource-Assignment.png\n│   └── Vault-Lock-Config.png\n├── 03-Recovery-Test-RDS/\n│   ├── DR-Test-Report-RDS-20240110.pdf\n│   ├── PITR-Command-Output.txt\n│   ├── Timeline-Evidence.png\n│   └── Data-Validation-Query.png\n├── 04-Recovery-Test-EC2/\n│   ├── DR-Test-Report-EC2-20240110.pdf\n│   ├── AMI-Restore-Console.png\n│   └── Application-Health-Check.png\n└── 05-Automation-Evidence/\n    ├── Backup-Audit-Report.csv\n    └── CloudWatch-Backup-Dashboard.png\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 수동 백업만 제출\n\n```\n❌ 잘못된 예: \n   \"aws rds create-db-snapshot\" 수동 실행 스크린샷만 제출\n\n✅ 올바른 예:\n   AWS Backup Plan의 자동 스케줄 설정 + \n   실제 자동 실행된 Job 히스토리 제출\n```\n\n**감사관 코멘트:** *\"자동화된 백업이 아닌 수동 백업은 운영 성숙도를 증명하지 못합니다.\"*\n\n---\n\n### 🚫 실수 2: RTO/RPO 정의 없이 테스트만 제출\n\n```\n❌ 잘못된 예:\n   \"복구 테스트 완료, 소요시간 2시간\"\n\n✅ 올바른 예:\n   \"RTO 목표: 4시간, 실제 소요: 2시간 → 목표 대비 50% 달성\"",
      "language": "ko",
      "createdAt": "2026-01-07T02:21:15.537Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-016_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-016",
      "category": "Operations",
      "title": "클라우드 재무 관리",
      "advice": "# OPS-016: 클라우드 재무 관리 (FinOps) 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP에서 핵심인가?\n\nAWS MSP의 본질적 가치는 **고객의 클라우드 투자 대비 비즈니스 성과 최적화**입니다. 기술적 운영 능력만으로는 차별화가 어렵고, **재무적 가시성과 최적화 역량**이 MSP의 수익성과 고객 신뢰를 결정합니다. AWS는 MSP가 단순 리셀러가 아닌 **FinOps 전문 파트너**임을 증명하길 요구합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 검증 영역 | 감사관의 질문 의도 | 증명해야 할 역량 |\n|-----------|-------------------|------------------|\n| **TCO 분석 정확성** | \"On-premises vs Cloud 비교 시 숨겨진 비용을 어떻게 산정하나요?\" | 라이선스, 인건비, 시설비용 등 간접비용 포함 능력 |\n| **비용 모니터링 깊이** | \"이상 비용 발생 시 몇 분 내 탐지 가능한가요?\" | 실시간 알람 및 자동화된 대응 체계 |\n| **리셀러 청구 투명성** | \"고객별 마진 구조와 할인 적용을 어떻게 관리하나요?\" | 복잡한 요율 체계의 정확한 계산 및 리포팅 |\n| **최적화 실행력** | \"지난 6개월간 고객 비용을 얼마나 절감했나요?\" | 구체적인 절감 사례와 수치 |\n| **예측 정확도** | \"예산 대비 실제 지출 편차율이 어느 정도인가요?\" | 월별 예측 정확도 90% 이상 |\n\n### 관련 AWS 서비스 생태계\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    AWS FinOps 도구 스택                      │\n├─────────────────────────────────────────────────────────────┤\n│  분석/계획        │  모니터링         │  최적화             │\n│  ─────────────   │  ─────────────   │  ─────────────      │\n│  • Migration     │  • Cost Explorer │  • Compute Optimizer│\n│    Evaluator     │  • Budgets       │  • Trusted Advisor  │\n│  • Pricing       │  • Cost Anomaly  │  • Savings Plans    │\n│    Calculator    │    Detection     │  • Reserved         │\n│  • TCO Calculator│  • Cost &        │    Instances        │\n│    (Legacy)      │    Usage Reports │  • Spot Instances   │\n├─────────────────────────────────────────────────────────────┤\n│  파트너 전용: AWS Partner Central Billing Console           │\n│              AWS Marketplace Seller Reports                 │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 📁 증빙 자료 구조\n\n```\nOPS-016_FinOps_Evidence/\n├── 01_TCO_Analysis/\n│   ├── TCO_Methodology_Document_v2.1.pdf\n│   ├── TCO_Calculator_Template.xlsx\n│   ├── Customer_TCO_Sample_Redacted.pdf\n│   └── Demo_Recording_TCO_Tool.mp4\n├── 02_Cost_Monitoring/\n│   ├── Cost_Monitoring_Architecture.pdf\n│   ├── Alert_Configuration_Screenshots/\n│   ├── Monthly_Cost_Report_Sample.pdf\n│   └── Demo_Recording_Cost_Dashboard.mp4\n├── 03_Billing_Tool/\n│   ├── Reseller_Billing_System_Overview.pdf\n│   ├── Rate_Card_Management_Process.pdf\n│   ├── Customer_Invoice_Sample_Redacted.pdf\n│   └── Demo_Recording_Billing_Portal.mp4\n└── 04_Optimization_Results/\n    ├── Cost_Savings_Case_Studies.pdf\n    └── Quarterly_FinOps_Report_Sample.pdf\n```\n\n### 📄 각 증빙의 필수 포함 내용\n\n#### 1️⃣ TCO 분석 방법론 문서\n\n```markdown\n## TCO_Methodology_Document_v2.1.pdf 필수 섹션\n\n### 1. 비용 카테고리 정의\n- 직접 비용: 하드웨어, 소프트웨어 라이선스, 네트워크 장비\n- 간접 비용: 데이터센터 공간, 전력/냉각, 물리적 보안\n- 운영 비용: 인건비(FTE 환산), 유지보수 계약, 교육비\n- 기회 비용: 자본 비용(WACC 적용), 감가상각\n\n### 2. AWS 매핑 로직\n- EC2 사이징 공식 (vCPU, Memory 기준)\n- 스토리지 티어 선정 기준 (IOPS, 처리량 기반)\n- 네트워크 비용 산정 (Data Transfer 패턴 분석)\n- 관리형 서비스 전환 시 TCO 영향\n\n### 3. 3년/5년 비용 예측 모델\n- AWS 가격 변동 가정 (연 -5% ~ -10%)\n- 사용량 증가율 시나리오 (Low/Mid/High)\n- Reserved Instance/Savings Plans 적용 효과\n```\n\n#### 2️⃣ 비용 모니터링 아키텍처\n\n```yaml\n# Cost_Monitoring_Architecture.pdf에 포함될 다이어그램 예시\n\n모니터링 파이프라인:\n  데이터 수집:\n    - AWS Cost and Usage Report → S3 버킷\n    - 수집 주기: 시간별 (Hourly granularity)\n    - 리소스 태깅 정책 적용\n    \n  데이터 처리:\n    - Athena 쿼리로 CUR 분석\n    - Lambda로 일일 집계 처리\n    - QuickSight 대시보드 자동 갱신\n    \n  알람 체계:\n    - AWS Budgets: 예산 80%/100% 도달 시\n    - Cost Anomaly Detection: ML 기반 이상 탐지\n    - SNS → Slack/Email 즉시 알림\n    \n  대응 프로세스:\n    - 이상 탐지 → 15분 내 1차 분석\n    - 원인 파악 → 2시간 내 고객 리포트\n    - 시정 조치 → 24시간 내 완료\n```\n\n#### 3️⃣ 리셀러 빌링 도구 (필수 - 리셀러인 경우)\n\n```\n## Reseller_Billing_System_Overview.pdf 핵심 내용\n\n1. 요율 관리 체계\n   - 고객별 할인율 설정 (Tier 1: 5%, Tier 2: 8%, Tier 3: 12%)\n   - 서비스별 마진 구조 (EC2: X%, RDS: Y%, Support: Z%)\n   - 프로모션/크레딧 적용 로직\n\n2. 청구서 생성 프로세스\n   - AWS 원본 청구 데이터 수신 (매월 3일)\n   - 요율 적용 및 검증 (자동화 + 수동 검토)\n   - 고객 청구서 발행 (매월 10일)\n   - 차이 분석 리포트 생성\n\n3. 고객 포털 기능\n   - 실시간 사용량 조회\n   - 서비스별/프로젝트별 비용 분석\n   - 청구서 다운로드 및 이력 조회\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Phase 1: TCO 분석 역량 구축 (2-3주)\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ Step 1: TCO 템플릿 및 도구 준비                              │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│ 📌 실행 항목:                                                │\n│                                                             │\n│ 1. AWS Migration Evaluator 활성화                           │\n│    - Partner Central에서 Migration Evaluator 접근 권한 요청  │\n│    - Agentless Collector 배포 가이드 숙지                    │\n│    - 최소 1개 고객 환경에서 데이터 수집 완료                  │\n│                                                             │\n│ 2. 자체 TCO 스프레드시트 개발                                │\n│    └── 필수 시트 구성:                                       │\n│        ├── Input_OnPrem: 현재 인프라 입력                    │\n│        ├── Mapping_Logic: AWS 서비스 매핑 규칙               │\n│        ├── AWS_Pricing: API 연동 또는 수동 업데이트          │\n│        ├── Calculation: 3년/5년 TCO 계산                    │\n│        └── Output_Report: 경영진용 요약                      │\n│                                                             │\n│ 3. TCO 분석 수행 이력 확보                                   │\n│    - 최소 2-3개 고객 TCO 분석 완료 (민감정보 마스킹)          │\n│    - 분석 결과 대비 실제 AWS 비용 비교 (정확도 검증)          │\n│                                                             │\n│ ⏱️ 담당: 클라우드 아키텍트 + FinOps 담당자                    │\n│ 📅 기간: 2주                                                 │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Phase 2: 비용 모니터링 체계 구축 (2-3주)\n\n```python\n# Step 2: Cost Monitoring 인프라 구성 예시\n\n\"\"\"\nAWS Cost Monitoring 자동화 구성 체크리스트\n\"\"\"\n\n# 1. Cost and Usage Report 설정\ncur_config = {\n    \"report_name\": \"msp-hourly-cur\",\n    \"time_unit\": \"HOURLY\",  # 감사관 선호: 시간별 상세 데이터\n    \"format\": \"Parquet\",     # Athena 쿼리 최적화\n    \"compression\": \"PARQUET\",\n    \"s3_bucket\": \"company-cur-reports\",\n    \"s3_prefix\": \"cur/\",\n    \"integration\": \"ATHENA\",  # Athena 자동 통합 필수\n    \"refresh\": True,\n    \"resource_ids\": True      # 리소스 레벨 추적 필수\n}\n\n# 2. AWS Budgets 설정 (고객당 최소 구성)\nbudget_templates = [\n    {\n        \"name\": \"{customer}-monthly-total\",\n        \"type\": \"COST\",\n        \"limit\": \"customer_agreed_budget\",\n        \"alerts\": [\n            {\"threshold\": 50, \"notification\": \"email\"},\n            {\"threshold\": 80, \"notification\": \"email+slack\"},\n            {\"threshold\": 100, \"notification\": \"email+slack+pagerduty\"}\n        ]\n    },\n    {\n        \"name\": \"{customer}-ec2-compute\",\n        \"type\": \"COST\",\n        \"filter\": {\"Service\": \"Amazon Elastic Compute Cloud - Compute\"},\n        \"alerts\": [{\"threshold\": 90, \"notification\": \"email+slack\"}]\n    }\n]\n\n# 3. Cost Anomaly Detection 설정\nanomaly_monitors = [\n    {\n        \"name\": \"service-monitor\",\n        \"type\": \"DIMENSIONAL\",\n        \"dimension\": \"SERVICE\",\n        \"threshold\": 10  # 10% 이상 이상치 탐지\n    },\n    {\n        \"name\": \"account-monitor\", \n        \"type\": \"DIMENSIONAL\",\n        \"dimension\": \"LINKED_ACCOUNT\"\n    }\n]\n```\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│ Step 3: 대시보드 및 리포팅 구축                              │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│ 📊 QuickSight 대시보드 필수 구성요소:                        │\n│                                                             │\n│ Dashboard 1: Executive Summary                              │\n│ ├── 월별 총 비용 트렌드 (12개월)                            │\n│ ├── 예산 대비 실제 지출 (Gauge 차트)                        │\n│ ├── Top 5 비용 서비스                                       │\n│ └── 전월 대비 증감률                                        │\n│                                                             │\n│ Dashboard 2: Service Deep Dive                              │\n│ ├── EC2: 인스턴스 타입별, 구매 옵션별 비용                  │\n│ ├── RDS: 엔진별, 인스턴스별 비용                            │\n│ ├── S3: 스토리지 클래스별, 버킷별 비용                      │\n│ └── Data Transfer: 리전별, 유형별 비용                      │\n│                                                             │\n│ Dashboard 3: Optimization Opportunities                     │\n│ ├── 유휴 리소스 목록 (CPU < 5% 지속)                        │\n│ ├── RI/SP 커버리지 및 활용률                                │\n│ ├── 이전 세대 인스턴스 목록                                 │\n│ └── 예상 절감 금액                                          │\n│                                                             │\n│ ⏱️ 담당: FinOps 엔지니어 + 데이터 분석가                     │\n│ 📅 기간: 2주                                                 │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Phase 3: 리",
      "language": "ko",
      "createdAt": "2026-01-07T02:22:13.915Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-017_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-017",
      "category": "Operations",
      "title": "마이그레이션",
      "advice": "# OPS-017: 마이그레이션 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n마이그레이션은 MSP의 **핵심 역량 중 하나**입니다. AWS는 파트너가 단순히 인프라를 운영하는 것이 아니라, 고객의 온프레미스 워크로드를 클라우드로 안전하게 이전하고 현대화할 수 있는 **End-to-End 역량**을 보유하고 있는지 검증합니다. 특히 7Rs 전략 중 **리팩토링/리플랫포밍**을 요구하는 것은 단순 Lift-and-Shift를 넘어선 **진정한 클라우드 네이티브 전환 역량**을 확인하기 위함입니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **🎯 7Rs 전략 적용 근거** | 각 애플리케이션에 왜 특정 마이그레이션 전략을 선택했는지 명확한 의사결정 기록이 있는가? |\n| **🏗️ 랜딩 존 설계 역량** | AWS Control Tower, Organizations, 네트워크 아키텍처를 체계적으로 구성했는가? |\n| **📊 포트폴리오 발견 도구 활용** | AWS Application Discovery Service, Migration Hub 등을 실제로 사용했는가? |\n| **🔄 리팩토링/리플랫포밍 실행력** | 최소 1개 고객 사례에서 실제로 아키텍처를 변경하여 클라우드 네이티브화했는가? |\n| **📋 거버넌스 체계** | RACI, 커뮤니케이션 플랜, 전환 계획이 문서화되어 실제로 운영되었는가? |\n\n### 관련 AWS 서비스 및 도구\n\n```\n발견/평가: AWS Application Discovery Service, Migration Hub, Migration Evaluator\n마이그레이션 실행: AWS MGN (Application Migration Service), DMS, SMS\n현대화: AWS App2Container, AWS Modernization Pathways\n랜딩 존: AWS Control Tower, AWS Organizations, Service Catalog\n운영: AWS CloudWatch, AWS Config, Systems Manager\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 구조 (2개 고객 사례)\n\n#### 📁 고객 사례 A (리팩토링/리플랫포밍 필수 포함)\n\n| 문서명 | 형식 | 핵심 포함 내용 |\n|--------|------|---------------|\n| `CustomerA_Portfolio_Discovery_Report.xlsx` | Excel | 발견된 서버/앱 목록, 의존성 맵, 7Rs 분류 결과 |\n| `CustomerA_Migration_Strategy_Decision.pdf` | PDF | 각 워크로드별 7Rs 선택 근거, 리팩토링 대상 선정 이유 |\n| `CustomerA_Landing_Zone_Architecture.pdf` | Visio/Draw.io | Account 구조, OU 설계, 네트워크 토폴로지, 보안 경계 |\n| `CustomerA_RACI_Matrix.xlsx` | Excel | 역할별 책임 매트릭스 (고객/MSP/AWS 구분 명확) |\n| `CustomerA_Refactoring_Technical_Design.pdf` | PDF | **리팩토링 전/후 아키텍처 비교**, 컨테이너화 또는 서버리스 전환 상세 |\n| `CustomerA_Runbook_Operations.docx` | Word | 마이그레이션 런북, 롤백 절차, 모니터링 설정 |\n| `CustomerA_Cutover_Communication_Plan.pdf` | PDF | 전환 일정, 이해관계자 커뮤니케이션 매트릭스, 에스컬레이션 경로 |\n\n#### 📁 고객 사례 B (Rehost 또는 다른 전략 가능)\n\n| 문서명 | 형식 | 핵심 포함 내용 |\n|--------|------|---------------|\n| `CustomerB_Discovery_Assessment.pdf` | PDF | AWS Migration Evaluator 또는 ADS 결과 리포트 |\n| `CustomerB_Wave_Planning.xlsx` | Excel | 마이그레이션 웨이브 계획, 우선순위, 의존성 |\n| `CustomerB_Security_Compliance_Checklist.pdf` | PDF | 보안 요구사항, 규정 준수 체크리스트, 위험 평가 |\n| `CustomerB_Training_Plan.pdf` | PDF | 고객 인력 교육 계획, 기술 전수 일정 |\n| `CustomerB_Pilot_MVP_Report.pdf` | PDF | 파일럿 마이그레이션 결과, 성공 기준 달성 여부 |\n| `CustomerB_Post_Migration_Operations.pdf` | PDF | 마이그레이션 후 운영 핸드오버 문서 |\n\n### 각 증빙에 반드시 포함되어야 할 내용\n\n#### 🔴 리팩토링/리플랫포밍 증빙 (가장 중요)\n\n```\n✓ AS-IS 아키텍처 다이어그램 (온프레미스 또는 기존 AWS)\n✓ TO-BE 아키텍처 다이어그램 (클라우드 네이티브)\n✓ 변경된 기술 스택 명시 (예: EC2 → ECS/EKS, RDS → Aurora Serverless)\n✓ 리팩토링 결정 근거 (비용, 성능, 확장성 분석)\n✓ 코드 또는 구성 변경 사항 요약\n✓ 마이그레이션 전/후 성능 비교 데이터\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 적합한 고객 사례 선정 (1주)\n\n**담당: 프로젝트 매니저 + 솔루션 아키텍트**\n\n```\n선정 기준:\n□ 최근 24개월 이내 완료된 프로젝트\n□ 고객 사례 A: 반드시 리팩토링 또는 리플랫포밍 포함\n  - 예: 모놀리식 → 마이크로서비스\n  - 예: VM → 컨테이너 (ECS/EKS)\n  - 예: 자체 DB → Aurora/DynamoDB\n□ 고객 사례 B: 7Rs 중 어떤 전략이든 가능\n□ 두 사례 모두 랜딩 존 구축이 포함된 프로젝트 우선\n□ 고객 동의서(NDA 범위 내 공유 가능) 확보 가능 여부\n```\n\n### Step 2: 포트폴리오 발견 문서 정리 (2주)\n\n**담당: 솔루션 아키텍트**\n\n```\nAWS 도구 활용 증빙:\n1. AWS Application Discovery Service 에이전트 설치 기록\n2. Migration Hub 대시보드 스크린샷 (서버 발견 결과)\n3. 의존성 맵 시각화 (Migration Hub 또는 자체 도구)\n\n7Rs 분류 문서 작성:\n┌─────────────────────────────────────────────────────────────┐\n│ 애플리케이션명 │ 현재 환경 │ 7Rs 전략 │ 선택 근거 │ 대상 서비스 │\n├─────────────────────────────────────────────────────────────┤\n│ 레거시 ERP    │ Oracle/AIX │ Replatform │ 라이선스 절감 │ Aurora PostgreSQL │\n│ 웹 포털      │ Tomcat/VM  │ Refactor   │ 확장성 확보  │ ECS Fargate      │\n│ 파일서버     │ Windows FS │ Rehost     │ 빠른 이전   │ EC2 + FSx        │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Step 3: 랜딩 존 설계 문서 작성 (2주)\n\n**담당: 클라우드 아키텍트**\n\n```\n필수 포함 요소:\n□ AWS Organizations OU 구조도\n□ Account 전략 (Workload/Sandbox/Security/Log Archive 등)\n□ AWS Control Tower 가드레일 설정 목록\n□ 네트워크 아키텍처 (Transit Gateway, VPC 설계)\n□ IAM 역할/정책 설계\n□ 보안 기준선 (Security Hub, GuardDuty 활성화)\n\n실제 구현 증빙:\n- Control Tower 대시보드 스크린샷\n- Organizations 콘솔의 OU 구조 스크린샷\n- CloudFormation/Terraform 코드 (민감정보 마스킹)\n```\n\n### Step 4: 리팩토링 기술 문서 상세화 (2주)\n\n**담당: DevOps 엔지니어 + 개발팀**\n\n```\n리팩토링 사례 문서 구조:\n\n1. 비즈니스 배경\n   - 왜 리팩토링이 필요했는가?\n   - 기대 효과 (비용 절감 %, 성능 개선 목표)\n\n2. 기술적 변환 상세\n   ┌──────────────────────────────────────────┐\n   │ AS-IS                │ TO-BE              │\n   ├──────────────────────────────────────────┤\n   │ Apache + PHP (EC2)   │ ALB + ECS Fargate  │\n   │ MySQL 5.7 (EC2)      │ Aurora MySQL 3.0   │\n   │ NFS 파일 스토리지    │ S3 + CloudFront    │\n   │ Cron 배치 작업       │ EventBridge + Lambda│\n   └──────────────────────────────────────────┘\n\n3. 마이그레이션 실행 단계\n   - 컨테이너 이미지 빌드 과정\n   - 데이터베이스 스키마 변환 (SCT 사용 시 리포트 첨부)\n   - 테스트 결과 및 성능 비교\n\n4. 결과 메트릭\n   - 응답 시간: 2.5초 → 0.8초\n   - 월 비용: $15,000 → $8,500\n   - 배포 주기: 월 1회 → 일 5회\n```\n\n### Step 5: 거버넌스 및 운영 문서 완성 (1주)\n\n**담당: 프로젝트 매니저**\n\n```\nRACI 매트릭스 예시:\n┌────────────────────────────────────────────────────────┐\n│ 활동              │ 고객 │ MSP │ AWS │\n├────────────────────────────────────────────────────────┤\n│ 마이그레이션 계획 승인 │ A    │ R   │ C   │\n│ 랜딩 존 구축         │ I    │ R   │ C   │\n│ 애플리케이션 테스트   │ R    │ A   │ I   │\n│ 전환 실행           │ A    │ R   │ S   │\n│ 운영 핸드오버       │ R    │ A   │ I   │\n└────────────────────────────────────────────────────────┘\n(R=Responsible, A=Accountable, C=Consulted, I=Informed, S=Support)\n\n커뮤니케이션 플랜:\n- 주간 상태 보고서 샘플 첨부\n- 전환 D-Day 커뮤니케이션 타임라인\n- 에스컬레이션 매트릭스\n```\n\n### Step 6: 런북 및 모니터링 설정 문서화 (1주)\n\n**담당: 운영팀**\n\n```\n런북 필수 섹션:\n□ 마이그레이션 실행 체크리스트 (시간대별)\n□ 롤백 절차 (상세 단계 + 예상 소요시간)\n□ 검증 테스트 항목 및 성공 기준\n□ 장애 대응 연락처 및 에스컬레이션\n\n모니터링 설정 증빙:\n- CloudWatch 대시보드 스크린샷\n- 알람 설정 목록 (임계값 포함)\n- 마이그레이션 전/후 메트릭 비교 차트\n```\n\n### Step 7: 최종 패키징 및 검토 (1주)\n\n**담당: QA + 프로젝트 매니저**\n\n```\n제출 패키지 구조:\nMSP_OPS017_Migration_Evidence/\n├── CustomerA_Refactoring_Case/\n│   ├── 01_Portfolio_Discovery/\n│   ├── 02_Migration_Strategy/\n│   ├── 03_Landing_Zone/\n│   ├── 04_Refactoring_Design/\n│   ├── 05_Governance_RACI/\n│   ├── 06_Runbook_Operations/\n│   └── 07_Security_Compliance/\n├── CustomerB_Rehost_Case/\n│   └── (동일 구조)\n└── README_Evidence_Index.pdf\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 | 왜 문제인가 | 해결 방법 |\n|------|------------|----------|\n| **리팩토",
      "language": "ko",
      "createdAt": "2026-01-07T02:23:09.143Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-018_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-018",
      "category": "Operations",
      "title": "인공지능",
      "advice": "# OPS-018: 인공지능 (AI) - AWS MSP 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS는 MSP 파트너가 **단순 인프라 관리자를 넘어 AI 혁신 파트너**로 진화하기를 기대합니다. 이 항목은 선택사항이지만, 2024년 이후 AWS가 생성형 AI를 전략적 우선순위로 삼으면서 **MSP 차별화의 핵심 지표**가 되었습니다. AI 역량을 갖춘 MSP는 갱신 심사에서 유리한 평가를 받습니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **실제 구현 여부** | 계획서만 있는 것이 아니라 실제로 AI를 적용했는지 |\n| **AWS AI 서비스 활용** | Amazon Bedrock, SageMaker 등 AWS 네이티브 서비스 사용 여부 |\n| **비즈니스 임팩트** | 비용 절감, 효율성 향상 등 측정 가능한 결과가 있는지 |\n| **반복 가능성** | 일회성이 아닌 재사용 가능한 AI 솔루션인지 |\n| **고객 가치 전달** | 내부 사용이든 고객 프로젝트든 명확한 가치가 있는지 |\n\n### 관련 AWS 서비스\n\n```\n🤖 생성형 AI: Amazon Bedrock, Amazon Q, PartyRock\n🧠 ML 플랫폼: Amazon SageMaker, SageMaker Canvas\n💬 AI 서비스: Amazon Lex, Amazon Comprehend, Amazon Transcribe\n🔍 검색/RAG: Amazon Kendra, Amazon OpenSearch (벡터 검색)\n⚙️ 인프라: AWS Lambda, Amazon ECS (AI 워크로드 호스팅)\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 증빙 옵션 A: 내부 AI 활용 (권장 - 준비 용이)\n\n| 증빙 자료 | 포함 내용 | 파일명 예시 |\n|----------|----------|-------------|\n| **AI 도구 사용 정책서** | 승인된 AI 도구 목록, 사용 가이드라인, 데이터 보안 규정 | `AI_Usage_Policy_v2.1.pdf` |\n| **내부 AI 봇 구현 문서** | 아키텍처, 사용 통계, 비용 절감 효과 | `Internal_ChatBot_Implementation.pdf` |\n| **운영 자동화 스크립트** | AI 기반 티켓 분류, 장애 예측 코드 | `AI_Ticket_Classification_Design.pdf` |\n\n### 증빙 옵션 B: 고객 프로젝트\n\n| 증빙 자료 | 포함 내용 | 파일명 예시 |\n|----------|----------|-------------|\n| **SOW (작업 명세서)** | AI 프로젝트 범위, 사용 AWS 서비스, 산출물 | `Customer_GenAI_SOW_2024.pdf` |\n| **프로젝트 계획서** | 마일스톤, 리소스, 기술 스택 | `GenAI_Project_Plan_CustomerX.xlsx` |\n| **스프린트 계획/회고** | Jira 스프린트 캡처, AI 기능 개발 내역 | `Sprint_Planning_AI_Features.pdf` |\n| **아키텍처 다이어그램** | Bedrock/SageMaker 기반 솔루션 구조 | `GenAI_Architecture_Diagram.png` |\n\n### 각 증빙에 반드시 포함되어야 할 핵심 내용\n\n```markdown\n📌 SOW 필수 포함 사항:\n- \"Amazon Bedrock\" 또는 \"Amazon SageMaker\" 명시적 언급\n- Claude, Titan, Llama 등 사용 모델명\n- 프롬프트 엔지니어링 또는 RAG 구현 범위\n- 예상 비용 및 ROI 추정\n\n📌 프로젝트 계획서 필수 포함 사항:\n- AI 모델 선정 기준 및 비교 분석\n- 데이터 준비 및 벡터화 계획\n- 할루시네이션 방지 전략\n- 성능 측정 KPI (응답 정확도, 지연시간 등)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### 🚀 가장 빠른 경로: 내부 운영 AI 봇 구축 (2-3주)\n\n#### Step 1: Amazon Q Business 또는 Bedrock 기반 내부 봇 구축 (5일)\n```\n담당: 클라우드 엔지니어 1명\n도구: Amazon Bedrock + Claude 3, Amazon Kendra\n\n구현 내용:\n- 내부 운영 매뉴얼을 Knowledge Base로 구성\n- Slack/Teams 연동 챗봇 배포\n- 직원들의 반복 질문 자동 응답\n```\n\n#### Step 2: 티켓 자동 분류 시스템 구현 (3일)\n```python\n# 증빙용 코드 스니펫 예시 (문서에 포함)\nimport boto3\n\nbedrock = boto3.client('bedrock-runtime')\n\ndef classify_ticket(ticket_text):\n    response = bedrock.invoke_model(\n        modelId='anthropic.claude-3-sonnet-20240229-v1:0',\n        body={\n            \"prompt\": f\"다음 티켓을 분류하세요: {ticket_text}\",\n            \"max_tokens\": 100\n        }\n    )\n    return response['category'], response['priority']\n```\n\n#### Step 3: 사용 통계 및 효과 측정 대시보드 구축 (2일)\n```\n담당: 데이터 분석가\n도구: Amazon CloudWatch, QuickSight\n\n측정 지표:\n- 일일 AI 봇 사용 횟수\n- 티켓 처리 시간 단축률 (예: 평균 15분 → 3분)\n- 직원 만족도 설문 결과\n```\n\n#### Step 4: 문서화 및 증빙 패키지 작성 (3일)\n```\n산출물:\n1. AI_Implementation_Summary.pdf (2-3페이지)\n   - 비즈니스 문제 정의\n   - 솔루션 아키텍처\n   - 사용된 AWS 서비스 목록\n   - 측정된 비즈니스 임팩트\n\n2. Architecture_Diagram.png\n   - Bedrock, Lambda, API Gateway 연동 구조\n\n3. Usage_Metrics_Dashboard.pdf\n   - CloudWatch/QuickSight 대시보드 스크린샷\n```\n\n#### Step 5: 고객 프로젝트 SOW 템플릿 준비 (2일)\n```\n목적: 향후 고객에게 AI 서비스 제공 가능함을 증명\n내용:\n- 생성형 AI 컨설팅 서비스 SOW 템플릿\n- 가격 모델 (예: Bedrock 토큰 비용 + 구현 비용)\n- 레퍼런스 아키텍처 3종\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### ❌ 감사 탈락 원인 Top 5\n\n| 실수 | 왜 문제인가 | 해결책 |\n|------|-----------|--------|\n| **OpenAI API만 사용** | AWS 서비스 활용 증명 불가 | Bedrock으로 마이그레이션하거나 병행 사용 문서화 |\n| **계획서만 제출** | 실제 구현 증거 없음 | 최소한 PoC 수준의 동작하는 시스템 필요 |\n| **비즈니스 임팩트 미측정** | \"AI 도입했다\"만으로 부족 | 구체적 수치 (시간 절감 30%, 비용 절감 $X) 포함 |\n| **고객 정보 노출** | NDA 위반 위험 | 고객명 익명화, 민감 정보 마스킹 |\n| **일회성 실험** | 지속 가능성 의문 | 운영 중인 시스템 또는 반복 가능한 프로세스 증명 |\n\n### 🚫 피해야 할 안티패턴\n\n```\n❌ \"ChatGPT를 업무에 활용하고 있습니다\" \n   → AWS 서비스가 아니므로 증빙 불가\n\n❌ 단순 번역/요약 기능만 구현\n   → 비즈니스 가치가 불명확\n\n❌ 아키텍처 없이 코드만 제출\n   → 전체 솔루션 이해 불가\n\n❌ \"AI 도입 예정\" 로드맵만 제출\n   → 실제 구현 증거 필요\n```\n\n### ✅ 감사관이 좋아하는 증빙 패턴\n\n```\n✓ \"Amazon Bedrock을 활용해 내부 지식 검색 봇을 구축하여 \n   엔지니어 문의 응답 시간을 평균 45분에서 5분으로 단축\"\n\n✓ \"고객사 A의 고객센터에 Amazon Lex + Bedrock 기반 \n   AI 상담 시스템을 구축하여 단순 문의 70% 자동 처리\"\n\n✓ \"SageMaker를 활용한 이상 탐지 모델로 \n   인프라 장애 예측 정확도 85% 달성\"\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | **AWS AI 서비스 명시** | 문서에서 Ctrl+F로 \"Bedrock\", \"SageMaker\" 검색 | 최소 1개 이상 AWS AI 서비스 언급 |\n| 2 | **아키텍처 다이어그램 포함** | 이미지 파일 존재 확인 | AWS 아이콘 사용, 데이터 흐름 명확 |\n| 3 | **비즈니스 임팩트 수치화** | 문서에서 %, $, 시간 단위 검색 | 최소 2개 이상 측정 가능한 KPI |\n| 4 | **실제 구현 증거** | 스크린샷, 코드 스니펫, 로그 확인 | 동작하는 시스템 또는 완료된 프로젝트 |\n| 5 | **날짜 및 버전 정보** | 문서 헤더/푸터 확인 | 최근 12개월 이내 날짜 |\n| 6 | **고객 정보 보호** | 고객명, 계정 ID 마스킹 확인 | 민감 정보 완전 제거 |\n| 7 | **AWS 서비스 정확한 명칭** | \"Bedrock\" (O) vs \"bedrock\" (△) | 공식 서비스명 사용 |\n\n### 📊 품질 자가 평가\n\n```\n증빙 품질 점수 (각 항목 1점, 총 7점)\n\n□ Bedrock/SageMaker 등 AWS AI 서비스 사용 증명\n□ 실제 운영 중이거나 완료된 프로젝트\n□ 측정 가능한 비즈니스 가치 (ROI, 시간 절감 등)\n□ 재사용 가능한 솔루션 또는 서비스 오퍼링\n□ 명확한 아키텍처 문서\n□ 프로젝트 관리 증적 (SOW, 스프린트 등)\n□ 향후 확장 계획 또는 고객 적용 로드맵\n\n5점 이상: 제출 권장\n3-4점: 보완 후 제출\n2점 이하: 추가 구현 필요\n```\n\n---\n\n## 💡 빠른 시작 권장 사항\n\n**시간이 부족하다면:**\n1. Amazon Q Business를 내부 Wiki/Confluence에 연결 (1주)\n2. 사용 통계 수집 (2주)\n3. 요약 문서 작성 (2일)\n\n**차별화를 원한다면:**\n1. 고객 프로젝트에 Bedrock 기반 RAG 솔루션 제안\n2. MSP 운영 자동화에 AI 적용 (티켓 분류, 장애 예측)\n3. AI 서비스 오퍼링 카탈로그 개발",
      "language": "ko",
      "createdAt": "2026-01-07T02:24:15.022Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-001",
      "category": "Operations",
      "title": "인시던트 관리",
      "advice": "# OPSP-001: 인시던트 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n인시던트 관리는 AWS MSP의 **운영 성숙도를 가장 직접적으로 보여주는 핵심 역량**입니다. AWS는 MSP 파트너가 고객의 클라우드 환경에서 발생하는 장애와 보안 위협에 **체계적이고 반복 가능한 방식**으로 대응할 수 있는지 확인합니다. 이는 단순히 문서가 있는지가 아니라, **실제로 작동하는 프로세스**인지를 검증합니다.\n\n### 🎯 감사관이 확인하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 의도 |\n|--------|-------------------|\n| **IT 인시던트와 보안 인시던트의 명확한 구분** | 두 유형의 인시던트가 다른 에스컬레이션 경로와 대응 절차를 가지는지 |\n| **인시던트 분류 체계(Severity Matrix)의 구체성** | P1/P2/P3/P4 또는 Critical/High/Medium/Low가 정량적 기준으로 정의되어 있는지 |\n| **플레이북의 실행 가능성** | 담당자가 바뀌어도 동일한 품질의 대응이 가능한 수준의 상세함이 있는지 |\n| **고객 커뮤니케이션 SLA** | 인시던트 심각도별 고객 통지 시간과 업데이트 주기가 명시되어 있는지 |\n| **Post-Incident Review 프로세스** | 인시던트 종료 후 RCA(Root Cause Analysis)와 개선 조치가 문서화되는지 |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS Systems Manager Incident Manager**: 인시던트 생성, 추적, 에스컬레이션 자동화\n- **Amazon CloudWatch Alarms**: 인시던트 자동 식별 및 트리거\n- **AWS Security Hub**: 보안 인시던트 통합 관리\n- **Amazon EventBridge**: 인시던트 이벤트 라우팅 및 자동화\n- **AWS CloudTrail**: 인시던트 조사를 위한 감사 로그\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 OPSP-001_Incident_Management/\n├── 01_Incident_Management_Policy_v2.3.pdf\n├── 02_Incident_Classification_Matrix.xlsx\n├── 03_Playbooks/\n│   ├── PB-001_EC2_Instance_Failure.pdf\n│   ├── PB-002_RDS_Connection_Exhaustion.pdf\n│   ├── PB-003_Security_Unauthorized_Access.pdf\n│   ├── PB-004_DDoS_Attack_Response.pdf\n│   └── PB-005_Data_Breach_Response.pdf\n├── 04_Customer_Communication_Templates/\n│   ├── Initial_Notification_Template.docx\n│   ├── Status_Update_Template.docx\n│   └── Resolution_Notification_Template.docx\n├── 05_Incident_Log_Sample_Q4_2024.xlsx\n└── 06_Post_Incident_Review_Sample.pdf\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📄 인시던트 관리 정책 문서 (Policy)\n\n```markdown\n필수 포함 섹션:\n┌─────────────────────────────────────────────────────────────┐\n│ 1. 목적 및 범위                                              │\n│    - IT 인시던트 정의: \"서비스 중단 또는 품질 저하를 야기하는 │\n│      계획되지 않은 이벤트\"                                   │\n│    - 보안 인시던트 정의: \"정보 자산의 기밀성, 무결성, 가용성을│\n│      위협하는 이벤트\"                                        │\n├─────────────────────────────────────────────────────────────┤\n│ 2. 역할 및 책임 (RACI Matrix)                               │\n│    - Incident Commander                                      │\n│    - Technical Lead                                          │\n│    - Customer Communication Lead                             │\n│    - Security Incident Response Team (보안 인시던트 전용)    │\n├─────────────────────────────────────────────────────────────┤\n│ 3. 인시던트 라이프사이클                                     │\n│    Detection → Triage → Investigation → Resolution → Closure│\n├─────────────────────────────────────────────────────────────┤\n│ 4. 에스컬레이션 매트릭스                                     │\n│    - 시간 기반 에스컬레이션                                  │\n│    - 심각도 기반 에스컬레이션                                │\n└─────────────────────────────────────────────────────────────┘\n```\n\n#### 📊 인시던트 분류 매트릭스 (Classification Matrix)\n\n| Severity | 비즈니스 영향 | 영향 범위 | 초기 응답 SLA | 고객 통지 SLA | 업데이트 주기 |\n|----------|--------------|----------|--------------|--------------|--------------|\n| **P1 - Critical** | 전체 서비스 중단, 데이터 유출 | 전체 고객 또는 핵심 시스템 | 15분 | 30분 이내 | 매 30분 |\n| **P2 - High** | 주요 기능 장애, 성능 심각 저하 | 다수 사용자 영향 | 30분 | 1시간 이내 | 매 1시간 |\n| **P3 - Medium** | 일부 기능 제한, 우회 가능 | 일부 사용자 영향 | 2시간 | 4시간 이내 | 매 4시간 |\n| **P4 - Low** | 경미한 이슈, 비즈니스 영향 없음 | 개별 사용자 | 8시간 | 다음 영업일 | 해결 시 |\n\n#### 📘 플레이북 필수 구성 요소\n\n```yaml\n# PB-003_Security_Unauthorized_Access.yaml 예시 구조\n\nplaybook_id: PB-003\ntitle: \"비인가 접근 탐지 대응\"\nversion: 1.2\nlast_updated: 2024-01-15\nowner: Security Incident Response Team\n\ntrigger_conditions:\n  - GuardDuty Finding: UnauthorizedAccess:IAMUser/ConsoleLogin\n  - CloudTrail: ConsoleLogin from unusual location\n  - Security Hub: AWS Foundational Security Best Practices 위반\n\nimmediate_actions:\n  step_1:\n    action: \"의심 계정 즉시 비활성화\"\n    command: \"aws iam update-login-profile --user-name <USER> --password-reset-required\"\n    responsible: Security Engineer\n    time_limit: 5분\n    \n  step_2:\n    action: \"활성 세션 강제 종료\"\n    command: \"aws iam delete-login-profile --user-name <USER>\"\n    responsible: Security Engineer\n    time_limit: 10분\n\ninvestigation_steps:\n  - CloudTrail 로그에서 해당 IAM User의 최근 24시간 활동 조회\n  - 생성된 리소스, 변경된 IAM 정책 식별\n  - 영향받은 데이터 범위 파악\n\ncustomer_notification:\n  initial: \"보안 인시던트 탐지 후 30분 이내\"\n  template: \"SEC-NOTIF-001\"\n  \nescalation:\n  - condition: \"데이터 유출 확인\"\n    escalate_to: \"CISO, Legal Team\"\n    action: \"데이터 침해 대응 플레이북(PB-005) 활성화\"\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 인시던트 데이터 수집 및 분석 (1주)\n\n**담당자**: Operations Manager + Security Lead\n\n```bash\n# AWS Systems Manager Incident Manager에서 최근 6개월 인시던트 추출\naws ssm-incidents list-incident-records \\\n  --filters '[{\"key\":\"creationTime\",\"condition\":{\"after\":\"2024-07-01T00:00:00Z\"}}]' \\\n  --output json > incident_history.json\n\n# 인시던트 유형별 분류 분석\njq '.incidentRecordSummaries | group_by(.impact) | map({impact: .[0].impact, count: length})' incident_history.json\n```\n\n**산출물**: 인시던트 유형별 통계, 평균 해결 시간(MTTR), 재발률 분석 보고서\n\n### Step 2: IT/보안 인시던트 분류 체계 정의 (3일)\n\n**담당자**: Technical Architect + Security Architect\n\n| 구분 | IT 인시던트 예시 | 보안 인시던트 예시 |\n|------|-----------------|-------------------|\n| **탐지 소스** | CloudWatch Alarms, Health Dashboard | GuardDuty, Security Hub, WAF |\n| **1차 대응팀** | Cloud Operations Team | Security Incident Response Team |\n| **에스컬레이션** | Service Delivery Manager | CISO → Legal (필요시) |\n| **고객 통지 기준** | SLA 기반 | 즉시 (데이터 관련 시) |\n\n### Step 3: 플레이북 작성 (2주)\n\n**담당자**: Senior Engineers (각 도메인별)\n\n**최소 필수 플레이북 목록**:\n\n```\nIT 인시던트 플레이북:\n├── EC2 인스턴스 장애 대응\n├── RDS 연결 문제 대응\n├── ELB 헬스체크 실패 대응\n├── Lambda 함수 오류 급증 대응\n└── 네트워크 연결 장애 대응\n\n보안 인시던트 플레이북:\n├── 비인가 접근 탐지 대응\n├── 악성코드 감염 대응\n├── DDoS 공격 대응\n├── 데이터 유출 대응\n└── IAM 자격증명 유출 대응\n```\n\n### Step 4: 고객 커뮤니케이션 프로세스 정의 (3일)\n\n**담당자**: Customer Success Manager\n\n```markdown\n## 인시던트 통지 이메일 템플릿 (P1 Critical)\n\nSubject: [URGENT] Service Incident - {Incident_ID} - {Customer_Name}\n\nDear {Customer_Contact},\n\nWe are writing to inform you of a service incident affecting your AWS environment.\n\n**Incident Details:**\n- Incident ID: {Incident_ID}\n- Severity: P1 - Critical\n- Start Time: {Start_Time} (KST)\n- Affected Services: {Service_List}\n- Current Status: {Status}\n\n**Impact:**\n{Impact_Description}\n\n**Actions Taken:**\n{Actions_List}\n\n**Next Update:**\nWe will provide the next status update by {Next_Update_Time} or sooner if there are significant developments.\n\n**Contact:**\nIncident Commander: {IC_Name} ({IC_Phone})\n\nBest regards,\n{Company_Name} Cloud Operations Team\n```\n\n### Step 5: 인시던트 관리 도구 설정 (1주)\n\n**담당자**: DevOps Engineer\n\n```terraform\n# AWS Systems Manager Incident Manager 설정\nresource \"aws_ssmincidents_response_plan\" \"msp_incident_plan\" {\n  name = \"MSP-Standard-Response-Plan\"\n  \n  incident_template {\n    title         = \"Incident: {{$.incident.title}}\"\n    impact        = \"{{$.incident.impact}}\"\n    \n    notification_target {\n      sns_topic_arn = aws_sns_topic.incident_notifications.arn\n    }\n  }\n  \n  action {\n    ssm_automation {\n      document_name = \"AWS-GatherCloudWatchLogs\"\n      role_arn      = aws_iam_role.incident_automation.arn\n      target_account = \"RESPONSE_PLAN_OWNER_ACCOUNT\"\n    }\n  }\n  \n  engagement {\n    contact_arn = aws_ssmcontacts_contact.on_call_engineer.arn\n  }\n}\n```\n\n### Step 6: Post-Incident Review 프로세스 수립 (2일)\n\n**담당자**: Operations Manager\n\n```markdown\n## Post-Incident Review (PIR) 템플릿\n\n### 인시던트 개요\n- 인시던트 ID: INC-2024-0142\n- 발생 일시: 2024-01-15 14:32 KST\n- 해결 일시: 2024-01-15 16:45 KST\n- 총 영향 시간: 2시간 13분\n- 영향받은 고객: 3개사\n\n### 타임라인\n| 시간 | 이벤트 | 조치 |\n|------|--------|------|\n| 14:32 | CloudWatch Alarm 발생 | 자동 PagerDuty 호출 |\n| 14:37 | 온콜 엔지니어 응답 | 초기 조사 시작 |\n| 14:45 | P1 선언 | 고객 통지 발송 |\n| ... | ... | ... |\n\n### Root Cause Analysis\n**직접 원인**: RDS 인스턴스의 스토리지 IOPS 한도 도달\n**근본 원인**: 월말 배치 작업 증가에 대한 용량 계획 미흡\n\n### 개선 조치 (Action Items)\n| ID | 조치 내용 | 담당자 | 기한 | 상태 |\n|----|----------|--------|------|------|\n| AI-001 | RDS IOPS 모니터링 임계값 조정 | DBA | 01/20 | 완료 |\n| AI-002 | 월말 배치 작업 용량 계획 프로세스 수립 | Ops | 01/31 | 진행중 |",
      "language": "ko",
      "createdAt": "2026-01-07T01:36:28.165Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-002",
      "category": "Operations",
      "title": "문제 관리",
      "advice": "# OPSP-002: 문제 관리 (Post-Incident Analysis) 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n문제 관리(Problem Management)는 **인시던트 관리(Incident Management)와 명확히 구분**됩니다. 인시던트 관리가 \"불 끄기\"라면, 문제 관리는 **\"왜 불이 났는지 분석하고 다시 불이 나지 않게 하는 것\"**입니다. AWS는 MSP 파트너가 단순히 장애를 해결하는 것을 넘어, **근본 원인을 제거하여 고객 환경의 지속적인 안정성을 보장**할 수 있는지 평가합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **Root Cause Analysis 깊이** | 표면적 원인이 아닌 진짜 기여 원인(Contributing Factors)까지 파고들었는가? |\n| **5 Whys 또는 Fishbone 적용** | 체계적인 분석 방법론을 사용했는가? |\n| **Action Items의 구체성** | 실행 계획이 담당자, 기한, 완료 기준을 포함하는가? |\n| **고객 커뮤니케이션 품질** | 기술적 내용을 고객이 이해할 수 있게 전달했는가? |\n| **Lessons Learned 반영** | 분석 결과가 실제로 프로세스/아키텍처 개선으로 이어졌는가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n📊 분석 도구\n├── AWS CloudTrail - API 호출 추적으로 변경 이력 분석\n├── Amazon CloudWatch Logs Insights - 로그 기반 타임라인 구성\n├── AWS X-Ray - 분산 시스템 트레이싱\n├── Amazon Detective - 보안 인시던트 근본 원인 분석\n└── AWS Systems Manager OpsCenter - OpsItem으로 문제 추적\n\n📝 문서화/협업\n├── AWS Systems Manager Incident Manager - Post-Incident Analysis 기능 내장\n└── Amazon Q in Connect - 인시던트 패턴 분석\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 구성\n\n```\n📁 OPSP-002_Problem_Management_Evidence/\n│\n├── 📄 PIR_Report_[CustomerCode]_[YYYYMMDD].pdf\n│   └── 완성된 Post-Incident Review 보고서 (최소 2건)\n│\n├── 📄 Customer_Communication_[CustomerCode]_[YYYYMMDD].pdf\n│   └── 고객에게 발송한 실제 커뮤니케이션 (이메일, 보고서)\n│\n├── 📄 Action_Plan_Tracking_[CustomerCode].xlsx\n│   └── 실행 계획 및 완료 추적 현황\n│\n└── 📄 Problem_Management_Process.pdf\n    └── 문제 관리 프로세스 정의 문서\n```\n\n### 📄 Post-Incident Review 보고서 필수 포함 내용\n\n```markdown\n## PIR 보고서 필수 섹션 (감사 통과 기준)\n\n### 1. Executive Summary (경영진 요약)\n- 인시던트 개요 (1-2문장)\n- 영향 범위 및 비즈니스 임팩트\n- 핵심 개선 조치 요약\n\n### 2. Incident Timeline (타임라인)\n- 최초 감지 시점\n- 에스컬레이션 시점\n- 주요 조치 시점\n- 해결 완료 시점\n- 고객 통보 시점\n\n### 3. Impact Analysis (영향 분석)\n- 영향받은 서비스/리소스\n- 영향받은 사용자 수\n- 다운타임 또는 성능 저하 기간\n- 비즈니스 손실 추정 (가능한 경우)\n\n### 4. Root Cause Analysis (근본 원인 분석)\n- 5 Whys 분석 결과\n- Contributing Factors (기여 요인들)\n- 근본 원인 명시\n\n### 5. Action Items (실행 계획)\n- 즉시 조치 (Immediate)\n- 단기 개선 (Short-term, 1-2주)\n- 장기 개선 (Long-term, 1-3개월)\n- 각 항목별: 담당자, 기한, 완료 기준, 상태\n\n### 6. Lessons Learned (교훈)\n- 잘된 점 (What went well)\n- 개선할 점 (What could be improved)\n- 프로세스/도구 개선 권고\n```\n\n### 📧 고객 커뮤니케이션 예시\n\n**파일명:** `Customer_RCA_Report_ABC_20240115.pdf`\n\n```\n[실제 고객에게 발송한 형태로 준비]\n\n제목: [ABC Corp] 1월 15일 서비스 장애 분석 보고서\n\n존경하는 ABC Corp 담당자님께,\n\n1월 15일 발생한 서비스 장애에 대한 상세 분석 결과를 \n공유드립니다.\n\n■ 장애 요약\n- 발생 시간: 2024년 1월 15일 14:23 ~ 15:47 (84분)\n- 영향 범위: 웹 애플리케이션 응답 지연 (평균 응답시간 8초)\n- 영향 사용자: 약 2,300명\n\n■ 원인 분석\n근본 원인: RDS 인스턴스의 스토리지 IOPS 한도 도달\n기여 요인: \n  1) 배치 작업 스케줄 변경으로 인한 동시 실행\n  2) 스토리지 Auto Scaling 미설정\n\n■ 재발 방지 조치\n1. [완료] RDS 스토리지 Auto Scaling 활성화\n2. [진행중] 배치 작업 스케줄 분산 (1/20 완료 예정)\n3. [계획] CloudWatch 알람 임계값 조정 (1/25 완료 예정)\n\n문의사항이 있으시면 언제든 연락 주시기 바랍니다.\n\n감사합니다.\n[MSP 회사명] 클라우드 운영팀\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 분석 대상 인시던트 선정 (1일)\n\n```\n🎯 선정 기준\n├── 고객 영향이 있었던 실제 인시던트\n├── 최근 6개월 이내 발생\n├── 근본 원인 분석이 완료된 건\n└── 실행 계획이 이행된 건 (일부라도)\n\n⚠️ 주의: 가상의 시나리오는 감사에서 인정되지 않음\n```\n\n**담당:** 운영팀 리드 / **도구:** ITSM 시스템, AWS Systems Manager OpsCenter\n\n### Step 2: 5 Whys 분석 수행 (2-3일)\n\n```\n📊 실제 5 Whys 분석 예시\n\n인시던트: EC2 인스턴스 응답 없음\n\nWhy 1: 왜 EC2가 응답하지 않았나?\n→ CPU 사용률 100% 도달\n\nWhy 2: 왜 CPU가 100%에 도달했나?\n→ 메모리 부족으로 스왑 발생\n\nWhy 3: 왜 메모리가 부족했나?\n→ Java 힙 메모리 누수\n\nWhy 4: 왜 메모리 누수가 발생했나?\n→ 새 배포 버전의 커넥션 풀 미반환 버그\n\nWhy 5: 왜 배포 전 발견하지 못했나?\n→ 스테이징 환경 부하 테스트 미수행\n\n🎯 근본 원인: 배포 프로세스에 부하 테스트 단계 누락\n```\n\n**담당:** 기술 리드, SRE 엔지니어 / **도구:** CloudWatch Logs Insights, X-Ray\n\n### Step 3: Contributing Factors 식별 (1-2일)\n\n```\n🔍 기여 요인 분류 프레임워크\n\n┌─────────────────────────────────────────────────────┐\n│                    인시던트                          │\n├──────────┬──────────┬──────────┬──────────────────┤\n│  People  │ Process  │Technology│   Environment    │\n├──────────┼──────────┼──────────┼──────────────────┤\n│온콜 담당자│변경관리  │모니터링  │AWS 리전 이슈     │\n│교육 부족  │미준수    │알람 누락 │네트워크 지연     │\n│인수인계  │문서화    │용량 부족 │서드파티 장애     │\n│미흡      │부재      │          │                  │\n└──────────┴──────────┴──────────┴──────────────────┘\n```\n\n**담당:** 운영팀 전체 (브레인스토밍) / **도구:** Miro, Confluence\n\n### Step 4: 실행 계획 수립 (1일)\n\n```\n📋 Action Item 템플릿 (감사 통과 기준)\n\n┌────────────────────────────────────────────────────────────┐\n│ Action Item #1                                              │\n├─────────────┬──────────────────────────────────────────────┤\n│ 조치 내용    │ RDS Performance Insights 활성화 및           │\n│             │ 알람 설정                                     │\n├─────────────┼──────────────────────────────────────────────┤\n│ 유형        │ ☑ Immediate  ☐ Short-term  ☐ Long-term      │\n├─────────────┼──────────────────────────────────────────────┤\n│ 담당자      │ 김철수 (DBA)                                  │\n├─────────────┼──────────────────────────────────────────────┤\n│ 기한        │ 2024-01-20                                    │\n├─────────────┼──────────────────────────────────────────────┤\n│ 완료 기준   │ Performance Insights 대시보드 생성 및         │\n│             │ CPU/메모리 알람 SNS 연동 완료                 │\n├─────────────┼──────────────────────────────────────────────┤\n│ 상태        │ ✅ 완료 (2024-01-18)                         │\n├─────────────┼──────────────────────────────────────────────┤\n│ 완료 증빙   │ CloudWatch 알람 스크린샷, SNS 구독 확인      │\n└─────────────┴──────────────────────────────────────────────┘\n```\n\n**담당:** 운영팀 리드 / **도구:** Jira, ServiceNow, Excel\n\n### Step 5: 고객 커뮤니케이션 작성 (1일)\n\n```\n📧 고객 커뮤니케이션 작성 원칙\n\n✅ DO:\n- 비기술적 언어로 영향 설명\n- 구체적인 재발 방지 조치 명시\n- 조치 완료 일정 제공\n- 연락처 및 후속 미팅 제안\n\n❌ DON'T:\n- 책임 회피성 표현\n- 과도한 기술 용어\n- 모호한 일정 (\"빠른 시일 내\")\n- 고객 잘못 암시\n```\n\n**담당:** 고객 담당 매니저 + 기술 리드 / **도구:** 이메일, 고객 포털\n\n### Step 6: 실행 계획 이행 추적 (지속)\n\n```\n📊 Action Plan Tracking 스프레드시트 구조\n\n| ID | Action Item | Type | Owner | Due Date | Status | Completion Date | Evidence |\n|----|-------------|------|-------|----------|--------|-----------------|----------|\n| A1 | RDS PI 활성화 | Immediate | 김철수 | 01/20 | ✅ Done | 01/18 | [링크] |\n| A2 | 배치 스케줄 분산 | Short-term | 이영희 | 01/25 | 🔄 In Progress | - | - |\n| A3 | 부하테스트 파이프라인 | Long-term | 박민수 | 02/28 | ⏳ Planned | - | - |\n```\n\n**담당:** 프로젝트 매니저 / **도구:** Jira, Confluence, Excel\n\n### Step 7: 증빙 패키지 구성 (1일)\n\n```\n📁 최종 증빙 패키지 구성\n\nOPSP-002_Evidence/\n├── 01_Process_Document/\n│   └── Problem_Management_Process_v2.1.pdf\n│\n├── 02_PIR_Report_Case1/\n│   ├── PIR_Report_CustomerA_20240115.pdf\n│   ├── Timeline_Analysis.xlsx\n│   ├── 5Whys_Analysis.pdf\n│   └── Action_Plan_Tracking.xlsx\n│\n├── 03_PIR_Report_Case2/\n│   ├── PIR_Report_CustomerB_20240203.pdf\n│   ├── RCA_Fishbone_Diagram.pdf\n│   └── Action_Plan_Tracking.xlsx\n│\n├── 04_Customer_Communications/\n│   ├── Email_CustomerA_20240116.pdf\n│   ├── Email_CustomerA_20240125_Closure.pdf\n│   ├── Email_Customer",
      "language": "ko",
      "createdAt": "2026-01-07T01:37:32.658Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-003",
      "category": "Operations",
      "title": "배포 위험 관리",
      "advice": "# OPSP-003: 배포 위험 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\n배포 위험 관리는 AWS MSP의 **운영 성숙도를 직접적으로 보여주는 핵심 지표**입니다. 고객의 프로덕션 환경을 관리하는 MSP가 \"배포했는데 문제가 생기면 롤백합니다\" 수준의 대응만 한다면, 이는 고객 비즈니스에 심각한 영향을 줄 수 있습니다. AWS는 MSP 파트너가 **사전에 위험을 제한하는 배포 전략**을 구현할 수 있는지 검증합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 의도 |\n|------------|-------------------|\n| **점진적 노출 전략** | 전체 사용자에게 한 번에 배포하지 않고, 단계적으로 트래픽을 이동시키는 메커니즘이 있는가? |\n| **자동 롤백 조건** | 배포 실패 시 수동 개입 없이 자동으로 이전 버전으로 복구되는가? |\n| **배포 전 검증 단계** | 프로덕션 배포 전 스테이징/카나리 환경에서 충분한 검증이 이루어지는가? |\n| **모니터링 연계** | 배포 중 실시간 메트릭을 기반으로 진행/중단 결정이 내려지는가? |\n| **실제 적용 사례** | 문서만 있는 것이 아니라, 실제 고객 환경에서 사용된 증거가 있는가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    배포 위험 관리 도구                        │\n├─────────────────────────────────────────────────────────────┤\n│  CodeDeploy          → Blue/Green, Canary, Linear 배포      │\n│  ECS/EKS             → Rolling Update, Blue/Green 배포      │\n│  CloudFormation      → Change Sets, Stack Rollback          │\n│  Elastic Beanstalk   → Immutable, Traffic Splitting         │\n│  API Gateway         → Canary Release                       │\n│  Route 53            → Weighted Routing (트래픽 분산)        │\n│  CloudWatch          → 배포 중 메트릭 모니터링               │\n│  Lambda              → Alias + Weighted Traffic             │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 문서 목록\n\n#### 📄 문서 1: 배포 전략 표준 가이드\n**파일명 예시:** `Deployment-Risk-Management-Standard-v2.3.pdf`\n\n```yaml\n필수 포함 내용:\n  섹션_1_배포_유형_정의:\n    - Blue/Green 배포 적용 기준 및 절차\n    - Canary 배포 적용 기준 (트래픽 비율, 관찰 시간)\n    - Rolling 배포 적용 기준 및 배치 크기 결정 로직\n    - Immutable 배포 적용 시나리오\n    \n  섹션_2_위험_등급_분류:\n    - High Risk: 데이터베이스 스키마 변경, 핵심 API 수정\n    - Medium Risk: 신규 기능 추가, 의존성 업데이트\n    - Low Risk: UI 변경, 설정 값 수정\n    - 각 등급별 필수 배포 전략 매핑\n    \n  섹션_3_롤백_조건:\n    - 자동 롤백 트리거 메트릭 (에러율 > 5%, 레이턴시 > 2초 등)\n    - 수동 롤백 결정 기준\n    - 롤백 실행 절차 및 책임자\n```\n\n#### 📄 문서 2: 배포 파이프라인 아키텍처 다이어그램\n**파일명 예시:** `Production-Deployment-Pipeline-Architecture.png`\n\n```\n[반드시 포함해야 할 요소]\n\n┌──────────┐    ┌──────────┐    ┌──────────────┐    ┌─────────────┐\n│  Source  │───▶│  Build   │───▶│   Staging    │───▶│  Canary     │\n│  (Git)   │    │  (Test)  │    │  Validation  │    │  (10% 트래픽)│\n└──────────┘    └──────────┘    └──────────────┘    └──────┬──────┘\n                                                           │\n                                      ┌────────────────────┤\n                                      ▼                    ▼\n                               ┌─────────────┐      ┌─────────────┐\n                               │  Rollback   │◀─────│  Full       │\n                               │  (자동/수동) │      │  Production │\n                               └─────────────┘      └─────────────┘\n                                      ▲\n                                      │\n                               ┌─────────────┐\n                               │ CloudWatch  │\n                               │ Alarms      │\n                               └─────────────┘\n```\n\n#### 📄 문서 3: 실제 배포 실행 기록\n**파일명 예시:** `Customer-ABC-BlueGreen-Deployment-Record-2024Q1.pdf`\n\n```yaml\n필수 포함 내용:\n  배포_개요:\n    고객명: \"[실제 고객명 또는 익명화된 ID]\"\n    배포_일시: \"2024-02-15 14:00 KST\"\n    배포_유형: \"Blue/Green\"\n    변경_내용: \"결제 API v2.3.1 → v2.4.0 업그레이드\"\n    \n  위험_평가:\n    위험_등급: \"High\"\n    선택_근거: \"핵심 결제 로직 변경으로 Blue/Green 필수 적용\"\n    \n  배포_단계_기록:\n    - \"14:00 - Green 환경 생성 시작\"\n    - \"14:15 - Green 환경 헬스체크 통과\"\n    - \"14:20 - 10% 트래픽 Green으로 전환\"\n    - \"14:35 - 메트릭 정상 확인, 50% 트래픽 전환\"\n    - \"14:50 - 100% 트래픽 전환 완료\"\n    - \"15:20 - Blue 환경 종료\"\n    \n  모니터링_증거:\n    - CloudWatch 대시보드 스크린샷\n    - 에러율/레이턴시 그래프\n    - 롤백 조건 미충족 확인 기록\n```\n\n#### 📄 문서 4: CodeDeploy/ECS 배포 설정 파일\n**파일명 예시:** `appspec-bluegreen-config.yml`, `ecs-service-definition.json`\n\n```yaml\n# appspec.yml 예시 (Blue/Green with Hooks)\nversion: 0.0\nResources:\n  - TargetService:\n      Type: AWS::ECS::Service\n      Properties:\n        TaskDefinition: \"arn:aws:ecs:ap-northeast-2:123456789:task-definition/my-app:10\"\n        LoadBalancerInfo:\n          ContainerName: \"my-app\"\n          ContainerPort: 8080\n        PlatformVersion: \"LATEST\"\n\nHooks:\n  - BeforeInstall: \"LambdaFunctionToValidateBeforeInstall\"\n  - AfterInstall: \"LambdaFunctionToValidateAfterInstall\"\n  - AfterAllowTestTraffic: \"LambdaFunctionToValidateTestTraffic\"\n  - BeforeAllowTraffic: \"LambdaFunctionToValidateBeforeTraffic\"\n  - AfterAllowTraffic: \"LambdaFunctionToValidateAfterTraffic\"\n```\n\n```json\n// CodeDeploy 배포 그룹 설정 예시\n{\n  \"deploymentConfigName\": \"CodeDeployDefault.ECSCanary10Percent5Minutes\",\n  \"blueGreenDeploymentConfiguration\": {\n    \"terminateBlueInstancesOnDeploymentSuccess\": {\n      \"action\": \"TERMINATE\",\n      \"terminationWaitTimeInMinutes\": 60\n    },\n    \"deploymentReadyOption\": {\n      \"actionOnTimeout\": \"CONTINUE_DEPLOYMENT\",\n      \"waitTimeInMinutes\": 0\n    }\n  },\n  \"autoRollbackConfiguration\": {\n    \"enabled\": true,\n    \"events\": [\"DEPLOYMENT_FAILURE\", \"DEPLOYMENT_STOP_ON_ALARM\"]\n  },\n  \"alarmConfiguration\": {\n    \"enabled\": true,\n    \"alarms\": [\n      {\"name\": \"HighErrorRate-Alarm\"},\n      {\"name\": \"HighLatency-Alarm\"}\n    ]\n  }\n}\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 배포 방식 인벤토리 작성 (2-3일)\n\n**담당:** DevOps 엔지니어\n\n```bash\n# 현재 사용 중인 배포 서비스 확인\naws deploy list-applications\naws ecs list-services --cluster production-cluster\naws elasticbeanstalk describe-environments\n\n# 각 서비스의 배포 설정 확인\naws deploy get-deployment-config --deployment-config-name CodeDeployDefault.ECSCanary10Percent5Minutes\n```\n\n**산출물:** 서비스별 현재 배포 방식 매트릭스\n| 서비스 | 현재 방식 | 목표 방식 | 갭 |\n|--------|----------|----------|-----|\n| 결제 API | Rolling | Blue/Green | 구현 필요 |\n| 웹 프론트엔드 | 수동 배포 | Canary | 파이프라인 구축 필요 |\n\n---\n\n### Step 2: 배포 전략 표준 문서 작성 (3-4일)\n\n**담당:** 솔루션 아키텍트 + DevOps 리드\n\n**핵심 작성 내용:**\n\n```markdown\n## 배포 전략 선택 기준표\n\n| 변경 유형 | 위험 등급 | 권장 전략 | 최소 관찰 시간 |\n|-----------|----------|----------|---------------|\n| DB 스키마 변경 | Critical | Blue/Green + 수동 승인 | 2시간 |\n| 핵심 비즈니스 로직 | High | Blue/Green | 1시간 |\n| 신규 기능 추가 | Medium | Canary (10%→50%→100%) | 30분씩 |\n| 설정 변경 | Low | Rolling (25% 배치) | 10분 |\n| 핫픽스 | Variable | 위험 평가 후 결정 | - |\n\n## 자동 롤백 트리거 조건\n\nCloudWatch Alarm 기반 자동 롤백:\n- HTTP 5xx 에러율 > 5% (5분 평균)\n- P99 레이턴시 > 3초 (5분 평균)  \n- 헬스체크 실패 > 3회 연속\n- CPU 사용률 > 90% (10분 평균)\n```\n\n---\n\n### Step 3: 파이프라인 구현 및 설정 (5-7일)\n\n**담당:** DevOps 엔지니어\n\n**CodeDeploy Blue/Green 설정 (ECS 기준):**\n\n```bash\n# 1. 배포 그룹 생성\naws deploy create-deployment-group \\\n  --application-name MyApp \\\n  --deployment-group-name MyApp-Production-BlueGreen \\\n  --service-role-arn arn:aws:iam::123456789:role/CodeDeployServiceRole \\\n  --deployment-config-name CodeDeployDefault.ECSCanary10Percent15Minutes \\\n  --ecs-services clusterName=production,serviceName=my-service \\\n  --load-balancer-info targetGroupPairInfoList=[{targetGroups=[{name=tg-blue},{name=tg-green}],prodTrafficRoute={listenerArns=[arn:aws:elasticloadbalancing:...]}}] \\\n  --blue-green-deployment-configuration \"terminateBlueInstancesOnDeploymentSuccess={action=TERMINATE,terminationWaitTimeInMinutes=60},deploymentReadyOption={actionOnTimeout=CONTINUE_DEPLOYMENT}\" \\\n  --auto-rollback-configuration enabled=true,events=DEPLOYMENT_FAILURE,DEPLOYMENT_STOP_ON_ALARM \\\n  --alarm-configuration enabled=true,alarms=[{name=HighErrorRate},{name=HighLatency}]\n```\n\n**CloudWatch Alarm 설정:**\n\n```bash\n# 에러율 알람 생성\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"HighErrorRate-Production\" \\\n  --alarm-description \"5xx error rate exceeds 5%\" \\\n  --metric-name \"HTTPCode_Target_5XX_Count\" \\\n  --namespace \"AWS/ApplicationELB\" \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 50 \\\n  --comparison-operator GreaterThanThreshold \\\n  --dimensions Name=LoadBalancer,Value=app/my-alb/xxx \\\n  --evaluation-periods 1 \\\n  --treat-missing-data notBreaching\n```\n\n---\n\n### Step 4: 테스트 배포 실행 및 기록 (3-4일)\n\n**담당:** DevOps 엔지니어 + QA\n\n**실행 체크리스트:**\n\n```markdown\n□ 스테이징 환경에서 Blue/Green 배포 테스트\n  - 정상 배포 시나리오 검증\n  - 의도적 실패 → 자동 롤백 검증\n  \n□ Canary 배포 테스트  \n  - 10% → 50% → 100% 트래픽 전환 확인\n  - 각 단계에서 메트릭 수집 확인\n  \n□ 롤백 테",
      "language": "ko",
      "createdAt": "2026-01-07T01:38:25.650Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-004_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-004",
      "category": "Operations",
      "title": "클라우드 재무 관리",
      "advice": "# OPSP-004: 클라우드 재무 관리 (Cloud Financial Management)\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n클라우드 재무 관리(FinOps)는 MSP의 **핵심 부가가치**입니다. AWS는 고객이 단순히 인프라를 운영하는 것을 넘어, **지속적인 비용 최적화를 통해 ROI를 극대화**하는 파트너를 원합니다. 이 항목은 MSP가 \"관리형 서비스\"의 본질인 **proactive한 비용 관리 역량**을 갖추고 있는지 검증합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **정기성 (Regularity)** | 일회성이 아닌 월간/분기별 정기 리뷰가 프로세스화되어 있는가? |\n| **구체적 권장사항** | \"비용을 줄이세요\"가 아닌 특정 리소스/서비스에 대한 actionable한 권장사항인가? |\n| **고객 전달 증빙** | 내부 분석이 아닌 실제 고객에게 전달된 문서가 있는가? |\n| **절감 효과 추적** | 권장사항 이행 후 실제 절감 효과를 측정하고 있는가? |\n| **AWS 도구 활용** | Cost Explorer, Trusted Advisor, Compute Optimizer 등 AWS 네이티브 도구를 활용하는가? |\n\n### 관련 AWS 서비스 및 기능\n\n```\n💰 비용 분석: AWS Cost Explorer, AWS Cost and Usage Report (CUR)\n📊 최적화 도구: AWS Compute Optimizer, Trusted Advisor, Savings Plans\n🏷️ 비용 할당: Cost Allocation Tags, AWS Organizations\n📈 예산 관리: AWS Budgets, Anomaly Detection\n🔍 리소스 분석: AWS Resource Explorer, Rightsizing Recommendations\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### A. 월간 비용 최적화 보고서 (Monthly Cost Optimization Report)\n```\n📄 파일명 예시: \"ABC고객_AWS_월간비용최적화보고서_2024년11월.pdf\"\n```\n\n**포함되어야 할 핵심 내용:**\n- 당월 총 AWS 비용 및 전월 대비 변화율\n- 서비스별/계정별 비용 breakdown\n- Top 5 비용 증가 항목 분석\n- **구체적 최적화 권장사항 3개 이상** (아래 예시 참조)\n- 예상 월간 절감액 (달러 또는 퍼센트)\n- 고객 전달 일자 및 수신자 정보\n\n**권장사항 예시 (감사 통과 수준):**\n```\n❌ 나쁜 예: \"EC2 인스턴스를 최적화하세요\"\n✅ 좋은 예: \"prod-web-server-01 (m5.2xlarge)의 평균 CPU 사용률이 \n           12%입니다. m5.large로 다운사이징 시 월 $156 절감 예상.\n           Compute Optimizer 권장사항 기반.\"\n```\n\n#### B. Savings Plans / Reserved Instance 분석 보고서\n```\n📄 파일명 예시: \"XYZ고객_SavingsPlans_구매권장_2024Q4.xlsx\"\n```\n\n**포함 내용:**\n- 현재 On-Demand 대비 커버리지 비율\n- 권장 Savings Plans 유형 및 commitment 금액\n- 1년/3년 옵션별 예상 절감액 시뮬레이션\n- 구매 시점 권장 및 근거\n\n#### C. 고객 전달 증빙 (이메일 또는 미팅 기록)\n```\n📄 파일명 예시: \"DEF고객_비용리뷰미팅_회의록_20241115.pdf\"\n```\n\n**포함 내용:**\n- 미팅 일시, 참석자 (고객측 + MSP측)\n- 논의된 권장사항 목록\n- 고객의 의사결정 또는 피드백\n- 후속 조치 사항\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: Cost and Usage Report (CUR) 설정 확인 (Day 1-2)\n```bash\n# CUR이 S3에 정상 적재되는지 확인\naws cur describe-report-definitions --region us-east-1\n\n# Athena 테이블 생성 여부 확인 (CUR 쿼리용)\n```\n- **담당자:** 클라우드 엔지니어\n- **산출물:** CUR 설정 스크린샷, Athena 쿼리 예시\n\n### Step 2: 비용 최적화 분석 수행 (Day 3-5)\n```sql\n-- Athena에서 미사용 EBS 볼륨 찾기\nSELECT line_item_resource_id, \n       SUM(line_item_unblended_cost) as monthly_cost\nFROM cur_database.cur_table\nWHERE line_item_product_code = 'AmazonEC2'\n  AND line_item_usage_type LIKE '%EBS:VolumeUsage%'\n  AND line_item_resource_id NOT IN (\n    SELECT volume_id FROM attached_volumes\n  )\nGROUP BY line_item_resource_id\nORDER BY monthly_cost DESC;\n```\n\n**활용 도구:**\n| 분석 영역 | AWS 도구 | 확인 항목 |\n|----------|----------|----------|\n| EC2 Rightsizing | Compute Optimizer | 과다 프로비저닝 인스턴스 |\n| 미사용 리소스 | Trusted Advisor | Idle ELB, 미연결 EIP |\n| 예약 커버리지 | Cost Explorer | SP/RI 커버리지 갭 |\n| 스토리지 최적화 | S3 Storage Lens | 비효율적 스토리지 클래스 |\n\n### Step 3: 권장사항 문서화 (Day 6-7)\n```markdown\n## 권장사항 #1: EC2 Rightsizing\n\n| 항목 | 내용 |\n|------|------|\n| 대상 리소스 | i-0abc123def456 (prod-api-server) |\n| 현재 사양 | m5.4xlarge (16 vCPU, 64GB) |\n| 권장 사양 | m5.xlarge (4 vCPU, 16GB) |\n| 근거 | 최근 30일 평균 CPU 8%, Memory 22% |\n| 예상 절감 | $412/월 (67% 절감) |\n| 리스크 | Low - 피크 시간에도 40% 미만 사용률 |\n| 구현 방법 | 점검 시간에 인스턴스 타입 변경 |\n```\n\n### Step 4: 고객 리뷰 미팅 진행 (Day 8)\n- **소요 시간:** 30-60분\n- **참석자:** 고객 IT 담당자, 재무 담당자, MSP 클라우드 아키텍트\n- **아젠다:**\n  1. 전월 비용 트렌드 리뷰 (10분)\n  2. 최적화 권장사항 설명 (20분)\n  3. 우선순위 및 실행 계획 합의 (15분)\n  4. Q&A (15분)\n\n### Step 5: 전달 증빙 확보 (Day 8-9)\n```\n✉️ 이메일 전송 시 포함할 내용:\n- 첨부: 월간 비용 최적화 보고서 PDF\n- 본문: 주요 권장사항 요약 3줄\n- 수신: 고객 담당자 (CC: 고객 매니저)\n- 제목: \"[ABC고객] 2024년 11월 AWS 비용 최적화 보고서\"\n```\n\n### Step 6: 이행 추적 및 효과 측정 (Ongoing)\n```\n📊 권장사항 이행 추적 스프레드시트:\n| 권장사항 | 제안일 | 고객승인 | 이행일 | 예상절감 | 실제절감 |\n|----------|--------|----------|--------|----------|----------|\n| EC2 RS   | 11/15  | 11/20    | 12/01  | $412     | $398     |\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n#### 실수 #1: 내부 분석 문서만 제출\n```\n❌ 문제: \"비용 분석은 했는데 고객에게 전달한 기록이 없어요\"\n✅ 해결: 반드시 이메일 발송 기록, 미팅 회의록, 또는 티켓 시스템 기록 포함\n        → 고객 수신 확인이 가능한 증빙 필수\n```\n\n#### 실수 #2: 일반적인 권장사항만 나열\n```\n❌ 문제: \"Reserved Instance를 구매하세요\" (구체성 부족)\n✅ 해결: \"us-east-1에서 m5.xlarge Linux 인스턴스 10대에 대해 \n        1년 No Upfront Compute Savings Plan 구매 시 \n        연간 $18,240 절감 (현재 커버리지 23% → 85%)\"\n```\n\n#### 실수 #3: 단발성 보고서 제출\n```\n❌ 문제: 감사 직전에 만든 1회성 보고서\n✅ 해결: 최소 3개월 연속 보고서 제출 (정기성 증명)\n        → 10월, 11월, 12월 보고서 세트로 준비\n```\n\n#### 실수 #4: AWS 도구 미활용\n```\n❌ 문제: Excel로 수동 분석한 결과만 제출\n✅ 해결: Cost Explorer 스크린샷, Compute Optimizer 권장사항,\n        Trusted Advisor 체크 결과 등 AWS 네이티브 도구 출력물 포함\n```\n\n#### 실수 #5: 절감 효과 미추적\n```\n❌ 문제: 권장사항만 제시하고 이행 결과 없음\n✅ 해결: \"지난 분기 권장사항 이행 결과\" 섹션 추가\n        → 제안 vs 실제 절감액 비교 데이터 포함\n```\n\n### 감사 탈락 주요 원인\n\n| 탈락 사유 | 비율 | 예방 방법 |\n|----------|------|----------|\n| 고객 전달 증빙 부재 | 35% | 이메일 + 회의록 이중 확보 |\n| 정기성 미충족 | 25% | 월간 리포트 자동화 구축 |\n| 권장사항 구체성 부족 | 20% | 리소스 ID + 금액 명시 |\n| AWS 도구 미활용 | 15% | 네이티브 도구 스크린샷 포함 |\n| 단일 고객만 제출 | 5% | 최소 2-3개 고객 사례 준비 |\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | **고객 전달 증빙 존재** | 이메일 발송 기록 또는 미팅 회의록 확인 | 고객 수신자 이름/이메일 명시, 날짜 확인 가능 |\n| 2 | **정기성 증명** | 연속 3개월 이상 보고서 | 월간 또는 분기별 일정한 주기 |\n| 3 | **구체적 권장사항** | 각 권장사항에 리소스 ID 포함 여부 | 최소 3개 이상의 actionable 권장사항 |\n| 4 | **절감 금액 명시** | 달러 또는 퍼센트 수치 확인 | 각 권장사항별 예상 절감액 기재 |\n| 5 | **AWS 도구 활용 증빙** | Cost Explorer, Compute Optimizer 스크린샷 | 최소 2개 이상 AWS 네이티브 도구 출력물 |\n| 6 | **다중 고객 사례** | 2개 이상 고객 보고서 | 고객명 익명화 가능하나 구분 가능해야 함 |\n| 7 | **이행 추적 기록** | 과거 권장사항 이행 결과 | 제안 → 승인 → 이행 → 효과 측정 사이클 증빙 |\n\n### 품질 기준 자가 진단\n\n```\n📊 점수 계산 (각 항목 1점, 총 7점)\n\n7점: 🟢 감사 통과 확실\n5-6점: 🟡 보완 후 제출 권장  \n4점 이하: 🔴 재작업 필요\n```\n\n### 최종 제출 파일 구성 예시\n\n```\n📁 OPSP-004_클라우드재무관리_증빙/\n├── ",
      "language": "ko",
      "createdAt": "2026-01-07T01:39:23.914Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-005_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-005",
      "category": "Operations",
      "title": "서비스 연속성",
      "advice": "# OPSP-005: 서비스 연속성 - AWS MSP 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS MSP 파트너는 고객의 미션 크리티컬 워크로드를 관리합니다. **파트너 자체의 운영 중단**이 발생하면 수십~수백 개의 고객사가 동시에 영향을 받습니다. 이 항목은 \"고객 인프라의 DR\"이 아닌 **\"MSP 파트너 자체의 서비스 제공 능력 연속성\"**을 검증합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 의도 |\n|--------|-------------------|\n| **1. 대체 운영 능력** | \"본사 데이터센터/사무실이 불능 상태가 되면 어디서 고객을 지원하나요?\" |\n| **2. 핵심 도구 이중화** | \"모니터링 시스템, 티켓팅 시스템, 배포 파이프라인이 다운되면 대안이 있나요?\" |\n| **3. 인력 가용성** | \"핵심 엔지니어 3명이 동시에 불능 상태면 누가 대체하나요?\" |\n| **4. 실제 테스트 수행** | \"문서만 있는 게 아니라 실제로 대체 환경에서 운영해봤나요?\" |\n| **5. 복구 시간 측정** | \"테스트에서 실제 복구까지 얼마나 걸렸고, 목표 대비 어땠나요?\" |\n\n### 관련 AWS 서비스 및 기능\n\n```\nMSP 자체 인프라 연속성 관련:\n├── AWS Organizations (멀티 어카운트 관리 연속성)\n├── AWS Control Tower (랜딩존 관리 연속성)\n├── Amazon WorkSpaces (대체 작업 환경)\n├── AWS Client VPN (원격 접속 대안)\n├── AWS Backup (MSP 관리 도구 백업)\n├── Route 53 (DNS 페일오버)\n└── CloudWatch (모니터링 연속성)\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 📁 필수 증빙 자료 세트\n\n#### Option A: 자체 BCP 문서 + 테스트 결과 (권장)\n\n| 문서 | 파일명 예시 | 핵심 포함 내용 |\n|------|-------------|----------------|\n| **비즈니스 연속성 계획서** | `MSP-BCP-2024-v2.1.pdf` | 범위, RTO/RPO, 대체 운영 절차 |\n| **연속성 테스트 계획서** | `BCP-Test-Plan-2024Q3.pdf` | 테스트 시나리오, 참여자, 성공 기준 |\n| **테스트 실행 결과 보고서** | `BCP-Test-Results-20240815.pdf` | 실제 수행 내역, 측정값, 스크린샷 |\n| **개선 조치 추적표** | `BCP-Remediation-Tracker.xlsx` | 발견된 문제, 조치 상태, 완료일 |\n\n#### Option B: ISO 22301 인증서\n\n| 문서 | 요구사항 |\n|------|----------|\n| **ISO 22301 인증서** | AWS MSP 서비스 운영이 명시적으로 범위에 포함되어야 함 |\n| **인증 범위 명세서** | \"Managed Services for AWS Cloud Infrastructure\" 등 명시 |\n\n---\n\n### 📄 비즈니스 연속성 계획서 필수 섹션\n\n```markdown\n# MSP 서비스 연속성 계획서 (BCP)\n\n## 1. 범위 및 목적\n- 적용 대상: AWS MSP 서비스 운영 전체\n- 제외 대상: (명시적으로 기재)\n\n## 2. 핵심 서비스 및 RTO/RPO 정의\n| 서비스 | RTO | RPO | 우선순위 |\n|--------|-----|-----|----------|\n| 24x7 모니터링 | 1시간 | 0분 | P1 |\n| 인시던트 대응 | 2시간 | N/A | P1 |\n| 변경 관리 | 4시간 | 1시간 | P2 |\n| 고객 포털 | 8시간 | 4시간 | P3 |\n\n## 3. 위협 시나리오\n- 시나리오 1: 본사 사무실 접근 불가 (자연재해, 정전)\n- 시나리오 2: 주요 관리 도구 장애 (모니터링, ITSM)\n- 시나리오 3: 핵심 인력 동시 불능 (감염병, 사고)\n- 시나리오 4: 사이버 공격으로 인한 시스템 격리\n\n## 4. 대체 운영 절차\n### 4.1 대체 작업 환경\n- Primary: 서울 본사 NOC\n- Secondary: AWS WorkSpaces (ap-northeast-2)\n- Tertiary: 부산 DR 사이트\n\n### 4.2 대체 도구\n| 주요 도구 | 대체 도구 | 전환 절차 |\n|-----------|-----------|-----------|\n| Datadog | CloudWatch | runbook-monitoring-failover.md |\n| ServiceNow | Jira Service Desk | runbook-itsm-failover.md |\n| Jenkins | AWS CodePipeline | runbook-cicd-failover.md |\n\n## 5. 커뮤니케이션 계획\n- 내부 비상 연락망\n- 고객 통보 절차 및 템플릿\n- AWS 지원 에스컬레이션\n\n## 6. 테스트 및 유지보수\n- 연간 테스트 일정\n- 문서 검토 주기\n```\n\n---\n\n### 📊 테스트 결과 보고서 필수 요소\n\n```markdown\n# BCP 테스트 결과 보고서\n\n## 테스트 개요\n- 테스트 일시: 2024년 8월 15일 09:00 - 17:00 KST\n- 테스트 유형: Full-scale Exercise (전체 시나리오 실행)\n- 참여자: NOC팀 전원, 플랫폼팀 2명, 경영진 1명\n\n## 테스트 시나리오\n\"서울 본사 데이터센터 정전으로 NOC 운영 불가 상황에서 \n대체 환경으로 전환하여 고객 모니터링 및 인시던트 대응 수행\"\n\n## 실행 타임라인\n| 시간 | 활동 | 결과 |\n|------|------|------|\n| 09:00 | 시나리오 발동 선언 | - |\n| 09:05 | BCP 활성화 결정 | ✅ 5분 내 의사결정 |\n| 09:15 | WorkSpaces 접속 시작 | ✅ 전원 접속 성공 |\n| 09:35 | 대체 모니터링 활성화 | ⚠️ 10분 지연 (인증 문제) |\n| 09:50 | 고객 통보 발송 | ✅ 템플릿 활용 |\n| 10:30 | 테스트 인시던트 처리 | ✅ 정상 처리 |\n| 12:00 | 중간 점검 | - |\n| 16:00 | 원복 절차 시작 | ✅ |\n| 17:00 | 테스트 종료 | - |\n\n## 측정 결과\n| 항목 | 목표 | 실제 | 판정 |\n|------|------|------|------|\n| 대체 환경 전환 | 60분 | 35분 | ✅ PASS |\n| 모니터링 복구 | 60분 | 50분 | ✅ PASS |\n| 인시던트 대응 | 가능 | 가능 | ✅ PASS |\n| 고객 통보 | 30분 | 25분 | ✅ PASS |\n\n## 발견된 문제점\n1. WorkSpaces MFA 토큰 동기화 지연 (10분 소요)\n2. 대체 VPN 프로파일 미배포 상태 발견\n3. 비상 연락망 2명 연락처 outdated\n\n## 개선 조치 계획\n| 문제 | 조치 | 담당 | 완료 예정 |\n|------|------|------|-----------|\n| MFA 지연 | 하드웨어 토큰 추가 배포 | IT팀 | 2024-08-30 |\n| VPN 미배포 | 전 직원 프로파일 배포 | IT팀 | 2024-08-25 |\n| 연락처 outdated | 월간 검증 프로세스 추가 | HR | 2024-09-01 |\n\n## 증빙 첨부\n- [스크린샷] WorkSpaces 접속 화면\n- [스크린샷] 대체 모니터링 대시보드\n- [스크린샷] 테스트 인시던트 티켓\n- [사진] 테스트 참여자 (선택)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: MSP 핵심 서비스 식별 및 의존성 매핑 (1주)\n\n```\n🎯 목표: 고객 서비스에 필수적인 내부 시스템과 인력 식별\n\n수행 작업:\n1. MSP 서비스 카탈로그에서 핵심 서비스 추출\n   - 24x7 모니터링\n   - 인시던트 대응\n   - 변경 관리\n   - 고객 커뮤니케이션\n\n2. 각 서비스별 의존성 매핑\n   ┌─────────────────────────────────────────────┐\n   │ 24x7 모니터링 서비스                          │\n   ├─────────────────────────────────────────────┤\n   │ 도구: Datadog, PagerDuty, Slack             │\n   │ 인프라: NOC 워크스테이션, VPN, 인터넷        │\n   │ 인력: NOC 엔지니어 (최소 2명/shift)          │\n   │ 데이터: 알람 룰셋, 런북, 고객 연락처         │\n   └─────────────────────────────────────────────┘\n\n담당: 서비스 매니저 + NOC 리드\n산출물: MSP-Service-Dependency-Map.xlsx\n```\n\n### Step 2: 대체 운영 환경 구축 (2-3주)\n\n```\n🎯 목표: 주요 운영 환경 불능 시 대체 환경 확보\n\nAWS 기반 대체 환경 구성:\n\n1. Amazon WorkSpaces 배포\n   - NOC 엔지니어용 WorkSpaces 프로비저닝\n   - 필요 도구 사전 설치 (AWS CLI, 모니터링 에이전트)\n   - MFA 설정 및 테스트\n\n2. 대체 접속 경로 확보\n   - AWS Client VPN 엔드포인트 구성\n   - 고객 환경 접속용 IAM Role 사전 설정\n   - Session Manager 기반 접속 경로 확보\n\n3. 대체 도구 준비\n   - CloudWatch 기반 백업 대시보드 구성\n   - AWS SNS/EventBridge 기반 알람 대체 경로\n   - 백업 ITSM (Jira Service Desk 등) 설정\n\n담당: 플랫폼팀 + IT팀\n산출물: 대체 환경 구성 문서, 접속 가이드\n```\n\n### Step 3: BCP 문서 작성 (1-2주)\n\n```\n🎯 목표: 감사 요구사항을 충족하는 공식 BCP 문서 작성\n\n문서 작성 체크리스트:\n□ 범위가 \"AWS MSP 서비스 운영\"으로 명확히 정의\n□ 최소 3개 이상의 위협 시나리오 포함\n□ 각 핵심 서비스별 RTO/RPO 정의\n□ 대체 환경/도구/인력 명시\n□ 단계별 전환 절차 (runbook 수준)\n□ 커뮤니케이션 계획 (내부 + 고객)\n□ 테스트 일정 및 방법론\n\n담당: 서비스 매니저 + 품질팀\n산출물: MSP-BCP-2024.pdf\n```\n\n### Step 4: 테스트 계획 수립 (3-5일)\n\n```\n🎯 목표: 실제적이고 측정 가능한 테스트 시나리오 설계\n\n테스트 유형 선택:\n┌────────────────────────────────────────────────────┐\n│ Tabletop Exercise (탁상 훈련)                       │\n│ - 회의실에서 시나리오 기반 토론                      │\n│ - 소요: 2-3시간                                    │\n│ - 적합: 첫 테스트, 절차 검증                        │\n├────────────────────────────────────────────────────┤\n│ Functional Exercise (기능 훈련)                     │\n│ - 실제 대체 환경 접속 및",
      "language": "ko",
      "createdAt": "2026-01-07T01:40:18.660Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEO-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEO-001",
      "category": "People",
      "title": "인력 온보딩",
      "advice": "# PEO-001: 인력 온보딩 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nAWS MSP 파트너의 서비스 품질은 결국 **사람**에서 시작됩니다. 신규 엔지니어가 고객의 프로덕션 환경에 접근하기 전에 충분한 준비가 되어 있지 않다면, 보안 사고나 서비스 장애로 이어질 수 있습니다. AWS는 MSP 파트너가 체계적인 온보딩을 통해 **일관된 서비스 품질**과 **보안 기준**을 유지하는지 확인하고자 합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **AWS 서비스 역량 검증** | 신규 인력이 고객 환경 접근 전 AWS 핵심 서비스(EC2, VPC, IAM, CloudWatch 등)에 대한 실무 역량을 갖추었는지 |\n| **보안 교육 완료** | AWS 환경에서의 보안 모범 사례, 고객 데이터 취급 정책, IAM 권한 관리 원칙을 이해하는지 |\n| **도구 숙련도** | MSP 운영에 사용하는 도구(AWS Control Tower, Organizations, Service Catalog 등)를 다룰 수 있는지 |\n| **에스컬레이션 체계 이해** | 장애 발생 시 누구에게, 어떻게 보고해야 하는지 명확히 아는지 |\n| **실제 적용 기록** | 프로세스가 문서로만 존재하는 게 아니라 실제로 사용되고 있다는 증거 |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS Skill Builder**: 온보딩 교육 콘텐츠 제공\n- **AWS Certification**: 역량 검증 기준\n- **AWS IAM Identity Center**: 신규 인력 접근 권한 프로비저닝\n- **AWS CloudTrail**: 신규 인력의 초기 활동 모니터링\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 PEO-001_온보딩_증빙/\n├── 01_온보딩_프로세스_정의서.pdf\n├── 02_온보딩_체크리스트_템플릿.xlsx\n├── 03_완료된_온보딩_기록/\n│   ├── 김철수_온보딩완료_20240115.pdf\n│   ├── 이영희_온보딩완료_20240201.pdf\n│   └── 박민수_온보딩완료_20240315.pdf\n├── 04_교육이수_증빙/\n│   ├── AWS_교육이수_스크린샷/\n│   └── 내부교육_출석부.pdf\n└── 05_멘토링_기록.xlsx\n```\n\n### 각 증빙 자료의 핵심 내용\n\n#### 📄 온보딩 프로세스 정의서\n```markdown\n필수 포함 항목:\n- 온보딩 대상 정의 (MSP 팀 신규 합류자, 타 부서 전입자 구분)\n- 온보딩 기간 (예: 입사 후 4주)\n- 단계별 목표와 완료 기준\n- 책임자 지정 (버디/멘토, 팀 리더, HR)\n- 고객 환경 접근 권한 부여 조건\n```\n\n#### 📋 온보딩 체크리스트 (실제 예시)\n\n| 주차 | 항목 | 완료 기준 | 확인자 | 완료일 |\n|------|------|-----------|--------|--------|\n| 1주 | AWS IAM 모범 사례 교육 | 퀴즈 80점 이상 | 멘토 | |\n| 1주 | 내부 보안 정책 서약서 제출 | 서명 완료 | HR | |\n| 2주 | AWS Skill Builder - Cloud Practitioner 과정 | 수료증 발급 | 본인 | |\n| 2주 | 내부 티켓 시스템(Jira/ServiceNow) 실습 | 테스트 티켓 3건 처리 | 팀 리더 | |\n| 3주 | 샌드박스 환경 실습 과제 | EC2+RDS+ALB 구성 | 멘토 | |\n| 3주 | 장애 대응 시뮬레이션 참관 | 참관 확인서 | 팀 리더 | |\n| 4주 | 실제 고객 티켓 처리 (멘토 동반) | 5건 이상 | 멘토 | |\n\n#### 📊 완료된 온보딩 기록 예시\n\n**파일명**: `홍길동_온보딩완료_20240315.pdf`\n\n```\n[MSP팀 온보딩 완료 보고서]\n\n성명: 홍길동\n입사일: 2024.02.15\n온보딩 완료일: 2024.03.15\n담당 멘토: 김선배 (MSP팀 시니어 엔지니어)\n\n✅ 완료 항목:\n- AWS Cloud Practitioner Essentials 수료 (2024.02.20)\n- 내부 보안 교육 이수 (2024.02.22)\n- 샌드박스 실습 과제 통과 (2024.03.05)\n- 고객 환경 접근 권한 부여 승인 (2024.03.15)\n\n📎 첨부:\n- AWS Skill Builder 수료증\n- 보안 서약서 사본\n- 실습 과제 결과물 스크린샷\n- 멘토 평가서\n\n승인: 김팀장 (MSP팀 리더) - 2024.03.15\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 온보딩 현황 파악 (1-2일)\n\n**수행 작업:**\n- 최근 12개월간 MSP 팀에 합류한 인원 리스트 작성\n- 기존에 진행했던 온보딩 활동 기록 수집 (이메일, 슬랙, 교육 기록 등)\n\n**담당자:** HR + MSP 팀 리더\n\n**💡 실무 팁:** 기록이 없더라도 당시 담당자 인터뷰를 통해 실제 진행된 활동을 문서화할 수 있습니다.\n\n---\n\n### Step 2: 온보딩 프로세스 정의서 작성 (3-5일)\n\n**수행 작업:**\n```\n1. AWS MSP 운영에 필요한 역량 목록 정의\n   - 필수: IAM, VPC, EC2, CloudWatch, Cost Explorer\n   - 권장: Lambda, ECS, RDS, S3 보안 설정\n\n2. 온보딩 단계 설계\n   - Week 1: 회사/팀 소개 + 기본 보안 교육\n   - Week 2: AWS 기초 교육 + 내부 도구 학습\n   - Week 3: 샌드박스 실습 + 프로세스 학습\n   - Week 4: 멘토 동반 실무 + 평가\n\n3. 완료 기준 명확화\n   - \"교육 이수\" → \"AWS Skill Builder 과정 수료증 제출\"\n   - \"실습 완료\" → \"샌드박스에서 3-tier 아키텍처 구성 및 검증\"\n```\n\n**담당자:** MSP 팀 리더 + 시니어 엔지니어\n\n---\n\n### Step 3: 체크리스트 템플릿 제작 (2-3일)\n\n**수행 작업:**\n- Excel 또는 Notion 템플릿 제작\n- 각 항목에 완료 기준, 확인자, 날짜 필드 포함\n- 서명/승인 섹션 추가\n\n**사용 도구:** Excel, Google Sheets, Notion, Confluence\n\n**📌 체크리스트 필수 섹션:**\n```\n□ 기본 정보 (성명, 입사일, 멘토 배정)\n□ 보안 교육 (정책 숙지, 서약서 제출)\n□ AWS 기술 교육 (필수 과정 이수)\n□ 내부 도구 교육 (티켓 시스템, 모니터링 도구)\n□ 실습 과제 (샌드박스 환경)\n□ 멘토링 기록 (주간 1:1 미팅)\n□ 최종 평가 및 권한 부여 승인\n```\n\n---\n\n### Step 4: 최근 온보딩 대상자 기록 보완 (3-5일)\n\n**수행 작업:**\n- 최근 6개월 내 입사자 대상 소급 문서화\n- AWS Skill Builder 이수 기록 스크린샷 수집\n- 멘토/팀 리더 확인 서명 받기\n\n**담당자:** 각 온보딩 대상자 + 멘토\n\n**⚠️ 주의:** 감사 시점에 최소 **2-3명의 완료된 온보딩 기록**이 필요합니다.\n\n---\n\n### Step 5: 신규 입사자에게 프로세스 적용 (진행 중)\n\n**수행 작업:**\n- 새로 정의한 프로세스로 실제 온보딩 진행\n- 진행 중 발견된 문제점 피드백 수집\n- 체크리스트 실시간 업데이트\n\n**담당자:** 신규 입사자 + 멘토 + 팀 리더\n\n---\n\n### Step 6: 증빙 패키지 구성 (1-2일)\n\n**수행 작업:**\n```\n최종 증빙 패키지 구성:\n├── 프로세스 정의서 (PDF)\n├── 체크리스트 템플릿 (Excel/PDF)\n├── 완료된 온보딩 기록 2-3건 (PDF)\n│   └── 각 기록에 교육 이수 증빙 첨부\n└── (선택) 온보딩 개선 이력\n```\n\n**담당자:** MSP 팀 리더\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 유형 | 문제점 | 해결 방법 |\n|-----------|--------|-----------|\n| **프로세스만 있고 기록 없음** | \"우리는 이렇게 합니다\"라는 문서만 제출하고 실제 완료 기록이 없음 | 최소 2-3명의 **완료된** 온보딩 기록 필수 제출 |\n| **일반적인 HR 온보딩만 제출** | 회사 전체 신입사원 교육 자료만 제출 | **AWS MSP 실무**에 특화된 기술 온보딩 내용 포함 필수 |\n| **날짜/서명 누락** | 체크리스트에 언제, 누가 확인했는지 불명확 | 모든 항목에 완료일자 + 확인자 서명 포함 |\n| **AWS 교육 증빙 부재** | \"교육했습니다\"만 기재하고 증빙 없음 | AWS Skill Builder 수료증, 인증 시험 결과 등 첨부 |\n| **오래된 기록만 제출** | 2년 전 온보딩 기록만 제출 | 최근 12개월 이내 기록 포함 권장 |\n\n### ❌ 감사 탈락 주요 원인\n\n1. **\"프로세스는 있지만 따르지 않는다\"는 인상**\n   - 정의서와 실제 기록의 항목이 불일치\n   - 해결: 정의서 기반으로 체크리스트 작성, 체크리스트 기반으로 기록 작성\n\n2. **고객 환경 접근 권한 부여 기준 불명확**\n   - 온보딩 완료 전에 프로덕션 접근 권한이 부여된 기록\n   - 해결: \"온보딩 완료 승인 후 IAM Identity Center 권한 부여\" 프로세스 명시\n\n3. **AWS 기술 역량 검증 부재**\n   - 일반적인 회사 교육만 있고 AWS 특화 교육 없음\n   - 해결: AWS Skill Builder 과정 또는 AWS Certification 연계\n\n### 🔴 피해야 할 안티패턴\n\n```\n❌ \"신입사원 OJT 진행\" - 너무 모호함\n✅ \"AWS Skill Builder 'Cloud Practitioner Essentials' 과정 수료 (8시간)\"\n\n❌ \"보안 교육 완료\" - 무엇을 배웠는지 불명확\n✅ \"IAM 모범 사례 교육 이수 + 고객 데이터 취급 정책 서약서 제출\"\n\n❌ \"멘토링 진행\" - 기록 없음\n✅ \"주간 1:1 멘토링 4회 진",
      "language": "ko",
      "createdAt": "2026-01-07T01:45:39.190Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEO-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEO-002",
      "category": "People",
      "title": "클라우드 우수성 센터 (CCOE)",
      "advice": "# PEO-002: 클라우드 우수성 센터 (CCOE) - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nCCoE는 단순한 조직 구조가 아니라 **MSP의 클라우드 역량이 체계적으로 발전하고 있음을 증명하는 핵심 지표**입니다. AWS는 MSP 파트너가 고객에게 일관된 품질의 서비스를 제공하려면 내부적으로 클라우드 모범 사례를 제도화하는 메커니즘이 필수라고 봅니다. CCoE가 없으면 개별 엔지니어의 역량에 의존하게 되어 서비스 품질의 편차가 발생합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 의도 |\n|--------|-------------------|\n| **실제 운영 여부** | CCoE가 문서상으로만 존재하는지, 실제로 정기적인 활동을 하는지 |\n| **다기능 팀 구성** | 개발, 운영, 보안, 아키텍처 등 다양한 역할이 참여하는지 |\n| **비즈니스 영향력** | CCoE의 결정이 실제 프로젝트와 운영에 반영되는 경로가 있는지 |\n| **5대 영역 커버리지** | 채택, 교육, 거버넌스, 전략, 운영/자동화 모두를 다루는지 |\n| **측정 가능한 성과** | CCoE 활동의 결과물(표준, 가이드, 자동화 도구 등)이 있는지 |\n\n### 관련 AWS 서비스 및 프레임워크\n\n- **AWS Well-Architected Framework**: CCoE가 전파해야 할 핵심 모범 사례\n- **AWS Control Tower**: CCoE가 거버넌스를 구현하는 대표적 도구\n- **AWS Service Catalog**: 표준화된 서비스 제공을 위한 CCoE 산출물\n- **AWS Organizations**: 멀티 어카운트 거버넌스 구현\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 PEO-002_CCoE_증빙/\n├── 01_CCoE_Charter_v2.1.pdf\n├── 02_CCoE_Organization_Chart.pdf\n├── 03_CCoE_Operating_Model.pdf\n├── 04_CCoE_Meeting_Minutes_2024/\n│   ├── CCoE_Weekly_Standup_20240115.pdf\n│   ├── CCoE_Monthly_Review_202401.pdf\n│   └── CCoE_Quarterly_Strategy_2024Q1.pdf\n├── 05_CCoE_Deliverables/\n│   ├── Cloud_Adoption_Playbook_v1.2.pdf\n│   ├── AWS_Governance_Standards.pdf\n│   └── Automation_Templates_Catalog.xlsx\n└── 06_CCoE_Engagement_Evidence/\n    ├── Project_Consultation_Records.pdf\n    └── Training_Program_Schedule.pdf\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📄 CCoE 헌장 (Charter)\n```markdown\n필수 포함 항목:\n- 미션 및 비전 선언문\n- CCoE의 권한 범위 (예: 클라우드 표준 승인 권한, 아키텍처 리뷰 권한)\n- 5대 영역별 책임 명시\n  • 클라우드 채택: 신규 서비스 도입 검토, PoC 지원\n  • 교육/변경관리: 내부 교육 커리큘럼 관리, 인증 로드맵\n  • 거버넌스: 보안 기준선, 비용 정책, 태깅 표준\n  • 전략: 연간 클라우드 로드맵, 서비스 포트폴리오 관리\n  • 운영/자동화: IaC 표준, CI/CD 파이프라인 템플릿\n- 의사결정 프로세스 (RACI 매트릭스)\n- 헌장 승인자 서명 및 날짜\n```\n\n#### 📄 조직 구조 (Organization Chart)\n```\nCCoE 리더 (Head of Cloud Excellence)\n    │\n    ├── Cloud Architect Lead ─── 아키텍처 표준, Well-Architected 리뷰\n    ├── DevOps Lead ─────────── CI/CD 표준, IaC 템플릿 관리\n    ├── Security Lead ────────── 보안 기준선, 컴플라이언스 가이드\n    ├── FinOps Lead ──────────── 비용 최적화 표준, 예산 거버넌스\n    └── Training Lead ────────── 교육 프로그램, 인증 관리\n\n* 각 역할별 담당자 이름, 직급, 참여 비율(%) 명시 필수\n* 예: \"김철수 - Senior Architect - CCoE 참여 30%\"\n```\n\n#### 📄 운영 프로세스 (Operating Model)\n```yaml\n정기 회의 체계:\n  주간_스탠드업:\n    빈도: 매주 화요일 10:00\n    참석자: 전체 CCoE 멤버\n    안건: 진행 중인 표준화 작업, 블로커 공유\n    \n  월간_리뷰:\n    빈도: 매월 첫째 주 금요일\n    참석자: CCoE + 사업부 대표\n    안건: KPI 리뷰, 신규 이니셔티브 검토\n    \n  분기_전략회의:\n    빈도: 분기 시작 2주차\n    참석자: CCoE + 경영진\n    안건: 로드맵 업데이트, 예산 검토\n\n비즈니스 참여 프로세스:\n  신규_프로젝트_참여:\n    트리거: 프로젝트 킥오프 시 CCoE 리뷰 요청\n    산출물: Architecture Decision Record (ADR)\n    \n  표준_예외_승인:\n    요청자: 프로젝트 리드\n    승인자: CCoE 리더\n    SLA: 3영업일 내 응답\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: CCoE 멤버 구성 및 역할 정의 (2주)\n\n**담당자**: 클라우드 사업부 리더\n\n```\n실행 항목:\n□ 5대 영역별 리드 선정 (최소 5명, 겸직 가능)\n□ 각 멤버의 CCoE 참여 시간 할당 확보 (최소 주 4시간)\n□ CCoE 리더 임명 (VP/Director 레벨 권장)\n\n주의: 감사관은 \"전담팀\"을 요구하지 않습니다. \n겸직이 가능하나, 명시적인 시간 할당이 문서화되어야 합니다.\n```\n\n### Step 2: 헌장 작성 및 경영진 승인 (1주)\n\n**담당자**: CCoE 리더\n\n```\n헌장 작성 시 반드시 포함할 문구 예시:\n\n\"본 CCoE는 [회사명]의 클라우드 운영 표준을 수립하고 \n전사적으로 전파할 권한을 가지며, 모든 클라우드 프로젝트는 \nCCoE의 아키텍처 리뷰를 거쳐야 한다.\"\n\n승인 형식:\n- CEO 또는 CTO 서명\n- 승인 날짜 명시\n- 버전 관리 (v1.0, v1.1 등)\n```\n\n### Step 3: 운영 프로세스 수립 및 첫 회의 개최 (2주)\n\n**담당자**: CCoE 전체\n\n```\n첫 회의 안건 예시:\n1. CCoE 헌장 공유 및 역할 확인\n2. 5대 영역별 현재 상태 진단\n3. 분기 목표 설정 (예: Q1 목표 - IaC 표준 수립)\n4. 회의 체계 확정\n\n필수 산출물:\n- 회의록 (참석자, 안건, 결정사항, 액션아이템)\n- 분기 로드맵 초안\n```\n\n### Step 4: 5대 영역별 초기 산출물 생성 (4주)\n\n**담당자**: 각 영역 리드\n\n```\n영역별 최소 산출물:\n\n1. 클라우드 채택\n   └── Cloud Adoption Checklist (신규 서비스 도입 시 검토 항목)\n\n2. 교육/변경관리\n   └── AWS Certification Roadmap (직급/역할별 권장 인증)\n   └── 내부 교육 일정표\n\n3. 거버넌스\n   └── AWS Account Baseline (필수 설정 항목)\n   └── Tagging Standard (필수 태그 목록)\n\n4. 전략\n   └── Cloud Service Portfolio (제공 가능 서비스 목록)\n   └── 연간 클라우드 로드맵\n\n5. 운영/자동화\n   └── Terraform/CloudFormation 템플릿 카탈로그\n   └── CI/CD 파이프라인 표준\n```\n\n### Step 5: 비즈니스 참여 증빙 수집 (2주)\n\n**담당자**: CCoE 리더\n\n```\n수집해야 할 증빙:\n\n□ 프로젝트 아키텍처 리뷰 기록 (최소 3건)\n  - 리뷰 요청서\n  - 리뷰 결과 (승인/조건부승인/반려)\n  - ADR (Architecture Decision Record)\n\n□ 표준 전파 활동 기록\n  - 내부 세미나/워크샵 참석자 명단\n  - 표준 문서 배포 이력\n\n□ 거버넌스 적용 사례\n  - Control Tower 가드레일 적용 화면 캡처\n  - Service Catalog 제품 목록\n```\n\n### Step 6: 문서 패키징 및 검토 (1주)\n\n**담당자**: CCoE 리더 + 품질 담당\n\n```\n최종 패키징 체크:\n□ 모든 문서에 버전, 날짜, 작성자 명시\n□ 회의록에 참석자 서명 또는 이메일 증빙 첨부\n□ 스크린샷에 날짜/시간 표시 확인\n□ 영문 번역본 준비 (감사관 요청 시)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: \"Paper CCoE\" - 문서만 있고 실제 활동이 없음\n\n```\n감사관 질문: \"최근 3개월간 CCoE 회의록을 보여주세요\"\n\n실패 사례:\n- 회의록이 1건도 없음\n- 회의록은 있으나 참석자가 매번 1-2명\n- 회의록 내용이 \"특이사항 없음\"으로만 기재\n\n해결책:\n- 최소 월 1회 정기 회의 개최 및 기록\n- 회의록에 구체적인 논의 내용과 결정사항 기재\n- 액션아이템과 담당자, 완료일 명시\n```\n\n### 🚫 실수 2: 5대 영역 중 일부만 커버\n\n```\n감사관 질문: \"교육/변경관리 영역에서 CCoE가 하는 활동은?\"\n\n실패 사례:\n- \"아직 그 영역은 준비 중입니다\"\n- 거버넌스와 운영에만 집중하고 나머지 영역 무시\n\n해결책:\n- 헌장에 5대 영역 모두 명시적으로 포함\n- 각 영역별 최소 1개 이상의 활동/산출물 준비\n- 영역별 담당자 지정\n```\n\n### 🚫 실수 3: CCoE와 비즈니스의 연결고리 부재\n\n```\n감사관 질문: \"CCoE의 표준이 실제 프로젝트에 어떻게 적용되나요?\"\n\n실패 사례:\n- 표준 문서는 있으나 프로젝트에서 사용한 증빙 없음\n- \"권고사항\"으로만 존재하고 강제성 없음\n\n해결책:\n- 프로젝트 착수 시 CCoE 리뷰 필수화 (프로세스 문서화)\n- 실제 리뷰 기록 3건 이상 준비\n- 리뷰 결과가 프로젝트에 반영된 증빙 (설계 변경 이력 등)\n```\n\n### 🚫 실수 4: 조직도에 이름만 있고 역할 불명확\n\n```\n감사관 질문: \"Security Lead는 CCoE에서 구체적으로 무슨 일을 하나요?\"\n\n실패 사례:\n- \"보안 관련 업무를 담당합니다\" (너무 추상적)\n- 담당자가 CCoE 역할을 인지하지 못함\n\n해결",
      "language": "ko",
      "createdAt": "2026-01-07T01:46:45.241Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEO-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEO-003",
      "category": "People",
      "title": "인력 오프보딩",
      "advice": "# PEO-003: 인력 오프보딩 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n인력 오프보딩은 **보안 사고의 가장 취약한 시점**입니다. AWS MSP는 다수의 고객 AWS 계정에 대한 권한 있는 액세스를 보유하므로, 퇴직자의 액세스가 단 하나라도 남아있으면 **다중 고객 환경에 대한 보안 위협**으로 직결됩니다. AWS는 MSP 파트너가 \"최소 권한 원칙\"을 퇴직 시점까지 일관되게 적용하는지 검증합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **즉시성** | 퇴직일 기준 24시간 이내에 모든 액세스가 차단되었는가? |\n| **완전성** | AWS 콘솔, CLI, API 키, SSO, VPN, 고객 환경 등 **모든 접점**이 포함되었는가? |\n| **추적성** | 누가, 언제, 어떤 액세스를 제거했는지 로그로 증명 가능한가? |\n| **고객 환경 분리** | 파트너 내부 시스템과 고객 AWS 계정의 액세스 제거가 **별도로 관리**되는가? |\n| **검증 절차** | 액세스 제거 후 실제로 접근 불가능함을 **테스트**했는가? |\n\n### 🔗 관련 AWS 서비스 및 기능\n\n- **AWS IAM Identity Center (SSO)**: 중앙 집중식 액세스 관리 및 즉시 비활성화\n- **AWS Organizations**: 다중 계정 환경의 권한 관리\n- **AWS CloudTrail**: 액세스 제거 작업의 감사 로그\n- **AWS IAM Access Analyzer**: 잔여 권한 탐지\n- **AWS Secrets Manager**: API 키/자격 증명 로테이션\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 옵션 A: 완료된 오프보딩 기록 (권장)\n\n| 문서명 | 형식 | 핵심 포함 내용 |\n|--------|------|---------------|\n| `MSP_Offboarding_Checklist_v2.3.pdf` | PDF/체크리스트 | 액세스 제거 항목별 완료 여부, 담당자 서명, 일시 |\n| `Offboarding_Record_[직원명]_[날짜].xlsx` | 스프레드시트 | 실제 퇴직자의 오프보딩 실행 기록 (최소 2건) |\n| `IAM_User_Deletion_CloudTrail_[날짜].json` | CloudTrail 로그 | DeleteUser, RemoveUserFromGroup 등 API 호출 기록 |\n| `SSO_Access_Revocation_Screenshot.png` | 스크린샷 | IAM Identity Center에서 사용자 비활성화 화면 |\n\n#### 옵션 B: 업계 인증서\n\n| 인증 | 요구 조건 |\n|------|----------|\n| **ISO 27001** | A.7.3.1 (고용 종료 또는 변경) 통제 항목이 MSP 실무 범위에 포함 |\n| **SOC 2 Type II** | CC6.2 (논리적 액세스 제거) 통제가 테스트되고 예외 없음 |\n\n### 📄 각 증빙에 포함되어야 할 핵심 내용\n\n**오프보딩 체크리스트 필수 항목:**\n\n```\n□ AWS IAM 사용자 삭제/비활성화\n□ AWS IAM Identity Center(SSO) 액세스 제거\n□ AWS Access Key 비활성화 및 삭제\n□ 고객 AWS 계정 Cross-Account Role 제거\n□ AWS CodeCommit/GitHub 리포지토리 액세스 제거\n□ VPN/Bastion Host 접근 권한 제거\n□ Slack/Teams 등 협업 도구에서 고객 채널 제거\n□ 물리적 보안 배지/토큰 회수\n□ 회사 기기 반납 및 원격 삭제 확인\n```\n\n### 📁 실제 파일명 예시\n\n```\n/evidence/PEO-003/\n├── MSP_Offboarding_Policy_v2.1_2024.pdf\n├── Offboarding_Checklist_Template_AWS_MSP.xlsx\n├── Completed_Records/\n│   ├── Offboarding_KimMinsu_2024-08-15.pdf\n│   ├── Offboarding_LeeJihye_2024-09-22.pdf\n│   └── Offboarding_ParkJunho_2024-10-05.pdf\n├── CloudTrail_Logs/\n│   ├── DeleteUser_KimMinsu_2024-08-15.json\n│   └── DeactivateUser_SSO_2024-08-15.json\n└── Screenshots/\n    ├── IAM_Identity_Center_User_Disabled.png\n    └── Access_Analyzer_No_External_Access.png\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 액세스 인벤토리 구축 (3-5일)\n\n**담당자**: 보안팀 + 클라우드 운영팀\n\n```bash\n# AWS CLI로 모든 IAM 사용자 및 액세스 키 목록 추출\naws iam list-users --query 'Users[*].[UserName,CreateDate]' --output table\n\n# IAM Identity Center 사용자 목록\naws identitystore list-users --identity-store-id d-1234567890\n\n# 모든 계정의 Cross-Account Role 신뢰 관계 확인\naws iam list-roles --query 'Roles[?contains(AssumeRolePolicyDocument.Statement[0].Principal.AWS, `arn:aws:iam::`)].RoleName'\n```\n\n**산출물**: `AWS_Access_Inventory_[날짜].xlsx`\n\n---\n\n### Step 2: 오프보딩 체크리스트 설계 (2-3일)\n\n**담당자**: 보안팀 + HR\n\n**체크리스트 구조 예시:**\n\n| 단계 | 액세스 유형 | 담당 시스템 | 담당자 | SLA | 완료 확인 방법 |\n|------|------------|-------------|--------|-----|---------------|\n| 1 | AWS IAM 사용자 | AWS Console | 클라우드팀 | 4시간 | CloudTrail 로그 |\n| 2 | IAM Identity Center | AWS SSO | 클라우드팀 | 4시간 | 로그인 실패 테스트 |\n| 3 | 고객 환경 Role | 고객 AWS 계정 | 프로젝트 PM | 24시간 | AssumeRole 실패 확인 |\n| 4 | VPN 액세스 | Cisco AnyConnect | IT팀 | 4시간 | 연결 시도 실패 |\n| 5 | 코드 저장소 | GitHub Enterprise | DevOps팀 | 4시간 | 403 에러 확인 |\n\n---\n\n### Step 3: 자동화 워크플로우 구축 (1-2주)\n\n**담당자**: DevOps팀\n\n**AWS Step Functions + Lambda를 활용한 자동화:**\n\n```python\n# Lambda 함수 예시: 오프보딩 자동화\ndef offboard_user(event, context):\n    username = event['username']\n    \n    # 1. IAM 사용자 액세스 키 비활성화\n    iam.update_access_key(UserName=username, AccessKeyId=key_id, Status='Inactive')\n    \n    # 2. IAM 사용자 콘솔 비밀번호 삭제\n    iam.delete_login_profile(UserName=username)\n    \n    # 3. MFA 디바이스 비활성화\n    iam.deactivate_mfa_device(UserName=username, SerialNumber=mfa_arn)\n    \n    # 4. 모든 그룹에서 제거\n    for group in iam.list_groups_for_user(UserName=username)['Groups']:\n        iam.remove_user_from_group(GroupName=group['GroupName'], UserName=username)\n    \n    # 5. CloudTrail에 커스텀 이벤트 기록\n    cloudtrail.put_events(Entries=[{\n        'EventType': 'OFFBOARDING_COMPLETED',\n        'Username': username,\n        'Timestamp': datetime.now().isoformat()\n    }])\n```\n\n---\n\n### Step 4: 실제 오프보딩 실행 및 기록 (퇴직 발생 시)\n\n**담당자**: HR → 보안팀 → 각 시스템 담당자\n\n**타임라인:**\n\n```\nD-7  : HR이 퇴직 예정 통보 → 보안팀 티켓 생성\nD-1  : 고객 환경 액세스 제거 시작 (고객 PM 통보)\nD-Day: 퇴직일 업무 종료 시점\n      └─ 모든 내부 시스템 액세스 즉시 제거\n      └─ 물리적 자산 회수\nD+1  : 액세스 제거 검증 테스트 실행\nD+3  : 오프보딩 완료 보고서 작성 및 서명\n```\n\n---\n\n### Step 5: 검증 테스트 실행 (오프보딩 후 24시간 내)\n\n**담당자**: 보안팀\n\n```bash\n# 퇴직자 자격 증명으로 로그인 시도 (실패해야 함)\naws sts get-caller-identity --profile offboarded_user\n# 예상 결과: \"An error occurred (InvalidClientTokenId)\"\n\n# Cross-Account Role Assume 시도 (실패해야 함)\naws sts assume-role --role-arn arn:aws:iam::CUSTOMER_ACCOUNT:role/MSP-Access \\\n    --role-session-name test --profile offboarded_user\n# 예상 결과: \"An error occurred (AccessDenied)\"\n```\n\n---\n\n### Step 6: 증빙 자료 패키징 (1-2일)\n\n**담당자**: 보안팀\n\n**증빙 패키지 구성:**\n\n```\nPEO-003_Evidence_Package/\n├── 1_Policy/\n│   └── MSP_Offboarding_Policy_v2.1.pdf (정책 문서)\n├── 2_Checklist/\n│   └── Offboarding_Checklist_Template.xlsx (체크리스트 템플릿)\n├── 3_Completed_Records/\n│   ├── Record_001_2024-08-15.pdf (완료된 오프보딩 기록 #1)\n│   ├── Record_002_2024-09-22.pdf (완료된 오프보딩 기록 #2)\n│   └── Record_003_2024-10-05.pdf (완료된 오프보딩 기록 #3)\n├── 4_Technical_Evidence/\n│   ├── CloudTrail_DeleteUser_Logs.json\n│   ├── IAM_Access_Analyzer_Report.pdf\n│   └── SSO_Deactivation_Screenshots/\n└── 5_Summary/\n    └── PEO-003_Evidence_Summary.pdf (증빙 요약 문서)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수 TOP 5\n\n| 순위 | 실수 유형 | 왜 문제인가? | 해결책 |\n|------|----------|-------------|--------|\n| **1** | **고객 환경 액세스 누락** | 파트너 내부 시스템만 제거하고 고객 AWS 계정의 Cross-Account Role을 잊음 | 고객별 액세스 매트릭스 유지, 오프보딩 시 고객 PM 체크 필수 |\n| **2** | **API 키만 삭제, 콘솔 비밀번호 유지** | IAM 사용자가 여전히 콘솔 로그인 가능 | `delete_login_profile` API 호출 필수 |\n| **3** | **SSO 비활성화 지연** | IAM Identity Center 사용자가 수일간 활성 상태 유지 | SSO 비활성화를 체크리스트 1순위로 배치 |\n| **4** | **서비스 계정 혼동** | 퇴직자가 생성한 서비스 계정/봇 계정이 계속 활성화 | 계정 생성 시 Owner 태깅 필수, 퇴직 시 Owner 기준 검색 |\n| **5** | **증빙에 날짜 누락** | 오프보딩이 언제 완료되었는지 증명 불가 | 모든 기록에 타임스탬프 + 담당자 서명 포함 |\n\n### 💀 감사 탈락 주요 원인\n\n```\n❌ \"오프보딩 정책은 있지만 실제 실행 기록이 없음\"\n   → 최소 2-3건의 완료된 오프보딩 기록 필수\n\n❌ \"CloudTrail 로그가 비활성화되어 있어 액세스 제거 증명 불가\"\n   → 모든 리전에서 CloudTrail 활성화 필수\n\n❌ \"고객 환경 액세스 제거가 체크리스트에 포함되지 않음\"\n   → MSP",
      "language": "ko",
      "createdAt": "2026-01-07T01:47:39.034Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEOP-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEOP-001",
      "category": "People",
      "title": "인력 기술",
      "advice": "# PEOP-001: 인력 기술 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS MSP 프로그램은 **\"사람이 서비스의 품질을 결정한다\"**는 철학을 기반으로 합니다. 아무리 좋은 도구와 프로세스가 있어도, 이를 운영하는 인력의 기술 수준이 낮으면 고객에게 제공되는 관리 서비스 품질이 저하됩니다. AWS는 파트너가 **체계적이고 지속적인 학습 문화**를 갖추고 있는지 확인하여, 향후 AWS 서비스 업데이트나 신규 기능 출시에도 빠르게 대응할 수 있는 조직인지 평가합니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **1. 전략의 문서화 여부** | 단순히 교육을 실시하는 것이 아니라, \"왜, 어떻게, 언제\" 교육하는지에 대한 명문화된 전략이 있는가? |\n| **2. MSP 운영 직원 대상 여부** | 일반 직원이 아닌, 실제 관리 서비스 운영에 참여하는 엔지니어/운영자가 학습 대상인가? |\n| **3. 12개월 내 실제 활동** | 계획만 있는 것이 아니라, 지난 1년간 실제로 학습 활동이 이루어졌는가? |\n| **4. 다양한 학습 형태** | AWS 공식 인증만이 아닌, 내부 세미나, 핸즈온 랩, 기술 공유 세션 등 다양한 형태가 있는가? |\n| **5. 측정 가능한 결과** | 학습 활동의 효과를 측정하고 개선하는 피드백 루프가 있는가? |\n\n### 관련 AWS 서비스 및 프로그램\n\n- **AWS Skill Builder**: 온라인 학습 플랫폼 (무료/유료 과정)\n- **AWS Certification**: 공식 인증 프로그램 (SAA, SAP, DevOps 등)\n- **AWS Partner Training**: 파트너 전용 교육 과정\n- **AWS re:Invent / re:Inforce / Summit**: 글로벌/로컬 컨퍼런스\n- **AWS Workshops**: 핸즈온 실습 자료\n- **AWS Well-Architected Labs**: 실습 기반 학습\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 인력 기술 개발 전략서\n**파일명 예시**: `MSP_Workforce_Skill_Development_Strategy_2024_v2.1.pdf`\n\n**포함 내용**:\n```\n1. 전략 개요\n   - 기술 개발 비전 및 목표\n   - 연간 학습 시간 목표 (예: 1인당 연 40시간)\n   - 인증 취득 목표 (예: 팀당 최소 2개 AWS 인증)\n\n2. 학습 경로 정의\n   - Junior Engineer → Mid-level → Senior 별 필수 교육\n   - 역할별 권장 AWS 인증 매핑\n   \n3. 학습 방법론\n   - 공식 교육 (AWS Training, 외부 교육기관)\n   - 비공식 학습 (내부 세미나, 기술 블로그 작성)\n   - 실습 기반 학습 (PoC 프로젝트, 핸즈온 랩)\n\n4. 예산 및 지원 정책\n   - 교육비 지원 한도\n   - 인증 시험비 지원\n   - 학습 시간 업무 인정 정책\n```\n\n#### 📄 문서 2: 학습 활동 실적 보고서 (12개월)\n**파일명 예시**: `MSP_Team_Learning_Activities_Report_2023Q4-2024Q3.xlsx`\n\n**포함 내용**:\n| 날짜 | 참여자 | 활동 유형 | 활동명 | 시간 | 증빙 |\n|------|--------|-----------|--------|------|------|\n| 2024-01-15 | 김OO | AWS 인증 | SAA-C03 취득 | - | 인증서 |\n| 2024-02-20 | 팀 전체 | 내부 세미나 | EKS 운영 베스트 프랙티스 | 2h | 발표자료 |\n| 2024-03-10 | 박OO, 이OO | 외부 교육 | AWS Summit Seoul 참석 | 8h | 참가 확인서 |\n| 2024-04-05 | 운영팀 | 핸즈온 랩 | Well-Architected 리뷰 실습 | 4h | 실습 결과물 |\n\n#### 📄 문서 3: 학습 활동 증빙 패키지\n**폴더 구조 예시**:\n```\n/Evidence_PEOP-001/\n├── 01_Certifications/\n│   ├── 김OO_AWS_SAA_Certificate_20240115.pdf\n│   ├── 박OO_AWS_DVA_Certificate_20240301.pdf\n│   └── Certification_Summary_2024.xlsx\n├── 02_Internal_Training/\n│   ├── 20240220_EKS_Seminar_Slides.pdf\n│   ├── 20240220_EKS_Seminar_Attendance.xlsx\n│   └── 20240405_WAR_Workshop_Photos.jpg\n├── 03_External_Training/\n│   ├── AWS_Summit_Seoul_2024_Registration.pdf\n│   └── AWS_SkillBuilder_Completion_Certificates/\n└── 04_Learning_Culture/\n    ├── Tech_Blog_Posts_List.xlsx\n    └── Monthly_TechTalk_Schedule_2024.pdf\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: MSP 운영 인력 식별 및 현황 파악 (1주)\n**담당**: HR + MSP 운영팀장\n\n```\n🎯 수행 작업:\n1. MSP 운영에 직접 참여하는 인력 명단 작성\n   - 이름, 직급, 역할, 입사일, 보유 인증\n2. 각 인원의 지난 12개월 학습 이력 수집\n   - AWS Certification Portal에서 인증 현황 확인\n   - AWS Skill Builder 학습 이력 다운로드\n\n💡 Tip: AWS Partner Central > Training > Team Progress에서 \n      팀원들의 학습 현황을 한눈에 확인 가능\n```\n\n### Step 2: 기존 학습 활동 증빙 수집 (2주)\n**담당**: 각 팀 리더\n\n```\n🎯 수행 작업:\n1. 내부 세미나/기술 공유 세션 자료 수집\n   - Confluence/SharePoint에서 발표 자료 검색\n   - 참석자 명단 (캘린더 초대 또는 출석부)\n   \n2. 외부 교육 참석 증빙 수집\n   - AWS Summit/re:Invent 등록 확인 이메일\n   - 외부 교육기관 수료증\n   \n3. 자기주도 학습 증빙 수집\n   - AWS Skill Builder 수료 인증서\n   - 기술 블로그 포스팅 목록\n\n⚠️ 주의: 날짜가 12개월 이내인지 반드시 확인\n```\n\n### Step 3: 인력 기술 개발 전략서 작성/업데이트 (1주)\n**담당**: MSP 운영 총괄 + HR\n\n```\n🎯 수행 작업:\n1. 기존 교육 정책 문서가 있다면 MSP 관점으로 보완\n2. 없다면 신규 작성 (위 템플릿 참조)\n\n📌 필수 포함 요소:\n- \"관리 서비스 운영 직원\"이라는 표현 명시\n- 구체적인 연간 목표 (시간, 인증 수 등)\n- 학습 예산 및 지원 정책\n- 학습 효과 측정 방법\n```\n\n### Step 4: 학습 활동 실적 보고서 작성 (3일)\n**담당**: MSP 운영팀 담당자\n\n```\n🎯 수행 작업:\n1. 수집된 증빙을 기반으로 활동 목록 정리\n2. 각 활동별 참여자, 날짜, 시간, 유형 기록\n3. 증빙 파일과 연결 (하이퍼링크 또는 파일명 매칭)\n\n📊 권장 형식:\n- Excel 또는 Google Sheets\n- 필터링 가능한 테이블 형태\n- 활동 유형별 통계 요약 포함\n```\n\n### Step 5: 증빙 부족 영역 보완 활동 실시 (2-4주)\n**담당**: MSP 운영팀 전체\n\n```\n🎯 만약 증빙이 부족하다면:\n1. 즉시 실행 가능한 활동:\n   - 내부 기술 세미나 개최 (1-2시간)\n   - AWS Skill Builder 과정 수료 (온라인, 즉시 가능)\n   - Well-Architected Labs 핸즈온 실습\n\n2. 2-4주 내 실행 가능:\n   - AWS 인증 시험 응시\n   - AWS Workshop 진행\n   - 기술 블로그 포스팅 작성\n\n💡 Tip: 최소 3가지 이상의 다양한 학습 유형 확보 권장\n```\n\n### Step 6: 증빙 패키지 구성 및 품질 검토 (3일)\n**담당**: MSP 운영팀장 + QA 담당\n\n```\n🎯 수행 작업:\n1. 폴더 구조에 맞게 모든 증빙 파일 정리\n2. 파일명 규칙 통일 (날짜_활동명_유형.확장자)\n3. 각 증빙의 날짜, 참여자, 내용 일관성 확인\n4. 민감 정보 마스킹 (필요시)\n```\n\n### Step 7: 최종 검토 및 제출 준비 (2일)\n**담당**: MSP 프로그램 담당자\n\n```\n🎯 수행 작업:\n1. 전략서 ↔ 실적 보고서 ↔ 증빙 간 일관성 확인\n2. 감사관 관점에서 스토리라인 검토\n3. 제출 형식 확인 (PDF, 파일 크기 제한 등)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 일반 직원 교육과 MSP 운영 직원 교육 혼동\n```\n❌ 잘못된 예:\n\"전사 신입사원 AWS 기초 교육 실시\" → MSP 운영과 무관\n\n✅ 올바른 예:\n\"MSP 운영팀 대상 CloudWatch 알람 설정 심화 교육 실시\"\n→ 관리 서비스 운영에 직접 연관된 교육\n```\n\n### 🚫 실수 2: 12개월 기간 미준수\n```\n❌ 잘못된 예:\n감사일: 2024년 10월\n제출 증빙: 2023년 5월 인증 취득 (17개월 전) → 기간 초과\n\n✅ 올바른 예:\n감사일: 2024년 10월\n제출 증빙: 2023년 11월 ~ 2024년 10월 사이 활동만 포함\n```\n\n### 🚫 실수 3: 전략 문서 없이 활동 증빙만 제출\n```\n❌ 잘못된 예:\n인증서 10장만 제출 → \"전략\"의 존재를 증명하지 못함\n\n✅ 올바른 예:\n전략 문서 + 해당 전략에 따른 실행 결과물 함께 제출\n→ \"계획 → 실행 → 결과\"의 연결고리 증명\n```\n\n### 🚫 실수 4: 단일 유형의 학습 활동만 제시\n```\n❌ 잘못된 예:\nAWS 인증 취득 기록만 제출 → \"다양한 학습 문화\" 미증명\n\n✅ 올바른 예:\n- 공식 인증 (AWS Certification)\n- 내부 세미나 (Tech Talk)\n- 핸즈온 실습 (Workshop)\n- 자기주도 학습 (Skill Builder)\n→ 최소 3가지 이상의 학습 유형 제시\n```\n\n### 🚫 실수 5: 증빙의 구체성 부족\n```\n❌ 잘못된 예:\n\"2024년 상반기 기술 교육 실시\" (날짜, 참여자, 내용 불명확)\n\n✅ 올바른 예:\n\"2024년 3월 15일, MSP 운영팀 5",
      "language": "ko",
      "createdAt": "2026-01-07T01:29:59.442Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-001",
      "category": "Platform",
      "title": "계정 관리",
      "advice": "# PLAT-001: 계정 관리 - AWS MSP 증빙 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS MSP 프로그램에서 계정 격리는 **보안과 규정 준수의 근간**입니다. 하나의 AWS 계정에 여러 고객 워크로드가 혼재되면 다음과 같은 심각한 문제가 발생합니다:\n\n- **데이터 유출 위험**: IAM 정책 실수로 고객 A가 고객 B의 S3 버킷에 접근\n- **비용 분쟁**: 리소스 비용을 정확히 분리할 수 없어 청구 분쟁 발생\n- **규정 준수 실패**: HIPAA, PCI-DSS 등 컴플라이언스 요건 충족 불가\n- **보안 사고 확산**: 한 고객의 침해가 다른 고객에게 전파\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 예시 |\n|------------|-------------------|\n| **1:1 매핑 원칙** | \"고객 A의 프로덕션 환경은 어떤 AWS 계정에 있습니까? 해당 계정에 다른 고객 리소스가 있습니까?\" |\n| **계정 생성 프로세스** | \"새 고객 온보딩 시 AWS 계정은 언제, 누가, 어떻게 생성합니까?\" |\n| **기존 계정 인수 절차** | \"고객이 기존 AWS 계정을 가져올 때 어떻게 관리 권한을 이전받습니까?\" |\n| **예외 상황 관리** | \"SaaS 제품이 있다면 멀티테넌시를 어떻게 구현했습니까?\" |\n| **계정 목록 관리** | \"현재 관리 중인 모든 고객 계정 목록을 보여주실 수 있습니까?\" |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    AWS Organizations                        │\n│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │\n│  │ Management  │  │   OU:       │  │   OU:       │         │\n│  │   Account   │──│ Customer-A  │──│ Customer-B  │         │\n│  └─────────────┘  └──────┬──────┘  └──────┬──────┘         │\n│                          │                 │                │\n│                   ┌──────┴──────┐   ┌──────┴──────┐        │\n│                   │ Prod Account│   │ Prod Account│        │\n│                   │ Dev Account │   │ Dev Account │        │\n│                   └─────────────┘   └─────────────┘        │\n└─────────────────────────────────────────────────────────────┘\n```\n\n- **AWS Organizations**: 계정 계층 구조 및 SCP 적용\n- **AWS Control Tower**: 계정 프로비저닝 자동화 및 가드레일\n- **AWS Service Catalog**: 표준화된 계정 생성 템플릿\n- **AWS IAM Identity Center**: 중앙 집중식 접근 관리\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 고객 계정 격리 정책서\n**파일명 예시**: `MSP-POL-001_Customer_Account_Isolation_Policy_v2.3.pdf`\n\n```markdown\n## 포함되어야 할 핵심 내용\n\n### 섹션 1: 정책 목적 및 범위\n- \"본 정책은 [회사명]이 관리하는 모든 AWS 고객 환경에 적용된다\"\n- \"각 고객은 최소 1개 이상의 전용 AWS 계정을 보유한다\"\n\n### 섹션 2: 계정 격리 원칙\n- 원칙 1: 고객 간 AWS 계정 공유 금지\n- 원칙 2: 환경별(Prod/Dev/Staging) 계정 분리 권장\n- 원칙 3: 예외 사항(자사 SaaS 제품)의 명시적 정의\n\n### 섹션 3: 신규 계정 생성 절차\n- 트리거: 고객 계약 체결 시점\n- 책임자: Cloud Operations Team\n- 도구: AWS Control Tower Account Factory\n- SLA: 계약 체결 후 2영업일 이내\n\n### 섹션 4: 기존 계정 인수 절차\n- 사전 점검 체크리스트\n- 관리자 역할 생성 및 권한 위임\n- 기존 리소스 인벤토리 작성\n\n### 섹션 5: 예외 관리\n- SaaS 제품의 멀티테넌시 구현 방식\n- 예외 승인 프로세스\n```\n\n#### 📄 문서 2: 계정 생성 표준 운영 절차서 (SOP)\n**파일명 예시**: `MSP-SOP-012_AWS_Account_Provisioning_Procedure.pdf`\n\n```markdown\n## 포함되어야 할 핵심 내용\n\n### 절차 1: 계정 생성 요청\n- 요청 채널: ServiceNow 티켓 또는 Jira 이슈\n- 필수 입력 정보:\n  - 고객명\n  - 계정 용도 (Production/Development/Sandbox)\n  - 예상 월 비용\n  - 담당 TAM(Technical Account Manager)\n\n### 절차 2: Control Tower를 통한 계정 생성\n- Account Factory 실행 단계\n- 기본 OU 배치 규칙\n- 필수 가드레일 적용 확인\n\n### 절차 3: 초기 설정\n- CloudTrail 활성화 확인\n- Config Rules 배포\n- Security Hub 연동\n- 비용 알림 설정\n\n### 절차 4: 고객 인계\n- 관리자 IAM 역할 생성\n- 접근 권한 문서 전달\n- 온보딩 미팅 일정\n```\n\n#### 📄 문서 3: 고객-계정 매핑 레지스트리\n**파일명 예시**: `Customer_Account_Registry_2024Q4.xlsx`\n\n| 고객명 | AWS Account ID | Account Alias | 환경 | OU 경로 | 생성일 | 담당 TAM |\n|--------|---------------|---------------|------|---------|--------|----------|\n| ABC Corp | 123456789012 | abc-prod | Production | /Customers/ABC | 2023-01-15 | 김철수 |\n| ABC Corp | 234567890123 | abc-dev | Development | /Customers/ABC | 2023-01-15 | 김철수 |\n| XYZ Inc | 345678901234 | xyz-prod | Production | /Customers/XYZ | 2023-03-22 | 이영희 |\n\n#### 📄 문서 4: 계정 인수 체크리스트 (기존 계정용)\n**파일명 예시**: `MSP-CHK-003_Account_Takeover_Checklist.pdf`\n\n```markdown\n## 기존 AWS 계정 관리 인수 체크리스트\n\n### Phase 1: 사전 평가 (Day 1-3)\n□ 현재 계정 소유자 확인\n□ 루트 계정 이메일 소유권 확인\n□ 기존 IAM 사용자/역할 인벤토리\n□ 활성 리소스 목록 작성\n□ 현재 월 비용 확인\n\n### Phase 2: 권한 이전 (Day 4-5)\n□ MSP 관리용 IAM 역할 생성 (OrganizationAccountAccessRole)\n□ 크로스 계정 신뢰 관계 설정\n□ 기존 관리자 권한 검토\n\n### Phase 3: 통합 (Day 6-10)\n□ AWS Organizations 초대 발송\n□ 고객 승인 후 조직 가입\n□ 적절한 OU로 이동\n□ SCP 적용 확인\n□ 모니터링 도구 연동\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 계정 구조 감사 (3-5일)\n\n```bash\n# AWS CLI를 사용한 Organizations 계정 목록 추출\naws organizations list-accounts --query 'Accounts[*].[Id,Name,Email,Status]' --output table\n\n# 각 계정의 태그 확인 (고객 식별용)\nfor account_id in $(aws organizations list-accounts --query 'Accounts[*].Id' --output text); do\n    echo \"Account: $account_id\"\n    aws organizations list-tags-for-resource --resource-id $account_id\ndone\n```\n\n**담당자**: Cloud Operations Lead  \n**산출물**: 현재 계정 목록 및 고객 매핑 현황 스프레드시트\n\n### Step 2: 격리 위반 사항 식별 (2-3일)\n\n다음 상황을 점검하고 문서화합니다:\n\n```\n⚠️ 위반 사례 체크리스트:\n□ 하나의 계정에 여러 고객의 EC2 인스턴스 존재\n□ S3 버킷 네이밍에서 여러 고객명 혼재\n□ 태그 기반으로만 고객 분리 (계정 분리 아님)\n□ 공유 VPC에 여러 고객 워크로드 배치\n```\n\n**담당자**: Security Team  \n**산출물**: 격리 위반 사항 보고서 및 개선 계획\n\n### Step 3: 정책 문서 작성 (5-7일)\n\n```markdown\n## 정책 문서 작성 체크포인트\n\n### 필수 섹션\n✅ 정책 목적 (Why)\n✅ 적용 범위 (Who/What)\n✅ 격리 원칙 (How)\n✅ 예외 사항 (SaaS 제품)\n✅ 역할과 책임 (RACI)\n✅ 절차 참조 (SOP 링크)\n✅ 버전 관리 및 승인 이력\n\n### 승인 체계\n- 작성자: Cloud Architect\n- 검토자: Security Officer\n- 승인자: CTO 또는 VP of Engineering\n```\n\n**담당자**: Cloud Architect + Compliance Team  \n**산출물**: 승인된 정책 문서 (PDF, 서명 포함)\n\n### Step 4: Control Tower 기반 계정 팩토리 구축 (7-10일)\n\n```python\n# Account Factory 커스터마이제이션 예시 (AWS CDK)\nfrom aws_cdk import (\n    aws_servicecatalog as sc,\n    aws_ssm as ssm,\n)\n\nclass AccountFactoryStack(Stack):\n    def __init__(self, scope, id, **kwargs):\n        super().__init__(scope, id, **kwargs)\n        \n        # 필수 태그 파라미터\n        customer_name = CfnParameter(self, \"CustomerName\",\n            type=\"String\",\n            description=\"고객사 이름 (필수)\"\n        )\n        \n        environment_type = CfnParameter(self, \"EnvironmentType\",\n            type=\"String\",\n            allowed_values=[\"Production\", \"Development\", \"Sandbox\"],\n            description=\"환경 유형\"\n        )\n        \n        # 계정 생성 시 자동 적용되는 기본 설정\n        # - CloudTrail 활성화\n        # - Config 활성화\n        # - GuardDuty 활성화\n        # - Security Hub 연동\n```\n\n**담당자**: Platform Engineering Team  \n**산출물**: 작동하는 Account Factory + 테스트 결과\n\n### Step 5: 계정 인수 프로세스 수립 (3-5일)\n\n```mermaid\ngraph TD\n    A[고객 계약 체결] --> B{기존 AWS 계정 보유?}\n    B -->|Yes| C[계정 인수 프로세스]\n    B -->|No| D[신규 계정 생성]\n    \n    C --> C1[사전 평가]\n    C1 --> C2[권한 이전]\n    C2 --> C3[Organizations 가입]\n    C3 --> E[모니터링 연동]\n    \n    D --> D1[Control Tower Account Factory]\n    D1 --> D2[OU 배치]\n    D2 --> E\n    \n    E --> F[고객 온보딩 완료]\n```\n\n**담당자**: Customer Success Team + Cloud Ops  \n**산출물**: 계정 인수 SOP 문서 + 체크리스트\n\n### Step 6: 증빙 자료 패키지 구성 (2-3일)\n\n```\n📁 PLAT-001_Evidence_Package/\n├── 📄 01_Policy/\n│   └── MSP-POL-001_Customer_Account_Isolation_Policy_v2.3.pdf\n├── 📄 02_Procedures/\n│   ├── MSP-SOP-012_Account_Provisioning_Procedure.pdf\n│   └── MSP-SOP-015_Account_Takeover_Procedure.pdf\n├── 📄 03_Registry/\n│   └── Customer_Account_Registry_2024Q4.xlsx\n├── 📄 04_Screenshots/\n│   ├── AWS_Organizations_Structure.png\n│   ├── Control_Tower_Dashboard.png\n│   └── Account_Factory_Configuration.png\n└── 📄 05_Audit_Logs/\n    └── Recent_Account_Creation_CloudTrail.json\n```\n\n**담당자**: Compliance Team  \n**산출물**: 정리된 증빙 자료 패키지\n\n---\n\n## 4. ⚠️",
      "language": "ko",
      "createdAt": "2026-01-07T01:54:20.155Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-002",
      "category": "Platform",
      "title": "솔루션 역량",
      "advice": "# PLAT-002: 솔루션 역량 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\n이 항목은 **AWS MSP의 핵심 기술 역량**을 직접적으로 검증합니다. 단순히 AWS 서비스를 사용할 줄 아는 것이 아니라, **고객의 비즈니스 요구사항을 AWS 아키텍처로 변환하는 설계 능력**을 증명해야 합니다. 감사관은 이 항목을 통해 파트너가 실제로 엔터프라이즈급 프로젝트를 수행할 역량이 있는지 판단합니다.\n\n### 🎯 감사관이 확인하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 | 검증 방법 |\n|--------|--------------|-----------|\n| **설계 체계성** | \"요구사항에서 아키텍처까지 논리적 흐름이 있는가?\" | 요구사항 → 설계 결정 → 아키텍처 다이어그램 연결 확인 |\n| **SA 인증자 검토** | \"현재 유효한 SA 인증 보유자가 실제로 검토했는가?\" | 승인자 이름 + 인증 번호 + 승인 일자 확인 |\n| **고객 독립성** | \"두 프로젝트가 실제로 다른 고객인가?\" | 고객사명, 산업군, 프로젝트 성격 비교 |\n| **구현 완료 여부** | \"설계가 실제로 구현되었는가?\" | 운영 중인 시스템 증거 또는 구현 완료 확인서 |\n| **18개월 기준 충족** | \"문서 작성일이 기준 내인가?\" | 문서 버전 히스토리, 타임스탬프 확인 |\n\n### 🔗 관련 AWS 서비스 및 도구\n\n- **AWS Architecture Icons**: 공식 아키텍처 다이어그램 작성\n- **AWS Well-Architected Tool**: 설계 검토 및 개선점 문서화\n- **AWS Trusted Advisor**: 설계 권장사항 근거 자료\n- **AWS Config**: 구현된 아키텍처 증빙\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 문서 세트 (고객당 1세트, 총 2세트)\n\n```\n📁 고객A_프로젝트명/\n├── 01_요구사항정의서_v1.2.pdf\n├── 02_상세설계서_v2.0.pdf\n├── 03_아키텍처다이어그램_v2.0.png (또는 .drawio)\n├── 04_SA인증자_검토승인서.pdf\n└── 05_구현완료확인서.pdf (선택적이나 권장)\n\n📁 고객B_프로젝트명/\n└── (동일 구조)\n```\n\n### 📄 각 문서별 필수 포함 내용\n\n#### 문서 1: 요구사항 정의서\n```markdown\n필수 섹션:\n□ 프로젝트 개요 (고객명, 프로젝트명, 기간)\n□ 비즈니스 요구사항 (최소 5개 이상 명시)\n□ 기술 요구사항 (성능, 가용성, 보안 수치 포함)\n□ 제약조건 (예산, 기존 시스템 연동, 컴플라이언스)\n□ 성공 기준 (측정 가능한 KPI)\n```\n\n**예시 - 기술 요구사항 작성:**\n```\nREQ-T-001: 시스템 가용성 99.95% 이상 (월간 다운타임 22분 미만)\nREQ-T-002: API 응답시간 P99 기준 200ms 이하\nREQ-T-003: 개인정보 암호화 (저장 시 AES-256, 전송 시 TLS 1.2+)\nREQ-T-004: 동시 접속자 10,000명 처리 가능\n```\n\n#### 문서 2: 상세 설계서\n```markdown\n필수 섹션:\n□ 설계 원칙 (Well-Architected Framework 6개 Pillar 기반)\n□ 아키텍처 개요 및 컴포넌트 설명\n□ 각 AWS 서비스 선정 근거 (왜 이 서비스인가?)\n□ 네트워크 설계 (VPC, 서브넷, 보안그룹 상세)\n□ 보안 설계 (IAM, 암호화, 로깅)\n□ 비용 추정 (AWS Pricing Calculator 기반)\n□ 요구사항 추적 매트릭스 (요구사항 ↔ 설계 요소 매핑)\n```\n\n**예시 - 서비스 선정 근거:**\n```\n| 요구사항 | 선택 서비스 | 선정 근거 | 대안 검토 |\n|---------|------------|----------|----------|\n| REQ-T-001 (99.95%) | Multi-AZ RDS | 자동 장애조치, SLA 보장 | Aurora 검토했으나 비용 대비 과잉 |\n| REQ-T-002 (200ms) | ElastiCache Redis | 인메모리 캐싱으로 DB 부하 감소 | DynamoDB DAX도 고려 |\n```\n\n#### 문서 3: SA 인증자 검토 승인서\n\n```markdown\n[설계 검토 승인서]\n\n프로젝트명: ○○○ 클라우드 마이그레이션\n고객사: ○○○ 주식회사\n설계 문서 버전: v2.0\n검토 일자: 2024-XX-XX\n\n검토자 정보:\n- 성명: 홍길동\n- AWS 인증: AWS Certified Solutions Architect - Professional\n- 인증 번호: AWS-XXXXXX (또는 Credly 배지 URL)\n- 인증 유효기간: 2023-XX-XX ~ 2026-XX-XX\n\n검토 결과: ☑ 승인 / ☐ 조건부 승인 / ☐ 반려\n\n검토 의견:\n- Well-Architected Framework 기준 적합성 확인\n- 고가용성 설계 적절함\n- 비용 최적화 추가 검토 권장 (Reserved Instance 적용 고려)\n\n서명: _________________\n```\n\n### 📎 증빙 자료 파일명 예시\n\n```\n✅ 좋은 예시:\n- ABC제조_ERP마이그레이션_요구사항정의서_v1.2_20240315.pdf\n- XYZ금융_실시간분석플랫폼_상세설계서_v2.0_20240420.pdf\n\n❌ 피해야 할 예시:\n- 설계서.pdf\n- customer_doc_final_final_v3.docx\n- 20240315.pdf\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### 🔄 전체 프로세스 (예상 4-6주)\n\n```\nWeek 1-2: 후보 프로젝트 선정 및 기존 문서 수집\nWeek 2-3: 문서 보완 및 표준화\nWeek 3-4: SA 인증자 검토 및 승인\nWeek 4-5: 최종 검토 및 제출 준비\nWeek 5-6: 버퍼 기간 (수정 대응)\n```\n\n### 📌 Step 1: 적합한 프로젝트 선정 (3-5일)\n\n**선정 기준 체크리스트:**\n```\n□ 18개월 이내 설계 완료 (2023년 1월 이후)\n□ 실제 구현 완료된 프로젝트\n□ 서로 다른 고객사 (계열사도 별도 고객으로 인정 가능)\n□ 최소 5개 이상 AWS 서비스 사용\n□ 문서화 수준이 양호한 프로젝트\n```\n\n**프로젝트 평가 매트릭스:**\n```\n| 프로젝트 | 고객 | 완료일 | 서비스 수 | 문서화 | 복잡도 | 선정 |\n|---------|-----|--------|----------|--------|--------|-----|\n| A사 마이그레이션 | A사 | 2024-02 | 12개 | 상 | 중 | ✅ |\n| B사 데이터레이크 | B사 | 2024-05 | 8개 | 중 | 상 | ✅ |\n| C사 웹서비스 | A사 계열 | 2024-03 | 4개 | 하 | 하 | ❌ |\n```\n\n### 📌 Step 2: 요구사항 문서 정비 (5-7일)\n\n**담당자:** 프로젝트 매니저 또는 비즈니스 분석가\n\n**작업 내용:**\n```\n1. 기존 제안서/RFP 응답서에서 요구사항 추출\n2. 비즈니스 요구사항 ↔ 기술 요구사항 분리\n3. 각 요구사항에 고유 ID 부여 (REQ-B-001, REQ-T-001 형식)\n4. 측정 가능한 수치로 변환 (예: \"빠른 응답\" → \"200ms 이하\")\n5. 고객 확인 또는 내부 승인 획득\n```\n\n**AWS 도구 활용:**\n- 기존 AWS Config 규칙에서 컴플라이언스 요구사항 추출\n- CloudWatch 대시보드에서 성능 요구사항 수치 확인\n\n### 📌 Step 3: 아키텍처 다이어그램 작성/갱신 (3-5일)\n\n**담당자:** 솔루션 아키텍트\n\n**필수 다이어그램 유형:**\n```\n1. 전체 시스템 아키텍처 (High-Level)\n2. 네트워크 토폴로지 (VPC, 서브넷, 라우팅)\n3. 데이터 흐름도 (Data Flow Diagram)\n4. 보안 아키텍처 (IAM, 암호화, 네트워크 보안)\n```\n\n**다이어그램 품질 기준:**\n```\n✅ AWS Architecture Icons 2024 버전 사용\n✅ 모든 AWS 서비스명 정확히 표기\n✅ 리전/AZ 경계 명확히 표시\n✅ 데이터 흐름 방향 화살표 포함\n✅ 범례(Legend) 포함\n✅ 버전 번호 및 작성일 표기\n```\n\n**도구 추천:**\n- draw.io (무료, AWS 아이콘 내장)\n- Lucidchart (협업 기능 우수)\n- AWS Application Composer (IaC 연동)\n\n### 📌 Step 4: 설계 결정 근거 문서화 (5-7일)\n\n**담당자:** 솔루션 아키텍트\n\n**핵심 작업 - ADR(Architecture Decision Record) 작성:**\n\n```markdown\n## ADR-001: 데이터베이스 선택\n\n### 상황 (Context)\n- 일일 트랜잭션 100만 건 처리 필요\n- 복잡한 JOIN 쿼리 다수 존재\n- 기존 Oracle에서 마이그레이션\n\n### 결정 (Decision)\nAmazon Aurora PostgreSQL 선택\n\n### 근거 (Rationale)\n1. PostgreSQL 호환으로 마이그레이션 용이\n2. 읽기 복제본 최대 15개로 읽기 확장성 확보\n3. 스토리지 자동 확장 (10GB ~ 128TB)\n4. Oracle 대비 1/10 비용\n\n### 검토한 대안\n- RDS Oracle: 라이선스 비용 과다\n- DynamoDB: 복잡한 JOIN 쿼리 부적합\n- Aurora MySQL: PostgreSQL 기능 필요\n\n### 결과 (Consequences)\n- 긍정: 비용 절감, 운영 자동화\n- 부정: Oracle 전용 기능 일부 재작성 필요\n```\n\n### 📌 Step 5: SA 인증자 검토 진행 (3-5일)\n\n**담당자:** AWS SA 인증 보유자\n\n**검토 프로세스:**\n```\n1. 검토자 자격 확인\n   - AWS Certified Solutions Architect (Associate 또는 Professional)\n   - 인증 유효기간 확인 (만료 시 갱신 필요)\n   - Credly 배지 URL 또는 인증서 사본 확보\n\n2. 검토 체크리스트 기반 검토\n   □ Well-Architected Framework 6개 Pillar 충족 여부\n   □ 요구사항 ↔ 설계 추적성\n   □ 보안 모범 사례 준수\n   □ 비용 최적화 고려\n   □ 운영 우수성 설계\n\n3. 검토 의견 및 승인서 작성\n   - 검토 일자 명시\n   - 구체적인 검토 의견 기재\n   - 서명 또는 전자 승인\n```\n\n**⚠️ 중요:** 검토자는 설계 작성자와 **다른 사람**이어야 합니다. 자기 검토는 인정되지 않습니다.\n\n### 📌 Step 6: 문서",
      "language": "ko",
      "createdAt": "2026-01-07T01:55:18.141Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-003",
      "category": "Platform",
      "title": "비기능적 요구사항",
      "advice": "# PLAT-003: 비기능적 요구사항 (Non-Functional Requirements) 상세 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n비기능적 요구사항(NFR)은 MSP의 **아키텍처 설계 성숙도**를 직접적으로 보여주는 핵심 지표입니다. AWS는 MSP 파트너가 단순히 기능 구현을 넘어서, 고객 시스템의 **성능, 확장성, 가용성을 정량적으로 정의하고 검증**할 수 있는 역량을 갖추길 기대합니다. 이는 AWS Well-Architected Framework의 운영 우수성, 성능 효율성, 안정성 기둥과 직접 연결됩니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관 질문 예시 | 기대하는 증빙 |\n|--------|------------------|---------------|\n| **정량적 목표 설정** | \"응답 시간 목표가 구체적인 숫자로 명시되어 있나요?\" | P95 응답시간 200ms 이하, 동시 사용자 10,000명 등 |\n| **SLA 연계성** | \"NFR이 고객과 합의된 SLA와 어떻게 연결되나요?\" | SLA 문서와 설계 문서 간 추적 가능성 |\n| **모니터링 전략** | \"이 목표를 어떻게 측정하고 모니터링하나요?\" | CloudWatch 대시보드, 알람 설정 명세 |\n| **검증 프로세스** | \"설계된 NFR을 어떻게 테스트했나요?\" | 부하 테스트 결과, 장애 복구 테스트 기록 |\n| **AWS 서비스 매핑** | \"NFR 달성을 위해 어떤 AWS 서비스를 선택했나요?\" | Auto Scaling 정책, Multi-AZ 구성 근거 |\n\n### 관련 AWS 서비스 및 기능\n\n```\n📊 모니터링/측정: CloudWatch Metrics, CloudWatch Logs Insights, X-Ray, \n                  CloudWatch Synthetics, Application Insights\n⚡ 성능/확장성: Auto Scaling, ElastiCache, CloudFront, Global Accelerator\n🔄 가용성/복원력: Multi-AZ, Cross-Region Replication, Route 53 Health Checks\n🧪 테스트/검증: AWS Fault Injection Simulator, Load Testing (외부 도구 연계)\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 구성\n\n**📁 고객 A 프로젝트 패키지**\n```\nCustomer_A_NFR_Package/\n├── 01_System_Design_Document_v2.1.pdf\n│   └── 섹션 4: 비기능적 요구사항 (15페이지 이상)\n├── 02_NFR_Specification_Matrix.xlsx\n├── 03_SLA_Agreement_Excerpt.pdf (민감정보 마스킹)\n├── 04_Monitoring_Architecture.pdf\n├── 05_Performance_Test_Report.pdf\n└── 06_CloudWatch_Dashboard_Screenshots/\n```\n\n**📁 고객 B 프로젝트 패키지**\n```\nCustomer_B_NFR_Package/\n├── 01_Technical_Design_Specification_v1.3.pdf\n├── 02_Capacity_Planning_Document.xlsx\n├── 03_Availability_Requirements_and_Design.pdf\n├── 04_Validation_Test_Results.pdf\n└── 05_Monitoring_Setup_Evidence/\n```\n\n### 각 증빙 자료에 포함되어야 할 핵심 내용\n\n#### 📄 상세 설계 문서 (System Design Document)\n\n```markdown\n## 필수 포함 섹션 구조\n\n### 4. 비기능적 요구사항 (Non-Functional Requirements)\n\n#### 4.1 성능 요구사항 (Performance Requirements)\n┌─────────────────────────────────────────────────────────────┐\n│ 항목              │ 목표값        │ 측정 방법      │ AWS 서비스  │\n├───────────────────┼───────────────┼────────────────┼─────────────┤\n│ API 응답시간(P95) │ < 200ms       │ X-Ray Trace    │ API Gateway │\n│ 페이지 로드 시간  │ < 3초         │ Synthetics     │ CloudFront  │\n│ 데이터베이스 쿼리 │ < 50ms        │ RDS Insights   │ Aurora      │\n│ 배치 처리 시간    │ < 2시간/일    │ Step Functions │ Lambda      │\n└─────────────────────────────────────────────────────────────┘\n\n#### 4.2 용량 요구사항 (Capacity Requirements)\n- 동시 사용자: 10,000명 (피크 시간 기준)\n- 일일 트랜잭션: 500만 건\n- 데이터 증가율: 월 20GB\n- Auto Scaling 정책: CPU 70% 기준 스케일 아웃\n\n#### 4.3 가용성 요구사항 (Availability Requirements)\n- 목표 가용성: 99.95% (연간 다운타임 4.38시간 이내)\n- RTO (복구 시간 목표): 15분\n- RPO (복구 시점 목표): 5분\n- 장애 조치 전략: Multi-AZ Active-Standby\n\n#### 4.4 SLA 연계\n[고객과 합의된 SLA 조항 참조 - 부록 A]\n\n#### 4.5 모니터링 전략\n[CloudWatch 대시보드 설계 - 섹션 7 참조]\n\n#### 4.6 검증 계획\n[성능 테스트 시나리오 - 부록 B]\n```\n\n#### 📊 NFR 명세 매트릭스 (Excel)\n\n```\n┌──────────────────────────────────────────────────────────────────────────────┐\n│ Sheet 1: Performance NFR Matrix                                               │\n├─────────┬──────────────┬─────────┬──────────────┬────────────┬───────────────┤\n│ NFR-ID  │ 요구사항     │ 목표값  │ 현재 달성값  │ 측정 도구  │ 담당 AWS 서비스│\n├─────────┼──────────────┼─────────┼──────────────┼────────────┼───────────────┤\n│ PERF-01 │ API 응답시간 │ <200ms  │ 145ms (P95)  │ X-Ray      │ API GW+Lambda │\n│ PERF-02 │ DB 쿼리 성능 │ <50ms   │ 32ms (avg)   │ RDS PI     │ Aurora MySQL  │\n│ PERF-03 │ 캐시 히트율  │ >90%    │ 94.2%        │ CloudWatch │ ElastiCache   │\n└─────────┴──────────────┴─────────┴──────────────┴────────────┴───────────────┘\n\n┌──────────────────────────────────────────────────────────────────────────────┐\n│ Sheet 2: Availability NFR Matrix                                              │\n├─────────┬──────────────┬─────────┬──────────────┬────────────┬───────────────┤\n│ NFR-ID  │ 요구사항     │ 목표값  │ 설계 달성값  │ 구현 방식  │ 검증 방법     │\n├─────────┼──────────────┼─────────┼──────────────┼────────────┼───────────────┤\n│ AVAIL-01│ 서비스 가용성│ 99.95%  │ 99.99%       │ Multi-AZ   │ 월간 리포트   │\n│ AVAIL-02│ RTO          │ <15분   │ 8분          │ Auto-failover│ DR 훈련     │\n│ AVAIL-03│ RPO          │ <5분    │ 1분          │ 동기 복제  │ 복구 테스트   │\n└─────────┴──────────────┴─────────┴──────────────┴────────────┴───────────────┘\n```\n\n#### 🧪 검증 테스트 결과 보고서\n\n```markdown\n## 성능 테스트 결과 보고서\n\n### 테스트 개요\n- 테스트 일자: 2024-XX-XX\n- 테스트 도구: Apache JMeter + CloudWatch\n- 테스트 환경: Production-equivalent (Staging)\n\n### 부하 테스트 시나리오\n┌─────────────────────────────────────────────────────┐\n│ 시나리오 1: 정상 부하 (Normal Load)                 │\n│ - 동시 사용자: 5,000명                              │\n│ - 지속 시간: 30분                                   │\n│ - 결과: P95 응답시간 142ms ✅ (목표: <200ms)        │\n├─────────────────────────────────────────────────────┤\n│ 시나리오 2: 피크 부하 (Peak Load)                   │\n│ - 동시 사용자: 10,000명                             │\n│ - 지속 시간: 15분                                   │\n│ - 결과: P95 응답시간 189ms ✅ (목표: <200ms)        │\n├─────────────────────────────────────────────────────┤\n│ 시나리오 3: 스트레스 테스트 (Stress Test)           │\n│ - 동시 사용자: 15,000명 (150% 초과)                 │\n│ - Auto Scaling 동작: 3분 내 인스턴스 추가 확인 ✅   │\n└─────────────────────────────────────────────────────┘\n\n### 장애 복구 테스트\n- AZ 장애 시뮬레이션: Route 53 Health Check 기반 8분 내 전환 ✅\n- 데이터베이스 장애 조치: Aurora 자동 장애 조치 45초 ✅\n```\n\n### 증빙 자료 예시 (실제 파일명)\n\n```\n✅ 좋은 예시:\n- \"ABC_Corp_E-Commerce_Platform_Technical_Design_v2.1_2024-03.pdf\"\n- \"XYZ_Healthcare_System_NFR_Specification_Matrix_Final.xlsx\"\n- \"ABC_Corp_Performance_Test_Report_LoadRunner_2024-04-15.pdf\"\n- \"XYZ_Healthcare_CloudWatch_Monitoring_Architecture.pdf\"\n\n❌ 피해야 할 예시:\n- \"설계문서.pdf\" (고객/프로젝트 식별 불가)\n- \"NFR_Template.docx\" (템플릿이 아닌 실제 문서 필요)\n- \"test_results.txt\" (정식 보고서 형식 필요)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 적격 프로젝트 선정 (1-2일)\n\n```\n🎯 선정 기준 체크리스트:\n□ 지난 18개월 이내 완료 또는 진행 중인 프로젝트\n□ 2개의 서로 다른 고객 (동일 고객의 2개 프로젝트는 불인정)\n□ AWS 인프라 기반 시스템 (온프레미스 전용 제외)\n□ 성능/가용성 요구사항이 명시적으로 정의된 프로젝트\n□ 실제 운영 환경에 배포된 시스템\n\n📋 프로젝트 후보 평가표:\n┌─────────────┬─────────┬─────────┬─────────┬─────────┬───────┐\n│ 프로젝트    │ 완료일  │ NFR 문서│ SLA 존재│ 테스트  │ 적합성│\n├─────────────┼─────────┼─────────┼─────────┼─────────┼───────┤\n│ A사 커머스  │ 2024-03 │ ✅      │ ✅      │ ✅      │ 적합  │\n│ B사 포털    │ 2024-01 │ ✅      │ ❌      │ ✅      │ 보완  │\n│ C사 데이터  │ 2023-06 │ ✅      │ ✅      │ ❌      │ 보완  │\n└─────────────┴─────────┴─────────┴─────────┴─────────┴───────┘\n```\n\n**담당자**: 프로젝트 매니저 / 아키텍트\n**산출물**: 프로젝트 선정 결과서\n\n---\n\n### Step 2: 기존 문서 NFR 섹션 감사 (3-5일)\n\n```\n🔍 기존 설계 문서 NFR 섹션 점검:\n\n각 프로젝트의 설계 문서에서 다음 항목 존재 여부 확인:\n\n[성능 요구사항]\n□ 응답 시간 목표 (구체적 수치 - ms 단위)\n□ 처리량 목표 (TPS, 동시 사용자 수)\n□ 리소스 사용률 기준 (CPU, 메모리 임계값)\n\n[용량 요구사항]  \n□ 초기 용량 산정 근거\n□ 성장 예측 및 확장 계획\n□ Auto Scaling 정책 명세\n\n[가용성 요구사항]\n□ 목표 가용성 (99.9%, 99.95% 등)\n□ RTO/RPO 정의\n□ 장애 조치",
      "language": "ko",
      "createdAt": "2026-01-07T01:56:10.707Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-004_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-004",
      "category": "Platform",
      "title": "Well-Architected",
      "advice": "# PLAT-004: Well-Architected 요구사항 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nWell-Architected는 MSP의 **기술적 역량을 직접적으로 증명**하는 핵심 항목입니다. AWS는 MSP 파트너가 단순히 인프라를 구축하는 것이 아니라, **AWS 모범 사례에 기반한 아키텍처 설계 능력**을 보유하고 있는지 검증합니다. 이 항목은 MSP가 고객에게 제공하는 서비스의 품질 수준을 가장 객관적으로 보여주는 증거입니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **6개 기둥 전체 고려** | 보안, 운영 우수성, 안정성, 성능 효율성, 비용 최적화, 지속 가능성이 모두 반영되었는가? |\n| **HRI 0개 달성** | 특히 보안/운영 우수성/안정성 3개 기둥에서 고위험 이슈가 완전히 해결되었는가? |\n| **실제 구현 증거** | 설계 문서가 실제로 구현된 시스템을 반영하는가? (계획서가 아닌 구현 결과) |\n| **고객 독립성** | 2개 고객이 실제로 별개의 독립적인 프로젝트인가? |\n| **18개월 이내** | 증빙 자료가 최근 18개월 내에 작성/업데이트되었는가? |\n\n### 🔗 관련 AWS 서비스 및 도구\n\n- **AWS Well-Architected Tool** - WAFR 수행 및 보고서 생성\n- **AWS Trusted Advisor** - 자동화된 모범 사례 점검\n- **AWS Config** - 리소스 구성 준수 확인\n- **AWS Security Hub** - 보안 상태 통합 대시보드\n- **AWS CloudFormation/Terraform** - IaC 기반 아키텍처 구현 증빙\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 옵션 A: 상세 설계 문서 (HLD/LLD)\n\n```\n📁 증빙 자료 구조\n├── 고객A_상세설계문서_v2.1_20240315.pdf\n│   ├── 아키텍처 다이어그램 (현재 구현 상태)\n│   ├── 6개 기둥별 설계 결정 사항\n│   ├── 구현된 AWS 서비스 목록 및 구성\n│   └── Well-Architected 매핑 테이블\n│\n└── 고객B_상세설계문서_v1.8_20240201.pdf\n    ├── (동일 구조)\n    └── ...\n```\n\n#### 📄 상세 설계 문서에 반드시 포함할 내용\n\n| 섹션 | 필수 포함 내용 | 감사관 체크 포인트 |\n|------|---------------|-------------------|\n| **Executive Summary** | 프로젝트 개요, 고객명(익명화 가능), 구현 완료일 | 18개월 이내 확인 |\n| **Architecture Diagram** | 현재 운영 중인 아키텍처 (draw.io, Lucidchart 등) | 실제 구현 여부 |\n| **보안 기둥** | IAM 정책, 암호화 전략, 네트워크 보안, 로깅 | HRI 0개 증명 |\n| **운영 우수성 기둥** | 모니터링, 알람, 자동화, 런북 | HRI 0개 증명 |\n| **안정성 기둥** | 백업, DR, 멀티AZ, Auto Scaling | HRI 0개 증명 |\n| **Well-Architected 매핑** | 각 설계 결정이 어떤 기둥/원칙에 해당하는지 | 의도적 설계 증명 |\n\n### 옵션 B: WAFR 보고서 (권장)\n\n```\n📁 WAFR 증빙 자료 구조\n├── 고객A_WAFR_Export_20240320.pdf\n│   ├── Workload Summary\n│   ├── Pillar별 점수 및 상태\n│   ├── High Risk Issues: 0개 (보안, 운영, 안정성)\n│   └── Improvement Plan (Medium/Low 이슈)\n│\n├── 고객B_WAFR_Export_20240215.pdf\n│   └── (동일 구조)\n│\n└── WAFR_수행_증빙_스크린샷/\n    ├── 고객A_WAT_Console_Screenshot.png\n    └── 고객B_WAT_Console_Screenshot.png\n```\n\n#### 🔴 WAFR 보고서 HRI 상태 예시\n\n```\n┌─────────────────────────────────────────────────────────┐\n│  Well-Architected Framework Review - 고객A Workload     │\n├─────────────────────────────────────────────────────────┤\n│  기둥              │ HRI │ MRI │ 상태                   │\n├─────────────────────────────────────────────────────────┤\n│  🔒 Security       │  0  │  2  │ ✅ 통과               │\n│  ⚙️ Ops Excellence │  0  │  1  │ ✅ 통과               │\n│  🛡️ Reliability    │  0  │  3  │ ✅ 통과               │\n│  ⚡ Performance    │  1  │  2  │ ⚠️ (HRI 허용)         │\n│  💰 Cost Optim.    │  2  │  4  │ ⚠️ (HRI 허용)         │\n│  🌱 Sustainability │  1  │  1  │ ⚠️ (HRI 허용)         │\n└─────────────────────────────────────────────────────────┘\n※ 보안, 운영 우수성, 안정성 3개 기둥만 HRI 0개 필수\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Phase 1: 대상 고객 선정 (1-2일)\n\n```\n🎯 선정 기준 체크리스트:\n□ 18개월 이내 구현 완료된 프로젝트\n□ 현재 운영 중인 워크로드 (구현만 하고 종료된 것 X)\n□ AWS 서비스를 충분히 활용 (EC2만 있는 단순 구성 X)\n□ 고객 동의 획득 가능 (NDA 또는 익명화 동의)\n□ 2개 고객이 명확히 다른 회사/프로젝트\n```\n\n**⚠️ 주의**: 같은 회사의 다른 프로젝트는 \"독립적인 고객\"으로 인정되지 않을 수 있습니다.\n\n### Phase 2: AWS Well-Architected Tool에서 WAFR 수행 (3-5일/고객)\n\n```bash\n# AWS Well-Architected Tool 접근 경로\nAWS Console → Well-Architected Tool → Define Workload → Start Review\n```\n\n#### 📋 WAFR 수행 시 필수 입력 정보\n\n| 필드 | 입력 예시 | 주의사항 |\n|------|----------|----------|\n| Workload Name | \"고객A-이커머스-플랫폼\" | 식별 가능한 명확한 이름 |\n| Description | 상세한 워크로드 설명 | 감사관이 맥락 이해 가능하도록 |\n| Environment | Production | 반드시 Production 선택 |\n| AWS Regions | ap-northeast-2 | 실제 운영 리전 |\n| Account IDs | 123456789012 | 실제 AWS 계정 |\n\n### Phase 3: HRI 식별 및 해결 (1-4주/고객)\n\n#### 🔴 보안 기둥 흔한 HRI와 해결책\n\n| HRI 질문 | 흔한 문제 | 해결 방법 |\n|----------|----------|----------|\n| SEC 1: 워크로드를 안전하게 운영하는 방법 | Root 계정 MFA 미설정 | Root MFA 활성화 + IAM Identity Center 구성 |\n| SEC 2: 사용자 ID 관리 | IAM User 직접 사용 | IAM Role + Identity Federation 전환 |\n| SEC 4: 보안 이벤트 감지 | CloudTrail 미활성화 | 모든 리전 CloudTrail + S3 로깅 |\n| SEC 9: 데이터 보호 | 미암호화 EBS/S3 | KMS 기반 암호화 적용 |\n\n#### ⚙️ 운영 우수성 기둥 흔한 HRI와 해결책\n\n| HRI 질문 | 흔한 문제 | 해결 방법 |\n|----------|----------|----------|\n| OPS 4: 워크로드 상태 이해 | 모니터링 부재 | CloudWatch Dashboard + 핵심 메트릭 알람 |\n| OPS 6: 배포 위험 완화 | 수동 배포 | CodePipeline/CodeDeploy 자동화 |\n| OPS 10: 운영 이벤트 관리 | 런북 부재 | 주요 장애 시나리오별 런북 작성 |\n\n#### 🛡️ 안정성 기둥 흔한 HRI와 해결책\n\n| HRI 질문 | 흔한 문제 | 해결 방법 |\n|----------|----------|----------|\n| REL 2: 네트워크 토폴로지 계획 | 단일 AZ 구성 | Multi-AZ 아키텍처 전환 |\n| REL 9: 데이터 백업 | 백업 정책 미수립 | AWS Backup 정책 + 복구 테스트 |\n| REL 11: 워크로드 복구 | DR 계획 부재 | RPO/RTO 정의 + DR 절차 문서화 |\n\n### Phase 4: WAFR 보고서 내보내기 (30분)\n\n```\nAWS Console → Well-Architected Tool → 해당 Workload 선택\n→ Generate Report → PDF 다운로드\n```\n\n#### 📄 내보내기 전 최종 확인\n\n```\n✅ 보안 기둥 HRI: 0개\n✅ 운영 우수성 기둥 HRI: 0개  \n✅ 안정성 기둥 HRI: 0개\n✅ Review Date: 18개월 이내\n✅ Workload Status: Active\n```\n\n### Phase 5: 보조 증빙 자료 준비 (2-3일)\n\n```\n📁 추가 증빙 (선택적이지만 권장)\n├── 아키텍처_다이어그램_고객A.png\n│   └── WAFR과 매칭되는 현재 아키텍처\n├── HRI_해결_이력.xlsx\n│   └── 발견된 HRI → 해결 조치 → 완료일\n└── 고객_승인서.pdf\n    └── 증빙 자료 제출 동의 (익명화 시에도 권장)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 감사 탈락 주요 원인\n\n#### 실수 1: \"계획\" 문서를 \"구현\" 문서로 제출\n\n```\n❌ 잘못된 예시:\n\"향후 Multi-AZ로 전환할 예정입니다\"\n\"암호화 적용을 검토 중입니다\"\n\n✅ 올바른 예시:\n\"2024년 1월 Multi-AZ 구성 완료 (ALB: arn:aws:elasticloadbalancing:...)\"\n\"모든 EBS 볼륨 KMS 암호화 적용 완료 (Key ID: alias/customer-a-key)\"\n```\n\n#### 실수 2: 3개 필수 기둥 외 HRI를 0개로 만들려고 시간 낭비\n\n```\n📊 HRI 허용 범위:\n┌────────────────────┬─────────────┐\n│ 기둥               │ HRI 허용    │\n├────────────────────┼─────────────┤\n│ 🔒 Security        │ 0개 필수    │\n│ ⚙️ Ops Excellence  │ 0개 필수    │\n│ 🛡️ Reliability     │ 0개 필수    │\n│ ⚡ Performance     │ 허용        │\n│ 💰 Cost Optim.     │ 허용        │\n│ 🌱 Sustainability  │ 허용        │\n└────────────────────┴─────────────┘\n```\n\n#### 실수 3: 동일 그룹사를 2개 독립 고객으로 제출\n\n```\n❌ 인정되지 않는 경우:\n- A홀딩스 자회사 B사 + A홀딩스 자회사 C사\n- 동일 고객의 개발환경 + 운영환경\n\n✅ 인정되는 경우:\n- 완전히 다른 회사 2개\n- 계약 관계가 별개인 2개 프로젝트\n```\n\n#### 실수 4: WAFR을 \"체크박스 채우기\"로 수행",
      "language": "ko",
      "createdAt": "2026-01-07T01:57:05.635Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-005_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-005",
      "category": "Platform",
      "title": "AWS 서비스 전문성",
      "advice": "# PLAT-005: AWS 서비스 전문성 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 중요한 이유\nAWS MSP는 단순히 EC2/RDS 같은 기본 서비스만 운영하는 것이 아니라, **AWS의 200개 이상 서비스를 고객 요구에 맞게 조합하여 최적의 아키텍처를 설계**할 수 있어야 합니다. 이 항목은 MSP가 \"진정한 클라우드 네이티브 전문가\"인지를 검증하는 핵심 관문입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 의도 |\n|------------|-------------------|\n| **서비스 선택의 합리성** | \"왜 Lambda가 아닌 ECS를 선택했나요?\" - 기술적 근거 확인 |\n| **서비스 간 통합 능력** | 개별 서비스 사용이 아닌 유기적 연결 설계 능력 |\n| **비즈니스 가치 연결** | 기술 선택이 고객의 비용/성능/보안에 미친 실제 영향 |\n| **제외 서비스 이해** | EC2, VPC, RDS, S3, EBS, IAM, CloudWatch, CloudTrail, CloudFormation은 \"기본\"으로 간주 |\n| **실제 프로덕션 적용** | PoC가 아닌 실제 운영 중인 워크로드인지 여부 |\n\n### 면제 조건 확인\n```\n✅ 면제 가능: AWS Competency 3개 이상 보유\n✅ 면제 가능: AWS Service Delivery 3개 이상 보유\n✅ 면제 가능: Competency + Service Delivery 조합 3개 이상\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 제출물: 2개의 고객 워크로드 케이스\n\n#### 📄 워크로드 케이스 문서 구조\n\n**파일명 예시:**\n- `PLAT-005_Workload1_[고객명]_실시간분석플랫폼_v1.2.pdf`\n- `PLAT-005_Workload2_[고객명]_서버리스결제시스템_v1.0.pdf`\n\n**각 문서에 반드시 포함할 내용:**\n\n```markdown\n📌 워크로드 케이스 #1 템플릿\n\n1. 고객 및 프로젝트 개요\n   - 고객사명 (익명화 가능: \"국내 대형 이커머스 A사\")\n   - 프로젝트 기간: 2023년 6월 ~ 2023년 12월\n   - 현재 운영 상태: 프로덕션 운영 중 (2024년 1월~)\n\n2. 비즈니스 요구사항\n   - 해결해야 할 비즈니스 문제\n   - 기존 아키텍처의 한계점\n   - 목표 KPI (응답시간, 비용, 가용성 등)\n\n3. 아키텍처 다이어그램\n   - Before/After 비교 다이어그램\n   - 사용된 AWS 서비스 명확히 표시\n\n4. AWS 서비스 활용 상세 (핵심!)\n   [서비스별 상세 기술]\n\n5. 구현 결과 및 비즈니스 성과\n   - 정량적 개선 수치\n   - 고객 피드백/승인 증빙\n```\n\n### 서비스 활용 상세 작성 예시\n\n**✅ 좋은 예시 (합격):**\n```\n📍 Amazon Kinesis Data Streams\n- 용도: 실시간 클릭스트림 데이터 수집\n- 구성: 4개 샤드, 24시간 보존\n- 처리량: 초당 4,000 레코드\n- 선택 이유: SQS 대비 순서 보장 필요, 실시간 처리 요구\n\n📍 AWS Glue\n- 용도: ETL 파이프라인 및 데이터 카탈로그\n- 구성: Glue Job 3개, Crawler 5개\n- 처리 데이터: 일 500GB 원본 데이터 변환\n- 선택 이유: 서버리스 ETL로 운영 부담 최소화, Spark 기반 대용량 처리\n```\n\n**❌ 나쁜 예시 (탈락):**\n```\nAmazon Kinesis - 데이터 스트리밍에 사용\nAWS Glue - ETL에 사용\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 면제 조건 우선 확인 (1일)\n\n```bash\n# AWS Partner Central에서 확인\nPartner Central > 프로그램 > 보유 자격 확인\n\n현재 보유 현황:\n□ AWS Competency: ___개\n□ AWS Service Delivery: ___개\n□ 합계: ___개\n\n→ 3개 이상이면 이 항목 SKIP 가능\n```\n\n### Step 2: 후보 워크로드 선별 (3-5일)\n\n**선별 기준 매트릭스:**\n\n| 평가 기준 | 가중치 | 워크로드A | 워크로드B | 워크로드C |\n|----------|--------|----------|----------|----------|\n| 제외 서비스 외 4개 이상 사용 | 필수 | ✅ | ✅ | ❌ |\n| 프로덕션 운영 중 | 높음 | ✅ | ✅ | ✅ |\n| 아키텍처 다이어그램 존재 | 높음 | ✅ | ❌ | ✅ |\n| 고객 승인 가능 | 높음 | ✅ | ✅ | ❌ |\n| 비즈니스 성과 측정 가능 | 중간 | ✅ | ✅ | ✅ |\n\n**제외 서비스 체크리스트:**\n```\n❌ 카운트 불가 (기본 서비스):\n- EC2, VPC, RDS, S3, EBS\n- IAM, CloudWatch, CloudTrail, CloudFormation\n\n✅ 카운트 가능 (전문 서비스 예시):\n- 컴퓨팅: Lambda, ECS, EKS, Fargate, Batch\n- 데이터베이스: DynamoDB, Aurora, ElastiCache, Neptune, DocumentDB\n- 분석: Athena, Kinesis, EMR, Glue, QuickSight, OpenSearch\n- AI/ML: SageMaker, Rekognition, Comprehend, Textract\n- 통합: SNS, SQS, EventBridge, Step Functions, API Gateway\n- 보안: Secrets Manager, KMS, WAF, Shield, GuardDuty\n- 기타: AppSync, Amplify, Cognito, Route 53, CloudFront\n```\n\n### Step 3: 서비스 사용 현황 추출 (2-3일)\n\n**AWS CLI를 활용한 서비스 사용 확인:**\n\n```bash\n# 특정 계정의 활성 서비스 확인 (Cost Explorer 활용)\naws ce get-cost-and-usage \\\n  --time-period Start=2024-01-01,End=2024-03-31 \\\n  --granularity MONTHLY \\\n  --metrics \"UsageQuantity\" \\\n  --group-by Type=DIMENSION,Key=SERVICE \\\n  --query 'ResultsByTime[].Groups[?Metrics.UsageQuantity.Amount>`0`].Keys[]' \\\n  --output table\n\n# CloudTrail에서 실제 API 호출 서비스 확인\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=EventSource,AttributeValue=lambda.amazonaws.com \\\n  --start-time 2024-01-01 \\\n  --end-time 2024-03-31\n```\n\n**AWS Config를 활용한 리소스 인벤토리:**\n```bash\n# 리소스 타입별 카운트\naws configservice get-discovered-resource-counts \\\n  --query 'resourceCounts[?count>`0`]' \\\n  --output table\n```\n\n### Step 4: 아키텍처 다이어그램 작성 (3-5일)\n\n**필수 포함 요소:**\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    아키텍처 다이어그램 체크리스트              │\n├─────────────────────────────────────────────────────────────┤\n│ □ AWS 공식 아이콘 사용 (2024 버전)                           │\n│ □ 각 서비스에 구체적 설정값 표시                              │\n│   예: \"DynamoDB - On-demand, GSI 2개\"                       │\n│ □ 데이터 흐름 화살표 및 프로토콜 표시                         │\n│   예: \"HTTPS\", \"gRPC\", \"Kinesis Stream\"                    │\n│ □ 리전/AZ 구분 명확히 표시                                   │\n│ □ 제외 서비스는 회색, 카운트 서비스는 컬러로 구분              │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**추천 도구:**\n- AWS Architecture Icons (공식): https://aws.amazon.com/architecture/icons/\n- draw.io with AWS shapes\n- Lucidchart AWS template\n- Cloudcraft (3D 다이어그램)\n\n### Step 5: 비즈니스 성과 데이터 수집 (2-3일)\n\n**정량적 성과 예시:**\n\n```markdown\n📊 성과 측정 항목\n\n| 지표 | Before | After | 개선율 |\n|------|--------|-------|--------|\n| API 응답시간 (p99) | 2,300ms | 180ms | 92% 감소 |\n| 월간 인프라 비용 | $45,000 | $28,000 | 38% 절감 |\n| 배포 빈도 | 월 2회 | 일 5회 | 75배 증가 |\n| 장애 복구 시간 | 4시간 | 15분 | 94% 단축 |\n```\n\n### Step 6: 고객 승인 및 익명화 처리 (3-5일)\n\n**고객 승인 요청 이메일 템플릿:**\n```\n제목: AWS MSP 인증 - 사례 활용 승인 요청\n\n[고객사명] 담당자님께,\n\n당사는 AWS MSP(Managed Service Provider) 인증을 \n준비 중이며, 귀사와 진행한 [프로젝트명] 사례를 \n인증 심사 자료로 활용하고자 합니다.\n\n활용 범위:\n- AWS 인증 심사관에게만 공개\n- 고객사명 익명화 가능 (예: \"국내 대형 제조사 A\")\n- 민감 정보 제외 (매출, 사용자 수 등)\n\n첨부된 자료 초안을 검토 후 승인 부탁드립니다.\n```\n\n### Step 7: 최종 문서화 및 검토 (3-5일)\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 탈락 원인 TOP 5\n\n#### 1. 제외 서비스를 카운트에 포함\n```\n❌ 잘못된 예:\n\"4개 서비스 사용: EC2, Lambda, DynamoDB, S3\"\n→ EC2, S3는 제외 서비스이므로 실제 2개만 인정\n\n✅ 올바른 예:\n\"4개 서비스 사용: Lambda, DynamoDB, API Gateway, Cognito\"\n→ 모두 카운트 가능\n```\n\n#### 2. 서비스 \"사용\"만 하고 \"활용\" 미입증\n```\n❌ 잘못된 예:\n\"SNS를 알림 전송에 사용했습니다\"\n\n✅ 올바른 예:\n\"SNS를 활용하여:\n- 3개 토픽으로 이벤트 유형별 분리\n- SQS와 연동하여 팬아웃 패턴 구현\n- 메시지 필터링으로 구독자별 맞춤 전달\n- 월 평균 500만 건 메시지 처리\"\n```\n\n#### 3. PoC/테스트 환경을 프로덕션으로 제출\n```\n감사관 확인 방법:\n- CloudWatch 메트릭의 트래픽 패턴 확인\n- 리소스 생성일과 활동 기간 확인\n- 비용 청구 내역 확인\n\n→ 최소 3개월 이상 프로덕션 운영 권장\n```\n\n#### 4. 두 워크로드가 너무 유사\n```\n❌ 피해야 할 패턴:\n- 워크로드 1: Lambda + API Gateway + DynamoDB + SNS\n- 워크로드 2: Lambda + API Gateway + DynamoDB + SQS\n→ 거의 동일한 서버리스 패턴\n\n✅ 권장 패턴:\n- 워크로드 1: 실시간 스트리밍 (Kinesis + Glue + Athena + QuickSight)\n- 워크로드 2: 컨테이너 기반 마이크로서비스 (EKS + AppMesh + X-Ray + Secrets Manager)\n→ 다양한 도메인 전문성 입증\n```\n\n#### 5. 아키텍처 선택 근거 부재\n```\n❌ 감사관 질문에 답변 불가:\nQ: \"왜 ECS가 아닌",
      "language": "ko",
      "createdAt": "2026-01-07T01:58:01.538Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLATP-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLATP-001",
      "category": "Platform",
      "title": "전문가 설계 검토",
      "advice": "# PLATP-001: 전문가 설계 검토 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n전문가 설계 검토는 AWS MSP의 **품질 보증 체계의 핵심**입니다. AWS는 MSP 파트너가 단순히 인프라를 구축하는 것이 아니라, **검증된 전문가의 검토를 거친 아키텍처**를 고객에게 제공하기를 요구합니다. 이는 고객이 MSP 파트너를 선택할 때 기대하는 \"전문성\"을 제도적으로 보장하는 장치입니다.\n\n### 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **정책의 명확성** | \"어떤 프로젝트에 어떤 수준의 인증자가 검토해야 하는지\" 기준이 모호하지 않은가? |\n| **검토자 자격 증명** | 검토를 수행한 사람이 실제로 해당 시점에 유효한 AWS 인증을 보유했는가? |\n| **검토 시점의 적절성** | 설계 검토가 구현 \"전\"에 이루어졌는가, 아니면 사후 형식적으로 진행했는가? |\n| **검토 깊이** | 단순 서명이 아닌, 실제 아키텍처에 대한 기술적 피드백이 있었는가? |\n| **예외 처리** | Professional/Specialty 검토가 필요한 경우의 기준이 정의되어 있고 준수되는가? |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS Well-Architected Tool**: 설계 검토 시 활용하면 검토의 체계성 증명\n- **AWS Certification 포털**: 검토자 인증 유효성 확인\n- **AWS Partner Central**: 파트너 인력의 인증 현황 관리\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 증빙 A: 설계 검토 정책 문서\n\n**파일명 예시**: `AWS_Design_Review_Policy_v2.1_2024.pdf`\n\n**포함되어야 할 핵심 내용**:\n\n```\n[정책 문서 필수 섹션]\n\n1. 목적 및 적용 범위\n   - 모든 AWS 고객 프로젝트에 적용됨을 명시\n   \n2. 검토자 자격 요건\n   - 기본: AWS Solutions Architect Associate 이상\n   - 상위 검토 필요 조건 (아래 예시)\n   \n3. Professional/Specialty 검토 필요 기준\n   ┌─────────────────────────────────────────────────────┐\n   │ • 월 예상 비용 $50,000 이상 프로젝트              │\n   │ • Multi-Region 또는 Hybrid 아키텍처               │\n   │ • 금융/의료 등 컴플라이언스 요구 산업             │\n   │ • 마이그레이션 대상 서버 100대 이상               │\n   │ • Machine Learning 또는 Data Analytics 워크로드   │\n   └─────────────────────────────────────────────────────┘\n\n4. 검토 프로세스 및 타이밍\n   - 설계 완료 후, 구현 시작 전 필수\n   \n5. 검토 기록 및 승인 절차\n   - 검토 결과 문서화 방법\n   - 승인 권한자 지정\n```\n\n#### 📄 증빙 B: 검토자 인증 현황 매트릭스\n\n**파일명 예시**: `Certified_Reviewer_Matrix_Q4_2024.xlsx`\n\n| 검토자명 | 인증 종류 | 인증 번호 | 취득일 | 만료일 | 검토 가능 프로젝트 유형 |\n|---------|----------|----------|--------|--------|----------------------|\n| 김OO | SA Professional | AWS-SAP-XXXXX | 2023-06-15 | 2026-06-15 | 전체 |\n| 이OO | SA Associate + Security Specialty | AWS-SAA-XXXXX | 2024-01-20 | 2027-01-20 | 보안 요구 프로젝트 |\n| 박OO | SA Associate | AWS-SAA-XXXXX | 2024-03-10 | 2027-03-10 | 일반 프로젝트 |\n\n#### 📄 증빙 C: 실제 프로젝트 설계 검토 기록 (최소 3건)\n\n**파일명 예시**: `Design_Review_CustomerA_ECommerce_Migration_2024Q3.pdf`\n\n**각 검토 기록에 포함되어야 할 내용**:\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    설계 검토 기록서                          │\n├─────────────────────────────────────────────────────────────┤\n│ 프로젝트명: [고객사] E-Commerce 플랫폼 AWS 마이그레이션     │\n│ 검토 일자: 2024-09-15                                       │\n│ 검토자: 김OO (AWS SA Professional, AWS-SAP-12345)          │\n│                                                             │\n│ [프로젝트 개요]                                             │\n│ - 예상 월 비용: $75,000                                     │\n│ - 아키텍처 유형: Multi-AZ, 3-Tier                          │\n│ - 적용 정책 기준: Professional 검토 필요 (비용 기준 충족)   │\n│                                                             │\n│ [검토 항목 및 피드백]                                       │\n│ 1. 고가용성: RDS Multi-AZ 구성 확인 ✓                      │\n│    → 피드백: Aurora로 변경 권고 (비용 대비 성능 우수)       │\n│                                                             │\n│ 2. 보안: WAF 규칙 검토 ✓                                   │\n│    → 피드백: Rate limiting 규칙 추가 필요                  │\n│                                                             │\n│ 3. 비용 최적화: Reserved Instance 계획 검토 ✓              │\n│    → 피드백: Savings Plans 병행 권고                       │\n│                                                             │\n│ [검토 결과]                                                 │\n│ ☑ 승인 (권고사항 반영 후)                                  │\n│ ☐ 조건부 승인                                              │\n│ ☐ 재검토 필요                                              │\n│                                                             │\n│ 검토자 서명: 김OO (전자서명)        일자: 2024-09-15       │\n│ 프로젝트 매니저 확인: 박OO          일자: 2024-09-16       │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 인증 보유 인력 현황 파악 (1일)\n\n**담당자**: HR 또는 기술 리더\n\n```bash\n# AWS Partner Central에서 확인할 사항\n1. Partner Central > 팀 > 인증 현황 메뉴 접속\n2. 현재 유효한 인증 보유자 목록 다운로드\n3. 인증별 만료일 확인 (감사 시점에 유효해야 함)\n```\n\n**⚠️ 주의**: 감사 시점 기준으로 최소 **SA Associate 2명 이상**, **SA Professional 또는 Specialty 1명 이상** 확보 권장\n\n### Step 2: Professional/Specialty 검토 기준 정의 (2일)\n\n**담당자**: 기술 리더 + 영업 리더\n\n실제 프로젝트 포트폴리오를 분석하여 현실적인 기준 수립:\n\n```\n[기준 수립 워크시트]\n\n지난 12개월 프로젝트 분석:\n- 총 프로젝트 수: 45건\n- 월 $50K 이상: 8건 (18%)\n- Multi-Region: 5건 (11%)\n- 컴플라이언스 요구: 12건 (27%)\n\n→ Professional 검토 대상 예상 비율: 약 30-35%\n→ 현재 Professional 인증자 수로 커버 가능한지 확인\n```\n\n### Step 3: 정책 문서 작성 (3일)\n\n**담당자**: 기술 리더\n\n**정책 문서 작성 시 필수 포함 문구**:\n\n```\n\"모든 AWS 고객 프로젝트의 설계는 구현 착수 전에 \nAWS Solutions Architect Associate 이상의 인증을 보유한 \n내부 전문가의 검토를 받아야 한다.\n\n다음 조건 중 하나 이상 해당 시, AWS Solutions Architect \nProfessional 또는 관련 Specialty 인증 보유자가 검토해야 한다:\n[구체적 조건 나열]\"\n```\n\n### Step 4: 검토 템플릿 및 워크플로우 구축 (2일)\n\n**담당자**: PMO 또는 프로세스 담당자\n\n**Confluence/SharePoint 템플릿 구성 예시**:\n\n```\n프로젝트 설계 검토 요청서\n├── 프로젝트 기본 정보 (자동 입력)\n├── 아키텍처 다이어그램 첨부 (필수)\n├── 예상 비용 산정서 첨부 (필수)\n├── Professional 검토 필요 여부 체크리스트\n├── 검토자 지정 (인증 정보 자동 표시)\n├── 검토 의견 작성란\n└── 전자 승인 워크플로우\n```\n\n### Step 5: 파일럿 프로젝트 3건 검토 수행 (1-2주)\n\n**담당자**: 지정된 검토자\n\n```\n[파일럿 선정 기준]\n- 1건: 일반 프로젝트 (SA Associate 검토)\n- 1건: 대형 프로젝트 (SA Professional 검토)\n- 1건: 보안/컴플라이언스 프로젝트 (Specialty 검토)\n```\n\n### Step 6: 검토 기록 품질 검증 (2일)\n\n**담당자**: 품질 담당자\n\n각 검토 기록이 다음을 포함하는지 확인:\n- 검토자의 인증 번호가 명시되어 있는가?\n- 검토 일자가 구현 시작일보다 이전인가?\n- 단순 \"승인\"이 아닌 구체적 피드백이 있는가?\n\n### Step 7: 증빙 패키지 구성 (1일)\n\n**최종 제출 폴더 구조**:\n\n```\nPLATP-001_Design_Review_Evidence/\n├── 01_Policy/\n│   └── AWS_Design_Review_Policy_v2.1_2024.pdf\n├── 02_Reviewer_Certification/\n│   ├── Certified_Reviewer_Matrix_Q4_2024.xlsx\n│   └── Certification_Screenshots/\n│       ├── Kim_SAP_Certificate.png\n│       ├── Lee_SAA_Security_Certificate.png\n│       └── Park_SAA_Certificate.png\n├── 03_Project_Reviews/\n│   ├── Review_CustomerA_ECommerce_2024Q3.pdf\n│   ├── Review_CustomerB_DataLake_2024Q3.pdf\n│   └── Review_CustomerC_SecurityAudit_2024Q4.pdf\n└── 04_Evidence_Summary.pdf\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: \"모든 프로젝트에 Professional 검토\" 정책\n\n```\n❌ 잘못된 예:\n\"모든 프로젝트는 SA Professional이 검토한다\"\n\n⭕ 올바른 예:\n\"기본적으로 SA Associate가 검토하며, \n다음 조건 시 Professional이 검토한다: [조건]\"\n```\n\n**문제점**: 감사관은 \"언제 Professional이 필요한지\"에 대한 **판단 기준**을 보고 싶어합니다. 모든 프로젝트에 Professional을 요구하면 기준이 없는 것으로 간주됩니다.\n\n### 🚫 실수 2: 검토 일자가 구현 완료 후\n\n```\n프로젝트 타임라인 예시:\n- 설계 완료: 2024-09-01\n- 구현 시작: 2024-09-05\n- 구현 완료: 2024-10-15\n- 설계 검토: 2024-10-20  ← ❌ 탈락 사유\n```\n\n**해결책**: 검토 일자는 반드시 구현 시작일 이전이어야 합니다. 정책에 \"구현 착수 전 검토 완료 필수\"를 명시하세요.\n\n### 🚫 실수 3: 검토 기록에 인증 번호 누락\n\n```\n❌ 잘못된 예:\n\"검토자: 김OO (AWS SA Professional)\"\n\n⭕ 올바른 예:\n\"검토자: 김OO (AWS SA Professional, 인증번호: AWS-SAP-12345, \n유효기간: 2023-06-15 ~ 2026-06-15)\"\n```",
      "language": "ko",
      "createdAt": "2026-01-07T01:33:50.619Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-001",
      "category": "Security",
      "title": "보안 정책 및 절차",
      "advice": "# SEC-001: 보안 정책 및 절차 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램의 첫 번째 관문인가?\n\nSEC-001은 AWS MSP 프로그램의 **기초 신뢰성 검증** 항목입니다. AWS는 파트너에게 고객의 클라우드 인프라 관리를 위임하기 전, 해당 파트너가 **자기 자신의 보안도 제대로 관리하지 못한다면 고객 환경은 더더욱 위험하다**는 전제로 이 항목을 평가합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 실제 질문 예시 |\n|------------|------------------------|\n| **경영진 승인 여부** | \"이 보안 정책을 승인한 임원의 직책과 승인 일자를 보여주세요\" |\n| **정책의 현행성** | \"마지막 검토/갱신일이 언제입니까? 1년 이내인가요?\" |\n| **MSP 업무 범위 포함** | \"고객 AWS 환경 접근 시 적용되는 보안 통제가 정책에 명시되어 있나요?\" |\n| **실제 이행 증거** | \"이 정책이 실제로 적용된 사례(로그, 기록)를 보여주세요\" |\n| **직원 인지 여부** | \"직원들이 이 정책을 알고 있다는 증거가 있나요?\" |\n\n### 관련 AWS 서비스 및 기능\n\n이 항목은 직접적인 AWS 서비스 사용보다는 **조직 거버넌스**에 초점이 맞춰져 있지만, 다음 서비스들이 정책 이행 증거로 활용됩니다:\n\n- **AWS Organizations** - 다중 계정 보안 정책 적용\n- **AWS IAM Identity Center** - 중앙화된 접근 관리\n- **AWS CloudTrail** - 정책 준수 감사 로그\n- **AWS Config** - 보안 정책 준수 상태 모니터링\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 옵션 A: 업계 인증 보유 시 (권장 - 가장 빠른 경로)\n\n```\n📁 제출 파일 구조\n├── ISO27001_Certificate_[회사명]_2024.pdf\n├── SOC2_Type2_Report_[회사명]_2023-2024.pdf\n└── Certification_Scope_Statement.pdf (인증 범위가 MSP 업무 포함 확인)\n```\n\n**⚠️ 핵심 체크포인트:**\n- 인증서의 **유효기간**이 감사일 기준 유효해야 함\n- 인증 **범위(Scope)**에 \"Managed Services\" 또는 \"Cloud Operations\" 명시 필수\n- SOC2의 경우 **Type II** 보고서 권장 (Type I은 추가 설명 필요)\n\n### 옵션 B: 인증 미보유 시 - 자체 보안 관리 체계 증명\n\n```\n📁 제출 파일 구조\n├── 01_Information_Security_Policy_v3.2.pdf\n├── 02_Policy_Approval_Record.pdf (경영진 서명 포함)\n├── 03_Security_Procedures/\n│   ├── Access_Control_Procedure.pdf\n│   ├── Incident_Response_Procedure.pdf\n│   ├── Change_Management_Procedure.pdf\n│   └── Data_Protection_Procedure.pdf\n├── 04_Policy_Review_Minutes_2024Q1.pdf\n├── 05_Employee_Acknowledgment_Records.xlsx\n└── 06_Implementation_Evidence/\n    ├── CloudTrail_Security_Events_Sample.json\n    └── IAM_Policy_Screenshots.pdf\n```\n\n### 각 증빙에 포함되어야 할 핵심 내용\n\n#### 📄 Information_Security_Policy (정보보안정책서)\n\n```markdown\n필수 포함 섹션:\n1. 목적 및 범위 - \"본 정책은 [회사명]의 MSP 서비스 제공 활동을 포함한다\"\n2. 역할과 책임 - CISO/보안담당자 명시\n3. 자산 분류 - 고객 AWS 환경을 \"기밀\" 등급으로 분류\n4. 접근 통제 원칙 - 최소 권한 원칙, MFA 필수 등\n5. 사고 대응 - 보안 사고 발생 시 절차\n6. 검토 주기 - \"본 정책은 연 1회 이상 검토한다\"\n7. 승인 - 대표이사/CISO 서명 및 날짜\n```\n\n#### 📄 Policy_Approval_Record (정책 승인 기록)\n\n```\n[실제 예시 형식]\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n정보보안정책 승인 기록서\n\n문서명: 정보보안정책 v3.2\n승인일: 2024년 1월 15일\n승인자: 홍길동 (대표이사) [서명]\n        김보안 (CISO) [서명]\n\n검토 이력:\n- 2024.01.10: 보안팀 내부 검토 완료\n- 2024.01.12: 경영진 검토회의 (회의록 별첨)\n- 2024.01.15: 최종 승인\n\n다음 검토 예정일: 2025년 1월\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### 1단계: 현재 보유 인증 확인 및 경로 결정 (1일)\n\n```bash\n# 의사결정 플로우차트\nISO 27001 또는 SOC2 보유?\n├── YES → 인증 범위에 MSP 업무 포함?\n│         ├── YES → 옵션 A 진행 (2주 소요)\n│         └── NO → 인증 범위 확장 또는 옵션 B 진행\n└── NO → 옵션 B 진행 (4-6주 소요)\n```\n\n**담당자:** 보안팀장 또는 컴플라이언스 담당자\n\n### 2단계: (옵션 B) 기존 보안 문서 인벤토리 작성 (2-3일)\n\n```\n체크리스트:\n□ 기존 정보보안정책 문서 위치 확인\n□ 마지막 갱신일 확인 (1년 초과 시 갱신 필요)\n□ 경영진 승인 기록 존재 여부\n□ 관련 절차서(Procedure) 목록화\n□ 직원 교육/인지 기록 확인\n```\n\n### 3단계: 정책 문서 갱신 또는 신규 작성 (1-2주)\n\n**AWS MSP 맥락에서 반드시 추가해야 할 내용:**\n\n```markdown\n## 5. 고객 클라우드 환경 관리 보안\n\n5.1 접근 통제\n- 고객 AWS 계정 접근 시 반드시 IAM Role 기반 임시 자격 증명 사용\n- 모든 접근은 AWS CloudTrail을 통해 로깅\n- 고객별 접근 권한은 분리된 IAM Policy로 관리\n\n5.2 자격 증명 관리\n- AWS Access Key는 90일마다 교체\n- Root 계정 사용 금지, MFA 필수 적용\n- AWS Secrets Manager를 통한 자격 증명 중앙 관리\n\n5.3 네트워크 보안\n- 고객 환경 접근은 지정된 VPN 또는 AWS Direct Connect만 허용\n- Security Group 변경 시 변경관리 절차 준수\n```\n\n### 4단계: 경영진 승인 획득 (3-5일)\n\n```\n필수 진행 사항:\n1. 경영진 브리핑 자료 준비 (AWS MSP 프로그램 개요 포함)\n2. 정책 검토 회의 개최 및 회의록 작성\n3. 공식 승인 문서에 서명 획득 (전자서명 가능)\n4. 승인 기록을 별도 문서로 보관\n```\n\n**💡 팁:** 승인 문서에 \"AWS MSP 프로그램 요구사항 충족을 위해 검토됨\" 문구 포함 시 감사관에게 명확한 메시지 전달\n\n### 5단계: 이행 증거 수집 (1주)\n\n```python\n# 수집해야 할 이행 증거 예시\n\n1. AWS CloudTrail 로그 샘플\n   - 최근 30일 내 보안 관련 이벤트\n   - IAM 정책 변경, 로그인 시도 등\n\n2. IAM 정책 스크린샷\n   - 최소 권한 원칙 적용 증거\n   - MFA 강제 정책\n\n3. 보안 교육 기록\n   - 교육 참석자 명단\n   - 교육 자료 (AWS 보안 관련 내용 포함)\n\n4. 정책 인지 확인서\n   - 직원 서명 또는 전자 확인 기록\n```\n\n### 6단계: 문서 패키징 및 품질 검토 (2-3일)\n\n```\n파일 명명 규칙:\n[회사명]_SEC-001_[문서유형]_[버전]_[날짜].pdf\n\n예시:\nCloudTech_SEC-001_SecurityPolicy_v3.2_20240115.pdf\nCloudTech_SEC-001_ApprovalRecord_v1.0_20240115.pdf\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 #1: 인증 범위 불일치\n\n```\n❌ 잘못된 경우:\nISO 27001 인증서 보유, 하지만 인증 범위가 \n\"본사 데이터센터 운영\"만 포함\n\n✅ 올바른 경우:\n인증 범위에 \"Cloud Managed Services\" 또는 \n\"AWS 기반 고객 인프라 관리 서비스\" 명시\n```\n\n**해결책:** 인증 기관에 범위 확장 요청 또는 Scope Statement 추가 발급\n\n### 🚫 실수 #2: 정책 문서의 \"죽은 문서\" 상태\n\n```\n❌ 감사 탈락 사례:\n- 정책서 마지막 갱신일: 2021년 3월\n- AWS 관련 내용 전무\n- \"클라우드\" 단어 언급 없음\n\n✅ 통과 사례:\n- 연간 검토 기록 존재 (검토 결과 \"변경 없음\"도 OK)\n- AWS 서비스명 구체적 언급\n- MSP 업무 맥락 반영\n```\n\n### 🚫 실수 #3: 승인 증거 부재\n\n```\n❌ 감사관 지적 사례:\n\"정책 문서는 있는데, 누가 언제 승인했는지 알 수 없습니다\"\n\n✅ 필수 포함 요소:\n- 승인자 이름 및 직책 (C-Level 또는 Director 이상)\n- 승인 일자\n- 서명 (물리적 또는 전자서명)\n- 다음 검토 예정일\n```\n\n### 🚫 실수 #4: 정책과 실제 운영의 괴리\n\n```\n❌ 감사 중 발견되는 문제:\n정책: \"모든 접근에 MFA 적용\"\n실제: IAM User 중 30%가 MFA 미설정\n\n✅ 사전 점검 방법:\naws iam generate-credential-report\naws iam get-credential-report --output text | grep -c \"false\"\n```\n\n### 🚫 실수 #5: 직원 인지 증거 누락\n\n```\n❌ 부족한 증거:\n\"직원들에게 이메일로 정책 공유했습니다\" (이메일만으로는 부족)\n\n✅ 충분한 증거:\n- 정책 인지 확인서 (직원 서명)\n- 보안 교육 수료증\n- 정책 퀴즈 통과 기록\n- 전자 시스템 \"읽음 확인\" 로그\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | 인증서 유효기간 | 인증서 만료일 확인 | 감사일 기준 유효 |\n| 2 | 인증/정책 범위 | Scope 문서에서 \"MSP\", \"Managed Services\", \"Cloud\" 키워드 검색 | 1개 이상 명시 |\n| 3 | 경영진 승인 | 승인 문서에서 서명, 직책, 날짜 확인 | 3가지 모두 존재 |\n| 4 | 문서 현행성 | 마지",
      "language": "ko",
      "createdAt": "2026-01-07T01:59:00.161Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-002",
      "category": "Security",
      "title": "보안 인식 교육 및 테스트",
      "advice": "# SEC-002: 보안 인식 교육 및 테스트 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\nAWS MSP 파트너는 고객의 클라우드 인프라에 직접 접근하는 권한을 가집니다. **단 한 명의 직원이 피싱 메일에 속아도** 고객사 전체 AWS 환경이 위험에 노출될 수 있습니다. 이 항목은 \"기술적 보안\"이 아닌 **\"인적 보안\"**의 최소 기준선을 검증합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 관점 |\n|------------|--------------|\n| **교육 대상 범위** | MSP 업무 관련 전 직원이 포함되었는가? (개발자, 운영자, PM, 영업 포함) |\n| **교육 완료 시점** | 감사일 기준 12개월 이내에 완료되었는가? |\n| **교육 내용 적절성** | 클라우드/AWS 환경에 맞는 보안 위협을 다루는가? |\n| **완료 검증 방법** | 단순 수강이 아닌 테스트/퀴즈를 통한 이해도 확인이 있는가? |\n| **신규 입사자 처리** | 입사 후 30일 이내 교육 완료 프로세스가 있는가? |\n\n### 관련 AWS 서비스 및 리소스\n\n- **AWS Security Awareness Training** (https://learnsecurity.amazon.com/) - AWS 공식 무료 교육\n- **AWS Skill Builder** - 보안 관련 추가 학습 경로\n- **AWS Partner Central** - MSP 직원 등록 및 관리\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 세트\n\n```\n📁 SEC-002_보안인식교육/\n├── 01_교육완료현황_마스터리스트.xlsx\n├── 02_개인별_수료증/\n│   ├── 홍길동_AWS_Security_Awareness_Certificate_2024.pdf\n│   ├── 김철수_AWS_Security_Awareness_Certificate_2024.pdf\n│   └── ... (전 직원)\n├── 03_교육프로그램_커리큘럼.pdf\n├── 04_보안교육정책서.pdf\n└── 05_신규입사자_교육완료_증빙/ (해당 시)\n```\n\n### 각 증빙 자료 핵심 내용\n\n**① 교육완료현황 마스터리스트 (Excel)**\n```\n| 직원명 | 사번 | 부서 | 직책 | MSP역할 | 교육명 | 완료일 | 유효기간 | 점수 | 수료증번호 |\n|--------|------|------|------|---------|--------|--------|----------|------|------------|\n| 홍길동 | E001 | 클라우드사업부 | 시니어엔지니어 | 기술지원 | AWS Security Awareness | 2024-03-15 | 2025-03-14 | 92/100 | CERT-2024-0315 |\n```\n\n**② 개인별 수료증 요건**\n- 교육 제공 기관명 (AWS/제3자 기관)\n- 수강자 성명 (회사 이메일과 매칭 가능해야 함)\n- 교육 과정명\n- 완료 날짜\n- 테스트 점수 또는 Pass/Fail 표시\n\n**③ 교육 프로그램 커리큘럼 (AWS Learn Security 사용 시)**\n```markdown\nAWS Security Awareness Training 커리큘럼:\n- Module 1: 피싱 및 소셜 엔지니어링 (30분)\n- Module 2: 비밀번호 및 인증 보안 (20분)\n- Module 3: 데이터 보호 및 분류 (25분)\n- Module 4: 물리적 보안 (15분)\n- Module 5: 인시던트 보고 (20분)\n- Final Assessment: 20문항 퀴즈 (80% 이상 통과)\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: MSP 직원 범위 정의 (1일)\n\n**담당자**: HR + MSP 사업부장\n\n```\n✅ MSP 업무 관련 직원 범위 정의 기준:\n- AWS 콘솔/CLI 접근 권한 보유자 → 필수\n- 고객 AWS 계정 정보 접근자 → 필수  \n- MSP 프로젝트 PM/PL → 필수\n- MSP 영업/프리세일즈 → 필수\n- 경영진 (MSP 사업 의사결정자) → 필수\n- 백오피스 (재무/법무) → 선택적\n```\n\n> ⚠️ **주의**: \"개발자는 운영 안 하니까 제외\"는 감사에서 지적받는 대표적 실수입니다.\n\n---\n\n### Step 2: 교육 플랫폼 선택 및 계정 설정 (1-2일)\n\n**옵션 A: AWS Learn Security (권장)**\n```\n1. https://learnsecurity.amazon.com/ 접속\n2. 회사 도메인 이메일로 계정 생성\n3. \"AWS Security Awareness\" 과정 등록\n4. 관리자 대시보드 접근 권한 요청 (선택)\n```\n\n**옵션 B: 자체/제3자 교육 프로그램**\n```\n인정되는 대안:\n- KnowBe4 Security Awareness Training\n- SANS Security Awareness\n- Proofpoint Security Awareness\n- 자체 개발 프로그램 (아래 요건 충족 시)\n\n자체 프로그램 필수 요건:\n☐ 클라우드 환경 보안 위협 포함\n☐ AWS 특화 내용 포함 (IAM, S3 버킷 노출 등)\n☐ 최소 60분 이상 교육 시간\n☐ 평가 테스트 포함 (통과 기준 명시)\n☐ 수료증 발급 기능\n```\n\n---\n\n### Step 3: 전사 교육 실시 (2-4주)\n\n**실행 계획 예시**\n```\nWeek 1: 공지 및 계정 생성\n- 전사 메일 발송: 교육 목적, 기한, 방법 안내\n- 각 직원 learnsecurity.amazon.com 계정 생성 확인\n\nWeek 2-3: 교육 수강 기간\n- 매주 월요일 미수강자 리마인더 발송\n- 부서장에게 부서별 진행률 공유\n\nWeek 4: 마감 및 미수강자 처리\n- 미수강자 개별 연락\n- 불가피한 사유 시 대체 일정 협의\n```\n\n**진행률 추적 템플릿**\n```\n| 부서 | 대상인원 | 완료 | 진행중 | 미시작 | 완료율 |\n|------|----------|------|--------|--------|--------|\n| 클라우드사업부 | 15 | 12 | 2 | 1 | 80% |\n| 기술지원팀 | 8 | 8 | 0 | 0 | 100% |\n```\n\n---\n\n### Step 4: 수료증 수집 및 검증 (3-5일)\n\n**수료증 수집 방법**\n```python\n# 자동화 스크립트 예시 (Google Apps Script / Python)\n1. 교육 완료 시 자동으로 수료증 PDF를 공유 폴더에 업로드\n2. 파일명 규칙: {이름}_{교육명}_{완료일}.pdf\n3. 마스터리스트와 자동 매칭 검증\n```\n\n**수동 검증 체크포인트**\n```\n☐ 수료증의 이름이 재직자 명단과 일치\n☐ 완료일이 감사일 기준 12개월 이내\n☐ 테스트 점수가 통과 기준 이상\n☐ 수료증 위변조 여부 (원본 URL 확인 가능 시)\n```\n\n---\n\n### Step 5: 신규 입사자 프로세스 문서화 (1일)\n\n**보안교육정책서에 포함할 내용**\n```markdown\n## 4.2 신규 입사자 보안 인식 교육\n\n### 적용 대상\n- MSP 사업부 배치 전 직원\n\n### 교육 완료 기한\n- 입사일로부터 30일 이내\n\n### 프로세스\n1. 입사 첫 주: HR에서 교육 플랫폼 계정 발급\n2. 입사 2주차: 교육 수강 시작\n3. 입사 30일: 교육 완료 및 수료증 제출\n4. 미완료 시: 부서장 에스컬레이션 → AWS 접근 권한 제한\n\n### 기록 관리\n- 수료증: SharePoint/보안교육/신규입사자/ 폴더에 보관\n- 마스터리스트: 입사 즉시 추가, 완료 시 업데이트\n```\n\n---\n\n### Step 6: 증빙 자료 패키징 (1일)\n\n**폴더 구조 및 파일명 규칙**\n```\nSEC-002_보안인식교육_증빙_v1.0/\n├── README.txt (증빙 자료 설명)\n├── 01_MSP직원_교육완료현황_20241115.xlsx\n├── 02_수료증_전체.zip\n│   └── (개인별 PDF 파일들)\n├── 03_AWS_Security_Awareness_커리큘럼.pdf\n├── 04_[회사명]_보안교육정책서_v2.1.pdf\n└── 05_신규입사자_교육완료_증빙.zip (해당 시)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 감사 탈락 주요 원인\n\n| 실수 유형 | 구체적 사례 | 해결책 |\n|-----------|-------------|--------|\n| **대상자 누락** | \"인프라팀만 교육하고 개발팀은 제외\" | MSP 프로젝트 참여 전 인원 전수 포함 |\n| **유효기간 만료** | 2023년 1월 교육 → 2024년 3월 감사 시 만료 | 감사 3개월 전 갱신 교육 실시 |\n| **테스트 미포함** | 영상 시청만 하고 퀴즈 없는 교육 | 평가 테스트가 포함된 프로그램 선택 |\n| **수료증 불일치** | 수료증 이름과 재직자 명단 불일치 | 영문명/한글명 통일, 결혼 후 개명 확인 |\n| **신규 입사자 공백** | 입사 2개월 된 직원 교육 미완료 | 30일 이내 완료 정책 수립 및 이행 |\n\n### 🔴 피해야 할 안티패턴\n\n```\n❌ \"교육 수료증은 있는데 누가 MSP 직원인지 정의가 없음\"\n   → 감사관: \"이 사람이 왜 교육 대상인지 설명해주세요\"\n\n❌ \"자체 교육인데 AWS/클라우드 보안 내용이 없음\"\n   → 감사관: \"일반 정보보안 교육은 MSP 요건 충족 불가\"\n\n❌ \"수료증이 스크린샷 캡처본\"\n   → 감사관: \"원본 PDF 또는 검증 가능한 형태 요청\"\n\n❌ \"퇴사자 수료증도 포함되어 있음\"\n   → 감사관: \"현재 재직자 기준으로 다시 정리 요청\"\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|-----------|-----------|-----------|\n| 1 | MSP 직원 전원 포함 여부 | HR 재직자 명단 vs 교육완료 명단 대조 | 100% 일치 |\n| 2 | 교육 완료일 유효성 | 각 수료증 날짜 확인 | 감사일 기준 12개월 이내 |\n| 3 | 테스트/평가 포함 여부 | 수료증에 점수 또는 Pass 표시 확인 | 전원 통과 기록 있음 |\n| 4 | 교육 내용 적절성 | 커리큘럼에 클라우드/AWS 보안 포함 | 최소 1개 모듈 이상 |\n| 5 | 신규 입사자 프로세스 | 정책서에 30일 이내 완료 조항 | 문서화 완료 |\n| 6 | 수료증-재직자 매칭 | 이름, 이메일 일치 여부 | 100% 매칭 |\n| 7 | 파일 무결성 | PDF 열림 여부, 파일 손상 확인 | 전체",
      "language": "ko",
      "createdAt": "2026-01-07T01:59:58.752Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-003_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-003",
      "category": "Security",
      "title": "AWS 계정 구성",
      "advice": "# SEC-003: AWS 계정 구성 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\nAWS MSP 프로그램에서 SEC-003은 **파트너의 보안 운영 성숙도를 직접적으로 평가하는 핵심 항목**입니다. MSP가 고객 환경을 안전하게 관리할 수 있는 기본 역량이 있는지를 증명해야 합니다.\n\n이 항목은 단순히 \"보안 설정을 했다\"가 아니라, **모든 관리 계정에 일관된 보안 기준을 적용하고 지속적으로 모니터링하는 체계**가 있는지를 검증합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 |\n|--------|---------------|\n| **표준화된 보안 기준선** | \"부록 A의 모든 항목이 귀사의 보안 표준에 포함되어 있습니까?\" |\n| **가시성 확보** | \"전체 Organization의 보안 상태를 한눈에 볼 수 있는 대시보드가 있습니까?\" |\n| **예외 관리 프로세스** | \"High/Critical 발견사항에 대한 완화 계획과 수정 일정이 문서화되어 있습니까?\" |\n| **적용 범위** | \"관리하는 모든 고객 계정에 동일한 기준이 적용되고 있습니까?\" |\n| **지속적 모니터링** | \"새로운 발견사항이 생겼을 때 어떻게 대응합니까?\" |\n\n### 관련 AWS 서비스\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    AWS Security Hub (핵심)                   │\n│  - AWS Foundational Security Best Practices 표준 활성화      │\n│  - CIS AWS Foundations Benchmark 표준 활성화                │\n│  - 통합 대시보드 및 발견사항 집계                             │\n└─────────────────────────────────────────────────────────────┘\n         │                    │                    │\n         ▼                    ▼                    ▼\n┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐\n│   AWS Config    │  │   GuardDuty     │  │    IAM Access   │\n│   Rules         │  │   Findings      │  │    Analyzer     │\n└─────────────────┘  └─────────────────┘  └─────────────────┘\n         │                    │                    │\n         └────────────────────┼────────────────────┘\n                              ▼\n                    ┌─────────────────┐\n                    │  AWS Organizations │\n                    │  (위임 관리자)     │\n                    └─────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 보안 기준선 정의서\n**파일명 예시:** `MSP_Security_Baseline_Standard_v2.3.pdf`\n\n```markdown\n포함 필수 내용:\n├── 1. 부록 A 항목별 매핑 테이블\n│   ├── 부록 A 항목 ID\n│   ├── 귀사 보안 통제 ID\n│   ├── 구현 방법 (AWS 서비스/도구)\n│   └── 검증 방법\n│\n├── 2. 계정 보안 구성 체크리스트\n│   ├── Root 계정 MFA 활성화\n│   ├── Root 계정 Access Key 비활성화\n│   ├── CloudTrail 전 리전 활성화\n│   ├── S3 퍼블릭 액세스 차단\n│   ├── EBS 기본 암호화 활성화\n│   ├── IAM 암호 정책 설정\n│   └── VPC Flow Logs 활성화\n│\n└── 3. 신규 계정 온보딩 시 적용 절차\n```\n\n#### 📊 문서 2: Security Hub 대시보드 스크린샷\n**파일명 예시:** `SecurityHub_Dashboard_20240115_AllAccounts.png`\n\n```\n필수 캡처 화면:\n1. Security Hub > Summary 페이지 (전체 Organization 뷰)\n2. Security standards > Compliance score (FSBP, CIS)\n3. Findings by severity 차트\n4. Accounts with most findings 목록\n5. 각 멤버 계정별 보안 점수 테이블\n```\n\n#### 📋 문서 3: High/Critical 발견사항 완화 계획서\n**파일명 예시:** `Security_Findings_Remediation_Plan_Q1_2024.xlsx`\n\n| Finding ID | 심각도 | 영향 계정 | 발견사항 설명 | 완화 조치 | 담당자 | 목표 완료일 | 상태 |\n|------------|--------|-----------|---------------|-----------|--------|-------------|------|\n| arn:aws:securityhub:ap-northeast-2:123456789012:finding/abc123 | CRITICAL | prod-account-01 | Root account MFA not enabled | MFA 디바이스 등록 예정 | 김보안 | 2024-01-20 | In Progress |\n| arn:aws:securityhub:ap-northeast-2:234567890123:finding/def456 | HIGH | dev-account-03 | S3 bucket policy allows public access | 버킷 정책 수정 및 퍼블릭 액세스 차단 | 박클라우드 | 2024-01-25 | Planned |\n\n#### 📈 문서 4: 보안 점수 추이 리포트\n**파일명 예시:** `Security_Compliance_Trend_Report_6months.pdf`\n\n```\n포함 내용:\n- 최근 6개월 Security Hub 보안 점수 추이 그래프\n- 월별 High/Critical 발견사항 수 변화\n- 주요 개선 활동 타임라인\n- 목표 대비 달성률\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: Security Hub 중앙 집중화 구성 (2-3일)\n\n```bash\n# Management Account에서 Security Hub 위임 관리자 설정\naws securityhub enable-organization-admin-account \\\n    --admin-account-id 111122223333\n\n# 위임 관리자 계정에서 자동 활성화 설정\naws securityhub update-organization-configuration \\\n    --auto-enable \\\n    --auto-enable-standards\n```\n\n**확인 사항:**\n- [ ] 모든 멤버 계정에서 Security Hub 자동 활성화 확인\n- [ ] AWS Foundational Security Best Practices 표준 활성화\n- [ ] CIS AWS Foundations Benchmark 표준 활성화\n- [ ] Cross-Region aggregation 설정 (모든 리전 데이터 집계)\n\n### Step 2: 부록 A 항목별 구현 상태 점검 (3-5일)\n\n**부록 A 최소 보안 구성 체크리스트:**\n\n```\n┌────────────────────────────────────────────────────────────────┐\n│ 부록 A 항목                    │ 검증 방법                      │\n├────────────────────────────────────────────────────────────────┤\n│ 1. Root MFA 활성화             │ IAM > Security credentials    │\n│ 2. Root Access Key 없음        │ Credential Report 확인        │\n│ 3. CloudTrail 전 리전 활성화    │ CloudTrail > Trails          │\n│ 4. CloudTrail 로그 암호화       │ Trail 설정 > SSE-KMS         │\n│ 5. S3 퍼블릭 액세스 차단        │ S3 > Block Public Access     │\n│ 6. EBS 기본 암호화             │ EC2 > EBS encryption         │\n│ 7. IAM 암호 정책               │ IAM > Account settings       │\n│ 8. VPC Flow Logs              │ VPC > Flow logs              │\n│ 9. GuardDuty 활성화            │ GuardDuty > Settings         │\n│ 10. Config 활성화              │ Config > Settings            │\n└────────────────────────────────────────────────────────────────┘\n```\n\n### Step 3: 자동화된 보안 점검 스크립트 실행 (1-2일)\n\n```python\n# security_baseline_checker.py\nimport boto3\n\ndef check_security_baseline(account_id):\n    \"\"\"각 계정의 보안 기준선 준수 상태 확인\"\"\"\n    \n    results = {\n        'account_id': account_id,\n        'checks': []\n    }\n    \n    # Root MFA 확인\n    iam = boto3.client('iam')\n    account_summary = iam.get_account_summary()\n    root_mfa = account_summary['SummaryMap']['AccountMFAEnabled']\n    results['checks'].append({\n        'control': 'Root MFA',\n        'status': 'PASS' if root_mfa == 1 else 'FAIL'\n    })\n    \n    # CloudTrail 확인\n    cloudtrail = boto3.client('cloudtrail')\n    trails = cloudtrail.describe_trails()\n    multi_region_trail = any(\n        t['IsMultiRegionTrail'] for t in trails['trailList']\n    )\n    results['checks'].append({\n        'control': 'Multi-Region CloudTrail',\n        'status': 'PASS' if multi_region_trail else 'FAIL'\n    })\n    \n    return results\n```\n\n### Step 4: Security Hub 대시보드 구성 및 캡처 (1일)\n\n**대시보드 캡처 순서:**\n\n1. **전체 요약 화면**\n   - Security Hub > Summary\n   - 필터: \"All accounts in organization\"\n   - 스크린샷 저장\n\n2. **표준별 준수율**\n   - Security standards 탭\n   - FSBP 점수 캡처\n   - CIS Benchmark 점수 캡처\n\n3. **심각도별 발견사항**\n   - Findings 탭\n   - 필터: Severity = CRITICAL, HIGH\n   - 전체 목록 Export (CSV)\n\n### Step 5: High/Critical 발견사항 완화 계획 수립 (2-3일)\n\n```\n완화 계획 작성 프로세스:\n┌─────────────────────────────────────────────────────────────┐\n│ 1. Security Hub에서 CRITICAL/HIGH 발견사항 Export           │\n│    └─> Findings > Filter by Severity > Download            │\n├─────────────────────────────────────────────────────────────┤\n│ 2. 각 발견사항 분류                                         │\n│    ├─> 즉시 수정 가능 (1주 이내)                            │\n│    ├─> 계획 수정 필요 (1개월 이내)                          │\n│    └─> 위험 수용 (비즈니스 정당성 문서화)                    │\n├─────────────────────────────────────────────────────────────┤\n│ 3. 완화 계획서 작성                                         │\n│    ├─> 발견사항별 담당자 지정                               │\n│    ├─> 구체적 수정 단계 기술                                │\n│    └─> 목표 완료일 설정                                     │\n├─────────────────────────────────────────────────────────────┤\n│ 4. 위험 수용 항목 승인                                      │\n│    └─> CISO/보안 책임자 서명 필수                           │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### Step 6: 보안 기준선 문서 최종화 (2일)\n\n**문서 구조:**\n\n```markdown\n# [회사명] AWS 계정 보안 기준선 표준\n\n## 1. 목적 및 범위\n- 적용 대상: 관리하는 모든 고객 AWS 계정\n- 최종 수정일: 2024-01-15\n- 버전: 2.3\n\n## 2. AWS MSP 부록 A 매핑\n\n| 부록 A 항목 | 당사 통제 ID | 구현 상태 | 검증 주기 |\n|-------------|--------------|-----------|-----------|\n| Root MFA    | SEC-IAM-001  | 구현 완료  | 일간      |\n| ...         | ...          | ...       | ...       |\n\n## 3. 계정 온보딩 보안 체크리스트\n[체크리스트 상세 내용]\n\n## 4. 예외 처리 절차\n[예외 승인 프로세스]\n\n## 5. 모니터링 및 보고\n[Security Hub 대시보드 운영 절차]\n```\n\n### Step 7: 증빙 패키지 최종 조립 (1일)\n\n```\n📁 SEC-003_Evidence_Package/\n├── 📄 01_Security_Baseline_Standard_v2.3.pdf\n├── 📄 02_Appendix_A_Mapping_Table.xlsx\n├── 📁 03_SecurityHub_Screenshots/\n│   ├── Summary_Dashboard_20240115.png\n│   ├── FSBP_Compliance_Score.png\n│   ├── CIS_Benchmark_Score.png\n│   └── Findings_By_Severity.png\n├── 📄 04_Critical_High_Findings_List.csv\n├── 📄 05_Remediation_Plan_Q1_2024.xlsx\n├── 📄 06_Risk_Acceptance_Approvals.pdf\n└── 📄 07_Compliance_Trend_Report_6months.pdf\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 부분적인 Organization 커버리지\n\n```\n❌ 잘못된 예:\n\"10개 계정 중 8개만 Security Hub에 연결됨\"",
      "language": "ko",
      "createdAt": "2026-01-07T02:00:50.903Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-004_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-004",
      "category": "Security",
      "title": "신원 및 액세스 관리",
      "advice": "# SEC-004: 신원 및 액세스 관리 (Identity and Access Management)\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nAWS MSP 파트너는 수십~수백 개의 고객 AWS 계정에 접근 권한을 가지게 됩니다. 중앙 집중식 IdP(Identity Provider) 없이 개별 IAM 사용자로 관리할 경우, **퇴사자 계정 미삭제, 권한 과다 부여, 감사 추적 불가** 등 심각한 보안 사고로 이어질 수 있습니다. AWS는 MSP 파트너가 고객 자산을 안전하게 관리할 수 있는 성숙한 IAM 체계를 갖추고 있는지 검증합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관 질문 예시 |\n|------------|-----------------|\n| **단일 진실 공급원(Single Source of Truth)** | \"직원이 퇴사하면 모든 AWS 계정 접근이 자동으로 차단되나요?\" |\n| **Federation 구현** | \"고객 계정 접근 시 IAM User가 아닌 IAM Role을 통한 임시 자격증명을 사용하나요?\" |\n| **MFA 강제** | \"IdP 레벨에서 MFA가 필수로 적용되어 있나요?\" |\n| **세션 관리** | \"임시 자격증명의 유효 시간은 얼마이며, 어떻게 설정했나요?\" |\n| **접근 로깅** | \"누가 언제 어떤 고객 계정에 접근했는지 추적 가능한가요?\" |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS IAM Identity Center (구 AWS SSO)**: 중앙 집중식 접근 관리의 핵심\n- **AWS Organizations**: 다중 계정 구조의 기반\n- **IAM Roles for Cross-Account Access**: 고객 계정 접근 메커니즘\n- **AWS CloudTrail**: 접근 감사 로그\n- **외부 IdP 연동**: Okta, Azure AD, Google Workspace, OneLogin 등\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n| 증빙 유형 | 파일명 예시 | 형식 |\n|----------|------------|------|\n| **IdP 아키텍처 다이어그램** | `SEC-004_IdP_Architecture_Diagram_v2.1.pdf` | PDF/PNG |\n| **인증 흐름 시연 영상** | `SEC-004_Authentication_Demo_20240115.mp4` | MP4 (5-10분) |\n| **IdP 설정 스크린샷** | `SEC-004_Okta_AWS_Integration_Config.pdf` | PDF |\n| **IAM Identity Center 설정 증빙** | `SEC-004_IAM_Identity_Center_Settings.pdf` | PDF |\n| **MFA 정책 문서** | `SEC-004_MFA_Enforcement_Policy.pdf` | PDF |\n| **접근 로그 샘플** | `SEC-004_Access_Audit_Log_Sample.csv` | CSV/JSON |\n\n### 각 증빙에 포함되어야 할 핵심 내용\n\n#### 🎬 인증 흐름 시연 영상 (가장 중요)\n```\n시연 시나리오 (권장 순서):\n1. [0:00-1:00] IdP 로그인 화면에서 회사 계정으로 로그인\n2. [1:00-2:00] MFA 챌린지 완료 (Authenticator 앱 또는 하드웨어 키)\n3. [2:00-3:30] AWS 앱 포털에서 고객 계정 목록 확인\n4. [3:30-5:00] 특정 고객 계정 선택 → AWS Console 자동 로그인\n5. [5:00-6:30] AWS Console에서 임시 자격증명 확인 (STS GetCallerIdentity)\n6. [6:30-8:00] CloudTrail에서 해당 로그인 이벤트 확인\n7. [8:00-9:00] 세션 만료 또는 로그아웃 시연\n```\n\n#### 📊 IdP 아키텍처 다이어그램 필수 요소\n```\n[Corporate IdP] ──SAML/OIDC──▶ [AWS IAM Identity Center]\n      │                                    │\n      │                                    ▼\n      │                         [Permission Sets]\n      │                                    │\n      ▼                                    ▼\n[HR System] ◀──동기화──▶ [User Groups] ──▶ [Customer Account A]\n                                          [Customer Account B]\n                                          [Customer Account C]\n                                          [Internal Account]\n```\n\n#### 🔐 MFA 정책 문서 포함 내용\n- MFA 적용 범위 (전 직원 필수)\n- 허용되는 MFA 방식 (TOTP, FIDO2, 하드웨어 토큰)\n- MFA 분실/재설정 절차\n- 예외 처리 프로세스 (있다면)\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 IdP 환경 인벤토리 작성 (1-2일)\n\n```bash\n# 확인해야 할 항목 체크리스트\n□ 현재 사용 중인 IdP 솔루션 (Okta/Azure AD/Google Workspace/기타)\n□ IdP에 등록된 AWS 애플리케이션 수\n□ AWS Organizations 내 계정 수\n□ IAM Identity Center 활성화 여부\n□ 기존 IAM User로 관리되는 계정 존재 여부\n```\n\n**담당자**: 보안팀 + 인프라팀  \n**산출물**: `IdP_Inventory_Checklist.xlsx`\n\n### Step 2: AWS IAM Identity Center 구성 (3-5일)\n\n```yaml\n# IAM Identity Center 설정 체크리스트\nIdentity Source 설정:\n  - [ ] External IdP 연동 (SAML 2.0 또는 SCIM)\n  - [ ] Attribute Mapping 구성 (email, firstName, lastName, groups)\n  - [ ] Automatic Provisioning 활성화\n\nPermission Sets 생성:\n  - [ ] MSP-Admin (AdministratorAccess)\n  - [ ] MSP-ReadOnly (ReadOnlyAccess)  \n  - [ ] MSP-SecurityAudit (SecurityAudit)\n  - [ ] MSP-Billing (Billing)\n  - [ ] Custom Permission Sets (고객별 요구사항)\n\nSession Duration 설정:\n  - [ ] 최대 세션 시간: 4시간 이하 권장\n  - [ ] 재인증 요구 주기 설정\n```\n\n**담당자**: 클라우드 아키텍트  \n**AWS 도구**: AWS IAM Identity Center Console, AWS CLI\n\n### Step 3: 고객 계정 연동 구성 (2-3일/계정당)\n\n```bash\n# 각 고객 계정에서 실행할 작업\n# 1. Organization에 계정 초대 또는 생성\naws organizations invite-account-to-organization \\\n    --target Id=123456789012,Type=ACCOUNT\n\n# 2. IAM Identity Center에서 계정 할당\naws sso-admin create-account-assignment \\\n    --instance-arn arn:aws:sso:::instance/ssoins-xxx \\\n    --target-id 123456789012 \\\n    --target-type AWS_ACCOUNT \\\n    --permission-set-arn arn:aws:sso:::permissionSet/ssoins-xxx/ps-xxx \\\n    --principal-type GROUP \\\n    --principal-id \"MSP-Engineers-Group-ID\"\n```\n\n**담당자**: 고객 온보딩팀  \n**산출물**: 계정별 연동 완료 체크리스트\n\n### Step 4: MFA 강제 정책 구현 (1-2일)\n\n```json\n// Okta Sign-On Policy 예시\n{\n  \"name\": \"AWS Access - MFA Required\",\n  \"conditions\": {\n    \"app\": {\n      \"include\": [\"AWS IAM Identity Center\"]\n    }\n  },\n  \"actions\": {\n    \"signon\": {\n      \"requireFactor\": true,\n      \"factorPromptMode\": \"ALWAYS\",\n      \"allowedFactors\": [\"TOTP\", \"FIDO2_WEBAUTHN\"]\n    }\n  }\n}\n```\n\n**Azure AD Conditional Access 예시**:\n- 대상: AWS IAM Identity Center 앱\n- 조건: 모든 사용자\n- 제어: MFA 필수, 준수 디바이스 필수\n\n### Step 5: 감사 로깅 구성 (1-2일)\n\n```bash\n# CloudTrail에서 IAM Identity Center 이벤트 확인\naws cloudtrail lookup-events \\\n    --lookup-attributes AttributeKey=EventSource,AttributeValue=sso.amazonaws.com \\\n    --start-time 2024-01-01T00:00:00Z \\\n    --end-time 2024-01-15T23:59:59Z\n\n# 주요 모니터링 이벤트\n- Authenticate (로그인)\n- Federate (역할 수임)\n- CreateAccountAssignment (권한 변경)\n- DeleteAccountAssignment (권한 제거)\n```\n\n**담당자**: 보안팀  \n**AWS 도구**: CloudTrail, CloudWatch Logs, SIEM 연동\n\n### Step 6: 시연 영상 녹화 (반나절)\n\n```\n녹화 도구: OBS Studio, Loom, 또는 화면 녹화 소프트웨어\n해상도: 1920x1080 권장\n음성: 각 단계 설명 나레이션 포함 권장\n\n녹화 전 체크리스트:\n□ 테스트 계정 준비 (실제 고객 데이터 노출 금지)\n□ 브라우저 북마크/히스토리 정리\n□ 알림 끄기\n□ 화면에 민감 정보 없는지 확인\n```\n\n### Step 7: 문서화 및 제출 준비 (1-2일)\n\n**담당자**: 기술 문서 담당자  \n**예상 총 소요 시간**: 2-3주\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 자주 발생하는 실수\n\n| 실수 유형 | 문제점 | 해결책 |\n|----------|--------|--------|\n| **IAM User 병행 사용** | \"긴급 상황용\" IAM User가 여전히 존재 | Break-glass 계정도 IdP 연동하거나, 사용 시 알림 설정 |\n| **MFA 예외 허용** | \"VPN 접속 시 MFA 면제\" 정책 | 모든 AWS 접근에 MFA 필수, 예외 없음 |\n| **세션 시간 과다 설정** | 12시간 또는 무제한 세션 | 최대 4시간, 민감 작업은 1시간 권장 |\n| **그룹 기반 관리 미흡** | 개인별 권한 할당 | 역할 기반 그룹으로 권한 관리 |\n| **퇴사자 처리 지연** | IdP 비활성화 후 AWS 접근 가능 | SCIM 자동 프로비저닝으로 즉시 동기화 |\n\n### 🔴 감사 탈락 주요 원인\n\n1. **\"고객 계정 중 일부는 아직 IAM User로 접근합니다\"**\n   - 모든 관리 대상 계정이 중앙 IdP를 통해야 함\n   - 레거시 계정도 마이그레이션 완료 필요\n\n2. **\"IdP와 AWS 간 자동 동기화가 설정되어 있지 않습니다\"**\n   - 수동 프로비저닝은 불충분\n   - SCIM 또는 자동화된 동기화 필수\n\n3. **\"MFA가 IdP에서 선택 사항입니다\"**\n   - AWS 접근에 대해 MFA 100% 강제 필요\n\n4. **\"시연에서 실제 인증 흐름을 보여주지 못함\"**\n   - 아키텍처 문서만으로는 불충분\n   - 실제 로그인 → 고객 계정 접근 시연 필수\n\n### 🚨 피해야 할 안티패턴\n\n```\n❌ 안티패턴 1: Root 계정 공유\n\"긴급 상황을 위해 root 계정 비밀번호를 팀 공유 문서에 저장\"\n→ Root 계정은 MFA 설정 후 봉인, 접근 시 알림 설정\n\n❌ 안티패턴 2: 장기 자격증명 사용\n\"스크립트 실행을 위해 Access Key를 환경변수에 저장\"\n→ IAM Roles Anywhere 또는 임시 자격증명 사용\n\n❌ 안티패턴 3: 권한 분리 미흡\n\"모든 엔지니어에게 AdministratorAccess 부여\"\n→ 최소 권한 원칙에 따른 Permission Set 세분화\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | **IdP 연동 완료** | IAM Identity Center > Identity source 확인 | External identity provider 표시 |\n| 2 | **모든 계정 연동** | IAM Identity Center > AWS accounts ",
      "language": "ko",
      "createdAt": "2026-01-07T02:01:49.145Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-005_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-005",
      "category": "Security",
      "title": "정책 관리",
      "advice": "# SEC-005: 정책 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\nIAM 정책 관리는 AWS 환경의 **보안 기반**입니다. MSP가 고객 환경을 관리할 때 과도한 권한(Over-privileged access)은 데이터 유출, 리소스 남용, 규정 위반의 직접적인 원인이 됩니다. AWS는 MSP 파트너가 **최소 권한 원칙(Least Privilege)**을 체계적으로 검증하고 있는지 확인하려 합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 포인트 | 감사관의 질문 |\n|--------|--------------|\n| **🔍 정기적 검토 주기** | \"IAM 정책 검토가 12개월 내에 실제로 수행되었는가?\" |\n| **🛠️ 도구 활용** | \"IAM Access Analyzer를 단순히 활성화만 했는가, 실제로 findings를 분석했는가?\" |\n| **📊 기준선 설정** | \"그룹/역할 멤버십의 '정상 상태'가 정의되어 있는가?\" |\n| **🔄 조치 이력** | \"발견된 과도한 권한에 대해 실제로 수정 조치를 했는가?\" |\n| **📈 개선 추적** | \"검토 결과가 시간에 따라 개선되고 있는가?\" |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    필수 서비스                               │\n├─────────────────────────────────────────────────────────────┤\n│ • IAM Access Analyzer (External Access / Unused Access)     │\n│ • IAM Policy Simulator                                      │\n│ • AWS Organizations (SCP 분석용)                            │\n├─────────────────────────────────────────────────────────────┤\n│                    보조 서비스                               │\n├─────────────────────────────────────────────────────────────┤\n│ • AWS Config (iam-policy-* 규칙들)                          │\n│ • AWS CloudTrail (정책 변경 이력)                           │\n│ • AWS Security Hub (IAM 관련 findings)                      │\n│ • IAM Credential Report                                     │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 증빙 1: IAM Access Analyzer 검토 보고서\n**파일명 예시:** `IAM-Access-Analyzer-Review-Report-2024-Q3.pdf`\n\n**포함 내용:**\n```markdown\n1. 검토 일자: 2024년 9월 15일\n2. 검토 범위: \n   - AWS 계정: 123456789012, 234567890123 (총 5개 계정)\n   - Analyzer 유형: External Access Analyzer, Unused Access Analyzer\n3. 발견 사항 요약:\n   - External Access Findings: 12건\n   - Unused Access Findings: 47건\n4. 조치 결과:\n   - 해결됨: 52건\n   - 아카이브(예외 처리): 7건 (사유 명시)\n5. 검토자: 홍길동 (보안팀 리드)\n6. 승인자: 김철수 (CISO)\n```\n\n#### 📄 증빙 2: 그룹/역할 멤버십 기준선 문서\n**파일명 예시:** `IAM-Baseline-Group-Role-Membership-2024.xlsx`\n\n**포함 내용:**\n| IAM 그룹/역할 | 허용된 멤버십 기준 | 현재 멤버 수 | 검토 결과 |\n|--------------|-------------------|-------------|----------|\n| Admin-Group | CTO, CISO, DevOps Lead만 | 3명 | ✅ 정상 |\n| Developer-Role | 개발팀 정규직만 | 15명 | ⚠️ 1명 퇴사자 발견 |\n| ReadOnly-Role | 모든 직원 | 45명 | ✅ 정상 |\n\n#### 📄 증빙 3: 정책 권한 분석 결과\n**파일명 예시:** `IAM-Policy-Permission-Analysis-2024Q3.pdf`\n\n**포함 내용:**\n```json\n{\n  \"분석_대상_정책\": 127,\n  \"과도한_권한_발견\": [\n    {\n      \"정책명\": \"LegacyDevPolicy\",\n      \"문제\": \"s3:* 전체 권한\",\n      \"권장_조치\": \"특정 버킷으로 제한\",\n      \"조치_완료일\": \"2024-09-20\"\n    }\n  ],\n  \"Admin_권한_정책\": 5,\n  \"Wildcard_Action_사용\": 23\n}\n```\n\n#### 📄 증빙 4: IAM Access Analyzer 콘솔 스크린샷\n**파일명 예시:** `IAM-Access-Analyzer-Console-Screenshots-2024Q3.zip`\n\n**필수 스크린샷:**\n1. Access Analyzer 대시보드 (Analyzer 목록)\n2. External Access Findings 목록 (날짜 표시)\n3. Unused Access Findings 목록\n4. 해결된 Finding 상세 화면\n5. 아카이브된 Finding과 사유\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: IAM Access Analyzer 활성화 및 구성 (Day 1-2)\n\n```bash\n# AWS CLI로 Access Analyzer 생성\naws accessanalyzer create-analyzer \\\n    --analyzer-name \"MSP-External-Access-Analyzer\" \\\n    --type ACCOUNT \\\n    --tags Key=Purpose,Value=MSP-Audit\n\n# Unused Access Analyzer 생성 (Organizations 필요)\naws accessanalyzer create-analyzer \\\n    --analyzer-name \"MSP-Unused-Access-Analyzer\" \\\n    --type ORGANIZATION_UNUSED_ACCESS \\\n    --configuration '{\"unusedAccess\": {\"unusedAccessAge\": 90}}'\n```\n\n**담당자:** 클라우드 보안 엔지니어  \n**예상 소요 시간:** 2-4시간\n\n---\n\n### Step 2: 기준선(Baseline) 정의 (Day 3-5)\n\n**그룹 멤버십 기준선 템플릿:**\n\n```markdown\n## IAM 그룹 멤버십 기준선\n\n### 1. Administrators 그룹\n- **허용 대상:** C-Level, IT Director, Security Lead\n- **최대 인원:** 5명\n- **검토 주기:** 월 1회\n- **승인 권한자:** CISO\n\n### 2. Developers 그룹  \n- **허용 대상:** 정규직 개발자\n- **최대 인원:** 제한 없음\n- **검토 주기:** 분기 1회\n- **승인 권한자:** Engineering Manager\n\n### 3. ReadOnly 그룹\n- **허용 대상:** 전 직원\n- **최대 인원:** 제한 없음\n- **검토 주기:** 반기 1회\n```\n\n**담당자:** 보안팀 + HR팀 협업  \n**예상 소요 시간:** 1-2일\n\n---\n\n### Step 3: Access Analyzer Findings 수집 및 분석 (Day 6-10)\n\n```python\n# Python 스크립트로 Findings 추출\nimport boto3\nimport pandas as pd\nfrom datetime import datetime\n\nclient = boto3.client('accessanalyzer')\n\n# External Access Findings 수집\nfindings = []\npaginator = client.get_paginator('list_findings_v2')\n\nfor page in paginator.paginate(analyzerArn='arn:aws:access-analyzer:...'):\n    for finding in page['findings']:\n        findings.append({\n            'id': finding['id'],\n            'resourceType': finding['resourceType'],\n            'resource': finding['resource'],\n            'status': finding['status'],\n            'createdAt': finding['createdAt'],\n            'condition': finding.get('condition', {})\n        })\n\n# Excel로 내보내기\ndf = pd.DataFrame(findings)\ndf.to_excel(f'IAM-Findings-{datetime.now().strftime(\"%Y%m%d\")}.xlsx')\n```\n\n**담당자:** 보안 엔지니어  \n**예상 소요 시간:** 3-5일\n\n---\n\n### Step 4: 발견 사항 조치 및 문서화 (Day 11-20)\n\n**조치 우선순위 매트릭스:**\n\n```\n┌────────────────────┬─────────────────┬─────────────────┐\n│                    │   영향도 높음    │   영향도 낮음    │\n├────────────────────┼─────────────────┼─────────────────┤\n│ 긴급도 높음        │ 🔴 즉시 조치    │ 🟡 1주 내 조치   │\n│ (Public Access)    │ (24시간 내)     │                 │\n├────────────────────┼─────────────────┼─────────────────┤\n│ 긴급도 낮음        │ 🟡 1주 내 조치   │ 🟢 다음 검토 시  │\n│ (Cross-Account)    │                 │                 │\n└────────────────────┴─────────────────┴─────────────────┘\n```\n\n**조치 기록 양식:**\n```markdown\n## Finding 조치 기록\n\n**Finding ID:** f-1234567890\n**발견일:** 2024-09-15\n**리소스:** arn:aws:s3:::company-data-bucket\n**문제:** S3 버킷이 외부 AWS 계정에 공개됨\n\n**조치 내용:**\n1. 버킷 정책에서 외부 계정 Principal 제거\n2. S3 Block Public Access 활성화\n3. 버킷 소유자에게 통보 및 확인\n\n**조치 완료일:** 2024-09-16\n**검증 방법:** Access Analyzer에서 Finding 상태 'Resolved' 확인\n**조치자:** 홍길동\n```\n\n---\n\n### Step 5: IAM Policy Simulator 검증 (Day 21-23)\n\n```bash\n# 특정 정책의 권한 시뮬레이션\naws iam simulate-principal-policy \\\n    --policy-source-arn arn:aws:iam::123456789012:user/developer \\\n    --action-names s3:GetObject s3:PutObject s3:DeleteObject \\\n    --resource-arns arn:aws:s3:::production-bucket/*\n```\n\n**검증 체크리스트:**\n- [ ] Admin 역할이 의도한 리소스에만 접근 가능한가?\n- [ ] Developer 역할이 프로덕션 리소스 삭제 권한이 없는가?\n- [ ] ReadOnly 역할이 실제로 쓰기 권한이 없는가?\n\n---\n\n### Step 6: 최종 보고서 작성 (Day 24-25)\n\n**보고서 구조:**\n```\nIAM-Policy-Review-Report-2024Q3.pdf\n├── 1. Executive Summary (1페이지)\n├── 2. 검토 범위 및 방법론 (1페이지)\n├── 3. IAM Access Analyzer 결과 (3-5페이지)\n│   ├── External Access Findings\n│   ├── Unused Access Findings\n│   └── 조치 현황\n├── 4. 그룹/역할 멤버십 검토 (2페이지)\n├── 5. 정책 권한 분석 (2-3페이지)\n├── 6. 개선 권고사항 (1페이지)\n└── Appendix: 스크린샷, 상세 데이터\n```\n\n---\n\n### Step 7: 승인 및 아카이빙 (Day 26)\n\n```markdown\n## 승인 체인\n\n1단계: 보안 엔지니어 작성 → 보안팀 리드 검토\n2단계: 보안팀 리드 승인 → CISO 최종 승인\n3단계: 문서 버전 관리 시스템에 등록\n\n**문서 보관:**\n- 위치: SharePoint/Confluence + S3 백업\n- 보관 기간: 최소 3년\n- 접근 권한: 보안팀, 경영진, 감사팀\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: Access Analyzer \"활성화만\" 하고 Findings 미분석\n\n**문제 상황:**\n```\n감사관: \"Access Analyzer 결과를 보여주세요.\"\n파트너: \"네, 활성화되어 있습니다.\" (대시보드만 보여줌)\n감사관: \"이 47개 Findings에 대해 어떤 조치를 했나요?\"\n파트너: \"...\" 😰\n```\n\n**해결책:**\n- 모든 Finding에 대해 **조치(Resolve)** 또는 **아카이브(Archive with reason)** 처리\n- 아카이브 시 반드시 비즈니스 사유 문서화\n\n---\n\n### 🚫 실수 2: Unused Access Analyzer 미사용\n\n**문제 상황:**\nExternal Access Analyzer만 사용하고 Unused Access Analyzer를 설정하지 않음\n\n**왜 문제인가:**\n- 요구사항에 \"부여된 특정 권한을 평가\"가 명시됨\n- 90일 이상 사용하지 않은 권한 식별이 핵심\n\n**해결책:**\n```bash\n# Unused Access Analyzer 반드시 활성화\naws accessanalyzer create-analyzer \\\n    --analyzer-name \"Unused-Access-Analyzer\" \\\n    --type ACCOUNT_UNUSED_ACCESS \\\n    --configuration '{\"unusedAccess\": {\"unusedAccessAge\": 90}}'\n```\n\n---\n\n### 🚫 실수 3",
      "language": "ko",
      "createdAt": "2026-01-07T02:02:44.563Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-006_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-006",
      "category": "Security",
      "title": "역할 기반 액세스",
      "advice": "# SEC-006: 역할 기반 액세스 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n역할 기반 액세스는 AWS MSP 보안의 **핵심 기반**입니다. MSP는 수십~수백 개의 고객 AWS 계정에 접근하므로, 정적 자격 증명(Access Key/Secret Key)이 유출될 경우 **대규모 보안 사고**로 이어집니다. AWS는 MSP가 자사 및 고객 환경 모두에서 임시 자격 증명 기반의 접근 통제를 구현했는지 엄격히 검증합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 예시 |\n|------------|-------------------|\n| **IAM User의 Access Key 사용 현황** | \"현재 활성화된 IAM User Access Key가 몇 개이며, 각각의 용도는 무엇인가요?\" |\n| **IAM Role 기반 접근 구조** | \"엔지니어가 고객 계정에 접근할 때 어떤 Role을 Assume하나요?\" |\n| **최소 권한 원칙 적용** | \"DevOps 역할과 ReadOnly 역할의 권한 차이를 보여주세요\" |\n| **기계 신원(Machine Identity) 관리** | \"CI/CD 파이프라인이나 자동화 도구는 어떻게 AWS에 인증하나요?\" |\n| **예외 케이스 문서화** | \"정적 자격 증명이 필요한 서비스가 있다면, 해당 정책이 어떻게 제한되어 있나요?\" |\n\n### 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                    역할 기반 액세스 아키텍처                      │\n├─────────────────────────────────────────────────────────────────┤\n│                                                                 │\n│  [Human Identity]              [Machine Identity]               │\n│       │                              │                          │\n│       ▼                              ▼                          │\n│  ┌─────────────┐              ┌─────────────────┐              │\n│  │ AWS IAM     │              │ IAM Roles for   │              │\n│  │ Identity    │              │ Service Accounts│              │\n│  │ Center      │              │ (IRSA/EKS)      │              │\n│  │ (SSO)       │              └────────┬────────┘              │\n│  └──────┬──────┘                       │                        │\n│         │                              │                        │\n│         ▼                              ▼                        │\n│  ┌─────────────┐              ┌─────────────────┐              │\n│  │ Permission  │              │ EC2 Instance    │              │\n│  │ Sets        │              │ Profiles        │              │\n│  └──────┬──────┘              └────────┬────────┘              │\n│         │                              │                        │\n│         └──────────────┬───────────────┘                        │\n│                        ▼                                        │\n│              ┌─────────────────┐                                │\n│              │ AWS STS         │                                │\n│              │ (Temporary      │                                │\n│              │  Credentials)   │                                │\n│              └─────────────────┘                                │\n│                                                                 │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 증빙 1: IAM Role 구조 다이어그램 및 설명서\n**파일명 예시:** `SEC-006_IAM_Role_Architecture_v2.1.pdf`\n\n```yaml\n포함 내용:\n  - MSP 조직 내 역할별 IAM Role 매핑 (예: L1 Support → ReadOnlyAccess, DevOps → PowerUserAccess)\n  - Cross-account Role Assumption 흐름도\n  - Trust Policy와 Permission Policy 분리 설명\n  - Role 명명 규칙 (예: msp-{customer}-{function}-role)\n\n형식: \n  - Visio/Draw.io 다이어그램 + 설명 문서\n  - 최소 3개 이상의 서로 다른 권한 수준 Role 포함\n```\n\n#### 📄 증빙 2: IAM Credential Report 및 분석 결과\n**파일명 예시:** `SEC-006_Credential_Report_Analysis_20240115.xlsx`\n\n```yaml\n포함 내용:\n  - AWS Console에서 다운로드한 원본 Credential Report\n  - Access Key 사용 현황 분석 (활성/비활성/미사용 분류)\n  - 90일 이상 미사용 Access Key 목록 및 조치 계획\n  - Password 사용 IAM User 목록 (SSO 미사용 예외 케이스)\n\n필수 컬럼 분석:\n  - access_key_1_active / access_key_2_active\n  - access_key_1_last_used_date\n  - password_enabled\n  - mfa_active\n```\n\n#### 📄 증빙 3: Permission Set/IAM Role 정책 스크린샷\n**파일명 예시:** `SEC-006_PermissionSet_Screenshots.pdf`\n\n```yaml\n포함 내용:\n  - AWS IAM Identity Center Permission Set 목록 스크린샷\n  - 각 Permission Set의 Managed Policy 및 Inline Policy\n  - 실제 Role의 Trust Policy JSON\n  - IAM Access Analyzer 결과 (unused permissions 분석)\n\n캡처 필수 화면:\n  1. IAM Identity Center > Permission Sets 목록\n  2. 각 Permission Set의 상세 정책\n  3. IAM > Roles > Trust relationships\n  4. IAM Access Analyzer > Findings\n```\n\n#### 📄 증빙 4: 기계 신원(Machine Identity) 관리 증빙\n**파일명 예시:** `SEC-006_Machine_Identity_Inventory.xlsx`\n\n```yaml\n포함 내용:\n  - EC2 Instance Profile 사용 현황\n  - Lambda Execution Role 목록\n  - EKS IRSA(IAM Roles for Service Accounts) 설정\n  - CI/CD 파이프라인 인증 방식 (GitHub Actions OIDC, CodeBuild Role 등)\n  - 정적 자격 증명 예외 케이스 문서화\n\n예외 케이스 문서화 예시:\n  서비스: Amazon SES SMTP\n  사용 목적: 레거시 이메일 발송 시스템\n  정책 제한: ses:SendRawEmail 권한만 부여\n  검토 주기: 분기별\n  대체 계획: SES API v2로 마이그레이션 (2024 Q2)\n```\n\n#### 📄 증빙 5: 라이브 데모 시나리오 스크립트\n**파일명 예시:** `SEC-006_Live_Demo_Script.md`\n\n```yaml\n데모 시나리오:\n  1. AWS IAM Identity Center 로그인 과정 시연\n  2. 특정 고객 계정으로 Role Assume 시연\n  3. CloudTrail에서 AssumeRole 이벤트 확인\n  4. 권한 부족 시 Access Denied 발생 시연 (최소 권한 증명)\n  5. Credential Report에서 Access Key 없음 확인\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 자격 증명 현황 전수 조사 (2-3일)\n\n```bash\n# 모든 AWS 계정에서 Credential Report 수집\naws iam generate-credential-report\naws iam get-credential-report --output text --query Content | base64 -d > credential_report.csv\n\n# Access Key 사용 현황 분석 스크립트\naws iam list-users --query 'Users[*].UserName' --output text | while read user; do\n  echo \"=== $user ===\"\n  aws iam list-access-keys --user-name $user\ndone\n```\n\n**담당자:** 보안팀 + 클라우드팀  \n**산출물:** `Access_Key_Inventory_전체계정.xlsx`\n\n### Step 2: IAM User Access Key 제거 및 Role 전환 (1-2주)\n\n```\n제거 우선순위:\n┌────────────────────────────────────────────────────────┐\n│ 1순위: Console 로그인용 IAM User                        │\n│        → AWS IAM Identity Center(SSO)로 전환           │\n├────────────────────────────────────────────────────────┤\n│ 2순위: 개발자 로컬 CLI용 Access Key                     │\n│        → aws sso login 또는 aws sso configure로 전환   │\n├────────────────────────────────────────────────────────┤\n│ 3순위: CI/CD 파이프라인용 Access Key                    │\n│        → OIDC Provider + IAM Role로 전환               │\n├────────────────────────────────────────────────────────┤\n│ 4순위: EC2/Lambda에 하드코딩된 Access Key              │\n│        → Instance Profile / Execution Role로 전환      │\n└────────────────────────────────────────────────────────┘\n```\n\n**GitHub Actions OIDC 전환 예시:**\n```yaml\n# .github/workflows/deploy.yml\npermissions:\n  id-token: write\n  contents: read\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          role-to-assume: arn:aws:iam::123456789012:role/GitHubActionsDeployRole\n          aws-region: ap-northeast-2\n```\n\n### Step 3: 기능별 IAM Role 설계 및 생성 (3-5일)\n\n```json\n// 예시: L1 Support Role - ReadOnly + 특정 작업만 허용\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"ReadOnlyAccess\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:Describe*\",\n        \"rds:Describe*\",\n        \"cloudwatch:Get*\",\n        \"cloudwatch:List*\",\n        \"logs:Get*\",\n        \"logs:Describe*\"\n      ],\n      \"Resource\": \"*\"\n    },\n    {\n      \"Sid\": \"LimitedEC2Actions\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"ec2:StartInstances\",\n        \"ec2:StopInstances\",\n        \"ec2:RebootInstances\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"ec2:ResourceTag/Environment\": \"dev\"\n        }\n      }\n    }\n  ]\n}\n```\n\n**역할 매트릭스 예시:**\n\n| 조직 역할 | IAM Role/Permission Set | 주요 권한 | 제한 사항 |\n|----------|------------------------|----------|----------|\n| L1 Support | `msp-l1-support-role` | ReadOnly + EC2 Start/Stop | Dev 환경만 |\n| L2 Engineer | `msp-l2-engineer-role` | PowerUser | IAM 변경 불가 |\n| DevOps | `msp-devops-role` | Admin - IAM | IAM 정책 변경 불가 |\n| Security Admin | `msp-security-admin-role` | SecurityAudit + IAM | 승인 후 사용 |\n\n### Step 4: Trust Policy 설정 및 Cross-Account 구조 구현 (2-3일)\n\n```json\n// 고객 계정의 Role Trust Policy\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::MSP_ACCOUNT_ID:root\"\n      },\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"sts:ExternalId\": \"customer-unique-external-id-12345\"\n        },\n        \"Bool\": {\n          \"aws:MultiFactorAuthPresent\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n\n### Step 5: IAM Access Analyzer로 최소 권한 검증 (1-2일)\n\n```bash\n# Access Analyzer 활성화 및 분석\naws accessanalyzer create-analyzer \\\n  --analyzer-name msp-policy-analyzer \\\n  --type ACCOUNT\n\n# 미사용 권한 확인\naws accessanalyzer list-findings \\\n  --analyzer-arn arn:aws:access-analyzer:ap-northeast-2:123456789012:analyzer/msp-policy-analyzer \\\n  --filter '{\"status\": {\"eq\": [\"ACTIVE\"]}}'\n```\n\n**IAM Access Analyzer 결과 캡처 필수:**\n- Unused permissions 목록\n- Policy 개선 권고사항\n- External access findings\n\n### Step 6: 예외 케이스 문서화 및 정책 제한 (1일)\n\n```yaml\n# 예외 케이스 등록 양식\nexception_id: EXC-2024-001\nservice: Amazon SES SMTP\nreason: \"레거시 PHP 애플리케이션이 SMTP 인증만 지원\"\naccess_key_user: ses-smtp-user-prod\npolicy_attached:\n  - PolicyName: SES-SMTP-Only\n    PolicyDocument: |\n      {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [{\n          \"Effect\": \"Allow\",\n          \"Action\": \"ses:SendRawEmail\",\n          \"Resource\": \"arn:aws:ses:ap-northeast-2:*:identity/*\"\n        }]\n      }\nreview_date: 2024-04-15\nowner: platform-team@company.com\nremediation_plan: \"2024 Q2 SES API v2 마이그레이션\"\n```\n\n### Step 7: 라이브 데모 준비 및 리허설 (1일)\n\n```\n데모 시나리오 체크리스트:\n□ AWS IAM Identity Center 포털 로그인\n□ Permission Set 선택 화면\n□ ",
      "language": "ko",
      "createdAt": "2026-01-07T02:03:38.978Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-007_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-007",
      "category": "Security",
      "title": "다중 인증",
      "advice": "# SEC-007: 다중 인증 (MFA) - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\nMSP 파트너는 다수의 고객 AWS 계정에 접근하는 \"슈퍼 권한\"을 보유합니다. 단일 MSP 엔지니어의 자격 증명이 탈취되면 수십~수백 개의 고객 환경이 동시에 위험에 노출됩니다. AWS는 이러한 \"공급망 공격(Supply Chain Attack)\" 리스크를 차단하기 위해 MFA를 **필수 게이트키퍼**로 지정했습니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 검증 방식 |\n|------------|-------------------|\n| **예외 없는 강제성** | MFA 없이 로그인 시도 시 실제로 차단되는지 라이브 데모 요청 |\n| **모든 접근 경로 커버** | AWS Console, CLI, SDK, SSO 등 모든 경로에 MFA 적용 여부 |\n| **IdP 레벨 강제** | IAM User 개별 설정이 아닌 IdP(Okta, Azure AD 등)에서 정책 강제 |\n| **하드웨어 vs 소프트웨어 MFA** | 관리자 계정에 피싱 저항성 MFA(FIDO2/YubiKey) 사용 권장 |\n| **MFA 분실 대응 절차** | 직원 MFA 디바이스 분실 시 복구 프로세스 문서화 |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS IAM Identity Center (SSO)** - 중앙 집중식 MFA 강제\n- **AWS Organizations SCP** - MFA 없는 API 호출 차단 정책\n- **AWS CloudTrail** - MFA 사용 여부 로깅\n- **IAM Access Analyzer** - MFA 미설정 사용자 탐지\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📹 증빙 A: MFA 강제 시연 영상 (필수, 가장 중요)\n**파일명 예시:** `SEC-007_MFA_Enforcement_Demo_20240115.mp4`\n\n**영상에 반드시 포함되어야 할 시나리오:**\n\n```\n시나리오 1: MFA 미등록 사용자 로그인 시도\n├── 새 테스트 사용자 생성 (MFA 미등록 상태)\n├── AWS Console 로그인 시도\n├── \"MFA 등록 필수\" 화면에서 차단됨을 보여줌\n└── 등록 없이는 진행 불가함을 시연\n\n시나리오 2: MFA 등록 사용자 정상 로그인\n├── MFA 등록된 사용자로 로그인\n├── MFA 코드 입력 화면 표시\n├── 코드 입력 후 정상 접근\n└── CloudTrail에서 MFA 인증 로그 확인\n\n시나리오 3: CLI/SDK 접근 시 MFA 강제\n├── MFA 없이 aws sts get-caller-identity 실행\n├── Access Denied 오류 발생\n├── aws sts get-session-token --serial-number --token-code 실행\n└── 임시 자격 증명으로 정상 동작\n```\n\n#### 📄 증빙 B: IdP MFA 정책 설정 스크린샷\n**파일명 예시:** `SEC-007_Okta_MFA_Policy_Config.pdf`\n\n**포함 내용:**\n- IdP 관리 콘솔의 MFA 정책 설정 화면\n- \"모든 사용자\" 또는 \"AWS 접근 그룹\"에 MFA 필수 설정\n- 허용된 MFA 유형 (Authenticator App, Hardware Token 등)\n- 정책 적용 범위 (AWS 애플리케이션에 할당됨)\n\n#### 📄 증빙 C: SCP 정책 문서 (CLI/API 강제용)\n**파일명 예시:** `SEC-007_SCP_DenyWithoutMFA.json`\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyAllExceptListedIfNoMFA\",\n      \"Effect\": \"Deny\",\n      \"NotAction\": [\n        \"iam:CreateVirtualMFADevice\",\n        \"iam:EnableMFADevice\",\n        \"iam:GetUser\",\n        \"iam:ListMFADevices\",\n        \"iam:ListVirtualMFADevices\",\n        \"iam:ResyncMFADevice\",\n        \"sts:GetSessionToken\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"BoolIfExists\": {\n          \"aws:MultiFactorAuthPresent\": \"false\"\n        }\n      }\n    }\n  ]\n}\n```\n\n#### 📄 증빙 D: MFA 적용 현황 보고서\n**파일명 예시:** `SEC-007_MFA_Coverage_Report_20240115.xlsx`\n\n| 사용자/역할 | MFA 유형 | 등록일 | 마지막 사용 | 상태 |\n|------------|---------|--------|------------|------|\n| admin@company.com | YubiKey 5 | 2023-01-15 | 2024-01-14 | ✅ Active |\n| engineer1@company.com | Google Auth | 2023-03-20 | 2024-01-15 | ✅ Active |\n| service-account-01 | N/A (Role) | - | - | 🔵 Excluded |\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 MFA 적용 현황 감사 (Day 1-2)\n\n**실행 명령어:**\n```bash\n# 모든 IAM 사용자의 MFA 상태 확인\naws iam generate-credential-report\naws iam get-credential-report --query 'Content' --output text | base64 -d > credential_report.csv\n\n# MFA 미설정 사용자 필터링\ncat credential_report.csv | awk -F',' '$4==\"true\" && $8==\"false\" {print $1}'\n```\n\n**담당:** 보안팀 / **소요시간:** 4시간\n\n### Step 2: IdP MFA 정책 강화 (Day 3-5)\n\n**Okta 설정 예시:**\n```\nSecurity > Multifactor > Factor Enrollment\n├── Required factors: \"Okta Verify\" 또는 \"Google Authenticator\"\n├── Optional factors: \"YubiKey\" (관리자 권장)\n└── Factor Lifetime: \"Every sign-in\" (매 로그인 시 요구)\n\nApplications > AWS SSO > Sign On Policy\n├── Rule: \"Require MFA for all users\"\n├── Re-authentication: \"Every 12 hours\"\n└── Device Trust: Optional (추가 보안)\n```\n\n**담당:** IdP 관리자 / **소요시간:** 8시간\n\n### Step 3: AWS Organizations SCP 배포 (Day 6-7)\n\n```bash\n# SCP 생성\naws organizations create-policy \\\n  --name \"RequireMFAForHumanAccess\" \\\n  --type SERVICE_CONTROL_POLICY \\\n  --content file://mfa-required-scp.json\n\n# 루트 또는 OU에 연결\naws organizations attach-policy \\\n  --policy-id p-xxxxxxxxxx \\\n  --target-id ou-xxxx-xxxxxxxx\n```\n\n**담당:** 클라우드 아키텍트 / **소요시간:** 4시간\n\n### Step 4: 예외 케이스 문서화 (Day 8)\n\n**서비스 계정 예외 처리 문서:**\n```markdown\n## MFA 예외 대상 및 보상 통제\n\n| 계정 유형 | 예외 사유 | 보상 통제 |\n|----------|----------|----------|\n| CI/CD Service Role | 자동화 파이프라인 | IP 제한 + 단기 토큰(1시간) |\n| Lambda Execution Role | 서버리스 실행 | 최소 권한 + VPC 제한 |\n| Cross-Account Role | 고객 계정 접근 | External ID + 세션 태깅 |\n```\n\n**담당:** 보안팀 / **소요시간:** 4시간\n\n### Step 5: 시연 영상 녹화 (Day 9-10)\n\n**녹화 체크리스트:**\n- [ ] 화면 해상도 1080p 이상\n- [ ] 브라우저 북마크/개인정보 숨김\n- [ ] 시스템 시간 표시 (증빙 시점 증명)\n- [ ] 음성 또는 자막으로 각 단계 설명\n- [ ] 실패 → 성공 시나리오 모두 포함\n\n**담당:** 기술 문서팀 / **소요시간:** 8시간\n\n### Step 6: CloudTrail 로그 증빙 수집 (Day 11)\n\n```bash\n# MFA 인증 이벤트 조회\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=EventName,AttributeValue=ConsoleLogin \\\n  --start-time 2024-01-01 \\\n  --end-time 2024-01-15 \\\n  --query 'Events[*].CloudTrailEvent' | \\\n  jq '.[] | fromjson | select(.additionalEventData.MFAUsed == \"Yes\")'\n```\n\n**담당:** 보안팀 / **소요시간:** 2시간\n\n### Step 7: 최종 문서 패키징 (Day 12)\n\n```\nSEC-007_MFA_Evidence_Package/\n├── SEC-007_MFA_Enforcement_Demo.mp4\n├── SEC-007_IdP_MFA_Policy_Screenshots.pdf\n├── SEC-007_SCP_DenyWithoutMFA.json\n├── SEC-007_MFA_Coverage_Report.xlsx\n├── SEC-007_Exception_Justification.docx\n├── SEC-007_CloudTrail_MFA_Logs.json\n└── SEC-007_Evidence_Index.md (증빙 목록 및 설명)\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: IAM User 레벨에서만 MFA 설정\n\n**문제:** 개별 IAM User에 MFA를 설정했지만, IdP 레벨 강제가 없음\n```\n❌ 잘못된 접근:\n- IAM User마다 수동으로 MFA 활성화\n- 신규 입사자 MFA 설정 누락 가능성\n\n✅ 올바른 접근:\n- IdP(Okta/Azure AD)에서 \"AWS 앱 접근 시 MFA 필수\" 정책\n- IAM Identity Center에서 MFA 강제 설정\n```\n\n### 🚫 실수 2: Root 계정 MFA 미설정\n\n**문제:** 관리 계정의 Root User에 MFA가 없음\n```bash\n# Root 계정 MFA 확인 (Organizations 마스터 계정에서)\naws iam get-account-summary --query 'SummaryMap.AccountMFAEnabled'\n# 결과가 0이면 Root MFA 미설정 → 즉시 탈락 사유\n```\n\n### 🚫 실수 3: SMS 기반 MFA 사용\n\n**문제:** SMS MFA는 SIM 스와핑 공격에 취약\n```\n❌ 허용되지만 권장하지 않음: SMS MFA\n⚠️ 권장: TOTP (Google Authenticator, Authy)\n✅ 강력 권장 (관리자): FIDO2/WebAuthn (YubiKey)\n```\n\n### 🚫 실수 4: CLI 접근에 MFA 미적용\n\n**문제:** Console에만 MFA 적용, CLI/SDK는 장기 Access Key로 무제한 접근\n```bash\n# 이런 상황이면 탈락:\naws configure  # Access Key 설정\naws s3 ls      # MFA 없이 바로 실행됨\n\n# SCP로 차단해야 함:\n# \"Condition\": {\"BoolIfExists\": {\"aws:MultiFactorAuthPresent\": \"false\"}}\n```\n\n### 🚫 실수 5: MFA 복구 절차 미문서화\n\n**감사관 질문:** \"직원이 MFA 디바이스를 분실하면 어떻게 복구하나요?\"\n\n**필요한 문서:**\n```markdown\n## MFA 분실 복구 절차\n\n1. 직원이 IT 헬프데스크에 티켓 생성\n2. 관리자가 본인 확인 (영상 통화 + 사번 확인)\n3. IdP에서 기존 MFA 팩터 리셋\n4. 직원이 새 MFA 디바이스 등록\n5. 보안팀에 인시던트 로그 기록\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | **Root 계정 MFA 활성화** | `aws iam get-account-summary` | AccountMFAEnabled = 1 |\n| 2 | **모든 IAM User MFA 등록** | Credential Report 분석 | mfa_active = true (100%) |\n| 3 | **IdP MFA 정책 강제** | IdP 관리 콘솔 스크린샷 | \"Required\" 설정 확인 |\n| 4 | **SCP MFA 강제 정책** | Organizations 콘솔 | 정책이 OU/Account에 연결됨 |\n| 5 | **시연 영상 품질** | ",
      "language": "ko",
      "createdAt": "2026-01-07T02:04:45.179Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-008_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-008",
      "category": "Security",
      "title": "취약점 관리",
      "advice": "# SEC-008: 취약점 관리 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP 프로그램에서 중요한가?\n\n취약점 관리는 MSP가 고객의 AWS 환경을 **사전 예방적으로 보호**할 수 있는 역량을 증명하는 핵심 항목입니다. AWS는 MSP 파트너가 단순히 인프라를 운영하는 것이 아니라, **지속적으로 보안 위협을 탐지하고 대응**할 수 있어야 한다고 요구합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **스캔 범위의 포괄성** | EC2, ECR 컨테이너 이미지, Lambda 함수 등 다양한 워크로드를 커버하는가? |\n| **자동화 수준** | 수동 스캔이 아닌 스케줄링된 자동 스캔이 구현되어 있는가? |\n| **취약점 우선순위 지정** | CVSS 점수 기반 또는 자체 기준으로 심각도를 분류하는가? |\n| **고객 리포팅 체계** | 발견된 취약점을 고객에게 어떻게 전달하고 추적하는가? |\n| **실제 운영 증거** | 데모 환경이 아닌 실제 고객 환경에서 운영 중인 증거가 있는가? |\n\n### 🔗 관련 AWS 서비스\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    AWS 네이티브 취약점 스캔                    │\n├─────────────────────────────────────────────────────────────┤\n│  Amazon Inspector    │ EC2, ECR, Lambda 취약점 자동 스캔      │\n│  AWS Security Hub    │ 취약점 발견 사항 통합 및 대시보드        │\n│  Amazon ECR Scanning │ 컨테이너 이미지 취약점 스캔             │\n│  AWS Systems Manager │ 패치 규정 준수 상태 확인               │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📹 증빙 1: 라이브 시연 녹화 영상 (필수)\n**파일명 예시:** `SEC-008_Vulnerability_Scanning_Demo_[날짜].mp4`\n\n**포함해야 할 시연 시나리오:**\n```\n[시연 시나리오 - 총 15-20분]\n\n00:00-03:00 │ Amazon Inspector 대시보드 접속\n            │ → 활성화된 계정 수, 스캔 대상 리소스 현황 표시\n            \n03:00-07:00 │ EC2 인스턴스 취약점 스캔 결과 확인\n            │ → CVE ID, CVSS 점수, 영향받는 패키지 상세 조회\n            │ → Critical/High/Medium/Low 필터링 시연\n            \n07:00-11:00 │ ECR 컨테이너 이미지 스캔 결과 확인\n            │ → 특정 이미지의 취약점 목록 드릴다운\n            │ → 수정 권장사항 확인\n            \n11:00-14:00 │ Security Hub 통합 대시보드\n            │ → Inspector 발견 사항이 Security Hub로 집계되는 것 확인\n            │ → 고객별 필터링 및 리포트 생성 과정\n            \n14:00-17:00 │ 취약점 티켓 생성 및 추적 프로세스\n            │ → JIRA/ServiceNow 연동 또는 자체 시스템 시연\n```\n\n#### 📄 증빙 2: 취약점 관리 정책 문서\n**파일명 예시:** `SEC-008_Vulnerability_Management_Policy_v2.1.pdf`\n\n**필수 포함 섹션:**\n```yaml\n문서 구조:\n  1. 목적 및 범위:\n    - 스캔 대상 정의 (EC2, ECR, Lambda, RDS 등)\n    - 고객 환경 포함 여부 명시\n    \n  2. 스캔 주기 및 방법:\n    - 연속 스캔 (Amazon Inspector 기본)\n    - 컨테이너 이미지: 푸시 시 자동 스캔 + 주간 재스캔\n    \n  3. 심각도 분류 기준:\n    - Critical (CVSS 9.0-10.0): 24시간 내 대응\n    - High (CVSS 7.0-8.9): 72시간 내 대응\n    - Medium (CVSS 4.0-6.9): 14일 내 대응\n    - Low (CVSS 0.1-3.9): 다음 정기 패치 사이클\n    \n  4. 에스컬레이션 절차:\n    - 발견 → 분류 → 고객 통보 → 수정 → 검증 → 종료\n    \n  5. 예외 처리 프로세스:\n    - 비즈니스 사유로 패치 불가 시 보완 통제\n```\n\n#### 📊 증빙 3: 실제 고객 취약점 리포트 샘플 (익명화)\n**파일명 예시:** `SEC-008_Customer_Vulnerability_Report_Sample_Redacted.pdf`\n\n**리포트 필수 요소:**\n- 스캔 일시 및 범위\n- 발견된 취약점 요약 (심각도별 개수)\n- 상위 10개 Critical/High 취약점 상세\n- 수정 권장사항 및 우선순위\n- 이전 스캔 대비 개선/악화 트렌드\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: Amazon Inspector 전체 활성화 (Day 1-2)\n```bash\n# AWS CLI로 모든 리전에 Inspector 활성화\naws inspector2 enable --resource-types EC2 ECR LAMBDA \\\n  --region us-east-1\n\n# 멀티 계정 환경: Organizations 위임 관리자 설정\naws inspector2 enable-delegated-admin-account \\\n  --delegated-admin-account-id 123456789012\n```\n\n**체크포인트:**\n- [ ] 모든 관리 대상 고객 계정에 Inspector 활성화\n- [ ] EC2, ECR, Lambda 세 가지 리소스 타입 모두 활성화\n- [ ] 위임 관리자 계정에서 통합 뷰 확인 가능\n\n### Step 2: Security Hub 통합 구성 (Day 2-3)\n```bash\n# Security Hub에서 Inspector 통합 활성화\naws securityhub enable-import-findings-for-product \\\n  --product-arn arn:aws:securityhub:us-east-1::product/aws/inspector\n```\n\n**구성 항목:**\n- Inspector → Security Hub 자동 발견 사항 전송\n- 사용자 정의 인사이트 생성 (고객별, 심각도별)\n- 자동화 규칙으로 Critical 발견 시 SNS 알림\n\n### Step 3: 자동화된 리포팅 파이프라인 구축 (Day 3-5)\n```python\n# Lambda 함수 예시: 주간 취약점 리포트 생성\nimport boto3\nimport json\nfrom datetime import datetime, timedelta\n\ndef generate_weekly_report(event, context):\n    inspector = boto3.client('inspector2')\n    \n    # 지난 7일간 발견 사항 조회\n    findings = inspector.list_findings(\n        filterCriteria={\n            'updatedAt': [{\n                'startInclusive': datetime.now() - timedelta(days=7),\n                'endInclusive': datetime.now()\n            }]\n        }\n    )\n    \n    # 심각도별 집계\n    summary = {\n        'CRITICAL': 0, 'HIGH': 0, \n        'MEDIUM': 0, 'LOW': 0\n    }\n    \n    for finding in findings['findings']:\n        severity = finding['severity']\n        summary[severity] += 1\n    \n    # S3에 리포트 저장 및 SNS 알림\n    # ... (구현 계속)\n```\n\n### Step 4: 취약점 추적 시스템 연동 (Day 5-7)\n**JIRA 연동 예시 (EventBridge → Lambda → JIRA API):**\n```yaml\nEventBridge Rule:\n  Name: critical-vulnerability-to-jira\n  Pattern:\n    source: [\"aws.inspector2\"]\n    detail-type: [\"Inspector2 Finding\"]\n    detail:\n      severity: [\"CRITICAL\", \"HIGH\"]\n  Target: Lambda (CreateJiraTicket)\n```\n\n### Step 5: 시연 환경 준비 및 리허설 (Day 7-10)\n**시연용 테스트 환경 구성:**\n```bash\n# 의도적으로 취약한 EC2 인스턴스 생성 (시연용)\n# 오래된 AMI 사용하여 취약점 발견 유도\naws ec2 run-instances \\\n  --image-id ami-0abcdef1234567890 \\  # 6개월 이상 된 AMI\n  --instance-type t3.micro \\\n  --tag-specifications 'ResourceType=instance,Tags=[{Key=Purpose,Value=MSP-Audit-Demo}]'\n```\n\n**⚠️ 주의:** 시연 후 반드시 테스트 리소스 삭제\n\n### Step 6: 시연 녹화 및 검증 (Day 10-12)\n**녹화 체크리스트:**\n- [ ] 화면 해상도 1920x1080 이상\n- [ ] AWS 콘솔 언어 영어로 설정\n- [ ] 민감 정보 (계정 ID, 고객명) 마스킹 확인\n- [ ] 음성 해설 또는 자막 포함\n- [ ] 각 단계별 일시 정지하여 명확히 보이도록\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: Inspector만 활성화하고 실제 발견 사항이 없음\n```\n❌ 문제: Inspector 대시보드는 보여주지만 \"No findings\" 상태\n✅ 해결: 최소 2주 전에 활성화하여 충분한 스캔 데이터 축적\n        또는 의도적으로 취약한 테스트 환경 준비\n```\n\n### 🚫 실수 2: 컨테이너 스캔 누락\n```\n❌ 문제: EC2만 스캔하고 ECR 이미지 스캔 미구성\n✅ 해결: ECR 리포지토리 설정에서 \"Scan on push\" 활성화\n        기존 이미지에 대해 수동 스캔 실행하여 결과 확보\n```\n\n### 🚫 실수 3: 고객 환경과 분리된 데모 환경만 시연\n```\n❌ 문제: 별도 데모 계정에서만 시연, 실제 운영 증거 없음\n✅ 해결: 실제 관리 중인 고객 계정의 통합 대시보드 시연\n        (민감 정보 마스킹 필수)\n```\n\n### 🚫 실수 4: 취약점 발견 후 후속 조치 프로세스 미흡\n```\n❌ 문제: 스캔은 하지만 발견 사항 처리 워크플로우 없음\n✅ 해결: 티켓 시스템 연동, SLA 기반 대응 프로세스 문서화\n        실제 티켓 처리 이력 증빙 준비\n```\n\n### 🚫 실수 5: 서드파티 도구만 사용\n```\n❌ 문제: Qualys, Nessus 등 외부 도구만 사용, AWS 네이티브 도구 미활용\n✅ 해결: AWS Inspector를 기본으로 사용하고, \n        서드파티는 보완 도구로 위치시킴\n        (AWS MSP는 AWS 서비스 활용 역량을 중점 평가)\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 시연 영상 품질 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | Inspector 대시보드에 실제 발견 사항 존재 | 영상에서 Finding 개수 확인 | 최소 10개 이상 발견 사항 |\n| 2 | Critical/High 취약점 드릴다운 시연 | CVE 상세 정보 화면 캡처 | CVSS 점수, 영향 패키지 명확히 표시 |\n| 3 | 멀티 계정 통합 뷰 표시 | Security Hub 또는 Inspector 위임 관리자 화면 | 2개 이상 계정 데이터 통합 표시 |\n| 4 | 리포트 생성 과정 포함 | PDF/CSV 내보내기 또는 자동화 리포트 | 고객 전달 가능한 형식 |\n| 5 | 알림/에스컬레이션 설정 확인 | SNS, EventBridge 규칙 화면 | Critical 발견 시 자동 알림 구성 |\n\n### 문서",
      "language": "ko",
      "createdAt": "2026-01-07T02:05:42.172Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-009_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-009",
      "category": "Security",
      "title": "보안 이벤트 로깅",
      "advice": "# SEC-009: 보안 이벤트 로깅 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 AWS MSP 프로그램에서 중요한 이유\n\n보안 이벤트 로깅은 **MSP의 보안 운영 성숙도를 직접적으로 증명**하는 핵심 항목입니다. 고객 환경에서 발생하는 보안 사고의 탐지, 조사, 대응 능력은 모두 적절한 로깅에서 시작됩니다. AWS MSP 감사에서는 단순히 \"로그를 수집한다\"가 아니라, **고객과 합의된 요구사항 기반으로 체계적으로 운영되는지**를 평가합니다.\n\n### 🎯 감사관이 확인하고자 하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|--------------|\n| **1. 고객별 요구사항 정의 프로세스** | 로깅 요구사항이 고객과 문서화된 합의를 통해 결정되었는가? 일방적으로 MSP가 정한 것이 아닌가? |\n| **2. 보존 기간의 명시적 합의** | 30일, 90일, 1년 등 보존 기간이 계약서나 SLA에 명확히 기재되어 있는가? |\n| **3. 실제 로그 캡처 구현** | CloudTrail, VPC Flow Logs, GuardDuty 등이 실제로 활성화되어 있는가? |\n| **4. 보존 기간 자동화 제어** | S3 Lifecycle Policy, CloudWatch Logs retention 등이 합의된 기간에 맞게 설정되어 있는가? |\n| **5. 로그 무결성 보장** | 로그가 변조되지 않도록 보호 조치가 있는가? (CloudTrail Log File Validation 등) |\n\n### 🔧 관련 AWS 서비스 및 기능\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    보안 이벤트 로깅 아키텍처                    │\n├─────────────────────────────────────────────────────────────┤\n│  [수집]                                                      │\n│  • AWS CloudTrail (API 활동)                                │\n│  • VPC Flow Logs (네트워크 트래픽)                           │\n│  • AWS Config (구성 변경)                                    │\n│  • Amazon GuardDuty (위협 탐지)                              │\n│  • AWS Security Hub (통합 보안 뷰)                          │\n│  • ELB/ALB Access Logs                                      │\n│  • S3 Server Access Logs                                    │\n│  • RDS Audit Logs                                           │\n├─────────────────────────────────────────────────────────────┤\n│  [저장 및 보존]                                              │\n│  • Amazon S3 + Lifecycle Policies                           │\n│  • CloudWatch Logs + Retention Settings                     │\n│  • Amazon S3 Glacier (장기 보관)                            │\n├─────────────────────────────────────────────────────────────┤\n│  [보호]                                                      │\n│  • S3 Object Lock (WORM)                                    │\n│  • CloudTrail Log File Validation                           │\n│  • KMS 암호화                                               │\n└─────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 증빙 1: 고객 로깅 요구사항 합의 문서\n**파일명 예시:** `CustomerA_Security_Logging_Requirements_Agreement_v2.1.pdf`\n\n**포함되어야 할 핵심 내용:**\n```\n✓ 고객사명 및 계약 일자\n✓ 수집할 로그 유형 목록 (CloudTrail, VPC Flow Logs 등)\n✓ 각 로그 유형별 보존 기간 명시\n  - 예: CloudTrail: 1년, VPC Flow Logs: 90일, GuardDuty: 90일\n✓ 로그 접근 권한 정의 (누가 로그를 조회할 수 있는지)\n✓ 고객 서명 또는 이메일 승인 증적\n✓ 규정 준수 요구사항 (ISMS, PCI-DSS 등 해당 시)\n```\n\n**실제 문서 형식 예시:**\n```markdown\n# 보안 이벤트 로깅 요구사항 합의서\n\n고객사: ABC Corporation\n작성일: 2024-01-15\n버전: 2.1\n\n## 1. 로깅 범위\n| 로그 유형 | 수집 대상 | 보존 기간 | 저장 위치 |\n|----------|----------|----------|----------|\n| CloudTrail | 모든 리전, 관리 이벤트 + 데이터 이벤트(S3) | 365일 | s3://abc-corp-security-logs |\n| VPC Flow Logs | 모든 VPC, REJECT 트래픽 포함 | 90일 | CloudWatch Logs |\n| GuardDuty Findings | 모든 리전 | 90일 | Security Hub 통합 |\n| Config Rules | 모든 리소스 유형 | 180일 | S3 + Config 콘솔 |\n\n## 2. 고객 승인\n본 요구사항에 동의합니다.\n서명: [고객 보안 담당자]\n일자: 2024-01-15\n```\n\n---\n\n#### 📄 증빙 2: 로그 캡처 구현 증적\n**파일명 예시:** `CustomerA_Logging_Implementation_Evidence_20240115.pdf`\n\n**포함되어야 할 핵심 내용:**\n\n**CloudTrail 설정 스크린샷:**\n```\nAWS Console > CloudTrail > Trails > [Trail Name]\n캡처해야 할 정보:\n- Trail 이름 및 상태 (Logging: ON)\n- Multi-region trail: Yes\n- Log file validation: Enabled\n- S3 bucket 이름\n- KMS encryption: Enabled\n```\n\n**VPC Flow Logs 설정 스크린샷:**\n```\nAWS Console > VPC > Your VPCs > Flow Logs 탭\n캡처해야 할 정보:\n- Flow log ID\n- Filter: All 또는 Reject\n- Destination: CloudWatch Logs 또는 S3\n- Status: Active\n```\n\n**AWS CLI 출력 증적 (권장):**\n```bash\n# CloudTrail 상태 확인\naws cloudtrail describe-trails --query 'trailList[*].{Name:Name,S3Bucket:S3BucketName,IsMultiRegion:IsMultiRegionTrail,LogFileValidation:LogFileValidationEnabled}'\n\n# 출력 예시 (이 출력을 캡처)\n[\n    {\n        \"Name\": \"abc-corp-security-trail\",\n        \"S3Bucket\": \"abc-corp-security-logs-123456789012\",\n        \"IsMultiRegion\": true,\n        \"LogFileValidation\": true\n    }\n]\n```\n\n---\n\n#### 📄 증빙 3: 보존 기간 제어 구현 증적\n**파일명 예시:** `CustomerA_Log_Retention_Controls_Evidence.pdf`\n\n**S3 Lifecycle Policy 스크린샷:**\n```\nAWS Console > S3 > [Bucket] > Management > Lifecycle rules\n캡처해야 할 정보:\n- Rule name: cloudtrail-retention-365days\n- Scope: 전체 버킷 또는 prefix\n- Transition actions (Glacier로 이동 등)\n- Expiration: 365일 후 삭제\n- Status: Enabled\n```\n\n**CloudWatch Logs Retention 스크린샷:**\n```\nAWS Console > CloudWatch > Log groups > [Log Group]\n캡처해야 할 정보:\n- Log group name: /aws/vpc-flow-logs/abc-corp-vpc\n- Retention setting: 90 days (Never expire가 아님을 확인)\n```\n\n**Terraform/CloudFormation 코드 (IaC 사용 시):**\n```hcl\n# 이 코드를 증빙으로 제출\nresource \"aws_s3_bucket_lifecycle_configuration\" \"security_logs\" {\n  bucket = aws_s3_bucket.security_logs.id\n\n  rule {\n    id     = \"cloudtrail-retention\"\n    status = \"Enabled\"\n\n    transition {\n      days          = 90\n      storage_class = \"GLACIER\"\n    }\n\n    expiration {\n      days = 365  # 고객 합의 기간과 일치\n    }\n  }\n}\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 고객별 로깅 요구사항 수집 및 문서화 (3-5일)\n\n**담당자:** 고객 담당 매니저 + 보안 엔지니어\n\n**구체적 실행 방법:**\n```\n1. 고객 미팅 어젠다 준비\n   - 현재 규정 준수 요구사항 확인 (ISMS, PCI-DSS, GDPR 등)\n   - 산업별 로그 보존 법적 요구사항 조사\n   \n2. 로깅 요구사항 체크리스트 활용\n   □ API 활동 로그 필요 여부 (CloudTrail)\n   □ 네트워크 트래픽 로그 필요 여부 (VPC Flow Logs)\n   □ 데이터베이스 감사 로그 필요 여부 (RDS Audit)\n   □ 애플리케이션 로그 필요 여부 (CloudWatch Logs)\n   □ 보안 위협 탐지 로그 필요 여부 (GuardDuty)\n   \n3. 보존 기간 결정 매트릭스 작성\n   - 법적 요구사항 vs 비용 vs 운영 필요성 균형\n```\n\n**산출물:** `고객별_로깅_요구사항_합의서.docx`\n\n---\n\n### Step 2: 로깅 아키텍처 설계 (2-3일)\n\n**담당자:** 클라우드 아키텍트\n\n**구체적 실행 방법:**\n```\n중앙 집중식 로깅 아키텍처 설계:\n\n[고객 AWS 계정들]\n       │\n       ▼\n[CloudTrail Organization Trail]\n       │\n       ▼\n[중앙 로그 계정 S3 버킷]\n       │\n       ├── /cloudtrail/\n       ├── /vpc-flow-logs/\n       ├── /config/\n       └── /guardduty/\n       │\n       ▼\n[S3 Lifecycle Policy]\n  - 90일: Glacier 전환\n  - 365일: 만료 삭제\n```\n\n**AWS 도구 활용:**\n- AWS Control Tower (멀티 계정 환경)\n- AWS Organizations (조직 수준 CloudTrail)\n- S3 Cross-Account Access (중앙 로그 버킷)\n\n---\n\n### Step 3: CloudTrail 구성 (1일)\n\n**담당자:** 보안 엔지니어\n\n**구체적 CLI 명령어:**\n```bash\n# Organization Trail 생성 (권장)\naws cloudtrail create-trail \\\n  --name abc-corp-org-trail \\\n  --s3-bucket-name abc-corp-central-logs \\\n  --is-multi-region-trail \\\n  --enable-log-file-validation \\\n  --kms-key-id arn:aws:kms:ap-northeast-2:123456789012:key/xxx \\\n  --is-organization-trail\n\n# Trail 시작\naws cloudtrail start-logging --name abc-corp-org-trail\n\n# 데이터 이벤트 추가 (S3 객체 수준 로깅)\naws cloudtrail put-event-selectors \\\n  --trail-name abc-corp-org-trail \\\n  --event-selectors '[{\"ReadWriteType\":\"All\",\"IncludeManagementEvents\":true,\"DataResources\":[{\"Type\":\"AWS::S3::Object\",\"Values\":[\"arn:aws:s3\"]}]}]'\n```\n\n---\n\n### Step 4: VPC Flow Logs 및 기타 로그 구성 (2일)\n\n**담당자:** 네트워크 엔지니어\n\n**VPC Flow Logs 활성화:**\n```bash\n# 모든 VPC에 Flow Logs 활성화\nfor vpc_id in $(aws ec2 describe-vpcs --query 'Vpcs[*].VpcId' --output text); do\n  aws ec2 create-flow-logs \\\n    --resource-type VPC \\\n    --resource-ids $vpc_id \\\n    --traffic-type ALL \\\n    --log-destination-type cloud-watch-logs \\\n    --log-group-name /aws/vpc-flow-logs/$vpc_id \\\n    --deliver-logs-permission-arn arn:aws:iam::123456789012:role/VPCFlowLogsRole\ndone\n```\n\n**GuardDuty 활성화:**\n```bash\n# GuardDuty 활성화\naws guardduty create-detector --enable --finding-publishing-frequency FIFTEEN_MINUTES\n\n# S3 Protection 활성화\naws guardduty update-detector \\\n  --detector-id <detector-id> \\\n  --data-sources '{\"S3Logs\":{\"Enable\":true}}'\n```\n\n---\n\n### Step 5: 보존 기간 제어 구현 (1일)\n\n**담당자:** 보안 엔지니어\n\n**S3 Lifecycle Policy 설정:**\n```json\n{\n  \"Rules\": [\n    {\n      \"ID\": \"SecurityLogsRetention\",\n      \"Status\": \"Enabled\",\n      \"Filter\": {\n        \"Prefix\": \"\"\n      },\n      \"Transitions\": [\n        {\n          \"Days\": 90,\n          \"StorageClass\": \"GLACIER\"\n        }\n      ],\n      \"Expiration\": {\n        \"Days\": 365\n      },\n      \"NoncurrentVersionExpiration\": {\n        \"NoncurrentDays\": 30\n      }\n    }\n  ]\n}\n```\n\n**CloudWatch Logs Retention 설정:**\n```bash\n# 모든 보안 관련 로그 그",
      "language": "ko",
      "createdAt": "2026-01-07T02:06:33.357Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-010_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-010",
      "category": "Security",
      "title": "SaaS 도구 계정 액세스",
      "advice": "# SEC-010: SaaS 도구 계정 액세스 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 중요한가?\n\nAWS MSP 파트너는 고객 환경에 다양한 SaaS 도구(모니터링, 백업, 보안 스캐닝 등)를 연동합니다. 이 도구들이 **Access Key/Secret Key 방식**으로 접근하면 자격 증명 유출 시 고객 계정이 완전히 노출됩니다. **External ID가 포함된 IAM Role 방식**은 \"Confused Deputy\" 공격을 방지하고, 자격 증명 없이 안전한 교차 계정 액세스를 보장합니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 |\n|------------|--------------|\n| **SaaS 도구 인벤토리 완전성** | \"고객 계정에 접근하는 모든 도구가 목록에 있습니까?\" |\n| **External ID 사용 여부** | \"각 도구별로 고유한 External ID를 사용합니까?\" |\n| **IAM Role 신뢰 정책 구조** | \"sts:ExternalId 조건이 신뢰 정책에 명시되어 있습니까?\" |\n| **Access Key 미사용 확인** | \"SaaS 도구가 IAM User의 Access Key를 사용하지 않습니까?\" |\n| **최소 권한 원칙** | \"각 도구에 부여된 권한이 필요한 최소 범위입니까?\" |\n\n### 관련 AWS 서비스 및 기능\n\n- **AWS IAM**: Role, Trust Policy, External ID 조건\n- **AWS STS**: AssumeRole API\n- **AWS Organizations**: 교차 계정 역할 관리\n- **AWS CloudTrail**: AssumeRole 이벤트 로깅\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n```\n📁 SEC-010_SaaS_Tool_Access/\n├── 01_SaaS_Tool_Inventory.xlsx\n├── 02_IAM_Role_Trust_Policies/\n│   ├── Datadog_CrossAccount_Role_Policy.json\n│   ├── CloudHealth_Integration_Role_Policy.json\n│   ├── Prisma_Cloud_Scanner_Role_Policy.json\n│   └── [기타 도구별 정책 파일]\n├── 03_Architecture_Diagram_SaaS_Integration.pdf\n└── 04_External_ID_Management_Process.docx\n```\n\n### 각 증빙 자료의 핵심 내용\n\n#### 📊 SaaS Tool Inventory (필수)\n\n| 도구명 | 벤더 | 용도 | AWS 계정 접근 방식 | External ID 사용 | IAM Role ARN | 부여 권한 요약 |\n|--------|------|------|-------------------|-----------------|--------------|---------------|\n| Datadog | Datadog Inc. | 모니터링/APM | Cross-Account IAM Role | ✅ 예 | arn:aws:iam::*:role/DatadogIntegrationRole | CloudWatch ReadOnly, EC2 Describe |\n| CloudHealth | VMware | 비용 최적화 | Cross-Account IAM Role | ✅ 예 | arn:aws:iam::*:role/CloudHealthRole | Cost Explorer, Billing ReadOnly |\n| Prisma Cloud | Palo Alto | 보안 스캐닝 | Cross-Account IAM Role | ✅ 예 | arn:aws:iam::*:role/PrismaCloudRole | SecurityHub, Config ReadOnly |\n| Terraform Cloud | HashiCorp | IaC 배포 | Cross-Account IAM Role | ✅ 예 | arn:aws:iam::*:role/TerraformCloudRole | 배포 대상 리소스 권한 |\n\n#### 📄 IAM Role Trust Policy 예시 (각 도구별 필수)\n\n**Datadog Integration Role Trust Policy:**\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::464622532012:root\"\n      },\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"sts:ExternalId\": \"abc123def456ghi789xyz\"\n        }\n      }\n    }\n  ]\n}\n```\n\n**⚠️ 핵심 체크포인트:**\n- `Principal`에 SaaS 벤더의 AWS 계정 ID가 명시됨\n- `Condition` 블록에 `sts:ExternalId`가 반드시 포함됨\n- External ID는 도구/고객별로 고유한 값\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: SaaS 도구 전수 조사 (2-3일)\n\n**실행 방법:**\n```bash\n# 모든 고객 계정에서 외부 Principal을 가진 IAM Role 검색\naws iam list-roles --query 'Roles[?contains(AssumeRolePolicyDocument, `arn:aws:iam::`)]'\n\n# 각 Role의 Trust Policy 상세 확인\naws iam get-role --role-name DatadogIntegrationRole \\\n  --query 'Role.AssumeRolePolicyDocument'\n```\n\n**확인 대상 도구 카테고리:**\n- 🔍 모니터링: Datadog, New Relic, Dynatrace, Splunk\n- 💰 비용 관리: CloudHealth, Spot.io, Cloudability\n- 🔒 보안: Prisma Cloud, Lacework, Wiz, Orca Security\n- 🏗️ IaC/배포: Terraform Cloud, Pulumi, env0\n- 💾 백업: Veeam, Druva, Clumio\n- 📊 FinOps: Kubecost, CloudZero\n\n### Step 2: External ID 존재 여부 검증 (1일)\n\n**검증 스크립트:**\n```python\nimport boto3\nimport json\n\ndef check_external_id(role_name):\n    iam = boto3.client('iam')\n    role = iam.get_role(RoleName=role_name)\n    policy = role['Role']['AssumeRolePolicyDocument']\n    \n    for statement in policy.get('Statement', []):\n        conditions = statement.get('Condition', {})\n        string_equals = conditions.get('StringEquals', {})\n        \n        if 'sts:ExternalId' in string_equals:\n            return True, string_equals['sts:ExternalId']\n    \n    return False, None\n\n# 결과: (True, 'abc123...') 또는 (False, None)\n```\n\n### Step 3: 누락된 External ID 추가 (2-3일)\n\n**Trust Policy 수정 예시:**\n```json\n// 수정 전 (❌ 감사 탈락)\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Principal\": {\"AWS\": \"arn:aws:iam::464622532012:root\"},\n    \"Action\": \"sts:AssumeRole\"\n  }]\n}\n\n// 수정 후 (✅ 감사 통과)\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [{\n    \"Effect\": \"Allow\",\n    \"Principal\": {\"AWS\": \"arn:aws:iam::464622532012:root\"},\n    \"Action\": \"sts:AssumeRole\",\n    \"Condition\": {\n      \"StringEquals\": {\n        \"sts:ExternalId\": \"customer-abc-datadog-2024\"\n      }\n    }\n  }]\n}\n```\n\n### Step 4: Access Key 사용 도구 식별 및 전환 (3-5일)\n\n**Access Key 사용 도구 탐지:**\n```bash\n# CloudTrail에서 Access Key로 API 호출하는 외부 도구 식별\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=EventSource,AttributeValue=sts.amazonaws.com \\\n  --query 'Events[?contains(CloudTrailEvent, `AccessKeyId`)]'\n```\n\n**전환 우선순위:**\n1. 🔴 즉시 전환: 프로덕션 계정에 접근하는 도구\n2. 🟡 1주 내 전환: 개발/스테이징 계정 접근 도구\n3. 🟢 2주 내 전환: 읽기 전용 접근 도구\n\n### Step 5: 증빙 문서 작성 (1-2일)\n\n**인벤토리 스프레드시트 작성 시 필수 컬럼:**\n- 도구명 / 벤더명 / 연락처\n- 접근하는 고객 계정 목록\n- IAM Role ARN (패턴)\n- External ID (마스킹 처리: `abc***xyz`)\n- 부여된 IAM Policy 요약\n- 마지막 검토일\n\n### Step 6: 아키텍처 다이어그램 작성 (0.5일)\n\n```\n┌─────────────────┐     AssumeRole      ┌──────────────────┐\n│   SaaS Tool     │ ──────────────────► │  Customer AWS    │\n│   (Datadog)     │   + External ID     │     Account      │\n│                 │                     │                  │\n│ AWS Account:    │     Trust Policy    │ IAM Role:        │\n│ 464622532012    │ ◄────────────────── │ DatadogRole      │\n└─────────────────┘                     └──────────────────┘\n         │                                       │\n         │ API Calls with                        │\n         │ Temporary Credentials                 │\n         ▼                                       ▼\n   ┌──────────┐                          ┌──────────────┐\n   │ CloudWatch│                          │ EC2, RDS,    │\n   │ Metrics   │                          │ Lambda, etc. │\n   └──────────┘                          └──────────────┘\n```\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 감사 탈락 원인 TOP 5\n\n| 순위 | 실수 유형 | 발생 빈도 | 해결 방법 |\n|------|----------|----------|----------|\n| 1 | **External ID 누락** | 매우 높음 | 모든 교차 계정 Role에 sts:ExternalId 조건 추가 |\n| 2 | **SaaS 도구 목록 불완전** | 높음 | CloudTrail 분석으로 숨겨진 도구 발견 |\n| 3 | **Access Key 사용 도구 존재** | 중간 | IAM User 대신 IAM Role로 전환 |\n| 4 | **동일 External ID 재사용** | 중간 | 고객/도구별 고유 External ID 생성 |\n| 5 | **Trust Policy 스크린샷만 제출** | 낮음 | JSON 파일 원본 + 스크린샷 함께 제출 |\n\n### 🔴 피해야 할 안티패턴\n\n**안티패턴 1: 와일드카드 Principal**\n```json\n// ❌ 절대 금지\n{\n  \"Principal\": {\"AWS\": \"*\"},\n  \"Condition\": {\"StringEquals\": {\"sts:ExternalId\": \"...\"}}\n}\n```\n→ External ID가 있어도 모든 AWS 계정이 Role을 assume할 수 있음\n\n**안티패턴 2: 하드코딩된 공통 External ID**\n```json\n// ❌ 모든 고객에 동일한 External ID 사용\n\"sts:ExternalId\": \"msp-partner-default-id\"\n```\n→ 한 고객의 External ID가 유출되면 모든 고객이 위험\n\n**안티패턴 3: SaaS 도구에 Admin 권한 부여**\n```json\n// ❌ 과도한 권한\n{\n  \"Effect\": \"Allow\",\n  \"Action\": \"*\",\n  \"Resource\": \"*\"\n}\n```\n→ 모니터링 도구에는 ReadOnly 권한만 필요\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 제출 전 필수 확인 항목\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | 모든 SaaS 도구가 인벤토리에 포함됨 | CloudTrail 로그와 대조 | 누락된 도구 0개 |\n| 2 | 모든 도구가 IAM Role 방식 사용 | 인벤토리의 \"접근 방식\" 컬럼 확인 | Access Key 사용 도구 0개 |\n| 3 | 모든 Role에 External ID 조건 존재 | Trust Policy JSON 검토 | `sts:ExternalId` 100% 포함 |\n| 4 | External ID가 고객/도구별 고유함 | External ID 목록 중복 검사 | 중복 ID 0개 |\n| 5 | Trust Policy JSON 파일 제출 | 파일 형식 확인 | .json 파일 (스크린샷 아님) |\n| 6 | 아키텍처 다이어그램 포함 | 다이어그램에 External ID 흐름 표시 | AssumeRole + External ID 명시 |\n| 7 | 최소 권한 원칙 준수 | 각 도구의 IAM Policy 검토 | 불필요한 * 권한 없음 |\n\n### 품질 검증 스크립트\n\n```bash\n#!/bin/bash\n# SEC-010 증빙 품질 검증\n\necho \"=== SEC-010 Pre-submission Check ===\"\n\n# 1. Trust Policy 파일에서 External ID 존재 확인\nfor policy_file in ./02_IAM_Role_Trust_Policies/*.json; do\n  if grep -q \"sts:ExternalId\" \"$policy_file\"; then\n    echo \"✅ $policy_file - External ID 존재\"",
      "language": "ko",
      "createdAt": "2026-01-07T02:07:25.436Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SECP-001_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SECP-001",
      "category": "Security",
      "title": "액세스 키 노출 탐지",
      "advice": "# SECP-001: 액세스 키 노출 탐지 - 실무 가이드\n\n## 1. 📋 요구사항 이해\n\n### 왜 이 항목이 AWS MSP에서 중요한가?\n\n액세스 키 노출은 **AWS 보안 사고의 가장 흔한 원인**입니다. GitHub에 실수로 커밋된 키 하나가 수 분 내에 크립토마이닝 봇에 의해 탐지되어 수천 달러의 피해로 이어지는 사례가 빈번합니다. MSP로서 고객 계정을 관리한다면, 이런 사고에 **15분 이내 대응**할 수 있는 자동화 체계가 필수입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 확인 포인트 | 감사관의 질문 예시 |\n|------------|-------------------|\n| **자동화 존재 여부** | \"AWS Health 이벤트가 발생하면 티켓이 자동 생성되는 것을 보여주세요\" |\n| **모든 고객 계정 커버리지** | \"관리 중인 50개 계정 모두에 이 메커니즘이 적용되어 있습니까?\" |\n| **심각도 설정** | \"노출 키 알림이 P1/Critical로 분류되는 것을 확인할 수 있나요?\" |\n| **대응 절차 문서화** | \"키 노출 시 누가, 언제, 어떤 순서로 대응하는지 문서를 보여주세요\" |\n| **실제 대응 이력** | \"최근 6개월 내 실제 대응 사례나 모의 훈련 기록이 있나요?\" |\n\n### 관련 AWS 서비스 및 기능\n\n```\nAWS Health API → EventBridge Rule → Lambda/SNS → ITSM 티켓\n     ↓\nAWS_RISK_CREDENTIALS_EXPOSED 이벤트 타입\n```\n\n- **AWS Health Dashboard**: `AWS_RISK_CREDENTIALS_EXPOSED` 이벤트 발생 소스\n- **Amazon EventBridge**: Health 이벤트를 캡처하는 규칙 생성\n- **AWS Organizations**: 조직 전체 Health 이벤트 집계 (Management Account)\n- **AWS Lambda**: 티켓 생성 자동화 로직 실행\n- **Amazon SNS**: 알림 전파 및 ITSM 연동\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 노출 키 대응 절차서 (Runbook)\n**파일명 예시**: `SEC-RUNBOOK-001_Exposed_Credentials_Response_v2.3.pdf`\n\n**반드시 포함해야 할 내용**:\n```markdown\n1. 목적 및 범위\n2. 역할 및 책임 (RACI 매트릭스)\n3. 탐지 메커니즘 설명\n4. 단계별 대응 절차:\n   - Step 1: 알림 수신 및 티켓 확인 (5분 이내)\n   - Step 2: 노출된 키 즉시 비활성화 (10분 이내)\n   - Step 3: 영향 범위 분석 (CloudTrail 조회)\n   - Step 4: 키 교체 및 애플리케이션 업데이트\n   - Step 5: 근본 원인 분석 및 재발 방지\n5. 에스컬레이션 경로\n6. 고객 커뮤니케이션 템플릿\n```\n\n#### 📄 문서 2: 자동화 아키텍처 다이어그램\n**파일명 예시**: `SEC-ARCH-001_Health_Event_Automation_Architecture.png`\n\n**포함 요소**:\n- AWS Organizations 구조와 Health 이벤트 흐름\n- EventBridge 규칙 → Lambda → ITSM 연동 흐름\n- 모든 관리 계정이 커버됨을 시각적으로 표시\n\n#### 📄 문서 3: EventBridge 규칙 설정 스크린샷\n**파일명 예시**: `SEC-CONFIG-001_EventBridge_Rule_Screenshot.pdf`\n\n**캡처해야 할 화면**:\n```json\n{\n  \"source\": [\"aws.health\"],\n  \"detail-type\": [\"AWS Health Event\"],\n  \"detail\": {\n    \"service\": [\"RISK\"],\n    \"eventTypeCategory\": [\"issue\"]\n  }\n}\n```\n\n#### 📄 문서 4: 티켓 생성 증빙\n**파일명 예시**: `SEC-EVIDENCE-001_Auto_Generated_Ticket_Sample.pdf`\n\n**포함 내용**:\n- 자동 생성된 티켓 스크린샷 (심각도 P1/Critical 표시 필수)\n- 티켓에 포함된 정보: 영향받은 계정 ID, 노출된 키 ID, 탐지 시간\n- ITSM 시스템의 티켓 생성 타임스탬프\n\n#### 📄 문서 5: 대응 이력 또는 모의 훈련 기록\n**파일명 예시**: `SEC-DRILL-001_Credential_Exposure_Tabletop_Exercise_2024Q1.pdf`\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: AWS Organizations Health 이벤트 집계 설정 (2시간)\n**담당**: 클라우드 인프라팀\n\n```bash\n# Management Account에서 조직 전체 Health 이벤트 활성화 확인\naws organizations describe-organization\naws health describe-events-for-organization --region us-east-1\n```\n\n⚠️ **주의**: AWS Health API는 **us-east-1 리전에서만** 조직 레벨 이벤트 조회 가능\n\n### Step 2: EventBridge 규칙 생성 (1시간)\n**담당**: 클라우드 인프라팀\n\n```json\n// EventBridge Rule Pattern - 정확히 이 패턴 사용\n{\n  \"source\": [\"aws.health\"],\n  \"detail-type\": [\"AWS Health Event\"],\n  \"detail\": {\n    \"service\": [\"RISK\"],\n    \"eventTypeCode\": [\"AWS_RISK_CREDENTIALS_EXPOSED\"]\n  }\n}\n```\n\n### Step 3: Lambda 함수로 ITSM 티켓 자동 생성 (4시간)\n**담당**: DevOps팀\n\n```python\n# Lambda 핵심 로직 예시\ndef lambda_handler(event, context):\n    account_id = event['detail']['affectedAccount']\n    access_key_id = extract_key_from_event(event)\n    \n    ticket = create_itsm_ticket(\n        title=f\"[P1-CRITICAL] AWS Access Key Exposed - {account_id}\",\n        severity=\"Critical\",  # 반드시 최고 심각도\n        description=f\"Exposed Key: {access_key_id}\",\n        auto_assign_to=\"security-oncall\"\n    )\n    \n    # SNS로 즉시 알림도 발송\n    notify_security_team(ticket)\n```\n\n### Step 4: 대응 절차서(Runbook) 작성 (3시간)\n**담당**: 보안팀\n\n**필수 포함 타임라인**:\n| 시간 | 액션 | 담당자 |\n|------|------|--------|\n| T+0분 | 티켓 자동 생성 및 알림 | 시스템 |\n| T+5분 | 티켓 확인 및 담당자 배정 | On-call 엔지니어 |\n| T+15분 | 노출 키 비활성화 완료 | 보안팀 |\n| T+30분 | CloudTrail 분석 시작 | 보안팀 |\n| T+2시간 | 고객 1차 보고 | 고객담당 |\n| T+24시간 | 근본 원인 분석 완료 | 보안팀 |\n\n### Step 5: 테스트 및 모의 훈련 실시 (2시간)\n**담당**: 보안팀 + 운영팀\n\n```bash\n# 테스트용 Health 이벤트 시뮬레이션 (실제 이벤트 발생 없이)\n# EventBridge에 테스트 이벤트 전송\naws events put-events --entries file://test-health-event.json\n```\n\n### Step 6: 증빙 자료 수집 및 패키징 (2시간)\n**담당**: MSP 프로그램 담당자\n\n- 모든 스크린샷에 날짜/시간 표시 확인\n- 문서 버전 관리 및 승인 이력 포함\n- PDF로 통합 패키징\n\n---\n\n## 4. ⚠️ 주의사항 및 일반적인 실수\n\n### 🚫 실수 1: 단일 계정만 커버하는 설정\n```\n❌ 잘못된 예: 각 계정마다 개별 EventBridge 규칙 설정\n✅ 올바른 예: Management Account에서 Organizations 레벨 Health 이벤트 집계\n```\n\n**해결책**: AWS Organizations의 Delegated Administrator 또는 Management Account에서 조직 전체 이벤트를 중앙 집중 처리\n\n### 🚫 실수 2: 심각도 설정 누락\n```\n❌ 잘못된 예: 티켓이 \"Medium\" 또는 \"Normal\" 심각도로 생성\n✅ 올바른 예: 반드시 \"Critical/P1/Severity 1\"로 생성\n```\n\n**감사 탈락 사유**: 요구사항에 명시된 \"최고 심각도\" 미충족\n\n### 🚫 실수 3: 대응 절차서에 키 교체 절차 누락\n```\n❌ 잘못된 예: \"키를 삭제한다\"로만 기술\n✅ 올바른 예: \n   1. 새 키 생성\n   2. 애플리케이션에 새 키 적용\n   3. 기존 키 비활성화\n   4. 24시간 모니터링 후 삭제\n```\n\n### 🚫 실수 4: 수동 프로세스만 문서화\n```\n❌ 잘못된 예: \"담당자가 Health Dashboard를 주기적으로 확인\"\n✅ 올바른 예: EventBridge → Lambda → ITSM 자동화 파이프라인 구축\n```\n\n**핵심**: \"자동화된 메커니즘\"이 필수 요구사항\n\n### 🚫 실수 5: 테스트/훈련 기록 없음\n```\n❌ 잘못된 예: 문서만 있고 실제 동작 증빙 없음\n✅ 올바른 예: 분기별 Tabletop Exercise 기록 + 자동화 테스트 로그\n```\n\n---\n\n## 5. 🔍 최종 검토 체크리스트\n\n### 자동화 구성 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 1 | EventBridge 규칙이 `aws.health` 소스의 `RISK` 서비스 이벤트를 캡처하는가? | AWS 콘솔에서 규칙 패턴 확인 | `\"service\": [\"RISK\"]` 포함 |\n| 2 | 모든 관리 고객 계정이 커버되는가? | Organizations 레벨 설정 확인 | Management Account에서 집계 |\n| 3 | 티켓이 최고 심각도로 생성되는가? | 테스트 이벤트로 생성된 티켓 확인 | P1/Critical/Severity 1 |\n| 4 | 티켓에 필수 정보가 포함되는가? | 샘플 티켓 내용 확인 | 계정 ID, 키 ID, 탐지 시간 포함 |\n\n### 문서 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 5 | 대응 절차서에 키 비활성화 단계가 있는가? | 문서 내용 검토 | 명시적 단계 포함 |\n| 6 | 대응 절차서에 키 교체 단계가 있는가? | 문서 내용 검토 | 새 키 생성 → 적용 → 기존 키 삭제 |\n| 7 | 역할 및 책임이 명확한가? | RACI 매트릭스 확인 | 각 단계별 담당자 지정 |\n| 8 | 에스컬레이션 경로가 정의되어 있는가? | 문서 내용 검토 | 연락처 및 조건 명시 |\n\n### 증빙 완성도 검증\n\n| # | 체크 항목 | 검증 방법 | 합격 기준 |\n|---|----------|----------|----------|\n| 9 | 아키텍처 다이어그램이 전체 흐름을 보여주는가? | 시각적 검토 | Health → EventBridge → ITSM 흐름 표시 |\n| 10 | 스크린샷에 날짜/시간이 표시되는가? | 이미지 확인 | 최근 3개월 이내 날짜 |\n| 11 | 테스트 또는 훈련 기록이 있는가? | 기록 문서 확인 | 최근 6개월 이내 실시 |\n\n---\n\n## 💡 Pro Tips\n\n> **감사 인터뷰 대비**: 감사관이 \"실제로 키가 노출되면 어",
      "language": "ko",
      "createdAt": "2026-01-07T01:34:43.828Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SECP-002_ko_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SECP-002",
      "category": "Security",
      "title": "공개 리소스",
      "advice": "# SECP-002: 공개 리소스 - AWS MSP 감사 준비 가이드\n\n## 1. 📋 요구사항 이해\n\n### 이 항목이 중요한 이유\n공개 리소스 노출은 AWS 환경에서 발생하는 **데이터 유출 사고의 가장 흔한 원인**입니다. 2023년 기준 클라우드 보안 사고의 약 35%가 잘못 구성된 S3 버킷이나 공개 스냅샷에서 비롯되었습니다. AWS MSP로서 고객의 민감한 데이터를 보호하는 능력을 입증해야 하며, 이는 MSP 자격의 핵심 요건입니다.\n\n### 감사관이 확인하는 핵심 포인트\n\n| 포인트 | 감사관의 관점 |\n|--------|---------------|\n| **예방 메커니즘** | 공개 리소스 생성 자체를 차단하는 사전 통제가 있는가? |\n| **탐지 능력** | 이미 공개된 리소스를 얼마나 빨리 발견할 수 있는가? |\n| **대응 프로세스** | 탐지 후 조치까지 얼마나 걸리는가? (SLA 존재 여부) |\n| **7개 리소스 유형 커버리지** | S3, RDS, EC2, Security Group, EBS Snapshot, RDS Snapshot, AMI 모두 다루는가? |\n| **고객별 적용 증거** | 실제 고객 환경에 적용된 증거가 있는가? |\n\n### 관련 AWS 서비스 및 기능\n- **AWS Config Rules**: `s3-bucket-public-read-prohibited`, `rds-instance-public-access-check`, `ec2-instance-no-public-ip` 등\n- **AWS Security Hub**: FSBP(Foundational Security Best Practices) 표준\n- **S3 Block Public Access**: 계정/버킷 레벨 설정\n- **IAM Access Analyzer**: 외부 접근 분석\n- **Amazon Inspector**: EC2 네트워크 노출 평가\n- **AWS Trusted Advisor**: 공개 리소스 체크\n\n---\n\n## 2. ✅ 준비해야 할 증빙 자료\n\n### 필수 증빙 자료 목록\n\n#### 📄 문서 1: 공개 리소스 방지 정책 (Public Resource Prevention Policy)\n**파일명 예시**: `SEC-POL-003_Public_Resource_Prevention_Policy_v2.1.pdf`\n\n```\n포함 필수 내용:\n├── 정책 목적 및 적용 범위\n├── 7개 리소스 유형별 공개 금지 기준\n│   ├── S3: 퍼블릭 ACL/정책 금지 조건\n│   ├── RDS: PubliclyAccessible=false 필수\n│   ├── EC2: 퍼블릭 IP 자동 할당 금지 VPC 설정\n│   ├── Security Group: 0.0.0.0/0 허용 금지 포트 목록 (22, 3389, 3306, 5432 등)\n│   ├── EBS Snapshot: 퍼블릭 공유 금지\n│   ├── RDS Snapshot: 퍼블릭 공유 금지\n│   └── AMI: 퍼블릭 공유 금지\n├── 예외 승인 프로세스 (정적 웹사이트 등)\n├── 위반 시 대응 절차 및 SLA\n└── 연간 검토 주기 및 책임자\n```\n\n#### 📄 문서 2: 공개 리소스 탐지 운영 절차서 (Detection Runbook)\n**파일명 예시**: `SEC-RUN-007_Public_Resource_Detection_Runbook_v1.3.pdf`\n\n```\n포함 필수 내용:\n├── 자동 탐지 메커니즘 구성도\n│   ├── AWS Config Rules 목록 및 설정값\n│   ├── Security Hub 활성화 표준\n│   └── 커스텀 Lambda 탐지 로직 (있는 경우)\n├── 알림 체계 (SNS → Slack/PagerDuty 연동)\n├── 탐지 시 대응 워크플로우 (담당자, 에스컬레이션)\n├── 자동 교정(Auto-Remediation) 설정 여부\n└── 탐지 테스트 주기 및 방법\n```\n\n#### 📄 문서 3: 실제 적용 증거 (Implementation Evidence)\n**파일명 예시**: `SEC-EVD-012_Public_Resource_Controls_Evidence_Q4_2024.pdf`\n\n```\n포함 필수 내용:\n├── AWS Config Rules 활성화 스크린샷 (최소 3개 고객 계정)\n├── S3 Block Public Access 설정 스크린샷\n├── Security Hub 점수 및 공개 리소스 관련 Finding 현황\n├── 최근 90일 내 탐지 및 조치 이력 (최소 2-3건)\n└── 고객 계정 목록 (민감정보 마스킹)\n```\n\n#### 📄 문서 4: 예외 관리 대장 (Exception Register)\n**파일명 예시**: `SEC-REG-004_Public_Resource_Exception_Register.xlsx`\n\n```\n포함 필수 컬럼:\n├── 예외 ID\n├── 고객명/계정 ID\n├── 리소스 유형 및 ARN\n├── 공개 필요 사유 (예: 정적 웹사이트, CDN Origin)\n├── 승인자 및 승인일\n├── 보완 통제 (WAF, CloudFront 등)\n├── 만료일 및 재검토 일정\n└── 현재 상태\n```\n\n---\n\n## 3. 📝 단계별 준비 가이드\n\n### Step 1: 현재 공개 리소스 전수 조사 (3-5일)\n\n```bash\n# AWS CLI로 공개 S3 버킷 확인\naws s3api list-buckets --query 'Buckets[*].Name' --output text | \\\nxargs -I {} aws s3api get-bucket-acl --bucket {} --query \\\n\"Grants[?Grantee.URI=='http://acs.amazonaws.com/groups/global/AllUsers']\"\n\n# 공개 RDS 인스턴스 확인\naws rds describe-db-instances --query \\\n\"DBInstances[?PubliclyAccessible==\\`true\\`].[DBInstanceIdentifier,Endpoint.Address]\"\n\n# 공개 EBS 스냅샷 확인\naws ec2 describe-snapshots --owner-ids self --query \\\n\"Snapshots[?contains(to_string(CreateVolumePermissions), 'all')]\"\n\n# 위험한 Security Group 확인 (SSH 0.0.0.0/0)\naws ec2 describe-security-groups --query \\\n\"SecurityGroups[?IpPermissions[?IpRanges[?CidrIp=='0.0.0.0/0'] && (FromPort==\\`22\\` || FromPort==\\`3389\\`)]]\"\n```\n\n**담당자**: 클라우드 보안 엔지니어  \n**산출물**: 공개 리소스 현황 보고서\n\n---\n\n### Step 2: AWS Config Rules 배포 (2-3일)\n\n```yaml\n# CloudFormation 템플릿 예시 (config-rules-public-resources.yaml)\nResources:\n  S3BucketPublicReadProhibited:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      ConfigRuleName: s3-bucket-public-read-prohibited\n      Source:\n        Owner: AWS\n        SourceIdentifier: S3_BUCKET_PUBLIC_READ_PROHIBITED\n      MaximumExecutionFrequency: TwentyFour_Hours\n\n  RDSInstancePublicAccessCheck:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      ConfigRuleName: rds-instance-public-access-check\n      Source:\n        Owner: AWS\n        SourceIdentifier: RDS_INSTANCE_PUBLIC_ACCESS_CHECK\n\n  RestrictedSSH:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      ConfigRuleName: restricted-ssh\n      Source:\n        Owner: AWS\n        SourceIdentifier: INCOMING_SSH_DISABLED\n\n  EC2InstanceNoPublicIP:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      ConfigRuleName: ec2-instance-no-public-ip\n      Source:\n        Owner: AWS\n        SourceIdentifier: EC2_INSTANCE_NO_PUBLIC_IP\n```\n\n**필수 Config Rules 체크리스트**:\n- [ ] `s3-bucket-public-read-prohibited`\n- [ ] `s3-bucket-public-write-prohibited`\n- [ ] `rds-instance-public-access-check`\n- [ ] `rds-snapshots-public-prohibited`\n- [ ] `ec2-instance-no-public-ip`\n- [ ] `restricted-ssh`\n- [ ] `restricted-common-ports`\n- [ ] `ebs-snapshot-public-restorable-check`\n\n---\n\n### Step 3: S3 Block Public Access 계정 레벨 활성화 (1일)\n\n```bash\n# 조직 전체 계정에 S3 Block Public Access 적용\naws s3control put-public-access-block \\\n    --account-id <ACCOUNT_ID> \\\n    --public-access-block-configuration \\\n    \"BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\"\n```\n\n**증빙 스크린샷 필수 포함 항목**:\n- AWS Console > S3 > Block Public Access settings for this account\n- 4개 옵션 모두 \"On\" 상태 확인\n\n---\n\n### Step 4: Security Hub FSBP 표준 활성화 (1-2일)\n\n```bash\n# Security Hub 활성화 및 FSBP 표준 구독\naws securityhub enable-security-hub --enable-default-standards\n\n# FSBP 표준 ARN 확인 후 활성화\naws securityhub batch-enable-standards --standards-subscription-requests \\\n    StandardsArn=\"arn:aws:securityhub:ap-northeast-2::standards/aws-foundational-security-best-practices/v/1.0.0\"\n```\n\n**Security Hub에서 확인할 공개 리소스 관련 Controls**:\n- [S3.1] S3 Block Public Access setting should be enabled\n- [S3.2] S3 buckets should prohibit public read access\n- [S3.3] S3 buckets should prohibit public write access\n- [RDS.2] RDS DB instances should prohibit public access\n- [EC2.19] Security groups should not allow unrestricted access to high risk ports\n\n---\n\n### Step 5: 알림 및 자동 대응 구성 (2-3일)\n\n```python\n# Lambda 함수 예시: 공개 S3 버킷 자동 차단\nimport boto3\nimport json\n\ndef lambda_handler(event, context):\n    s3 = boto3.client('s3')\n    sns = boto3.client('sns')\n    \n    # Config Rule에서 전달된 NON_COMPLIANT 버킷\n    bucket_name = event['detail']['resourceId']\n    \n    # Block Public Access 강제 적용\n    s3.put_public_access_block(\n        Bucket=bucket_name,\n        PublicAccessBlockConfiguration={\n            'BlockPublicAcls': True,\n            'IgnorePublicAcls': True,\n            'BlockPublicPolicy': True,\n            'RestrictPublicBuckets': True\n        }\n    )\n    \n    # 알림 발송\n    sns.publish(\n        TopicArn='arn:aws:sns:ap-northeast-2:123456789012:security-alerts',\n        Subject=f'[AUTO-REMEDIATED] Public S3 Bucket Blocked: {bucket_name}',\n        Message=json.dumps({\n            'bucket': bucket_name,\n            'action': 'Block Public Access Enabled',\n            'timestamp': context.invoked_function_arn\n        })\n    )\n    \n    return {'statusCode': 200, 'body': 'Remediated'}\n```\n\n---\n\n### Step 6: 정책 및 절차서 문서화 (3-5일)\n\n**정책 문서 필수 섹션**:\n\n```markdown\n## 5. 리소스 유형별 통제 기준\n\n### 5.1 Amazon S3\n- 계정 레벨 Block Public Access: 필수 활성화\n- 버킷 레벨 Block Public Access: 필수 활성화\n- 예외: CloudFront Origin으로 사용 시 OAI/OAC 필수 적용\n\n### 5.2 Amazon RDS\n- PubliclyAccessible: false 필수\n- DB Security Group: 0.0.0.0/0 인바운드 금지\n- 예외: 없음 (VPN/Direct Connect 통한 접근만 허용)\n\n### 5.3 Security Groups - 금지 포트 목록\n| 포트 | 서비스 | 0.0.0.0/0 허용 |\n|------|--------|----------------|\n| 22 | SSH | ❌ 금지 |\n| 3389 | RDP | ❌ 금지 |\n| 3306 | MySQL | ❌ 금지 |\n| 5432 | PostgreSQL | ❌ 금지 |\n| 1433 | MSSQL | ❌ 금지 |\n| 27017 | MongoDB | ❌ 금지 |\n| 6379 | Redis | ❌ 금지 |\n\n### 5.4 스냅샷 및 AMI\n- EBS Snapshot: 퍼블릭 공유 금지\n- RDS Snapshot: 퍼블릭 공유 금지  \n- AMI: 퍼블릭 공유 금지\n- 예외: 승인된 파트너 계정 간 공유만 허용\n```\n\n---\n\n### Step 7: 탐지 테스트 및 증거 수집 (2-3일)\n\n```bash\n# 테스트 시나리오: 의도적으로 공개 리소스 생성 후 탐지 확인\n\n# 1. 테스트용 S3 버킷 생성 (Block Public Access 비활성화 계정에서)\naws s3api create-bucket --",
      "language": "ko",
      "createdAt": "2026-01-07T01:35:34.031Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    }
  ],
  "enAdvice": [
    {
      "id": "BUS-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-001",
      "category": "Business",
      "title": "Company Overview",
      "advice": "# BUS-001: Company Overview - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nThis is your **first impression opportunity** during the Full Audit. AWS auditors use this presentation to assess whether your organization truly understands the paradigm shift from traditional managed services to cloud-native operations. It's not just a company introduction—it's a litmus test for your MSP maturity and AWS-centric thinking.\n\n### 🎯 5 Key Points Auditors Evaluate\n\n1. **Cloud-Native Mindset Demonstration**: Auditors specifically look for language showing you understand \"cattle vs pets\" infrastructure philosophy, not just hosting services on AWS\n   \n2. **Automation-First Culture Evidence**: They want to see DevOps/GitOps practices woven into your service delivery model, not bolted on as an afterthought\n\n3. **Operational Scale Proof**: Your customer numbers, AWS monthly billing figures, and staff distribution must demonstrate you're operating at MSP-appropriate scale (typically $1M+ monthly AWS billing across customer base)\n\n4. **Geographic and Time Zone Coverage**: For 24/7 support claims, auditors verify your staff locations can actually deliver follow-the-sun support\n\n5. **AWS Partnership Depth**: They cross-reference your stated AWS Partner Path achievements, competencies, and billing data against AWS Partner Central records\n\n### Relevant AWS Elements to Reference\n- AWS Partner Central profile data\n- AWS Partner Paths (Software, Services, Training, Hardware)\n- AWS Competency badges held\n- AWS Service Delivery designations\n- Monthly AWS billing through your organization\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Primary Evidence: Live Presentation Deck\n**File Name Example**: `[CompanyName]_AWS_MSP_Overview_Audit_2024Q4.pptx`\n\n| Slide Topic | Required Content | Time Allocation |\n|-------------|------------------|-----------------|\n| Company Heritage | Founding year, evolution to cloud, MSP journey timeline | 2 min |\n| Global Footprint | Office map with employee counts per location, NOC/SOC locations | 2 min |\n| Workforce Composition | Total headcount, AWS-certified staff count, MSP practice team size | 2 min |\n| Customer Portfolio | Customer count by segment, ARR ranges, geographic distribution, logo slide (with permission) | 3 min |\n| Cloud-Native Differentiation | How your services differ from traditional MSPs—automation examples, IaC approach | 4 min |\n| AWS Relationship | Partner Path status, competencies, monthly billing range, PDM relationship | 3 min |\n| MSP Service Model | Your specific managed services mapped to AWS Well-Architected pillars | 4 min |\n\n### Supporting Documents (Have Ready, Don't Present)\n- `AWS_Partner_Central_Screenshot_[Date].pdf` - Current partnership status\n- `Customer_Reference_Authorization_Letters/` - Folder with 3-5 customer permission letters for logo usage\n- `AWS_Certification_Roster_[Date].xlsx` - Staff certification details\n- `Monthly_Billing_Summary_Redacted.pdf` - AWS billing showing scale (customer names redacted)\n\n### Evidence Examples That Passed Audits\n```\n✓ \"Acme_Cloud_MSP_Overview_Nov2024_v2.1.pptx\" (18 slides, 19 minutes)\n✓ Supporting: \"AWS_Partner_Scorecard_Q3_2024.pdf\"\n✓ Supporting: \"NOC_Staff_Distribution_Timezone_Coverage.xlsx\"\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Gather AWS Partnership Data (Day 1-2)\n**Responsible**: Alliance Manager / Partner Team\n**Time**: 4 hours\n\n- Log into AWS Partner Central → Dashboard → Download current scorecard\n- Screenshot your Partner Path status, competencies, and Service Delivery badges\n- Export monthly billing data for last 6 months from AWS Billing Console (aggregate across linked accounts)\n- Document your PDM (Partner Development Manager) name and engagement frequency\n\n### Step 2: Compile Workforce Analytics (Day 2-3)\n**Responsible**: HR + Technical Leadership\n**Time**: 6 hours\n\n- Export AWS Certification data from AWS Partner Central → Certifications tab\n- Create breakdown: Total employees → Cloud practice → MSP-dedicated → By location\n- Map staff to time zones for 24/7 coverage visualization\n- Calculate certification density (certs per technical employee)\n\n**Tool**: Use AWS Skill Builder organization dashboard if available\n\n### Step 3: Build Customer Portfolio Narrative (Day 3-5)\n**Responsible**: Sales Operations + Legal\n**Time**: 8 hours\n\n- Segment customers: Enterprise (>$50K MRR) / Mid-Market / SMB\n- Map by industry vertical (Financial Services, Healthcare, Retail, etc.)\n- Obtain written permission for any customer logos displayed\n- Prepare anonymized case metrics: \"Fortune 500 Retailer - 40% cost reduction\"\n\n### Step 4: Develop Cloud-Native Differentiation Story (Day 5-7)\n**Responsible**: Technical Director / CTO\n**Time**: 8 hours\n\nCreate specific comparison slides showing:\n\n| Traditional MSP Approach | Your Cloud-Native Approach |\n|--------------------------|---------------------------|\n| Ticket-based break/fix | Proactive auto-remediation via EventBridge + Lambda |\n| Manual patching windows | AWS Systems Manager Patch Manager with automated rollback |\n| Static capacity planning | Auto Scaling with predictive scaling policies |\n| Periodic security scans | Continuous compliance via AWS Config Rules + Security Hub |\n\n### Step 5: Craft the AWS Relationship Narrative (Day 7-8)\n**Responsible**: Alliance Manager\n**Time**: 4 hours\n\n- Timeline of AWS partnership milestones\n- Joint customer wins with AWS sales teams\n- AWS programs participated in (MAP, SDP, etc.)\n- Investment in AWS practice (training spend, lab environments)\n\n### Step 6: Design and Rehearse Presentation (Day 8-10)\n**Responsible**: Presenter (typically CEO/CTO/VP of MSP Practice)\n**Time**: 12 hours\n\n- Professional design consistent with company branding\n- **Strict 20-minute timing** - rehearse with stopwatch\n- Prepare for Q&A (auditors typically ask 10-15 minutes of follow-ups)\n- Record practice session and review for filler words, pacing\n\n### Step 7: Technical Setup Verification (Day 10)\n**Responsible**: Presenter + IT Support\n**Time**: 2 hours\n\n- Test screen sharing in audit platform (typically Webex or Chime)\n- Ensure backup presentation method (PDF export, secondary device)\n- Verify audio quality and backup microphone\n- Have supporting documents in organized folder for quick access\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic \"Cloud Services\" Language\n**Problem**: Saying \"we help customers migrate to the cloud\" without AWS-specific depth\n**Solution**: Use precise AWS terminology: \"We implement landing zones using AWS Control Tower with customized SCPs for regulated industries\"\n\n### ❌ Mistake 2: Overstating Partnership Status\n**Problem**: Claiming competencies or partner tier not reflected in Partner Central\n**Why It Fails**: Auditors verify against AWS systems in real-time\n**Solution**: Screenshot Partner Central the week of audit; only claim verified status\n\n### ❌ Mistake 3: Presenting Traditional MSP Model with AWS Branding\n**Problem**: Describing 24/7 NOC monitoring as \"watching CloudWatch dashboards\"\n**Why It Fails**: This is legacy MSP thinking—auditors want automation-first approach\n**Solution**: Emphasize automated response: \"CloudWatch Alarms trigger SNS → Lambda → auto-remediation, with human escalation only for novel issues\"\n\n### ❌ Mistake 4: Exceeding Time Limit\n**Problem**: 35-minute presentation crammed with content\n**Why It Fails**: Demonstrates poor preparation and inability to communicate efficiently\n**Solution**: Ruthlessly edit to 18 minutes, leaving 2-minute buffer\n\n### ❌ Mistake 5: No Concrete Numbers\n**Problem**: \"We serve many enterprise customers across various industries\"\n**Why It Fails**: Vague statements suggest lack of operational maturity\n**Solution**: \"147 active managed services customers, 23 enterprise (>$100K ARR), 68% in financial services and healthcare verticals\"\n\n### 🚫 Anti-Patterns to Avoid\n- Reading slides verbatim\n- Including customer logos without written permission\n- Showing AWS billing data with customer names visible\n- Claiming 24/7 support with staff only in one time zone\n- Presenting services you don't actually deliver today\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| Check Item | Verification Method | Pass Criteria |\n|------------|---------------------|---------------|\n| ⏱️ Presentation timing | Record full run-through | ≤ 20 minutes including transitions |\n| 🔢 AWS billing accuracy | Compare to Partner Central | Within 5% of official figures |\n| 📜 Customer logo permissions | Review authorization letters | Written approval for each logo shown |\n| 🏢 Employee count accuracy | Cross-reference HR system | Matches official headcount ± 5% |\n| 🎓 Certification claims | AWS Partner Central export | Every cert claimed is verifiable |\n| 🌍 Geographic coverage | Staff roster by location | Can demonstrate claimed coverage hours |\n| 🔧 Automation examples | Technical team validation | Each example is production-deployed, not theoretical |\n\n### Quality Criteria for Passing\n\n✅ **Narrative Flow**: Story progresses logically from company background → capability → differentiation → AWS alignment\n\n✅ **Specificity Score**: At least 15 specific numbers/metrics throughout presentation\n\n✅ **AWS Depth**: Minimum 10 specific AWS service references with context\n\n✅ **Differentiation Clarity**: Auditor can articulate your unique value in one sentence after viewing\n\n✅ **Professional Polish**: No typos, consistent formatting, high-resolution images\n\n### Day-of-Audit Readiness\n\n```\n□ Presentation loaded and tested in meeting platform\n□ Backup PDF version accessible\n□ Supporting documents in labeled folder\n□ Water and notes for presenter\n□ Technical support person on standby\n□ Quiet environment with professional background\n□ 15-minute buffer before scheduled time\n```\n\n---\n\n## 💡 Pro Tips from Successful Audits\n\n1. **Open with Impact**: Start with a compelling customer outcome, not \"Founded in 2005...\"\n\n2. **Show, Don't Tell**: Include 1-2 brief architecture diagrams showing your automation approach\n\n3. **Anticipate Questions**: Auditors often ask \"How do you handle X for customers?\" - prepare 3-4 scenario responses\n\n4. **Energy Matters**: This sets the tone for entire audit—bring enthusiasm for your MSP practice\n\n5. **Leave Them Wanting More**: End with a strong differentiator statement, not \"any questions?\"",
      "language": "en",
      "createdAt": "2026-01-07T02:41:48.808Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUS-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-002",
      "category": "Business",
      "title": "MSP Practice Growth",
      "advice": "# BUS-002: MSP Practice Growth - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nThis requirement is the **core metric that proves your viability as an MSP business**. AWS wants partners who are actively expanding their managed services practice, not those simply maintaining existing customer relationships. This demonstrates market traction, sales capability, and the ability to deliver value that wins new business.\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **Net New vs. Renewal Distinction**: Auditors specifically verify whether contracts represent genuinely new customer relationships or expanded scope—not just renewals of existing managed services without additional workloads\n\n2. **18-Month Window Compliance**: All 4+ contracts must have effective dates within the 18 months preceding your audit submission date—auditors calculate this precisely\n\n3. **Ongoing Managed Services Nature**: Contracts must clearly indicate recurring managed services (not one-time projects like migrations without subsequent management)\n\n4. **Customer Growth Evidence**: For existing customers, auditors look for quantifiable expansion—new AWS accounts, additional workloads, new regions, or architectural transformations\n\n5. **Commercial Terms Visibility**: Auditors verify that contracts contain actual managed services scope, not just generic consulting agreements\n\n### Relevant AWS Context\n- AWS Partner Central opportunity registration (to cross-reference customer relationships)\n- AWS Marketplace Private Offers (if applicable)\n- AWS Migration Acceleration Program (MAP) transitions to managed services\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Key Contents |\n|--------------|--------|--------------|\n| Customer Contracts | PDF (redacted) | Service scope, effective dates, recurring fee structure |\n| Contract Addenda | PDF (redacted) | New scope additions, expansion dates, incremental services |\n| Statement of Work (SOW) | PDF (redacted) | Detailed managed services deliverables |\n| Customer Onboarding Records | PDF/Screenshots | Proof of relationship start date |\n\n### 📄 Specific Document Requirements\n\n**For Each of the 4+ Contracts, Include:**\n\n1. **Master Services Agreement (MSA) or Managed Services Contract**\n   - Effective date clearly visible (within 18 months)\n   - Managed services scope section (not just \"consulting services\")\n   - Recurring billing terms (monthly/quarterly/annual)\n   - AWS-specific service references\n\n2. **Service Schedule or SOW Attachment**\n   - Specific AWS services being managed (EC2, RDS, EKS, etc.)\n   - SLA commitments (response times, availability targets)\n   - Operational responsibilities (monitoring, patching, incident response)\n\n3. **For Existing Customer Expansions:**\n   - Original contract date (proving pre-existing relationship)\n   - Addendum or change order with new effective date\n   - Clear description of NEW scope (migration of Application X, addition of Production environment, etc.)\n\n### 📁 Evidence File Naming Examples\n```\nBUS-002_Contract1_NewCustomer_AcmeCorp_MSA_2024-03-15.pdf\nBUS-002_Contract1_AcmeCorp_ManagedServices_SOW.pdf\nBUS-002_Contract2_ExistingCustomer_TechStart_Addendum_NewWorkload_2024-06-01.pdf\nBUS-002_Contract3_NewCustomer_GlobalRetail_MSA_2024-01-20.pdf\nBUS-002_Contract4_NewCustomer_FinanceInc_PrivateOffer_2024-04-10.pdf\nBUS-002_Summary_CustomerGrowth_Matrix.xlsx\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Contract Inventory Audit (Week 1)\n**Action:** Pull complete list of all managed services contracts signed in past 18 months from your CRM/contract management system\n\n**Specifics:**\n- Export from Salesforce, HubSpot, or contract repository\n- Filter by: Contract Type = \"Managed Services\" AND Effective Date >= [18 months ago]\n- Flag contracts as \"Net New Customer\" or \"Existing Customer Expansion\"\n\n**Tool:** CRM export + spreadsheet analysis\n**Owner:** Sales Operations / Legal\n**Time:** 2-3 days\n\n### Step 2: Categorize Growth Type (Week 1)\n**Action:** For each potential contract, document the specific growth category\n\n**Categories that QUALIFY:**\n- ✅ Brand new customer (never had MSP relationship)\n- ✅ Existing customer + new AWS workload migration\n- ✅ Existing customer + new AWS account/environment\n- ✅ Existing customer + architectural refactoring (e.g., monolith to microservices)\n- ✅ Existing customer + new AWS region expansion\n\n**Categories that DO NOT QUALIFY:**\n- ❌ Annual renewal of same managed services scope\n- ❌ Price adjustment without scope change\n- ❌ Contract extension without new workloads\n\n**Owner:** Account Managers + Delivery Leads\n**Time:** 1-2 days\n\n### Step 3: Validate 18-Month Window (Week 2)\n**Action:** Calculate exact date range and verify each contract falls within\n\n**Calculation:**\n```\nAudit Submission Date: [Your planned date]\nEarliest Valid Contract Date: [Submission Date - 18 months]\n\nExample: If submitting August 15, 2024\nValid range: February 15, 2023 - August 15, 2024\n```\n\n**Checkpoint:** Verify contract EFFECTIVE date (not signature date) falls in range\n**Owner:** Legal/Contracts Team\n**Time:** 1 day\n\n### Step 4: Prepare Redacted Contract Packages (Week 2-3)\n**Action:** Create audit-ready versions of each contract\n\n**Redaction Guidelines:**\n- ✅ KEEP: Customer name, effective date, service scope, term length, AWS services mentioned\n- ✅ KEEP: Managed services deliverables, SLA terms\n- 🔒 REDACT: Specific pricing/fees (if confidential)\n- 🔒 REDACT: Customer-specific security details\n- ❌ DO NOT REDACT: Dates, scope descriptions, service categories\n\n**Tool:** Adobe Acrobat Pro redaction feature (use proper redaction, not black boxes)\n**Owner:** Legal + MSP Program Lead\n**Time:** 3-4 days\n\n### Step 5: Create Growth Evidence Summary (Week 3)\n**Action:** Build a summary matrix that auditors can quickly reference\n\n**Matrix Columns:**\n| Customer | New/Expansion | Contract Date | Growth Description | AWS Services Managed | Contract Term |\n|----------|---------------|---------------|-------------------|---------------------|---------------|\n| Acme Corp | Net New | 2024-03-15 | New MSP customer, 3 AWS accounts | EC2, RDS, S3, CloudWatch | 24 months |\n| TechStart | Expansion | 2024-06-01 | Added production workload migration | EKS, Aurora, ElastiCache | 12 months |\n\n**Owner:** MSP Program Lead\n**Time:** 1 day\n\n### Step 6: Gather Supporting Corroboration (Week 3)\n**Action:** Collect additional evidence that validates contract authenticity\n\n**Supporting Documents:**\n- AWS Partner Central opportunity records (if registered)\n- Customer onboarding tickets from your ITSM system\n- Initial architecture review documents with dates\n- First invoice/billing record\n\n**Owner:** Sales + Delivery Teams\n**Time:** 2 days\n\n### Step 7: Final Package Assembly (Week 4)\n**Action:** Organize complete evidence package with clear navigation\n\n**Folder Structure:**\n```\nBUS-002_MSP_Practice_Growth/\n├── 00_Summary_Matrix.xlsx\n├── 01_Contract_AcmeCorp/\n│   ├── MSA_Redacted.pdf\n│   └── SOW_ManagedServices.pdf\n├── 02_Contract_TechStart/\n│   ├── Original_MSA_2022.pdf\n│   ├── Addendum_NewWorkload_2024.pdf\n│   └── Expansion_Scope_Description.pdf\n├── 03_Contract_GlobalRetail/\n│   └── ...\n└── 04_Contract_FinanceInc/\n    └── ...\n```\n\n**Owner:** MSP Program Lead\n**Time:** 1 day\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Renewal Contracts Without New Scope\n**Problem:** Submitting a contract that simply extends an existing managed services agreement for another year without any new workloads or services.\n\n**Auditor Red Flag:** Contract shows same scope as previous term, just new dates.\n\n**Solution:** If using existing customer contracts, include explicit addendum showing NEW workload (e.g., \"Addition of Customer's SAP environment to managed services scope effective June 2024\")\n\n---\n\n### ❌ Mistake 2: Project-Based Contracts Without Ongoing Management\n**Problem:** Submitting migration project contracts or one-time assessment engagements.\n\n**Auditor Red Flag:** Contract scope ends after migration completion with no recurring managed services.\n\n**Solution:** Ensure contracts explicitly include post-migration managed services with recurring fees. If migration-focused, include the managed services addendum that kicks in after migration.\n\n---\n\n### ❌ Mistake 3: Contracts Outside 18-Month Window\n**Problem:** Including contracts signed 20 months ago because \"the work is still ongoing.\"\n\n**Auditor Red Flag:** Contract effective date predates the valid window—no exceptions.\n\n**Solution:** Use the addendum approach—if you have a 3-year-old customer, show a recent addendum (within 18 months) that adds significant new scope.\n\n---\n\n### ❌ Mistake 4: Over-Redacting Critical Information\n**Problem:** Redacting so much that auditors cannot verify the contract represents managed services.\n\n**Auditor Red Flag:** \"Unable to verify managed services scope due to redactions.\"\n\n**Solution:** Only redact truly confidential commercial terms. Leave visible: customer name, dates, service descriptions, AWS references, term length, SLA commitments.\n\n---\n\n### ❌ Mistake 5: Generic \"IT Services\" Contracts Without AWS Specificity\n**Problem:** Submitting broad IT outsourcing agreements that don't specifically reference AWS managed services.\n\n**Auditor Red Flag:** Contract could apply to any infrastructure—no AWS-specific language.\n\n**Solution:** Ensure contracts or SOWs explicitly reference AWS services being managed (EC2, RDS, Lambda, etc.) and AWS-specific operational activities (CloudWatch monitoring, AWS Config compliance, etc.)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Minimum 4 contracts submitted** | Count distinct customer contracts | ≥4 separate customer engagements |\n| 2 | **All contracts within 18-month window** | Compare effective dates to submission date minus 18 months | 100% of contracts have valid dates |\n| 3 | **Each contract shows managed services scope** | Review for recurring operational services (not one-time projects) | Clear ongoing management language present |\n| 4 | **Net new OR expansion clearly demonstrated** | For existing customers, verify addendum shows NEW scope | Quantifiable expansion documented |\n| 5 | **AWS services explicitly referenced** | Search contract text for AWS service names | At least 2-3 AWS services mentioned per contract |\n| 6 | **Redactions don't obscure key evidence** | Have someone unfamiliar review redacted docs | Dates, scope, customer name, term all visible |\n| 7 | **Summary matrix accurately reflects contracts** | Cross-reference matrix against actual contract contents | 100% accuracy between summary and source docs |\n\n### 🏁 Quality Gate Questions\n\nBefore submitting, answer YES to all:\n\n- [ ] Would an auditor understand within 30 seconds that this is a NEW managed services relationship (or significant expansion)?\n- [ ] Can the auditor verify the 18-month window without asking follow-up questions?\n- [ ] Is it clear this is ONGOING managed services (not a completed project)?\n- [ ] For existing customer expansions, is the NEW scope explicitly described?\n- [ ] Are AWS services being managed clearly identified?\n\n### 📊 Passing Threshold\n- **Minimum:** 4 qualifying contracts\n- **Recommended:** 5-6 contracts (buffer for potential disqualification of 1-2)\n- **Strong Submission:** Include mix of net new customers AND existing customer expansions to demonstrate both acquisition and growth capabilities\n\n---\n\n## 💡 Pro Tips from Audit Experience\n\n1. **Include a Cover Letter:** Write a 1-page summary explaining your MSP growth story—auditors appreciate context\n\n2. **Highlight AWS Specificity:** If your contracts use generic language, add a supplementary document mapping contract services to specific AWS services\n\n3. **Show the Trend:** If you have more than 4 contracts, include all of them—demonstrating strong growth momentum strengthens your overall application\n\n4. **Prepare for Follow-ups:** Have unredacted versions ready in case auditors request clarification (they may ask to see specific sections)",
      "language": "en",
      "createdAt": "2026-01-07T02:42:50.163Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUS-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-003",
      "category": "Business",
      "title": "Financial Planning and Reporting",
      "advice": "# BUS-003: Financial Planning and Reporting - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters for AWS MSP Program\n\nAWS requires MSP Partners to demonstrate **financial stability and business sustainability**. This isn't just a formality—AWS entrusts customer workloads to MSP Partners, and financially unstable partners pose risks to customer continuity. This requirement verifies that your organization has mature financial governance to support long-term managed services delivery.\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **Forecasting Methodology**: Do you have a structured approach to predict AWS-related revenue, costs (including AWS consumption), and margins? Auditors look for evidence that you're not just \"winging it\"\n\n2. **Budget-to-Actual Tracking**: Can you demonstrate that you compare planned vs. actual financial performance? This shows operational maturity\n\n3. **Review Cadence**: Is there a regular rhythm (monthly/quarterly) for financial review? Ad-hoc reviews suggest immature processes\n\n4. **AWS Business Unit Visibility**: For larger organizations, auditors want to see that AWS/cloud practice financials are tracked distinctly, not buried in general P&L\n\n5. **Decision-Making Integration**: Evidence that financial data actually influences business decisions (not just reports that sit in a drawer)\n\n### 🔗 Relevant AWS Services & Tools\n\n- **AWS Cost Explorer** - For AWS consumption forecasting and trend analysis\n- **AWS Budgets** - For setting and tracking AWS spending thresholds\n- **AWS Cost and Usage Reports (CUR)** - Detailed billing data for financial planning\n- **AWS Partner Central Analytics** - Partner-specific business metrics\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Specific Document | Key Contents |\n|--------------|-------------------|--------------|\n| **Budget Document** | `FY2024_AWS_Practice_Budget.xlsx` or `Annual_Operating_Budget_2024.pdf` | Revenue targets, cost allocations, headcount planning, AWS consumption estimates |\n| **Financial Forecast** | `Q4_2024_Financial_Forecast_v2.xlsx` | 3-6 month forward projections, assumptions documented, variance from prior forecast |\n| **Monthly/Quarterly Report** | `Monthly_Financial_Review_Oct2024.pdf` | Actual vs. budget comparison, KPI dashboard, commentary on variances |\n| **Policy Document** | `Financial_Planning_Policy_v3.1.docx` | Approval workflows, review schedules, roles & responsibilities |\n| **Meeting Minutes** | `Finance_Review_Meeting_Minutes_20241015.pdf` | Attendees, decisions made, action items from financial review |\n\n### 📄 Key Content Requirements for Each Evidence\n\n**Budget Document Must Include:**\n- Line items for AWS-related revenue streams (managed services, professional services, resale)\n- AWS consumption cost projections (pass-through and internal)\n- Gross margin targets for cloud practice\n- Quarterly or monthly breakdown (not just annual totals)\n\n**Financial Forecast Must Show:**\n- Comparison to original budget\n- Updated projections based on current trends\n- Key assumptions (customer growth rate, AWS pricing changes, etc.)\n- Risk factors identified\n\n**Financial Report Must Contain:**\n- Actual figures for the reporting period\n- Variance analysis (% and absolute)\n- Trend charts (3+ months minimum)\n- Management commentary explaining significant variances\n\n### 📁 Example File Names That Pass Audits\n\n```\n✅ Good Examples:\n- \"CloudPractice_Budget_FY2024_Approved_20231115.xlsx\"\n- \"Q3_2024_Financial_Performance_Report_Final.pdf\"\n- \"Monthly_Finance_Review_Package_September2024.pptx\"\n- \"Financial_Planning_SOP_v2.3_Effective_20240101.pdf\"\n\n❌ Poor Examples:\n- \"budget.xlsx\" (no context)\n- \"financials_draft.pdf\" (draft status)\n- \"Q3 numbers.xlsx\" (informal naming)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Gather Existing Financial Documentation (2-3 days)\n**Owner:** Finance Manager + Cloud Practice Lead\n\n- Pull your most recent approved annual/quarterly budget from finance systems\n- Export last 3 months of financial reports from your ERP (NetSuite, QuickBooks, SAP, etc.)\n- Download AWS Cost Explorer data for the same period to cross-reference\n- **Tool:** Export AWS Cost Explorer → Reports → Create Report → Monthly costs by service\n\n### Step 2: Create AWS Practice-Specific Financial View (3-5 days)\n**Owner:** Finance Analyst\n\nIf your financials don't already break out AWS/cloud practice:\n- Create a cost center or department code mapping for AWS-related activities\n- Allocate shared costs (sales, marketing, overhead) using a documented methodology\n- Build a simple P&L template specifically for MSP practice:\n  ```\n  Revenue: Managed Services + Professional Services + AWS Resale\n  COGS: AWS Consumption + Direct Labor + Tools/Licenses\n  Gross Margin: XX%\n  Operating Expenses: Allocated overhead\n  Operating Income: XX%\n  ```\n\n### Step 3: Document Your Financial Planning Process (2-3 days)\n**Owner:** Finance Director\n\nCreate or update a Financial Planning Policy document including:\n- **Annual budgeting cycle** (e.g., \"Budget planning begins in October, Board approval by December 15\")\n- **Forecasting frequency** (e.g., \"Rolling 6-month forecast updated monthly\")\n- **Review meetings** (e.g., \"Monthly P&L review with leadership on 3rd Tuesday\")\n- **Approval authorities** (e.g., \"Variances >10% require VP Finance approval\")\n- **Tools used** (e.g., \"Adaptive Insights for budgeting, Power BI for reporting\")\n\n### Step 4: Generate Compliant Financial Reports (1-2 days)\n**Owner:** Finance Analyst\n\nProduce a sample monthly/quarterly financial report that includes:\n- Executive summary (1 page)\n- Revenue by service line with YoY and budget comparison\n- Cost breakdown with variance analysis\n- AWS consumption trends (pull from AWS Cost Explorer)\n- Key metrics: Gross margin %, customer count, ARR/MRR, AWS spend under management\n\n### Step 5: Collect Evidence of Review Process (1 day)\n**Owner:** Executive Assistant / Finance Manager\n\n- Export calendar invites for recurring finance review meetings\n- Gather meeting minutes or notes from last 2-3 financial reviews\n- Screenshot approval workflows from your finance system (if electronic)\n- Collect email threads showing budget approval chain\n\n### Step 6: Prepare Public Company Alternative (if applicable) (1 day)\n**Owner:** Investor Relations / Legal\n\nFor publicly traded companies:\n- Download most recent 10-K or 10-Q filing from SEC EDGAR\n- Highlight sections covering financial planning, budgeting, and forecasting processes\n- Include earnings call transcript if it discusses cloud/AWS business unit\n\n### Step 7: Package and Quality Check (1 day)\n**Owner:** MSP Program Lead\n\n- Organize all documents in a clearly labeled folder structure\n- Ensure dates are recent (within last quarter)\n- Verify no confidential customer data is exposed\n- Create a brief index document explaining each piece of evidence\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Only High-Level Company Financials\n**Problem:** Auditors receive a company-wide P&L with no visibility into AWS/cloud practice performance.\n\n**Solution:** Even if you're a small company, create a supplementary view that shows AWS-related revenue and costs specifically. A simple Excel breakdown is acceptable.\n\n### ❌ Mistake 2: Outdated Evidence\n**Problem:** Submitting a budget from 18 months ago or financial reports from 2+ quarters back.\n\n**Solution:** Evidence should be from the **most recent completed period**. If auditing in November 2024, submit Q3 2024 reports or October 2024 monthly report. Budget should be current fiscal year.\n\n### ❌ Mistake 3: No Evidence of Actual Review/Approval\n**Problem:** Beautiful budget document exists, but no proof anyone reviewed or approved it.\n\n**Solution:** Include:\n- Email showing budget approval (\"Approved by CFO on 12/15/2023\")\n- Meeting minutes from budget review session\n- Signature page or electronic approval timestamp\n- Screenshot of workflow approval in finance system\n\n### ❌ Mistake 4: Forecast Without Assumptions\n**Problem:** Financial forecast shows numbers but doesn't explain the \"why.\"\n\n**Solution:** Every forecast should include an assumptions section:\n- \"Assumes 15% customer growth rate based on current pipeline\"\n- \"AWS consumption projected at $X based on Cost Explorer trends\"\n- \"Headcount additions: 3 engineers in Q4 per hiring plan\"\n\n### ❌ Mistake 5: Policy Document Without Evidence of Execution\n**Problem:** Submitting a financial planning policy that describes monthly reviews, but no actual meeting minutes or reports to prove it happens.\n\n**Solution:** Always pair policy documents with execution evidence. If policy says \"monthly review,\" include 2-3 months of actual review meeting artifacts.\n\n### 🚫 Anti-Patterns to Avoid\n\n| Anti-Pattern | Why It Fails | What to Do Instead |\n|--------------|--------------|-------------------|\n| Generic corporate policy from parent company | Doesn't show AWS practice-specific governance | Adapt or supplement with practice-specific procedures |\n| Spreadsheet with just numbers, no context | Auditor can't verify it's a real budget vs. random data | Add headers, dates, approval signatures, version control |\n| Submitting AWS Budgets alerts only | Shows cost monitoring, not financial planning | AWS Budgets is supplementary; need business-level financial planning |\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Quality Gates\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Budget document is current fiscal year** | Check document date and fiscal year reference | Document dated within current FY; covers current operating period |\n| 2 | **Financial report is from most recent period** | Verify report date | Within last 90 days (ideally last completed month/quarter) |\n| 3 | **AWS/Cloud practice financials are identifiable** | Review for cloud-specific line items | Can clearly see managed services revenue, AWS consumption costs, practice margin |\n| 4 | **Forecast includes documented assumptions** | Look for assumptions section | Minimum 3-5 key assumptions explicitly stated |\n| 5 | **Evidence of review process exists** | Check for meeting minutes, approval emails, or signatures | At least one artifact showing human review/approval occurred |\n| 6 | **Policy document matches actual practice** | Cross-reference policy with reports | If policy says \"monthly review,\" evidence shows monthly reports exist |\n| 7 | **No sensitive data exposed** | Scan for customer names, SSNs, bank details | Redact or anonymize any PII or confidential customer information |\n\n### ✅ Quality Criteria Summary\n\n**Minimum Passing Standard:**\n- One budget OR forecast document (current period)\n- One financial report (last quarter or month)\n- Evidence of review process (policy OR meeting minutes)\n\n**Strong Submission Includes:**\n- Annual budget with quarterly breakdown\n- Monthly financial report with variance analysis\n- Rolling forecast with assumptions\n- Financial planning policy document\n- Meeting minutes from recent financial review\n- AWS Cost Explorer/Budgets data as supplementary evidence\n\n### 🎯 Final Verification Questions\n\nBefore submitting, ask yourself:\n\n1. \"If I were an auditor seeing this for the first time, would I understand our financial planning process?\"\n2. \"Can I trace from policy → budget → forecast → actual report → review meeting?\"\n3. \"Is the AWS/cloud business clearly visible in these financials, or buried in corporate numbers?\"\n4. \"Are all documents dated and from recent periods?\"\n5. \"Is there at least one piece of evidence showing someone actually reviewed and approved these financials?\"\n\n---\n\n## 💡 Pro Tips from Successful Audits\n\n**Tip 1:** If you're a smaller MSP without sophisticated finance systems, a well-organized Excel workbook with multiple tabs (Budget, Forecast, Actuals, Variance Analysis) can absolutely pass—just ensure it's clearly dated and shows evidence of being actively used.\n\n**Tip 2:** Include a brief cover memo (1 paragraph) explaining your financial planning cycle. This helps auditors quickly understand your process without digging through documents.\n\n**Tip 3:** If using AWS Cost Explorer for consumption forecasting, take screenshots showing you've enabled Cost Explorer forecasting features—this demonstrates AWS-native financial planning integration.",
      "language": "en",
      "createdAt": "2026-01-07T02:43:51.926Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUS-004_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUS-004",
      "category": "Business",
      "title": "Go-To-Market",
      "advice": "# BUS-004: Go-To-Market - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nGo-To-Market (GTM) is the **commercial foundation** that proves your organization is a sustainable MSP business, not just a technical service provider. AWS wants to confirm that you have a systematic approach to growing your managed services business—not relying on ad-hoc opportunities or existing customer relationships alone.\n\nThis requirement validates that your MSP practice is **scalable and repeatable**, with dedicated sales motions distinct from project-based consulting or resale activities.\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **MSP-Specific Sales Motion**: Auditors look for evidence that your sales process for managed services is DIFFERENT from selling projects or licenses. They want to see recurring revenue positioning, not one-time deal structures.\n\n2. **Seller Enablement Artifacts**: Proof that your sales team has been trained specifically on managed services value propositions, pricing models (monthly recurring), and customer qualification criteria.\n\n3. **Lead Generation Mechanisms**: Documented demand generation activities—not just \"we get referrals.\" They want to see intentional marketing campaigns, AWS co-sell activities, or partner-sourced lead programs.\n\n4. **AWS Collaboration Evidence**: How you work with AWS Account Managers, Partner Development Managers (PDMs), and leverage AWS Partner Network (APN) resources like ACE Pipeline Manager.\n\n5. **Customer Engagement Framework**: A structured first-call or discovery process that qualifies managed services opportunities and positions your MSP offering.\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Document Type | Specific Format | Key Contents |\n|---------------|-----------------|--------------|\n| **MSP Sales Playbook** | PDF/PPT (15-30 pages) | Opportunity identification criteria, qualification questions, competitive positioning, pricing guidance |\n| **First Call Deck** | PowerPoint (10-15 slides) | Customer-facing presentation used in initial MSP opportunity discussions |\n| **Seller Training Materials** | PDF/Video recordings | MSP-specific training curriculum, certification records, quiz results |\n| **Demand Generation Plan** | Document + Campaign Examples | Marketing campaigns, webinar recordings, AWS co-marketing activities |\n| **ACE Pipeline Screenshots** | Screenshots with dates | Active MSP opportunities registered in AWS ACE Pipeline Manager |\n\n### 📄 Specific Content Requirements for Each Evidence\n\n**MSP Sales Playbook Must Include:**\n- Ideal Customer Profile (ICP) for managed services (company size, AWS spend, technical maturity)\n- Qualification framework (e.g., BANT adapted for recurring services)\n- Objection handling scripts for common MSP objections (\"we can manage ourselves,\" \"too expensive monthly\")\n- Handoff process from sales to delivery/onboarding team\n- Pricing calculator or rate card for managed services tiers\n\n**First Call Deck Must Include:**\n- Your MSP value proposition (not generic company intro)\n- Service tier overview with clear deliverables\n- Customer success stories with measurable outcomes\n- Typical engagement timeline from contract to steady-state\n- Call-to-action and next steps\n\n**Example File Names:**\n```\nMSP_Sales_Playbook_v2.3_2024.pdf\nMSP_FirstCall_Deck_Enterprise_Tier.pptx\nSeller_Enablement_Training_Recording_Q1_2024.mp4\nAWS_CoSell_Campaign_FinServ_2024.pdf\nACE_Pipeline_MSP_Opportunities_Screenshot_20240115.png\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Document Your MSP Opportunity Identification Criteria (Week 1)\n**Action:** Create a written framework defining what makes a good MSP prospect\n\n- Define minimum AWS monthly spend threshold (e.g., >$10K/month)\n- List technical indicators (multi-account, production workloads, compliance needs)\n- Document business indicators (no internal cloud team, growth stage, M&A activity)\n- Create a scoring matrix for opportunity prioritization\n\n**Tool:** Use a spreadsheet template or Salesforce custom fields\n**Owner:** Sales Operations + MSP Practice Lead\n**Time:** 3-4 hours\n\n### Step 2: Build MSP-Specific First Call Deck (Week 1-2)\n**Action:** Create customer-facing presentation distinct from your general company deck\n\n- Open with customer pain points (not your company history)\n- Include 2-3 customer case studies with metrics (cost savings %, incident reduction)\n- Show your service delivery model visually (NOC, tools, escalation)\n- Include pricing philosophy (not exact numbers, but model explanation)\n\n**Tool:** PowerPoint/Google Slides with your brand template\n**Owner:** Marketing + MSP Sales Lead\n**Time:** 8-10 hours\n\n### Step 3: Develop Seller Training Program (Week 2-3)\n**Action:** Create and deliver MSP-specific sales training\n\n- Record a 30-60 minute training session covering:\n  - MSP market landscape and AWS MSP program benefits\n  - Your service tiers and pricing model\n  - Qualification questions and red flags\n  - Demo of your customer portal/tools\n- Create a 10-question certification quiz\n- Document attendance and completion records\n\n**Tool:** Zoom/Teams recording, Google Forms for quiz\n**Owner:** MSP Practice Lead + Sales Enablement\n**Time:** 6-8 hours (creation) + 2 hours (delivery)\n\n### Step 4: Document Demand Generation Activities (Week 3)\n**Action:** Compile evidence of intentional lead generation\n\n- Screenshot active campaigns (LinkedIn ads, Google Ads targeting \"AWS managed services\")\n- Export webinar registration/attendance lists from MSP-focused events\n- Document AWS co-marketing activities (joint webinars, case study publications)\n- Show content marketing examples (blog posts, whitepapers on managed services topics)\n\n**Tool:** Marketing automation platform exports, AWS Partner Marketing Central\n**Owner:** Marketing Team\n**Time:** 4-5 hours\n\n### Step 5: Configure and Populate ACE Pipeline Manager (Week 3-4)\n**Action:** Ensure MSP opportunities are properly registered with AWS\n\n- Log into AWS Partner Central → ACE Pipeline Manager\n- Register at least 3-5 active MSP opportunities with:\n  - Opportunity type: \"Managed Services\"\n  - Expected monthly recurring revenue\n  - Customer use case description\n- Take dated screenshots showing pipeline status\n\n**Tool:** AWS Partner Central ACE Pipeline Manager\n**Owner:** Partner Alliance Manager + Sales Reps\n**Time:** 2-3 hours\n\n### Step 6: Create Sales-to-Delivery Handoff Documentation (Week 4)\n**Action:** Document the transition process from closed deal to onboarding\n\n- Create handoff checklist (technical requirements, access credentials, SLA agreements)\n- Document kickoff meeting agenda template\n- Show CRM workflow or ticket creation for new MSP customers\n\n**Tool:** Confluence/SharePoint, CRM workflow screenshots\n**Owner:** Sales Operations + Delivery Lead\n**Time:** 3-4 hours\n\n### Step 7: Compile and Package Evidence (Week 4)\n**Action:** Organize all materials into audit-ready format\n\n- Create folder structure matching evidence requirements\n- Add cover sheet explaining each document's purpose\n- Include dates and version numbers on all materials\n- Prepare 2-3 minute verbal explanation for each artifact\n\n**Owner:** MSP Program Manager\n**Time:** 2-3 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Generic Company Sales Decks\n**Problem:** Partners submit their standard \"About Us\" presentation that covers all services, with managed services as one bullet point.\n\n**Solution:** Create a dedicated MSP-first deck where managed services is the PRIMARY topic, not a footnote. The deck should be usable in a real customer meeting focused solely on managed services.\n\n### ❌ Mistake 2: No Evidence of Seller Training Completion\n**Problem:** Partners claim \"we trained our team\" but have no attendance records, quiz scores, or training materials.\n\n**Solution:** Maintain a training log with:\n- Date of training\n- Attendee names and roles\n- Training agenda/curriculum\n- Completion certificates or quiz scores\n- Refresher training schedule\n\n### ❌ Mistake 3: Empty or Stale ACE Pipeline\n**Problem:** ACE Pipeline Manager shows zero MSP opportunities or only closed/lost deals from 12+ months ago.\n\n**Solution:** Actively register current opportunities BEFORE the audit. Auditors check ACE to verify you're actually pursuing MSP business. Minimum 3 active opportunities recommended.\n\n### ❌ Mistake 4: Confusing Project Sales with MSP Sales\n**Problem:** Sales playbook describes selling migration projects or one-time assessments, not recurring managed services.\n\n**Solution:** Ensure your playbook explicitly addresses:\n- Monthly recurring revenue conversations\n- Multi-year contract positioning\n- Ongoing service delivery expectations\n- Customer success/retention metrics (not just new logo acquisition)\n\n### ❌ Mistake 5: No AWS Co-Sell Evidence\n**Problem:** Partners operate in isolation without demonstrating AWS field team collaboration.\n\n**Solution:** Document at least 2-3 examples of:\n- Joint customer meetings with AWS Account Managers\n- Opportunities sourced through AWS referrals\n- Co-branded marketing activities\n- PDM engagement on MSP opportunities\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ | First Call Deck is MSP-specific | Review slide titles and content | >80% of content focuses on managed services, not general consulting |\n| ✅ | Sales Playbook includes qualification criteria | Search for \"qualification\" or \"ICP\" sections | Documented criteria with specific thresholds (spend, size, technical indicators) |\n| ✅ | Seller training has completion evidence | Check for attendance logs, quiz scores | At least 80% of customer-facing sellers completed training in last 12 months |\n| ✅ | Demand generation shows intentional activities | Review campaign materials, not just \"referrals\" | Minimum 2 documented campaigns or marketing activities targeting MSP prospects |\n| ✅ | ACE Pipeline has active MSP opportunities | Log into Partner Central and screenshot | 3+ opportunities with \"Managed Services\" type, created/updated within 90 days |\n| ✅ | AWS collaboration is documented | Check for joint meeting notes, co-sell evidence | At least 1 documented AWS co-sell activity or PDM engagement |\n| ✅ | Handoff process exists | Review sales-to-delivery documentation | Written checklist or workflow showing transition from sales close to service delivery |\n\n### 🏆 Quality Criteria for Passing\n\n- **Completeness:** All five evidence types present (Playbook, First Call Deck, Training, Demand Gen, ACE Pipeline)\n- **Specificity:** Materials are clearly MSP-focused, not repurposed from other service lines\n- **Currency:** Documents dated within last 12 months, ACE pipeline shows recent activity\n- **Practicality:** Materials appear to be actually used (not created just for audit)\n- **AWS Alignment:** Evidence of AWS partnership leverage (ACE, co-sell, partner programs)\n\n### 💡 Pro Tip for Audit Day\nBe prepared to **walk through a recent MSP opportunity** from lead identification to close (or current stage). Auditors may ask you to demonstrate how your documented process was applied to a real customer situation. Have 2-3 example opportunities ready to discuss with specific details.",
      "language": "en",
      "createdAt": "2026-01-07T02:44:48.022Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUSP-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUSP-001",
      "category": "Business",
      "title": "Web Presence",
      "advice": "# BUSP-001: Web Presence - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nThis is the **first touchpoint** where AWS and potential customers evaluate your MSP capabilities. AWS uses this landing page to verify that you're genuinely operating as an AWS-focused managed services provider, not just claiming the title. It's also a marketing validation—AWS wants partners who actively promote their AWS expertise, which helps expand AWS's market reach.\n\n### 🔎 Key Points Auditors Evaluate\n\n1. **AWS MSP-Specific Messaging**: Auditors check if your page explicitly mentions \"managed services\" for AWS—not just \"cloud consulting\" or generic IT services. The phrase \"AWS Managed Services\" or equivalent must be prominent.\n\n2. **Differentiated Value Proposition**: What makes YOUR AWS practice unique? Auditors look for specific claims like \"Healthcare compliance expertise on AWS\" or \"SAP on AWS migration specialists\"—not generic \"we help you with cloud.\"\n\n3. **Case Study Integration**: Direct links to AWS-specific case studies must be visible and functional. Auditors will click these links to verify they lead to actual AWS customer success stories.\n\n4. **Technical Credibility Signals**: Mentions of AWS certifications, competencies, partner tier status, and specific AWS services you manage (EC2, RDS, EKS, etc.) demonstrate genuine expertise.\n\n5. **Service Lifecycle Coverage**: Evidence that you cover Design → Build → Manage phases, not just one aspect of the customer journey.\n\n### Relevant AWS Features to Reference\n- AWS Partner Network (APN) badge/logo usage\n- AWS Competency badges (if earned)\n- AWS Service Delivery designations\n- AWS Well-Architected Framework alignment\n- Specific AWS services your team manages\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence\n| Evidence Type | Format | Specific Requirements |\n|--------------|--------|----------------------|\n| **Primary Landing Page URL** | Public URL | Must be live, indexed, and accessible without login |\n\n### Key Content That MUST Appear on Your Landing Page\n\n**Section 1: AWS MSP Practice Overview**\n- Clear statement: \"AWS Managed Services Provider\" or \"AWS MSP Partner\"\n- Description of your managed services offering (monitoring, optimization, security management, etc.)\n- Your AWS partner tier and any competencies\n\n**Section 2: Differentiated Expertise Statement**\n```\nExample: \"Specializing in financial services workloads on AWS, \nwe bring 8 years of PCI-DSS compliance expertise and have \nmigrated 50+ trading platforms to AWS.\"\n```\n\n**Section 3: Service Phases Covered**\n- **Design**: Architecture consulting, Well-Architected Reviews\n- **Build**: Migration, deployment, IaC implementation\n- **Manage**: 24/7 monitoring, incident response, cost optimization\n\n**Section 4: Case Study Links**\n- Minimum 2-3 AWS-specific case studies\n- Each must describe AWS services used and business outcomes\n\n### Evidence Examples\n```\n✅ Good URL: https://yourcompany.com/aws-managed-services\n✅ Good URL: https://yourcompany.com/services/aws-msp\n❌ Bad URL: https://yourcompany.com/cloud-services (too generic)\n❌ Bad URL: https://yourcompany.com/partners/aws (just a partner page, not MSP-specific)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Your Current Web Presence (Day 1-2)\n**Action**: Search your website for \"AWS\" and \"managed services\" terms\n- Use `site:yourcompany.com AWS managed services` in Google\n- Document what currently exists vs. what's missing\n- **Tool**: Screaming Frog SEO Spider for full site crawl\n\n**Responsible**: Marketing Manager + AWS Practice Lead\n**Time**: 4 hours\n\n### Step 2: Draft Differentiation Statement (Day 3-5)\n**Action**: Interview your AWS delivery team to identify unique strengths\n- What industries do you serve most?\n- What AWS services does your team use daily?\n- What customer problems do you solve that others don't?\n\n**Output Example**:\n```\n\"[Company] delivers AWS managed services for mid-market \nmanufacturing companies, specializing in IoT workload \nmanagement using AWS IoT Core, Greengrass, and Timestream. \nOur 15-person AWS-certified team has managed 200+ \nindustrial IoT deployments since 2019.\"\n```\n\n**Responsible**: AWS Practice Director\n**Time**: 8 hours\n\n### Step 3: Create/Update Landing Page Content (Day 6-12)\n**Action**: Build the page with required sections\n\n**Page Structure Template**:\n```\nH1: AWS Managed Services | [Your Company Name]\nH2: Your Trusted AWS MSP Partner\n   - Partner tier badge\n   - Competency badges\n   \nH2: Our AWS Managed Services\n   - 24/7 monitoring & incident response\n   - Cost optimization & FinOps\n   - Security & compliance management\n   - Infrastructure automation\n   \nH2: Design. Build. Manage.\n   - Describe each phase\n   \nH2: Why Choose Us (Differentiation)\n   - Industry expertise\n   - Team credentials\n   - Unique capabilities\n   \nH2: Customer Success Stories\n   - Case study cards with links\n   \nCTA: Contact Our AWS Team\n```\n\n**Responsible**: Web Developer + Content Writer\n**Time**: 20-30 hours\n\n### Step 4: Prepare and Link Case Studies (Day 8-15)\n**Action**: Create or update 2-3 AWS-specific case studies\n\n**Each Case Study Must Include**:\n- Customer industry (can anonymize company name)\n- Business challenge\n- AWS services used (be specific: \"Amazon RDS for PostgreSQL\" not just \"database\")\n- Quantified results (\"40% cost reduction\", \"99.99% uptime achieved\")\n- Your team's role in ongoing management\n\n**Responsible**: Customer Success Manager + Marketing\n**Time**: 16 hours (if creating new case studies)\n\n### Step 5: Add Technical Credibility Elements (Day 13-16)\n**Action**: Include proof points on the page\n\n**Must-Have Elements**:\n- AWS Partner Network logo (follow [AWS trademark guidelines](https://aws.amazon.com/trademark-guidelines/))\n- Team certification count (\"25 AWS certifications across our team\")\n- Specific AWS services you manage (list 8-12 services)\n- Any AWS Competencies or Service Delivery designations\n\n**Responsible**: AWS Practice Lead + Web Developer\n**Time**: 4 hours\n\n### Step 6: SEO and Accessibility Check (Day 17-18)\n**Action**: Ensure page is publicly accessible and indexed\n\n**Verification Steps**:\n```bash\n# Check if page is indexed\nsite:yourcompany.com/aws-managed-services\n\n# Verify no login required\ncurl -I https://yourcompany.com/aws-managed-services\n# Should return 200 OK without redirects to login\n\n# Check robots.txt doesn't block the page\nhttps://yourcompany.com/robots.txt\n```\n\n**Responsible**: SEO Specialist / Web Developer\n**Time**: 2 hours\n\n### Step 7: Internal Review and Go-Live (Day 19-21)\n**Action**: Final review before submission\n\n- Have AWS Practice Lead verify technical accuracy\n- Have Legal review any customer references\n- Test all case study links\n- Screenshot the page for your records\n\n**Responsible**: Marketing Manager + AWS Practice Director\n**Time**: 4 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic Cloud Page Instead of AWS MSP Page\n**Problem**: Submitting `yourcompany.com/cloud-services` that mentions AWS, Azure, and GCP equally\n**Solution**: Create a dedicated AWS MSP landing page or ensure AWS is the primary focus with explicit \"managed services\" language\n\n### ❌ Mistake 2: Case Study Links Lead to Gated Content\n**Problem**: Auditors click case study links but hit a form requiring email signup\n**Solution**: Ensure at least the summary/overview of each case study is publicly accessible. You can gate the full PDF, but the web version must be readable.\n\n### ❌ Mistake 3: Missing the \"Manage\" Phase\n**Problem**: Page describes migration and consulting but doesn't explain ongoing managed services\n**Solution**: Explicitly describe your operational services:\n- \"24/7 monitoring via Amazon CloudWatch\"\n- \"Monthly cost optimization reviews\"\n- \"Patch management and security updates\"\n- \"Incident response with 15-minute SLA\"\n\n### ❌ Mistake 4: Outdated Partner Tier or Competency Claims\n**Problem**: Page says \"AWS Advanced Partner\" but you're now Select tier, or claims a Competency you lost\n**Solution**: Verify current status in AWS Partner Central before publishing. Update page within 30 days of any status changes.\n\n### ❌ Mistake 5: No Differentiation Statement\n**Problem**: Page reads like every other MSP: \"We help you with AWS\"\n**Solution**: Answer these questions on your page:\n- What industries do you specialize in?\n- What AWS services are you best at?\n- What size companies do you serve?\n- What geography do you cover?\n\n### 🚫 Anti-Patterns to Avoid\n- Using stock photos of generic \"cloud\" imagery without AWS context\n- Listing every AWS service (150+) instead of your actual expertise areas\n- Claiming \"AWS experts\" without showing certifications or credentials\n- Having the page exist only in staging/preview mode during audit\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Page is publicly accessible** | Open in incognito browser, no VPN | Page loads without login, no 403/404 errors |\n| 2 | **\"AWS Managed Services\" explicitly stated** | Ctrl+F search for \"managed services\" | Phrase appears in H1, H2, or first paragraph |\n| 3 | **Differentiation statement present** | Read the \"Why Us\" section | Specific industry, service, or capability focus is clear—not generic |\n| 4 | **Design-Build-Manage lifecycle covered** | Scan service descriptions | All three phases mentioned with specific activities |\n| 5 | **Case study links functional** | Click each link | Links open to AWS-specific case studies, not generic portfolio |\n| 6 | **Case studies mention AWS services** | Read each case study | Specific AWS service names appear (not just \"cloud\") |\n| 7 | **AWS Partner credentials visible** | Visual scan of page | APN logo, partner tier, certifications, or competencies displayed |\n| 8 | **Page indexed by Google** | Search `site:yoururl.com/page-path` | Page appears in search results |\n\n### Quality Criteria Summary\n```\n✅ PASS: Dedicated AWS MSP page with clear differentiation, \n   working case study links, and explicit managed services \n   language covering full lifecycle\n\n⚠️ CONDITIONAL: Page exists but missing one element \n   (e.g., case studies not linked, differentiation unclear)\n   → Auditor may request clarification\n\n❌ FAIL: Generic cloud page, broken links, gated content, \n   or no mention of ongoing managed services\n```\n\n### Pro Tip for Audit Day\n📸 Take a full-page screenshot of your landing page on the day you submit evidence. If your marketing team updates the page before the audit review, you have proof of what was submitted. Use browser extensions like \"GoFullPage\" for Chrome.",
      "language": "en",
      "createdAt": "2026-01-07T02:25:15.315Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUSP-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUSP-002",
      "category": "Business",
      "title": "Sales and Marketing Accreditations",
      "advice": "# BUSP-002: Sales and Marketing Accreditations - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters for AWS MSP Program\nThis requirement ensures your customer-facing teams can effectively communicate AWS value propositions and technical capabilities. AWS wants MSP partners whose sales and marketing staff understand AWS fundamentals—not just technical teams. This directly impacts customer acquisition quality and reduces misaligned expectations during engagements.\n\n### 🔍 Key Points Auditors Examine\n\n1. **Coverage Ratio**: Auditors verify that ALL personnel in sales/marketing roles supporting AWS practice have completed accreditations—not just a subset. They cross-reference your organizational chart against completion records.\n\n2. **Accreditation Currency**: AWS Partner accreditations expire after **2 years**. Auditors check completion dates to ensure certifications are still valid at audit time.\n\n3. **Role-Accreditation Alignment**: Sales roles should have **Sales Accreditation (Business)**, while pre-sales/technical marketing roles may have **Accreditation (Technical)**. Auditors verify appropriate matching.\n\n4. **AWS Skill Builder Account Verification**: Completion records must show AWS Partner-specific accreditations (not general AWS training). The course codes BP1WX82N37 (Business) and 8DDTPJ2RK5 (Technical) must be identifiable.\n\n5. **Organizational Scope Definition**: Auditors want clarity on which business units constitute your \"AWS MSP practice\"—vague boundaries raise red flags.\n\n### Relevant AWS Platforms\n- **AWS Skill Builder** (partner.aws/training)\n- **AWS Partner Central** (partnercentral.awspartner.com)\n- **AWS Partner Training Portal**\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Key Contents |\n|--------------|--------|--------------|\n| **Accreditation Completion Report** | Excel/CSV | Name, Email, Role, Accreditation Name, Completion Date, Expiry Date |\n| **Individual Certificates** | PDF | AWS Skill Builder certificates showing course code and completion date |\n| **Organizational Chart** | PDF/PNG | Clearly marked AWS MSP practice sales/marketing team members |\n| **Role Definition Document** | Word/PDF | Description of which roles require which accreditation |\n\n### 📄 Specific Evidence Examples\n\n**File Name Examples:**\n- `BUSP-002_Sales_Marketing_Accreditation_Tracker_2024Q4.xlsx`\n- `BUSP-002_OrgChart_AWS_MSP_Practice_Sales_Team.pdf`\n- `AWS_Partner_Sales_Accreditation_JohnSmith_2024.pdf`\n- `BUSP-002_Role_Accreditation_Mapping.docx`\n\n### Required Content in Accreditation Tracker Spreadsheet\n\n```\nColumn A: Employee Full Name\nColumn B: Corporate Email\nColumn C: Job Title\nColumn D: Department (Sales/Marketing/Pre-Sales)\nColumn E: Accreditation Type (Business/Technical)\nColumn F: AWS Skill Builder Course ID\nColumn G: Completion Date\nColumn H: Expiry Date (Completion + 2 years)\nColumn I: Certificate File Reference\nColumn J: Status (Current/Expiring Soon/Expired)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Define AWS MSP Practice Scope (Day 1-2)\n**Action**: Create a formal document listing all business units supporting AWS MSP activities\n- Identify sales teams covering AWS-related deals\n- Include marketing staff creating AWS content/campaigns\n- Include business development roles pursuing AWS opportunities\n- **Output**: `AWS_MSP_Practice_Scope_Definition.pdf`\n- **Responsible**: Sales Director + HR\n\n### Step 2: Conduct Personnel Inventory (Day 3-5)\n**Action**: Extract employee list from HRIS for defined scope\n- Pull current roster from Workday/BambooHR/SAP\n- Include: Name, Email, Job Title, Start Date, Manager\n- Flag any contractors or part-time staff (they need accreditations too!)\n- **Tool**: HRIS export + Excel\n- **Responsible**: HR Business Partner\n\n### Step 3: Audit Current Accreditation Status (Day 6-10)\n**Action**: Access AWS Partner Central → Training Transcript\n- Navigate to: Partner Central > Training > My Team's Training\n- Export team completion records\n- Cross-reference against personnel inventory\n- Identify gaps: No accreditation, wrong type, or expired\n- **Tool**: AWS Partner Central Admin access required\n- **Responsible**: Partner Alliance Manager\n\n### Step 4: Launch Remediation Campaign (Day 11-25)\n**Action**: Enroll missing personnel in appropriate courses\n- **Sales Accreditation (Business)**: ~4 hours, self-paced\n  - URL: https://skillbuilder.aws/learn/BP1WX82N37\n- **Accreditation (Technical)**: ~4 hours, self-paced\n  - URL: https://skillbuilder.aws/learn/8DDTPJ2RK5\n- Set completion deadline 2 weeks before audit\n- Send calendar blocks for training time\n- **Responsible**: L&D Team + Direct Managers\n\n### Step 5: Collect Individual Certificates (Day 26-28)\n**Action**: Gather PDF certificates from each team member\n- Instruct staff to download from AWS Skill Builder profile\n- Certificates must show: Full name, Course title, Completion date\n- Store in centralized SharePoint/Google Drive folder\n- **Naming Convention**: `[LastName]_[FirstName]_[AccreditationType]_[YYYYMMDD].pdf`\n- **Responsible**: Training Coordinator\n\n### Step 6: Build Master Tracker & Validate (Day 29-30)\n**Action**: Compile all data into audit-ready spreadsheet\n- Ensure 100% coverage of defined scope\n- Verify no expiry dates fall before audit date\n- Add hyperlinks to individual certificate files\n- Calculate compliance percentage (must be 100%)\n- **Responsible**: Partner Alliance Manager\n\n### Step 7: Create Evidence Package (Day 31)\n**Action**: Assemble final submission materials\n- Combine tracker, org chart, and role mapping into single ZIP\n- Write brief cover memo explaining evidence structure\n- Conduct peer review before submission\n- **Responsible**: MSP Program Lead\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Excluding Contractors and Part-Time Staff\n**Problem**: Organizations often forget that contract sales reps or part-time marketing coordinators supporting AWS practice need accreditations too.\n**Solution**: Include ALL personnel regardless of employment type in your scope definition. If they touch AWS customers, they need accreditation.\n\n### ❌ Mistake 2: Submitting Expired Accreditations\n**Problem**: AWS Partner accreditations expire after 2 years. Teams submit certificates from 2021 for a 2024 audit.\n**Solution**: Add expiry date column to tracker. Set calendar reminders 90 days before expiration. Re-certify proactively.\n\n### ❌ Mistake 3: Wrong Accreditation Type for Role\n**Problem**: Technical pre-sales engineer has Sales Accreditation (Business) instead of Technical Accreditation.\n**Solution**: Create clear role-to-accreditation mapping. Pre-sales/Solutions Architects → Technical. Account Executives/Marketing → Business.\n\n### ❌ Mistake 4: Submitting Generic AWS Training Instead of Partner Accreditations\n**Problem**: Teams submit AWS Cloud Practitioner or other certifications thinking they satisfy this requirement.\n**Solution**: Only **AWS Partner: Sales Accreditation (Business)** or **AWS Partner: Accreditation (Technical)** count. Verify course IDs match BP1WX82N37 or 8DDTPJ2RK5.\n\n### ❌ Mistake 5: Incomplete Organizational Coverage\n**Problem**: Submitting accreditations for 15 people when org chart shows 20 in AWS practice.\n**Solution**: Auditors will count heads. Ensure tracker matches org chart exactly. Document any exceptions (e.g., new hire in onboarding with completion deadline).\n\n### 🚫 Anti-Patterns to Avoid\n- Rushing accreditations in final week (completion dates cluster suspiciously)\n- Using personal email accounts for AWS Skill Builder (corporate email required)\n- Submitting screenshots instead of official PDF certificates\n- Claiming \"marketing doesn't need this\" (they absolutely do)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ | **100% Coverage** | Compare tracker rows against org chart headcount | Every person in AWS MSP practice scope has a row |\n| ✅ | **Valid Expiry Dates** | Filter tracker for expiry dates | All expiry dates are AFTER scheduled audit date |\n| ✅ | **Correct Accreditation Types** | Cross-reference job titles with accreditation column | Sales/Marketing → Business; Pre-Sales/Technical → Technical |\n| ✅ | **Certificate-Tracker Match** | Spot-check 5 random certificates against tracker | Names, dates, and course titles match exactly |\n| ✅ | **Corporate Email Verification** | Review email column in tracker | All emails use company domain (no gmail/yahoo) |\n| ✅ | **Course ID Verification** | Check certificates for course codes | BP1WX82N37 or 8DDTPJ2RK5 visible on certificates |\n| ✅ | **Org Chart Currency** | Verify org chart date | Org chart dated within 30 days of submission |\n\n### 📊 Quality Criteria Summary\n- **Minimum Threshold**: 100% of defined scope must have valid accreditations\n- **Acceptable Evidence Formats**: PDF certificates, Excel tracker with hyperlinks, AWS Partner Central screenshots showing team completion\n- **Audit Red Flag**: Any gap between org chart headcount and accreditation count triggers deeper investigation\n\n### 💡 Pro Tip for Audit Day\nPrepare a simple reconciliation statement:\n> \"Our AWS MSP Sales & Marketing practice consists of 18 personnel across 3 departments. All 18 have completed required accreditations as evidenced in the attached tracker. 15 hold Sales Accreditation (Business) and 3 Pre-Sales Engineers hold Accreditation (Technical). All accreditations are valid through [DATE].\"\n\nThis proactive summary demonstrates control and reduces auditor questions.",
      "language": "en",
      "createdAt": "2026-01-07T02:26:03.396Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "BUSP-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "BUSP-003",
      "category": "Business",
      "title": "Customer Case Studies",
      "advice": "# BUSP-003: Customer Case Studies - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nCustomer Case Studies are the **core evidence demonstrating your actual managed service delivery capabilities**. AWS uses this item to verify that you're not just theoretically capable, but have actually delivered successful managed services to real customers. This is one of the most scrutinized items because it directly proves your operational track record.\n\n### 🎯 Key Points Auditors Specifically Look For\n\n1. **Managed Services Focus, Not Just Implementation**\n   - Auditors specifically check if the case study describes **ongoing operational management** (monitoring, patching, incident response, optimization) rather than one-time migration or deployment projects\n   - A common rejection reason: \"This describes a migration project, not managed services\"\n\n2. **Customer Challenge → AWS Solution → Business Outcome Flow**\n   - Clear articulation of the customer's original pain point\n   - How YOUR managed services (not just AWS services) addressed it\n   - Quantifiable business results (cost savings %, uptime improvement, etc.)\n\n3. **Diversity of Customer Scenarios**\n   - Different industries, company sizes, or use cases across the 4 case studies\n   - Shows breadth of your MSP capabilities\n\n4. **Freshness and Uniqueness**\n   - Case studies must NOT have been used in previous MSP audits or renewals\n   - Auditors cross-reference against your previous submissions\n\n5. **Public Artifact Authenticity**\n   - Public case studies must be actually accessible via URL\n   - Must clearly identify YOUR company as the MSP delivering the service\n\n### Relevant AWS Services Commonly Featured\n- **Operational Services**: AWS Systems Manager, Amazon CloudWatch, AWS Config, AWS Backup\n- **Security Services**: AWS Security Hub, Amazon GuardDuty, AWS WAF\n- **Cost Management**: AWS Cost Explorer, AWS Budgets, Savings Plans\n- **Infrastructure**: Amazon EC2, Amazon RDS, Amazon EKS, AWS Lambda\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Structure\n\n| Evidence Type | Quantity | Format | Key Requirement |\n|--------------|----------|--------|-----------------|\n| Public Case Studies | ≥ 2 | URL + PDF backup | Publicly accessible, your company named |\n| Private Case Studies | ≥ 2 | PDF/PPT/Word | Customer approval obtained |\n\n### 📄 Public Case Study Requirements\n\n**File Naming Convention:**\n```\nBUSP-003_Public_CaseStudy_[CustomerName]_[Industry]_[Date].pdf\nExample: BUSP-003_Public_CaseStudy_AcmeCorp_Retail_2024.pdf\n```\n\n**Must Include:**\n- ✅ Customer company name (with permission for public disclosure)\n- ✅ Your company clearly identified as the MSP partner\n- ✅ Specific AWS services used in the managed service\n- ✅ Quantifiable outcomes (e.g., \"99.95% uptime achieved\", \"40% cost reduction\")\n- ✅ Timeline showing ongoing service delivery (not just project completion)\n- ✅ Description of your operational processes (monitoring, incident management, etc.)\n\n**Acceptable Public Formats:**\n- Company blog post on your website\n- AWS Partner Network case study (if published through APN)\n- YouTube video with transcript\n- Published whitepaper\n- Press release with detailed service description\n\n### 📄 Private Case Study Requirements\n\n**File Naming Convention:**\n```\nBUSP-003_Private_CaseStudy_[CustomerCode]_[Industry]_[Date].pdf\nExample: BUSP-003_Private_CaseStudy_Client-A_Healthcare_2024.pdf\n```\n\n**Must Include:**\n- ✅ Customer industry and size (name can be anonymized)\n- ✅ Detailed technical architecture diagram\n- ✅ Your managed service scope and SLAs\n- ✅ Specific operational activities performed\n- ✅ Evidence of ongoing relationship (contract duration, renewal)\n- ✅ Customer testimonial or approval letter (even if anonymized)\n\n### 📋 Evidence Package Checklist\n\n```\n📁 BUSP-003_Evidence_Package/\n├── 📄 BUSP-003_CaseStudy_Summary_Matrix.xlsx\n├── 📁 Public_CaseStudies/\n│   ├── 📄 BUSP-003_Public_CaseStudy_1_[Customer]_[Industry].pdf\n│   ├── 📄 BUSP-003_Public_URL_Screenshot_1.png\n│   ├── 📄 BUSP-003_Public_CaseStudy_2_[Customer]_[Industry].pdf\n│   └── 📄 BUSP-003_Public_URL_Screenshot_2.png\n├── 📁 Private_CaseStudies/\n│   ├── 📄 BUSP-003_Private_CaseStudy_1_[Code]_[Industry].pdf\n│   ├── 📄 BUSP-003_Customer_Approval_Letter_1.pdf\n│   ├── 📄 BUSP-003_Private_CaseStudy_2_[Code]_[Industry].pdf\n│   └── 📄 BUSP-003_Customer_Approval_Letter_2.pdf\n└── 📄 BUSP-003_Previous_Audit_Declaration.pdf\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Your Existing Customer Portfolio (Week 1)\n**Time: 3-4 days | Owner: Account Management Team**\n\n🔧 **Specific Actions:**\n1. Export customer list from your CRM (Salesforce, HubSpot, etc.)\n2. Filter for customers with:\n   - Active managed service contracts ≥ 6 months\n   - AWS workloads being managed by your team\n   - No previous use in MSP audits\n3. Create scoring matrix:\n\n| Customer | Contract Duration | AWS Services | Public OK? | Story Strength (1-5) |\n|----------|------------------|--------------|------------|---------------------|\n| Acme Corp | 18 months | EC2, RDS, CloudWatch | Yes | 5 |\n| Beta Inc | 12 months | EKS, Lambda | No | 4 |\n\n### Step 2: Select and Prioritize 6-8 Candidates (Week 1)\n**Time: 1-2 days | Owner: MSP Program Lead**\n\n🎯 **Selection Criteria:**\n- Choose 6-8 candidates (buffer for customers who decline)\n- Ensure diversity:\n  - At least 2 different industries\n  - Mix of SMB and Enterprise\n  - Different AWS service focuses (compute, database, containers, serverless)\n- Prioritize customers with measurable outcomes\n\n### Step 3: Obtain Customer Permissions (Week 2-3)\n**Time: 2 weeks | Owner: Account Managers**\n\n📧 **For Public Case Studies - Send This Request:**\n```\nSubject: AWS MSP Partner Validation - Case Study Request\n\nDear [Customer Contact],\n\nAs part of our AWS Managed Service Provider certification, we'd like to \nfeature [Company Name] as a success story. This would involve:\n\n- A publicly available case study on our website\n- Mention of your company name and industry\n- Description of the AWS managed services we provide\n\nBenefits to you:\n- Featured as an innovative AWS adopter\n- Joint PR opportunity\n- Review/approval rights before publication\n\nWould you be open to a 30-minute call to discuss?\n```\n\n📧 **For Private Case Studies:**\n```\nSubject: AWS MSP Audit - Confidential Reference Request\n\nDear [Customer Contact],\n\nFor our AWS MSP certification audit, we need to provide confidential \ncase studies. Your company information would:\n\n- Only be shared with AWS auditors under NDA\n- NOT be published publicly\n- Can be anonymized if preferred\n\nWe simply need written approval to describe our managed service \nengagement. Would you be comfortable providing this?\n```\n\n### Step 4: Develop Case Study Content (Week 3-4)\n**Time: 1-2 weeks | Owner: Marketing + Technical Team**\n\n📝 **Use This Structure for Each Case Study:**\n\n**Section 1: Customer Profile (1 paragraph)**\n- Industry, size, business context\n- Why they needed managed services\n\n**Section 2: Challenge (2-3 paragraphs)**\n- Specific pain points before your engagement\n- Business impact of those challenges\n- Why they chose your MSP services\n\n**Section 3: Solution - YOUR Managed Services (3-4 paragraphs)**\n- Specific AWS services deployed\n- **YOUR operational processes** (this is critical):\n  - 24/7 monitoring setup using CloudWatch/Datadog\n  - Incident response procedures\n  - Patch management cadence\n  - Cost optimization reviews\n  - Security monitoring and response\n- SLAs committed and achieved\n\n**Section 4: Results (2 paragraphs + metrics)**\n- Quantifiable outcomes:\n  - \"Achieved 99.97% uptime (up from 98.5%)\"\n  - \"Reduced AWS spend by 35% through Reserved Instance management\"\n  - \"Mean Time to Resolution decreased from 4 hours to 45 minutes\"\n- Business impact quotes from customer\n\n**Section 5: Ongoing Partnership**\n- Contract renewal information\n- Future roadmap (shows ongoing relationship)\n\n### Step 5: Create Public Artifacts (Week 4-5)\n**Time: 1 week | Owner: Marketing Team**\n\n🌐 **For Blog Posts:**\n1. Publish on your company blog with proper SEO\n2. Include customer logo (with permission)\n3. Add AWS Partner badge\n4. Ensure URL is indexable (not behind login)\n\n🎥 **For Videos:**\n1. Record customer testimonial (even 2-3 minutes is sufficient)\n2. Upload to YouTube (unlisted is NOT acceptable - must be public)\n3. Create transcript document\n\n### Step 6: Compile Evidence Package (Week 5)\n**Time: 2-3 days | Owner: MSP Program Lead**\n\n📊 **Create Summary Matrix (Excel):**\n\n| Case Study | Type | Customer | Industry | AWS Services | Key Outcome | URL/Location |\n|------------|------|----------|----------|--------------|-------------|--------------|\n| CS-1 | Public | Acme Corp | Retail | EC2, RDS, CloudWatch | 99.95% uptime | www.yoursite.com/case-study-acme |\n| CS-2 | Public | Beta Inc | Finance | EKS, GuardDuty | 40% cost reduction | www.yoursite.com/case-study-beta |\n| CS-3 | Private | Client-A | Healthcare | EC2, S3, Backup | HIPAA compliance | [Attached PDF] |\n| CS-4 | Private | Client-B | Manufacturing | IoT, Lambda | 60% faster processing | [Attached PDF] |\n\n### Step 7: Pre-Submission Validation (Week 6)\n**Time: 2 days | Owner: Quality Assurance**\n\n✅ **Validation Checklist:**\n- [ ] All public URLs are accessible without login\n- [ ] Your company name appears in all public artifacts\n- [ ] \"Managed services\" language is explicit (not just \"implementation\")\n- [ ] Each case study has unique customer (no duplicates)\n- [ ] None were used in previous audits (check historical records)\n- [ ] Customer approval documentation is on file\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Migration/Implementation Projects as Managed Services\n\n**What Goes Wrong:**\nCase study describes: \"We migrated 50 servers to AWS over 3 months\"\n\n**Why It Fails:**\nAuditors specifically look for **ongoing operational management**, not project-based work.\n\n**How to Fix:**\nReframe to emphasize post-migration operations:\n- \"Following migration, we provide 24/7 monitoring, monthly patching, and quarterly optimization reviews\"\n- Include specific operational metrics (MTTR, uptime, ticket volumes)\n\n---\n\n### ❌ Mistake 2: Public Case Study URL Returns 404 or Requires Login\n\n**What Goes Wrong:**\n- URL was valid during preparation but page was moved/deleted\n- Case study is behind a gated form requiring email submission\n- Video is set to \"unlisted\" on YouTube\n\n**Why It Fails:**\nAuditors test every URL. If they can't access it freely, it doesn't count as \"publicly available.\"\n\n**How to Fix:**\n- Take screenshots of live pages as backup evidence\n- Test URLs from incognito browser mode\n- Set calendar reminder to verify URLs 1 week before audit\n\n---\n\n### ❌ Mistake 3: Reusing Case Studies from Previous Audits\n\n**What Goes Wrong:**\nPartner submits a case study that was used in their 2022 MSP renewal, thinking minor updates make it \"new.\"\n\n**Why It Fails:**\nAWS maintains records of previously submitted evidence. The requirement explicitly states case studies must not have been \"used in any previous MSP audits and renewals.\"\n\n**How to Fix:**\n- Maintain internal registry of all case studies submitted to AWS\n- Create declaration document: \"We confirm these case studies have not been submitted in previous MSP audits\"\n- Develop new customer stories continuously (not just at audit time)\n\n---\n\n### ❌ Mistake 4: Generic Case Studies Without YOUR Managed Service Details\n\n**What Goes Wrong:**\nCase study reads like an AWS service description rather than YOUR service delivery:\n\"Amazon RDS provides automated backups and multi-AZ deployment...\"\n\n**Why It Fails:**\nAuditors want to see YOUR operational processes, not AWS feature descriptions.\n\n**How to Fix:**\nInclude specific details about YOUR operations:\n- \"Our NOC team monitors 47 CloudWatch alarms configured for this customer\"\n- \"We perform weekly backup verification tests with documented runbooks\"\n- \"Our engineers conduct monthly cost optimization reviews using AWS Cost Explorer\"\n\n---\n\n### ❌ Mistake 5: No Quantifiable Business Outcomes\n\n**What Goes Wrong:**\nCase study concludes with: \"The customer was very satisfied with our services.\"\n\n**Why It Fails:**\nVague satisfaction statements don't demonstrate measurable value delivery.\n\n**How to Fix:**\nInclude specific metrics:\n- Uptime percentages (before/after)\n- Cost savings ($ or %)\n- Performance improvements (latency, throughput)\n- Operational efficiency (ticket reduction, MTTR)\n- Compliance achievements (certifications obtained)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Before Submission, Verify Each Item:\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Total case study count ≥ 4** | Count documents in evidence package | Exactly 4 or more unique case studies |\n| 2 | **Public case studies ≥ 2** | Verify URLs are accessible | Both URLs load without login in incognito mode |\n| 3 | **Your company identified in public artifacts** | Search for company name in each public piece | Company name appears at least once, clearly as the MSP |\n| 4 | **\"Managed services\" explicitly mentioned** | Ctrl+F search each document | Each case study uses \"managed service\" or equivalent terminology |\n| 5 | **No previous audit reuse** | Cross-reference with historical submission log | All 4 case studies are confirmed new |\n| 6 | **Customer diversity demonstrated** | Review summary matrix | At least 2 different industries represented |\n| 7 | **Quantifiable outcomes present** | Check Results section of each | Each case study has at least 2 specific metrics |\n| 8 | **Operational activities described** | Review Solution sections | Each describes YOUR monitoring, patching, incident response, or optimization activities |\n| 9 | **Customer approval documented** | Check for approval letters/emails | Written approval on file for all 4 customers |\n| 10 | **Evidence naming convention followed** | Review file names | All files follow BUSP-003_[Type]_CaseStudy_[Details] format |\n\n### 🏁 Quality Criteria for Passing\n\n**Each case study should score YES on all of these:**\n\n```\n□ Does it describe ONGOING managed services (not a one-time project)?\n□ Is YOUR company's role as MSP clearly articulated?\n□ Are specific AWS services mentioned?\n□ Are YOUR operational processes described (not just AWS features)?\n□ Are there quantifiable business outcomes?\n□ Is there evidence of customer approval?\n□ Is it genuinely new (not used in previous audits)?\n```\n\n**Minimum Passing Standard:**\n- 4/4 case studies meet all criteria above\n- 2/4 are publicly accessible with your company named\n- 0/4 have been used in previous MSP audits\n\n---\n\n## 💡 Pro Tips from Audit Experience\n\n1. **Start Early**: Customer approvals often take 4-6 weeks. Don't wait until audit prep begins.\n\n2. **Build a Pipeline**: Maintain a rolling list of 8-10 ",
      "language": "en",
      "createdAt": "2026-01-07T02:27:26.256Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-001",
      "category": "Governance",
      "title": "Risk and Mitigation Plans",
      "advice": "# GOV-001: Risk and Mitigation Plans - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters for AWS MSP Program\n\nGOV-001 is the **foundational governance requirement** that demonstrates your organization's maturity in operating an AWS managed services business. AWS wants to ensure that partners entrusted with customer workloads have systematically identified what could go wrong and have concrete plans to address those scenarios. This isn't about having zero risks—it's about proving you **understand and actively manage** the risks inherent in running an MSP practice.\n\n### 🎯 Key Points Auditors Specifically Look For\n\n1. **AWS Practice-Specific Risks**: Auditors reject generic corporate risk registers. They want to see risks directly tied to your AWS managed services business—not just IT security risks, but business risks like \"What happens if AWS releases a service that commoditizes your offering?\"\n\n2. **Quantified Impact Assessment**: Each risk must have measurable impact criteria (revenue impact, customer churn rate, SLA breach probability) rather than vague \"High/Medium/Low\" ratings without context.\n\n3. **Named Risk Owners**: Every risk must have a specific individual (not a team or role) accountable for monitoring and mitigation execution.\n\n4. **Evidence of Active Management**: Auditors look for timestamps, version history, and meeting minutes showing the risk register is a living document—not something created for the audit.\n\n5. **Connection to Business Planning**: Risks should link to your AWS practice growth plans, hiring roadmap, and customer acquisition strategy.\n\n### Relevant AWS Services & Features\n\n- **AWS Organizations** (for multi-account risk scenarios)\n- **AWS Business Associate Addendum** (compliance risk documentation)\n- **AWS Partner Central** (partner tier/competency loss risks)\n- **AWS Service Health Dashboard** (operational dependency risks)\n- **AWS Pricing Calculator** (financial modeling for cost risks)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Documents\n\n| Document | Format | Key Contents |\n|----------|--------|--------------|\n| **AWS Practice Risk Register** | Excel/Smartsheet with version control | Minimum 15-20 identified risks specific to AWS MSP operations |\n| **Risk Assessment Methodology Document** | PDF (3-5 pages) | Scoring criteria, assessment frequency, escalation thresholds |\n| **Quarterly Risk Review Meeting Minutes** | PDF with attendee signatures | Last 4 quarters of documented reviews |\n| **Risk Mitigation Action Plans** | Project plan format (Gantt/Kanban) | Active mitigation projects with deadlines |\n| **Risk Appetite Statement** | Board-approved PDF | Defines acceptable risk levels for AWS practice |\n\n### Key Content Requirements for Each Evidence\n\n**AWS Practice Risk Register Must Include:**\n```\nFor each risk entry:\n├── Risk ID (e.g., AWS-RISK-2024-007)\n├── Risk Category (Financial/Operational/Compliance/Strategic/Reputational)\n├── Risk Description (specific to AWS practice)\n├── Root Cause Analysis\n├── Likelihood Score (1-5 with defined criteria)\n├── Impact Score (1-5 with $ thresholds)\n├── Risk Score (calculated)\n├── Current Controls\n├── Residual Risk Level\n├── Mitigation Plan Reference\n├── Risk Owner (named individual)\n├── Review Date\n└── Status (Open/Mitigating/Accepted/Closed)\n```\n\n### 📁 Evidence File Name Examples\n\n```\nGOV-001-A_AWS_Practice_Risk_Register_v3.2_2024Q4.xlsx\nGOV-001-B_Risk_Assessment_Methodology_v2.0.pdf\nGOV-001-C_Risk_Review_Minutes_2024Q3.pdf\nGOV-001-D_Mitigation_Plan_AWS_Skills_Gap.pdf\nGOV-001-E_Risk_Appetite_Statement_Board_Approved.pdf\nGOV-001-F_Risk_Lifecycle_Process_Flowchart.pdf\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Conduct AWS Practice-Specific Risk Workshop (Week 1)\n**Time**: 4-hour facilitated session  \n**Responsible**: AWS Practice Lead + Finance Director + HR Lead + Operations Manager\n\n**Specific Actions:**\n- Use the **\"AWS MSP Risk Categories Framework\"** below to brainstorm:\n\n| Category | Example Risks to Discuss |\n|----------|-------------------------|\n| **Financial** | Customer concentration (>30% revenue from one client), AWS credit/discount dependency, currency exposure for global customers |\n| **Talent** | AWS certification attrition, key person dependency on Solutions Architects, hiring competition from AWS/hyperscalers |\n| **Operational** | NOC capacity limits, incident response during peak periods, tool vendor lock-in (e.g., CloudHealth discontinuation) |\n| **Compliance** | AWS Partner Program requirement changes, customer audit failures, data residency regulation changes |\n| **Strategic** | AWS launching competing managed services, partner tier demotion risk, technology obsolescence (e.g., EC2 vs. serverless shift) |\n| **Reputational** | Customer security breach, public SLA failure, negative AWS partner reviews |\n\n**Output**: Raw list of 30+ potential risks\n\n---\n\n### Step 2: Develop Quantified Scoring Criteria (Week 1-2)\n**Time**: 8 hours  \n**Responsible**: Finance Director + AWS Practice Lead\n\n**Create specific scoring matrices:**\n\n**Likelihood Criteria (Example):**\n| Score | Definition | Frequency |\n|-------|------------|-----------|\n| 1 | Rare | Less than once per 5 years |\n| 2 | Unlikely | Once per 2-3 years |\n| 3 | Possible | Once per year |\n| 4 | Likely | Multiple times per year |\n| 5 | Almost Certain | Monthly or more frequent |\n\n**Impact Criteria (Example for $10M AWS Practice):**\n| Score | Financial Impact | Customer Impact | Operational Impact |\n|-------|-----------------|-----------------|-------------------|\n| 1 | <$50K | Minor inconvenience | <4 hours disruption |\n| 2 | $50K-$200K | SLA credit required | 4-24 hours disruption |\n| 3 | $200K-$500K | Customer escalation | 1-3 days disruption |\n| 4 | $500K-$1M | Customer churn risk | 3-7 days disruption |\n| 5 | >$1M | Multiple customer losses | >7 days or permanent |\n\n---\n\n### Step 3: Build the Risk Register with AWS Practice Context (Week 2-3)\n**Time**: 16 hours  \n**Responsible**: AWS Practice Lead (owner) + Department heads (contributors)\n\n**Mandatory Risk Categories to Include:**\n\n🔴 **Must-Have Risks for AWS MSP Audit:**\n1. AWS Partner Program tier/competency loss risk\n2. Key AWS-certified personnel departure risk\n3. Customer concentration risk (name top 3 customers)\n4. AWS service outage impact on managed customers\n5. Security incident in customer AWS environment\n6. Compliance certification loss (SOC2, ISO27001)\n7. AWS pricing/discount structure changes\n8. Rapid growth capacity constraints\n9. Tool/platform vendor discontinuation\n10. Regulatory change affecting cloud services\n\n**Tool Recommendation**: Use Smartsheet or Jira with custom fields—auditors appreciate seeing a proper tracking system over Excel.\n\n---\n\n### Step 4: Document Risk Lifecycle Management Process (Week 3)\n**Time**: 8 hours  \n**Responsible**: Quality/Compliance Manager\n\n**Create a process document showing:**\n\n```\nRisk Lifecycle Stages:\n1. IDENTIFICATION → Who can submit risks? How are they logged?\n2. ASSESSMENT → Who scores? What's the review process?\n3. TREATMENT → Accept/Mitigate/Transfer/Avoid decision criteria\n4. MONITORING → Review frequency by risk level\n5. REPORTING → Who sees what? Board reporting threshold\n6. CLOSURE → Criteria for closing a risk\n```\n\n**Include a RACI matrix:**\n| Activity | Practice Lead | Finance | HR | Operations | Board |\n|----------|--------------|---------|----|-----------:|-------|\n| Identify New Risk | R | C | C | C | I |\n| Score Risk | A | R | R | R | I |\n| Approve Mitigation Budget | C | R | I | I | A |\n| Monthly Review | R | C | C | C | I |\n| Quarterly Board Report | R | C | I | I | A |\n\n---\n\n### Step 5: Create Mitigation Action Plans for Top Risks (Week 3-4)\n**Time**: 12 hours  \n**Responsible**: Risk Owners (various)\n\n**For each risk scored ≥15 (High), create a dedicated mitigation plan:**\n\n**Example: AWS Skills Gap Risk Mitigation Plan**\n```\nRisk: Insufficient AWS-certified staff to support growth\nCurrent State: 8 certified engineers, need 15 by Q4\nMitigation Actions:\n├── Action 1: Partner with AWS Training to get 50% cert discount (Owner: HR, Due: Jan 30)\n├── Action 2: Implement certification bonus program $2K/cert (Owner: Finance, Due: Feb 15)\n├── Action 3: Hire 3 senior AWS engineers (Owner: HR, Due: Mar 30)\n├── Action 4: Cross-train 4 existing staff on AWS (Owner: Training, Due: Apr 30)\n├── Action 5: Establish AWS re:Invent attendance rotation (Owner: Practice Lead, Due: May 15)\nBudget: $150,000\nSuccess Metrics: 15 certified engineers by Oct 1\nReview Frequency: Monthly\n```\n\n---\n\n### Step 6: Establish Governance Cadence with Evidence Trail (Week 4)\n**Time**: 4 hours setup + ongoing  \n**Responsible**: AWS Practice Lead + Executive Assistant\n\n**Set up recurring meetings with documented outputs:**\n\n| Meeting | Frequency | Attendees | Output Document |\n|---------|-----------|-----------|-----------------|\n| Risk Review | Monthly | Practice Lead + Risk Owners | Updated register + action items |\n| Executive Risk Committee | Quarterly | C-suite + Practice Lead | Board risk report |\n| Annual Risk Assessment | Yearly | All stakeholders | Full risk reassessment |\n\n**Critical**: Use calendar invites with agenda templates. Auditors will ask to see the invite history.\n\n---\n\n### Step 7: Prepare Audit-Ready Evidence Package (Week 4-5)\n**Time**: 6 hours  \n**Responsible**: Compliance Manager\n\n**Compile evidence showing the lifecycle:**\n- Screenshot of risk register version history (showing multiple updates)\n- Meeting minutes from last 4 quarterly reviews (with signatures)\n- Email threads showing risk escalations\n- Board presentation slides mentioning AWS practice risks\n- Closed risk examples showing full lifecycle\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic Enterprise Risk Register Submission\n**What Goes Wrong**: Partners submit their corporate risk register that mentions \"cloud services\" once in 50 risks.\n\n**Why Auditors Reject This**: The requirement explicitly states \"relevant to the AWS Partner's AWS managed service practice.\"\n\n**Fix**: Create a dedicated AWS Practice Risk Register. It can reference the enterprise register but must stand alone with AWS-specific content.\n\n---\n\n### ❌ Mistake 2: Static Document with No Version History\n**What Goes Wrong**: A beautifully formatted PDF risk assessment dated 6 months ago with no evidence of updates.\n\n**Auditor Question**: \"Show me how this document has changed in the last year.\"\n\n**Fix**: \n- Use a tool with automatic version tracking (SharePoint, Confluence, Smartsheet)\n- Include a \"Document Control\" section showing revision history\n- Minimum 3-4 updates visible in the last 12 months\n\n---\n\n### ❌ Mistake 3: Missing Financial Risk Quantification\n**What Goes Wrong**: Risks described as \"High Impact\" without dollar figures.\n\n**Auditor Expectation**: \"What does 'high' mean for your business? $100K? $10M?\"\n\n**Fix**: Every risk must have a financial impact estimate, even if it's a range. Example: \"Customer churn from major incident: $500K-$2M annual revenue impact\"\n\n---\n\n### ❌ Mistake 4: No Evidence of Board/Executive Awareness\n**What Goes Wrong**: Risk register exists but no proof leadership reviews it.\n\n**Auditor Question**: \"How does your leadership team engage with these risks?\"\n\n**Fix**: Include:\n- Board meeting minutes mentioning risk review\n- Executive signature on Risk Appetite Statement\n- Quarterly risk summary in board pack (even a single slide counts)\n\n---\n\n### ❌ Mistake 5: Mitigation Plans Without Progress Tracking\n**What Goes Wrong**: Mitigation actions listed but no status updates or completion evidence.\n\n**Auditor Expectation**: \"Show me a risk that was mitigated and how you tracked progress.\"\n\n**Fix**: \n- Use project management tool (Jira, Asana, Monday.com) for mitigation tracking\n- Include screenshots of completed mitigation tasks\n- Show before/after risk scores demonstrating mitigation effectiveness\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|--------------------:|---------------|\n| ✅ 1 | Risk register contains minimum 15 AWS practice-specific risks | Count risks, verify AWS relevance | All 15+ risks directly relate to AWS MSP operations |\n| ✅ 2 | Each risk has a named individual owner (not team/role) | Review \"Owner\" column | 100% of risks have \"John Smith\" not \"Operations Team\" |\n| ✅ 3 | Financial impact quantified for all High/Critical risks | Check impact descriptions | Dollar amounts or ranges present for risks scored ≥15 |\n| ✅ 4 | Version history shows updates in last 90 days | Check document metadata/version log | Minimum 2 updates visible in last quarter |\n| ✅ 5 | Quarterly review meeting minutes available for last 4 quarters | Locate meeting documentation | 4 separate dated documents with attendee lists |\n| ✅ 6 | At least 3 risks have detailed mitigation action plans | Cross-reference risk IDs to mitigation docs | Plans include owner, deadline, budget, success metrics |\n| ✅ 7 | Risk lifecycle process documented with RACI | Review methodology document | Clear process from identification to closure with responsibilities |\n\n### 🎯 Quality Criteria for Passing\n\n**Minimum Passing Standard:**\n- Risk register is clearly AWS practice-focused (not generic IT)\n- Evidence of active management (not a one-time document)\n- Leadership engagement demonstrated\n- Mitigation plans show progress, not just intentions\n\n**Excellence Standard (Auditor Commendation):**\n- Risk appetite statement board-approved\n- Automated risk scoring in GRC tool\n- Closed risks demonstrating full lifecycle\n- Risk metrics in regular management reporting\n- Integration with AWS Well-Architected risk findings\n\n---\n\n### 📌 Quick Reference: Auditor's Likely Questions\n\nPrepare answers for these specific questions:\n\n1. *\"Walk me through how a new risk gets added to your register.\"*\n2. *\"Show me a risk that was identified, mitigated, and closed.\"*\n3. *\"How does your board engage with AWS practice risks?\"*\n4. *\"What happens if your largest AWS customer churns tomorrow?\"*\n5. *\"How do you track mitigation plan progress?\"*\n6. *\"When was this risk register last updated, and by whom?\"*",
      "language": "en",
      "createdAt": "2026-01-07T02:49:15.258Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-002",
      "category": "Governance",
      "title": "Customer Satisfaction",
      "advice": "# GOV-002: Customer Satisfaction - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nAWS MSP 프로그램에서 고객 만족도 측정은 단순한 형식적 요건이 아닙니다. AWS는 MSP 파트너가 **지속적으로 고객 가치를 창출하고 있는지**를 검증하고자 합니다. 특히 AWS는 자체 CSAT 데이터(Partner Central 수집)를 인정하지 않으므로, **파트너 독자적인 피드백 수집 체계**가 필수입니다.\n\n### 🔍 Auditor가 집중적으로 확인하는 5가지 포인트\n\n1. **수집 방법의 객관성**: 고객이 솔직하게 응답할 수 있는 익명성 또는 제3자 수집 방식인가?\n2. **정기성과 체계성**: 일회성이 아닌 정기적 수집 프로세스가 문서화되어 있는가?\n3. **피드백 처리 프로세스**: 부정적 피드백 발생 시 에스컬레이션 및 해결 절차가 있는가?\n4. **실제 운영 증거**: 최근 6개월 이내 실제 수집된 데이터와 조치 이력이 있는가?\n5. **개선 활동 연계**: 수집된 피드백이 서비스 개선에 실제로 반영된 사례가 있는가?\n\n### 관련 AWS 서비스 및 도구\n- **Amazon Connect** (Contact-based Survey 구현)\n- **Amazon Pinpoint** (설문 발송 자동화)\n- **Amazon QuickSight** (CSAT 데이터 시각화 대시보드)\n- **AWS Lambda + API Gateway** (설문 응답 수집 자동화)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 필수 증거 목록\n\n| 증거 유형 | 파일명 예시 | 핵심 포함 내용 |\n|-----------|-------------|----------------|\n| **CSAT 정책 문서** | `CSAT_Policy_v2.1.pdf` | 수집 주기, 방법, 책임자, 에스컬레이션 기준 |\n| **설문 양식 템플릿** | `Customer_Survey_Template_2024.docx` | 실제 사용 중인 설문 문항 (NPS, CSAT 점수 포함) |\n| **수집 도구 스크린샷** | `SurveyMonkey_Dashboard_Screenshot.png` | 사용 중인 설문 플랫폼 설정 화면 |\n| **최근 설문 결과 리포트** | `CSAT_Report_Q1_2024.xlsx` | 최근 2개 분기 이상의 실제 응답 데이터 |\n| **피드백 처리 이력** | `Feedback_Action_Log_2024.xlsx` | 부정적 피드백 → 조치 → 완료까지 추적 기록 |\n| **고객 리뷰 미팅 회의록** | `QBR_Meeting_Minutes_CustomerA_Mar2024.pdf` | 만족도 논의 및 개선 약속 내용 |\n\n### 📝 각 증거의 핵심 포함 요소\n\n**1. CSAT 정책 문서 필수 섹션:**\n```\n1. 목적 및 범위\n2. 수집 방법 (3가지 중 택일 또는 복합)\n   - Formal Survey: 분기별 온라인 설문\n   - Contact-based: 티켓 종료 후 자동 발송\n   - QBR 기반: 분기 리뷰 미팅 시 구두/서면 수집\n3. 측정 지표 (NPS, CSAT Score, CES 등)\n4. 수집 주기 및 대상 고객 기준\n5. 부정적 피드백 에스컬레이션 프로세스\n6. 데이터 보관 및 분석 책임자\n```\n\n**2. 설문 양식 필수 문항 예시:**\n```\nQ1. 전반적인 서비스 만족도 (1-10점)\nQ2. 기술 지원 품질 만족도 (1-5점)\nQ3. 응답 속도 만족도 (1-5점)\nQ4. 추천 의향 (NPS: 0-10점)\nQ5. 개선이 필요한 영역 (객관식 + 주관식)\nQ6. 추가 의견 (자유 기술)\n```\n\n**3. 피드백 처리 이력 필수 컬럼:**\n```\n| 접수일 | 고객명 | 피드백 내용 | 심각도 | 담당자 | 조치 내용 | 완료일 | 고객 확인 |\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: CSAT 수집 방법 결정 (Day 1-3)\n**담당**: Service Delivery Manager\n\n세 가지 방법 중 조직에 맞는 방식 선택:\n\n| 방법 | 적합한 상황 | 도구 예시 |\n|------|-------------|-----------|\n| **Formal Survey** | 고객 수 10개 이상, 정기 수집 | SurveyMonkey, Typeform, Google Forms |\n| **Contact-based** | 티켓 기반 운영, 실시간 피드백 | Zendesk CSAT, ServiceNow, Freshdesk |\n| **QBR 기반** | 고객 수 적음, 관계 중심 | 미팅 체크리스트 + 서면 양식 |\n\n```\n💡 AWS Auditor 선호 조합:\n   Primary: Contact-based (티켓 종료 시 자동 발송)\n   Secondary: Quarterly Formal Survey\n   이 조합이 \"지속적 + 정기적\" 요건을 모두 충족\n```\n\n### Step 2: 설문 도구 구축 (Day 4-10)\n**담당**: IT Operations + Customer Success\n\n**SurveyMonkey 설정 예시:**\n```\n1. 계정 생성 → Team Plan 이상 권장 (브랜딩 제거)\n2. 설문 생성:\n   - 제목: \"[회사명] 서비스 만족도 조사\"\n   - 문항 수: 6-8개 (완료 시간 3분 이내)\n   - 익명 옵션: 활성화 (객관성 확보)\n3. 자동화 설정:\n   - Zapier 연동 → 티켓 종료 시 자동 발송\n   - 또는 분기별 일괄 발송 스케줄링\n```\n\n**Contact-based 구현 (Zendesk 예시):**\n```\n1. Admin → Business Rules → Automations\n2. 조건: Ticket Status = Solved, 24시간 경과\n3. 액션: Send CSAT Survey\n4. 설문 내용 커스터마이징 (한글화)\n```\n\n### Step 3: CSAT 정책 문서 작성 (Day 11-15)\n**담당**: Quality Assurance Manager\n\n```markdown\n## 문서 구조 템플릿\n\n### 1. 개요\n- 문서 버전: 2.1\n- 최종 수정일: 2024-03-15\n- 승인자: [CTO 이름]\n\n### 2. 수집 프로세스\n[플로우차트 삽입 - Lucidchart/draw.io 활용]\n\n### 3. 에스컬레이션 매트릭스\n| CSAT 점수 | 조치 수준 | 담당자 | SLA |\n|-----------|-----------|--------|-----|\n| 1-2점 | Critical | Account Manager | 24시간 내 연락 |\n| 3점 | High | Service Manager | 48시간 내 연락 |\n| 4점 | Medium | CSM | 주간 리뷰 시 논의 |\n| 5점 | Low | 기록만 | - |\n\n### 4. 보고 체계\n- 주간: 팀 내부 리뷰\n- 월간: 경영진 보고\n- 분기: 트렌드 분석 리포트\n```\n\n### Step 4: 파일럿 운영 및 데이터 수집 (Day 16-45)\n**담당**: Customer Success Team\n\n```\n⚠️ 중요: 최소 2개월 이상의 실제 데이터 필요\n   Auditor는 \"운영 중인 시스템\"을 확인하므로\n   최근 데이터가 없으면 즉시 Fail\n```\n\n**데이터 수집 목표:**\n- 최소 응답 수: 고객당 1회 이상 또는 총 20건 이상\n- 응답률 목표: 30% 이상 (업계 평균 25%)\n- 수집 기간: 감사 전 최소 60일\n\n### Step 5: 피드백 처리 프로세스 실행 (Day 16-60)\n**담당**: Account Management Team\n\n**실제 처리 사례 문서화 필수:**\n```\n[사례 1]\n- 고객: ABC Corp\n- 접수일: 2024-02-15\n- 피드백: \"인시던트 응답 시간이 너무 느림\" (CSAT 2점)\n- 조치: \n  1. 24시간 내 Account Manager 전화 연락\n  2. 원인 분석: 야간 인력 부족\n  3. 개선: 야간 On-call 인력 추가 배치\n- 완료일: 2024-02-28\n- 후속 확인: 3월 설문에서 4점으로 개선\n```\n\n### Step 6: 대시보드 및 리포트 구축 (Day 46-55)\n**담당**: Data Analyst / BI Team\n\n**QuickSight CSAT 대시보드 구성:**\n```\n1. 데이터 소스 연결 (S3 또는 직접 연동)\n2. 필수 시각화:\n   - NPS 트렌드 (월별 라인 차트)\n   - CSAT 평균 점수 (게이지 차트)\n   - 카테고리별 만족도 (막대 차트)\n   - 부정 피드백 처리 현황 (파이 차트)\n3. 자동 새로고침: 일간\n```\n\n### Step 7: 데모 시나리오 준비 (Day 56-60)\n**담당**: MSP Program Lead\n\n```\n🎬 Auditor 데모 시나리오 (15분)\n\n1. [3분] 정책 문서 화면 공유 및 설명\n2. [4분] 설문 도구 라이브 시연\n   - 실제 설문 링크 클릭 → 응답 화면\n   - 관리자 대시보드 → 응답 현황\n3. [4분] 피드백 처리 이력 시연\n   - 부정 피드백 사례 선택\n   - 에스컬레이션 → 조치 → 완료 과정 설명\n4. [4분] 개선 활동 연계 증거\n   - \"이 피드백으로 인해 X 프로세스를 변경했습니다\"\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ 실패 사례 1: AWS Partner Central CSAT 제출\n```\n문제: \"AWS에서 수집하는 CSAT 데이터를 제출했습니다\"\n결과: 즉시 Fail\n\n이유: 요건에 명시적으로 \"AWS owned and operated CSAT \n      data will not be accepted\"라고 기재됨\n      \n해결: 자체 수집 시스템 구축 필수\n```\n\n### ❌ 실패 사례 2: 설문만 있고 처리 프로세스 없음\n```\n문제: 설문 도구는 있으나 부정 피드백 처리 기록 없음\n결과: Conditional Pass 또는 Fail\n\nAuditor 질문: \"CSAT 3점 이하 받으면 어떻게 하나요?\"\n잘못된 답변: \"담당자가 알아서 처리합니다\"\n올바른 답변: \"정책 문서 3.2절에 따라 24시간 내 \n             Account Manager가 연락하고, \n             이 로그에서 보시는 것처럼 추적합니다\"\n```\n\n### ❌ 실패 사례 3: 오래된 데이터만 존재\n```\n문제: 6개월 전 데이터만 있고 최근 데이터 없음\n결과: Fail\n\nAuditor 관점: \"현재 운영되지 않는 프로세스\"로 판단\n             \n해결: 감사 2주 전까지의 데이터 확보 필수\n```\n\n### ❌ 실패 사례 4: 100% 긍정 피드백만 제출\n```\n문제: 모든 응답이 5점, 부정 피드백 0건\n결과: 신뢰성 의심 → 추가 질문\n\nAuditor 의심: \"실제 운영 데이터인가?\"\n             \"부정 피드백 처리 프로세스 검증 불가\"\n             \n해결: 실제 데이터 그대로 제출 (부정 피드백 포함)\n     부정 피드백 처리 사례가 오히려 가점 요소\n```\n\n### ❌ 실패 사례 5: 내부 만족도 조사와 혼동\n```\n문제: 직원 만족도 조사 자료를 제출\n결과: 즉시 Fail\n\n요건: \"Customer Satisfaction\" = 외부 ",
      "language": "en",
      "createdAt": "2026-01-07T02:50:27.356Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-003",
      "category": "Governance",
      "title": "Data Ownership and Customer Offboarding",
      "advice": "# GOV-003: Data Ownership and Customer Offboarding - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nThis requirement exists because AWS wants to ensure MSP Partners don't create \"vendor lock-in\" situations where customers cannot cleanly exit the relationship. AWS has seen cases where customers lost access to their own data or faced prolonged transitions due to poorly defined offboarding processes. This directly impacts AWS's reputation and customer trust in the partner ecosystem.\n\n### 🔍 Key Points Auditors Specifically Look For\n\n1. **Explicit Legal Data Ownership Statement** - Auditors verify that your contract explicitly states \"Customer retains full ownership of all data stored in AWS accounts\" - vague language like \"data will be handled appropriately\" fails audits\n\n2. **Concrete SLA for Account Handover** - A specific number (e.g., \"within 30 business days\") must be stated, not ranges like \"30-90 days\" or conditional language like \"as soon as reasonably possible\"\n\n3. **IAM Cleanup Procedure Details** - Auditors look for specific mention of removing:\n   - Cross-account roles used for MSP management\n   - SSO/Federation configurations pointing to MSP identity provider\n   - Service-linked roles created by MSP tooling\n   - AWS Organizations SCPs if applicable\n\n4. **Data Transfer Format Specification** - Must specify actual formats (CloudFormation templates, Terraform state files, CSV exports) not just \"industry standard formats\"\n\n5. **AWS Account Ownership Transfer Process** - If you manage accounts under your AWS Organizations, the contract must address how accounts are migrated out or transferred to customer's own Organization\n\n### Relevant AWS Services/Features\n- AWS Organizations (account transfer process)\n- AWS IAM Identity Center (formerly SSO) - federation removal\n- AWS Resource Access Manager (RAM) - shared resource cleanup\n- AWS Control Tower (if used for landing zone management)\n- AWS Backup (data export procedures)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Document | Format | Purpose |\n|----------|--------|---------|\n| Master Services Agreement (MSA) with Data Ownership Clause | PDF (signed template or redacted customer example) | Proves legal framework exists |\n| Customer Offboarding Runbook | PDF/Confluence export | Shows operational procedure |\n| Account Transition Checklist | Excel/PDF | Demonstrates systematic approach |\n\n### 📄 Key Content for Contract Template\n\n**Section 1: Data Ownership Declaration**\n```\nRequired language example:\n\"All data uploaded, processed, or stored by Customer within AWS services \nremains the sole property of Customer. [MSP Name] claims no ownership \nrights to Customer data and acts solely as a data processor.\"\n```\n\n**Section 2: Termination Data Handling (must include ALL of these)**\n- Timeline: \"Within [X] business days of termination notice\"\n- Data export format: \"JSON, CSV, or native AWS backup formats\"\n- Credential transfer method: \"Secure credential handover via [specific tool/method]\"\n- Data retention post-termination: \"Customer data deleted within [X] days after confirmed transfer\"\n\n**Section 3: IAM/Access Cleanup Specifics**\n```\nMust explicitly list:\n- Removal of [MSP Name] IAM users from Customer accounts\n- Deletion of cross-account IAM roles (e.g., MSPManagementRole)\n- Removal of SAML/OIDC federation configurations\n- Revocation of AWS SSO assignments\n- Removal of SCPs applied by [MSP Name]\n```\n\n**Section 4: AWS Account Transition**\n- Process for removing accounts from MSP's AWS Organizations\n- Timeline for billing relationship transfer\n- Handling of Reserved Instances/Savings Plans ownership\n\n### 📁 Evidence File Name Examples\n- `MSP_Master_Services_Agreement_v3.2_DataOwnership_Highlighted.pdf`\n- `Customer_Offboarding_Runbook_AWS_Accounts_2024.pdf`\n- `Account_Transition_Checklist_Template.xlsx`\n- `Sample_Offboarding_Completion_Certificate.pdf`\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Existing Contract Language (Week 1)\n**Action:** Extract all data-related clauses from your current MSA\n- Search for keywords: \"data,\" \"ownership,\" \"termination,\" \"exit,\" \"transfer\"\n- Create a gap analysis against the 4 required elements\n- **Tool:** Use document comparison in Microsoft Word or contract management system\n\n**Responsible:** Legal Counsel + MSP Practice Lead\n**Time:** 3-4 hours\n\n### Step 2: Draft Data Ownership Clause with Legal (Week 1-2)\n**Action:** Create explicit ownership language\n```\nTemplate starting point:\n\"8.1 Data Ownership. Customer exclusively owns all Customer Data. \n'Customer Data' means any data, content, or information that Customer \nuploads to, stores in, or processes through AWS Services under this Agreement.\n\n8.2 No MSP Rights. [MSP Name] acquires no rights or licenses to Customer \nData except the limited right to access Customer Data solely to perform \nthe Services.\"\n```\n\n**Responsible:** Legal Counsel\n**Time:** 4-6 hours of drafting + review cycles\n\n### Step 3: Define Specific Offboarding Timeline (Week 2)\n**Action:** Establish concrete SLAs based on operational capability\n- Survey your operations team: \"How long does full account transition actually take?\"\n- Add buffer for complexity (simple: 15 days, complex: 30 days)\n- Document in contract: \"Complete transition within 30 business days\"\n\n**Responsible:** Operations Manager + Legal\n**Time:** 2-3 hours\n\n### Step 4: Create IAM Cleanup Procedure Document (Week 2-3)\n**Action:** Document every IAM artifact your MSP creates in customer accounts\n\n**Create inventory checklist:**\n```\n□ MSP Management IAM Role (arn:aws:iam::*:role/MSPAdminRole)\n□ CloudWatch Cross-Account Role\n□ AWS Config Aggregator Role\n□ SSO Permission Sets: [list specific names]\n□ SAML Identity Provider: MSP-IdP\n□ Service Control Policies: MSP-Baseline-SCP\n□ AWS RAM Resource Shares: [list names]\n```\n\n**Tool:** AWS IAM Access Analyzer to identify cross-account access\n**Responsible:** Cloud Architect + Security Team\n**Time:** 8-10 hours\n\n### Step 5: Build Account Transfer Runbook (Week 3)\n**Action:** Create step-by-step operational guide for AWS Organizations account migration\n\n**Include these AWS-specific procedures:**\n1. Remove account from MSP Organization (AWS Organizations console)\n2. Customer accepts account into their Organization (or standalone)\n3. Update billing contact to customer\n4. Transfer RI/Savings Plans ownership (if applicable)\n5. Update AWS Support plan ownership\n\n**Tool:** AWS Organizations API documentation as reference\n**Responsible:** Cloud Operations Lead\n**Time:** 6-8 hours\n\n### Step 6: Create Data Export Procedure (Week 3-4)\n**Action:** Document how customer data is exported from each managed service\n\n**Service-specific procedures:**\n| Service | Export Method | Format |\n|---------|--------------|--------|\n| S3 | S3 Batch Operations or AWS DataSync | Native objects |\n| RDS | Automated snapshots shared to customer account | Snapshot |\n| DynamoDB | AWS Backup or Data Pipeline export | JSON/CSV |\n| CloudWatch Logs | Export to S3 | Gzip JSON |\n\n**Responsible:** Cloud Architect\n**Time:** 4-6 hours\n\n### Step 7: Integrate into Contract Template and Get Sign-off (Week 4)\n**Action:** Consolidate all elements into contract template\n- Add as Exhibit/Schedule to MSA\n- Get legal review and approval\n- Create highlighted version for auditor showing all 4 required elements\n\n**Responsible:** Legal Counsel + MSP Practice Lead\n**Time:** 4-5 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Using \"Reasonable Efforts\" Language\n**Problem:** Contract states \"MSP will use reasonable efforts to transition data within a reasonable timeframe\"\n**Why it fails:** Auditors require specific, enforceable commitments\n**Fix:** Replace with \"MSP will complete data transition within 30 business days of receiving written termination notice\"\n\n### ❌ Mistake 2: Missing IAM Federation Cleanup\n**Problem:** Contract mentions removing IAM users but ignores SSO/SAML configurations\n**Why it fails:** Auditors specifically check for federation removal because it's a common security gap\n**Fix:** Add explicit clause: \"Removal of all SAML identity providers, OIDC providers, and AWS IAM Identity Center configurations established by MSP\"\n\n### ❌ Mistake 3: No AWS Organizations Account Transfer Process\n**Problem:** Contract assumes customer already owns their AWS accounts directly\n**Why it fails:** Many MSPs create accounts under their own Organization - auditors know this\n**Fix:** Include clause addressing: \"For accounts created within MSP's AWS Organization, MSP will initiate account migration to Customer's designated AWS Organization within [X] days\"\n\n### ❌ Mistake 4: Submitting Generic MSA Without AWS-Specific Content\n**Problem:** Submitting standard IT services contract that mentions \"cloud services\" generically\n**Why it fails:** Auditors look for AWS-specific terminology (IAM, Organizations, specific services)\n**Fix:** Create AWS-specific exhibit/addendum that references actual AWS services and features\n\n### ❌ Mistake 5: No Post-Termination Data Destruction Timeline\n**Problem:** Contract covers data transfer but not what happens to MSP's copies\n**Why it fails:** Auditors verify complete data lifecycle including destruction\n**Fix:** Add: \"MSP will permanently delete all Customer Data from MSP systems within 30 days following confirmed successful transfer, and provide written certification of destruction upon request\"\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Data ownership explicitly stated** | Ctrl+F search for \"ownership\" in contract | Must find explicit statement that customer owns data, not implied |\n| 2 | **Specific timeline for data handover** | Look for number + \"days\" or \"hours\" | Must be specific number (e.g., \"30 business days\"), not ranges or \"reasonable\" |\n| 3 | **Data transfer format specified** | Check termination section | Must list actual formats (JSON, CSV, native snapshots), not \"industry standard\" |\n| 4 | **Credential transfer method defined** | Search for \"credential\" or \"access\" in termination section | Must specify secure method (encrypted email, secrets manager, in-person) |\n| 5 | **IAM cleanup procedure included** | Search for \"IAM,\" \"role,\" \"federation,\" \"SSO\" | Must explicitly mention: IAM roles, users, federation configs, SSO assignments |\n| 6 | **AWS Organizations handling addressed** | Search for \"Organization\" or \"account transfer\" | If MSP uses Organizations, must describe account migration process |\n| 7 | **Post-termination data destruction** | Search for \"delete,\" \"destroy,\" \"retention\" | Must specify when MSP deletes its copies of customer data |\n\n### 📋 Quality Criteria for Passing\n\n**Contract Template Must:**\n- ✅ Be an actual template or redacted real contract (not a policy document)\n- ✅ Contain signature blocks (showing it's legally binding)\n- ✅ Reference AWS services by name (not generic \"cloud services\")\n- ✅ Include all 4 required elements in searchable/highlightable form\n- ✅ Be scoped to AWS managed services (not general IT services)\n\n**Highlight for Auditor:**\nBefore submission, create a version with yellow highlighting on:\n- Data ownership statement\n- Timeline commitment\n- Transfer format/method\n- IAM cleanup list\n- Offboarding procedure reference\n\nThis makes auditor review faster and demonstrates you understand the requirements.\n\n---\n\n## 💡 Pro Tip for This Requirement\n\nCreate a **one-page \"Offboarding Summary Sheet\"** as a contract exhibit that consolidates all required elements in a table format. Auditors appreciate being able to verify all requirements on a single page rather than searching through a 40-page MSA. Example:\n\n| Offboarding Element | Commitment | Reference Section |\n|---------------------|------------|-------------------|\n| Data Ownership | Customer exclusively owns all data | Section 8.1 |\n| Transition Timeline | 30 business days | Section 12.3(a) |\n| Data Format | JSON, CSV, AWS native snapshots | Exhibit B |\n| Credential Transfer | Via AWS Secrets Manager or encrypted transfer | Section 12.3(c) |\n| IAM Cleanup | Full removal per Offboarding Runbook | Exhibit C |\n| Account Transfer | Migration from MSP Organization within 15 days | Section 12.4 |",
      "language": "en",
      "createdAt": "2026-01-07T02:51:29.900Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-004_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-004",
      "category": "Governance",
      "title": "Operational Readiness",
      "advice": "# GOV-004: Operational Readiness - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in the AWS MSP Program\n\nOperational Readiness is the **bridge between project delivery and ongoing managed services**. AWS wants to ensure that MSP Partners don't simply \"throw over the wall\" customer environments to operations teams. This requirement validates that you have a structured handoff process ensuring Day 2 operations are fully prepared before go-live.\n\nThis is fundamentally about **risk mitigation** - poorly prepared operations teams lead to incidents, customer dissatisfaction, and ultimately churn. AWS MSP Partners must demonstrate they systematically verify readiness across people, processes, and technology before accepting operational responsibility.\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **Completeness of Readiness Dimensions**: Auditors verify your checklist covers ALL three pillars - Personnel (skills, access, on-call schedules), Tools (monitoring, ticketing, automation), and Processes (runbooks, escalation paths, SLAs)\n\n2. **Customer Environment Specificity**: Generic checklists fail audits. Auditors look for evidence that checklists are customized per customer workload type (e.g., different readiness criteria for containerized vs. serverless vs. traditional EC2 workloads)\n\n3. **Go/No-Go Decision Authority**: Clear documentation of WHO makes the final readiness decision and WHAT criteria must be met - auditors specifically look for sign-off workflows\n\n4. **Integration with AWS Services**: Evidence that readiness verification includes AWS-native tooling setup (CloudWatch alarms configured, AWS Health Dashboard integrated, Trusted Advisor checks reviewed)\n\n5. **Traceability to Actual Handoffs**: Auditors may request completed checklists from real customer transitions to verify the process is actually used, not just documented\n\n### Relevant AWS Services & Features\n- AWS CloudWatch (alarm verification)\n- AWS Systems Manager (runbook readiness)\n- AWS Health Dashboard (event subscription setup)\n- AWS Trusted Advisor (baseline checks)\n- AWS Config (compliance rule verification)\n- Amazon EventBridge (alert routing confirmation)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Document | Format | Purpose |\n|----------|--------|---------|\n| Operational Readiness Checklist Template | Excel/Confluence with checkboxes | Master template showing all verification items |\n| Operational Readiness Process Document | PDF/Word (version controlled) | Describes end-to-end process flow |\n| Completed Customer Readiness Examples | Filled checklists (2-3 customers) | Proves process is actively used |\n| Readiness Gate Criteria Matrix | Table format | Defines mandatory vs. recommended items |\n| Sign-off Workflow Documentation | Process diagram + approval records | Shows governance and accountability |\n\n### 📄 Key Content Requirements for Each Evidence\n\n**Operational Readiness Checklist Template**\nMust include these sections with specific line items:\n\n```\nPERSONNEL READINESS\n├── Named primary/backup engineers assigned\n├── Engineers completed customer-specific training\n├── On-call rotation configured in PagerDuty/Opsgenie\n├── AWS console access provisioned and tested\n├── Customer communication channels established (Slack/Teams)\n\nTOOLING READINESS  \n├── CloudWatch dashboards created and validated\n├── Alerting thresholds configured per SLA requirements\n├── Ticketing system integration tested (ServiceNow/Jira)\n├── AWS Config rules deployed for compliance monitoring\n├── Cost anomaly detection enabled in AWS Cost Explorer\n├── Backup verification completed (AWS Backup job success)\n\nPROCESS READINESS\n├── Runbooks created for top 10 anticipated incidents\n├── Escalation matrix documented and distributed\n├── Change management process confirmed with customer\n├── SLA definitions reviewed and monitoring configured\n├── Disaster recovery procedures tested\n├── Security incident response plan aligned\n```\n\n**Operational Readiness Process Document**\nMust describe:\n- Trigger point (when readiness assessment begins)\n- Timeline (typically 2-4 weeks before go-live)\n- Roles involved (Project Manager, Operations Lead, Customer Success)\n- Escalation path for readiness gaps\n- Go/No-Go meeting structure\n\n### Example File Names\n- `OPS-READINESS-CHECKLIST-TEMPLATE-v2.3.xlsx`\n- `MSP-Operational-Readiness-Process-v1.5.pdf`\n- `CustomerABC-Readiness-Checklist-COMPLETED-2024-01.xlsx`\n- `Readiness-Gate-Criteria-Matrix.pdf`\n- `Go-Live-Approval-Workflow-Diagram.png`\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Your Current Handoff Process (Week 1)\n**Duration**: 3-4 days  \n**Owner**: Operations Manager\n\nInterview operations engineers who recently onboarded customer environments:\n- What information was missing at handoff?\n- What caused first-week incidents?\n- What tools weren't properly configured?\n\n**AWS Tool**: Review AWS CloudTrail logs from first 30 days of recent customer onboardings to identify reactive activities that should have been proactive readiness items.\n\n### Step 2: Build the Three-Pillar Checklist Structure (Week 1-2)\n**Duration**: 5 days  \n**Owner**: Operations Lead + Technical Writer\n\nCreate checklist sections for each pillar with **specific, verifiable items**:\n\n```\n❌ Bad: \"Monitoring is configured\"\n✅ Good: \"CloudWatch alarms exist for: CPU >80% (5 min), Memory >85%, Disk >90%, ALB 5xx >1%, RDS connections >80% max\"\n```\n\n**AWS Tool**: Use AWS Well-Architected Tool review reports to identify operational excellence items that should be readiness checkpoints.\n\n### Step 3: Define Workload-Specific Variants (Week 2)\n**Duration**: 3 days  \n**Owner**: Solutions Architect + Operations Lead\n\nCreate checklist variants for different workload types:\n- **Containerized (EKS/ECS)**: Add items for cluster monitoring, pod autoscaling verification, container image scanning setup\n- **Serverless**: Add items for Lambda concurrency limits, X-Ray tracing, dead letter queue configuration\n- **Traditional EC2**: Add items for SSM Agent verification, patch baseline assignment, AMI backup schedule\n\n### Step 4: Establish Gate Criteria and Sign-off Workflow (Week 2-3)\n**Duration**: 4 days  \n**Owner**: Service Delivery Manager\n\nDefine three categories:\n- 🔴 **Mandatory (Blocker)**: Must be complete for go-live (e.g., on-call schedule, critical alerts)\n- 🟡 **Required (Tracked)**: Must be complete within 7 days post-go-live\n- 🟢 **Recommended**: Best practice items tracked for continuous improvement\n\nCreate approval workflow in your ITSM tool showing:\n- Operations Lead initial sign-off\n- Customer Success Manager review\n- Final go-live approval authority\n\n### Step 5: Integrate with AWS Service Verification (Week 3)\n**Duration**: 3 days  \n**Owner**: Cloud Engineer\n\nBuild automated verification where possible:\n```python\n# Example: AWS CLI verification script for readiness checklist\naws cloudwatch describe-alarms --alarm-name-prefix \"PROD-\" --query 'MetricAlarms[?StateValue==`OK`]'\naws configservice describe-compliance-by-config-rule\naws backup list-backup-jobs --by-state COMPLETED --by-resource-type EC2\n```\n\n**AWS Tool**: Create an AWS Config conformance pack that validates operational readiness items are in place.\n\n### Step 6: Pilot with Active Customer Transition (Week 3-4)\n**Duration**: 1 week  \n**Owner**: Project Manager + Operations Team\n\nApply the checklist to a real customer handoff:\n- Document gaps discovered\n- Measure time to complete checklist\n- Gather feedback from operations engineers\n- Refine checklist based on learnings\n\n### Step 7: Document Process and Archive Completed Examples (Week 4)\n**Duration**: 3 days  \n**Owner**: Technical Writer + Compliance Lead\n\nFinalize documentation:\n- Version control the process document\n- Archive 2-3 completed customer checklists (redact sensitive data)\n- Create process flow diagram\n- Store in evidence repository with clear naming convention\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Checklist Too Generic\n**Problem**: Checklist items like \"Verify monitoring is working\" don't demonstrate operational rigor.\n\n**Solution**: Every checklist item must be **binary verifiable**:\n```\n❌ \"Ensure backups are configured\"\n✅ \"AWS Backup plan 'daily-retention-30' attached to all production EC2 instances - verify via: aws backup list-protected-resources\"\n```\n\n### ❌ Mistake 2: No Evidence of Actual Usage\n**Problem**: Submitting only templates without completed examples. Auditors will ask: \"Show me this was used for a real customer.\"\n\n**Solution**: Include 2-3 completed checklists from actual customer transitions (redact customer names if needed, but keep dates and sign-offs visible).\n\n### ❌ Mistake 3: Missing Personnel Readiness Section\n**Problem**: Focusing only on technical tooling while ignoring people readiness. Auditors specifically look for evidence that **humans are prepared**, not just systems.\n\n**Solution**: Include explicit items for:\n- Engineer assignment confirmation\n- Training completion records\n- On-call schedule configuration\n- Customer communication channel setup\n\n### ❌ Mistake 4: No Go/No-Go Decision Point\n**Problem**: Checklist exists but no clear decision gate. Who decides if operations is ready? What happens if they're not?\n\n**Solution**: Document explicit criteria:\n- \"Go-live requires 100% of 🔴 Mandatory items complete\"\n- \"Operations Lead must sign off in ServiceNow before go-live date\"\n- \"If blockers exist, escalation to Service Delivery Director within 24 hours\"\n\n### ❌ Mistake 5: Disconnected from SLA Commitments\n**Problem**: Readiness checklist doesn't reference the SLAs being committed to the customer.\n\n**Solution**: Link readiness items directly to SLA requirements:\n```\nSLA: 15-minute response time for P1 incidents\nReadiness Item: PagerDuty escalation policy configured with 5-minute timeout to backup engineer\n```\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | Checklist covers all three pillars (Personnel, Tools, Processes) | Review section headers | Minimum 5 items per pillar |\n| 2 | Each checklist item is binary verifiable | Read each item aloud as yes/no question | No ambiguous items like \"ensure\" or \"verify properly\" |\n| 3 | Workload-specific variants exist | Count checklist versions | At least 2 variants (e.g., EC2-based, containerized) |\n| 4 | Go/No-Go criteria clearly defined | Locate decision matrix | Mandatory vs. recommended items explicitly categorized |\n| 5 | Sign-off workflow documented | Find approval process | Named roles with approval authority identified |\n| 6 | Completed examples available | Locate filled checklists | 2-3 real customer examples with dates and signatures |\n| 7 | AWS service verification included | Search for AWS service names | CloudWatch, Config, Backup, SSM explicitly referenced |\n| 8 | Process document version controlled | Check document metadata | Version number, last updated date, document owner visible |\n\n### Quality Gate Questions (Ask Before Submission)\n\n1. **\"If a new operations engineer joined tomorrow, could they use this checklist to verify readiness without asking questions?\"** → If no, add more specific detail.\n\n2. **\"Can we demonstrate this checklist was used in the last 90 days?\"** → If no, complete a checklist for a recent/current transition.\n\n3. **\"Does this checklist reference specific AWS services and how to verify them?\"** → If no, add AWS CLI commands or console verification steps.\n\n4. **\"Is there a clear 'stop' mechanism if readiness isn't achieved?\"** → If no, add escalation path and go/no-go authority.\n\n---\n\n## 📎 Quick Reference: Minimum Viable Evidence Package\n\n```\n📁 GOV-004-Operational-Readiness/\n├── 📄 Operational-Readiness-Process-v2.0.pdf\n├── 📊 Readiness-Checklist-Template-v3.1.xlsx\n├── 📊 Readiness-Checklist-EKS-Variant-v1.0.xlsx\n├── 📄 Go-NoGo-Decision-Matrix.pdf\n├── 📊 Customer-Alpha-Readiness-COMPLETED-2024-02.xlsx\n├── 📊 Customer-Beta-Readiness-COMPLETED-2024-03.xlsx\n└── 🖼️ Readiness-Approval-Workflow-Diagram.png\n```",
      "language": "en",
      "createdAt": "2026-01-07T02:52:40.710Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-005_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-005",
      "category": "Governance",
      "title": "Shared Responsibility Model",
      "advice": "# GOV-005: Shared Responsibility Model - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nThe Shared Responsibility Model is the **foundation of MSP-customer relationships**. AWS itself operates on a shared responsibility model (AWS manages \"security OF the cloud,\" customers manage \"security IN the cloud\"), and MSPs must extend this concept to clearly delineate responsibilities between themselves and their customers. Without this clarity, security incidents lead to blame-shifting, and operational gaps emerge where \"nobody thought they were responsible.\"\n\n### 🎯 Key Points Auditors Examine\n\n1. **RACI Matrix Completeness**: Does the matrix cover ALL security domains (IAM, network, data, logging, patching, incident response) - not just a few cherry-picked areas?\n\n2. **Customer-Facing Format**: Is this actually delivered to customers during onboarding, or is it an internal document dressed up as customer-facing?\n\n3. **Alignment with AWS Shared Responsibility Model**: Does your RACI properly reflect the three-way relationship (AWS → MSP → Customer)?\n\n4. **Operational Specificity**: Does it address day-to-day operational tasks (who rotates keys, who reviews CloudTrail, who approves security group changes)?\n\n5. **Evidence of Customer Acknowledgment**: Did customers actually receive and acknowledge this documentation?\n\n### 🔗 Relevant AWS Services/Features\n\n- **AWS Artifact** (for AWS's own compliance documents and shared responsibility documentation)\n- **AWS Well-Architected Framework** (Security Pillar defines responsibility areas)\n- **AWS Control Tower** (defines guardrails that inform responsibility boundaries)\n- **AWS Organizations** (SCPs define what MSP controls vs. customer controls)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Document | Format | Purpose |\n|----------|--------|---------|\n| Customer Onboarding Package | PDF/Word | Master document delivered to customers |\n| Security RACI Matrix | Excel/PDF | Detailed responsibility assignment |\n| Customer Acknowledgment Records | Signed PDF/Email | Proof of customer receipt |\n\n### 📄 Document 1: Customer Onboarding Security Guide\n\n**Filename Example**: `[CompanyName]_MSP_Customer_Security_Onboarding_Guide_v2.3.pdf`\n\n**Must Include**:\n```\nSection 1: Three-Party Responsibility Overview\n├── AWS's Responsibilities (infrastructure, physical, hypervisor)\n├── [Your Company]'s Responsibilities (managed services scope)\n└── Customer's Responsibilities (data classification, user access decisions)\n\nSection 2: Security Domain Breakdown\n├── Identity & Access Management\n├── Network Security\n├── Data Protection & Encryption\n├── Logging & Monitoring\n├── Vulnerability Management\n├── Incident Response\n└── Compliance & Audit Support\n\nSection 3: Operational Expectations\n├── Customer obligations (response SLAs, approval workflows)\n├── Communication channels and escalation paths\n└── Change request procedures\n```\n\n### 📊 Document 2: Detailed RACI Matrix\n\n**Filename Example**: `[CompanyName]_Security_Operations_RACI_Matrix_v1.4.xlsx`\n\n**Critical Content Structure**:\n\n| Security Activity | AWS | MSP (Your Company) | Customer |\n|-------------------|-----|-------------------|----------|\n| Physical datacenter security | R/A | - | - |\n| EC2 instance patching | - | R/A | I |\n| IAM user creation/deletion | - | R | A/C |\n| Data classification decisions | - | C | R/A |\n| Security group rule changes | - | R | A |\n| CloudTrail log review | - | R/A | I |\n| Incident investigation | I | R/A | C |\n| Compliance evidence collection | C | R | A |\n| Root account MFA setup | - | R | A |\n| Application-level security | - | C | R/A |\n\n**Legend**: R=Responsible, A=Accountable, C=Consulted, I=Informed\n\n### 📧 Document 3: Customer Acknowledgment Evidence\n\n**Filename Examples**:\n- `Customer_ABC_Onboarding_Acknowledgment_2024-03-15.pdf`\n- `Onboarding_Completion_Records_Q1_2024.xlsx`\n\n**Must Show**:\n- Customer name and contact\n- Date of onboarding session\n- Specific documents delivered\n- Signature or email confirmation\n- Any customer questions/clarifications documented\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Map Your Service Catalog to Security Domains (Week 1)\n**Time**: 8-10 hours | **Owner**: Security Lead + Service Delivery Manager\n\n**Actions**:\n```\n□ List every managed service you offer (EC2 management, RDS management, etc.)\n□ For each service, identify security touchpoints:\n  - What security configurations do YOU manage?\n  - What requires customer input/approval?\n  - What does AWS handle automatically?\n□ Use AWS Well-Architected Security Pillar as your domain framework\n```\n\n**Tool**: Create a spreadsheet mapping services → security domains → responsibility owner\n\n### Step 2: Build the Three-Tier RACI Matrix (Week 1-2)\n**Time**: 12-15 hours | **Owner**: Security Lead\n\n**Actions**:\n```\n□ Create matrix with minimum 25-30 specific security activities\n□ Include these often-missed items:\n  - Root account credential management\n  - Service Control Policy (SCP) changes\n  - AWS Support case creation\n  - Cost anomaly investigation (security implications)\n  - Third-party tool integration approvals\n□ Validate each assignment against actual operational practice\n□ Have operations team verify \"this is how we actually work\"\n```\n\n**AWS Reference**: Download AWS's shared responsibility model diagrams from AWS Artifact\n\n### Step 3: Draft Customer-Facing Onboarding Document (Week 2)\n**Time**: 10-12 hours | **Owner**: Technical Writer + Security Lead\n\n**Actions**:\n```\n□ Write in customer-accessible language (avoid MSP jargon)\n□ Include visual diagrams showing responsibility boundaries\n□ Add specific examples for each domain:\n  \"Example: When you request a new IAM user, you (Customer) \n   specify the required permissions. We (MSP) implement the \n   user following least-privilege principles and enable MFA. \n   AWS provides the IAM service infrastructure.\"\n□ Include \"What happens if...\" scenarios\n```\n\n### Step 4: Create Customer Acknowledgment Mechanism (Week 2)\n**Time**: 4-6 hours | **Owner**: Operations Manager\n\n**Actions**:\n```\n□ Design acknowledgment form/process:\n  - Digital signature option (DocuSign, Adobe Sign)\n  - Or email confirmation template with specific language\n□ Create tracking spreadsheet for all customer acknowledgments\n□ Set up reminder workflow for unsigned documents\n```\n\n**Template Language**:\n```\n\"I acknowledge receipt of [Company Name]'s Security Responsibilities \nGuide and RACI Matrix dated [DATE]. I understand the security \nresponsibilities assigned to [Customer Company] and agree to \nfulfill these obligations.\"\n```\n\n### Step 5: Integrate into Actual Onboarding Process (Week 3)\n**Time**: 6-8 hours | **Owner**: Customer Success Team\n\n**Actions**:\n```\n□ Add RACI review as mandatory onboarding checklist item\n□ Create onboarding presentation slides explaining key responsibilities\n□ Train customer success team on walking through the RACI\n□ Document the onboarding workflow showing when/how documents are delivered\n```\n\n### Step 6: Collect Retroactive Acknowledgments (Week 3-4)\n**Time**: Variable | **Owner**: Account Managers\n\n**Actions**:\n```\n□ For existing customers without acknowledgment:\n  - Send updated RACI with cover letter explaining the formalization\n  - Schedule brief calls to review responsibilities\n  - Collect signed acknowledgments\n□ Document any customers who decline (with reasoning)\n```\n\n### Step 7: Prepare Audit Evidence Package (Week 4)\n**Time**: 4-5 hours | **Owner**: Compliance Lead\n\n**Actions**:\n```\n□ Compile 3-5 customer acknowledgment examples (redact sensitive info)\n□ Screenshot of onboarding checklist showing RACI delivery step\n□ Create evidence index document explaining each artifact\n□ Ensure version control shows document evolution\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic RACI Without Operational Reality\n**Problem**: Matrix says \"MSP handles patching\" but actual practice requires customer approval for each patch window.\n\n**Solution**: Walk through 5-10 recent operational scenarios and verify RACI matches reality. If there's a mismatch, update either the RACI or your operations.\n\n### ❌ Mistake 2: Missing the \"Three-Party\" Dimension\n**Problem**: RACI only shows MSP vs. Customer, ignoring AWS's role.\n\n**Solution**: Always include AWS column. Auditors specifically check that you understand where AWS's responsibility ends and yours begins. Example: AWS is responsible for RDS engine patching, but you're responsible for scheduling the maintenance window.\n\n### ❌ Mistake 3: Internal Document Presented as Customer-Facing\n**Problem**: Document uses internal terminology, references internal processes, or lacks customer-appropriate formatting.\n\n**Auditor Red Flag**: \"This looks like an internal SOP, not something you'd give to a customer.\"\n\n**Solution**: Have someone outside your security team (ideally a customer success person) review for readability. Add your company branding, professional formatting, and customer-centric language.\n\n### ❌ Mistake 4: No Evidence of Actual Delivery\n**Problem**: Beautiful RACI document exists but no proof customers received it.\n\n**Auditor Question**: \"Show me evidence that Customer X received this during onboarding.\"\n\n**Solution**: Maintain delivery log with dates, customer names, and acknowledgment status. Email delivery receipts are acceptable if they reference specific documents.\n\n### ❌ Mistake 5: RACI Doesn't Cover Security Incidents\n**Problem**: Matrix covers steady-state operations but not incident scenarios.\n\n**Missing Items Often Flagged**:\n- Who declares a security incident?\n- Who communicates with AWS Support during incidents?\n- Who notifies affected parties?\n- Who conducts post-incident review?\n\n**Solution**: Add dedicated \"Incident Response\" section with 8-10 specific activities.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | RACI includes AWS column | Visual inspection of matrix | All rows show AWS, MSP, and Customer columns with appropriate assignments |\n| 2 | Minimum 25 security activities covered | Count rows in RACI | ≥25 distinct activities across IAM, Network, Data, Logging, Patching, Incident Response domains |\n| 3 | Customer acknowledgment evidence exists | Pull 3 random customer records | Each shows: customer name, date, document version, signature/confirmation |\n| 4 | Document is customer-branded and formatted | Review as if you're the customer | Professional appearance, no internal jargon, company logo, version number, date |\n| 5 | Onboarding process includes RACI delivery | Review onboarding checklist/workflow | RACI delivery is explicit step with completion tracking |\n| 6 | Incident response responsibilities defined | Search RACI for \"incident\" | Minimum 5 incident-related activities with clear R/A assignments |\n| 7 | Document version matches delivered version | Compare master vs. customer copies | Customers received current version (within last 12 months) |\n\n### 🎯 Quality Criteria for Passing\n\n**Auditor Perspective**: \"Can I clearly understand who does what for any security scenario?\"\n\n✅ **Pass Indicators**:\n- RACI is specific enough to resolve ambiguity (\"IAM user creation\" not just \"IAM management\")\n- Customer responsibilities are realistic and achievable\n- Evidence shows systematic delivery, not ad-hoc\n- Document has been updated within past 12 months\n\n❌ **Fail Indicators**:\n- RACI is too high-level (only 10-15 generic categories)\n- No customer acknowledgment evidence\n- Document looks like internal policy, not customer deliverable\n- Responsibilities don't match your actual service delivery model\n\n### 📎 Evidence Package Final Assembly\n\n```\nGOV-005_Evidence_Package/\n├── 01_Customer_Onboarding_Security_Guide_v2.3.pdf\n├── 02_Security_RACI_Matrix_v1.4.xlsx\n├── 03_Customer_Acknowledgments/\n│   ├── Customer_A_Acknowledgment_2024-01-15.pdf\n│   ├── Customer_B_Acknowledgment_2024-02-20.pdf\n│   └── Customer_C_Acknowledgment_2024-03-10.pdf\n├── 04_Onboarding_Process_Documentation.pdf\n└── 05_Evidence_Index_GOV-005.pdf\n```",
      "language": "en",
      "createdAt": "2026-01-07T02:53:38.684Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOV-006_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOV-006",
      "category": "Governance",
      "title": "Sustainability Best Practices",
      "advice": "# GOV-006: Sustainability Best Practices - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nAWS는 2040년까지 탄소 중립(Net-Zero) 달성을 목표로 하며, MSP 파트너가 고객 워크로드의 에너지 효율성 최적화에 적극 기여하기를 기대합니다. 이 요구사항은 단순한 \"친환경 마케팅\"이 아닌, **실제 아키텍처 결정과 운영 프로세스에서 지속가능성을 고려하는 역량**을 검증합니다.\n\n### 🔍 감사관이 중점적으로 확인하는 5가지 포인트\n\n1. **구체적인 개선 사례 존재 여부**: \"지속가능성을 고려한다\"는 선언이 아닌, 실제 12개월 내 제안/구현한 개선 사례\n2. **6가지 최적화 영역 커버리지**: User, Software, Data, Hardware, Deployment patterns, Workload placement 중 최소 2-3개 영역의 실제 활동\n3. **정량적 측정 노력**: AWS Customer Carbon Footprint Tool 또는 유사 도구를 통한 탄소 발자국 측정 시도\n4. **고객 제안서/보고서에 지속가능성 섹션 포함**: 일상적 업무에 통합되었는지 확인\n5. **Graviton, Spot Instance, Right-sizing 등 에너지 효율 서비스 활용 실적**\n\n### 🛠️ 관련 AWS 서비스 및 기능\n- **AWS Customer Carbon Footprint Tool** (Console > Billing > Carbon Footprint)\n- **AWS Graviton Processors** (ARM 기반, 최대 60% 에너지 효율 향상)\n- **AWS Compute Optimizer** (Right-sizing 권장)\n- **Amazon S3 Intelligent-Tiering** (데이터 계층화)\n- **AWS Well-Architected Tool** (Sustainability Pillar 평가)\n- **Amazon EC2 Spot Instances** (유휴 용량 활용)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 필수 증거 목록\n\n| 증거 유형 | 파일명 예시 | 핵심 포함 내용 |\n|-----------|-------------|----------------|\n| **지속가능성 실천 정책서** | `MSP_Sustainability_Practice_Policy_v1.2.pdf` | 6가지 최적화 영역별 접근 방식, 고객 제안 시 고려사항 |\n| **개선 사례 보고서 (최소 2건)** | `Sustainability_Case_CustomerA_2024Q2.pdf` | Before/After 아키텍처, 예상 탄소 감축량, 비용 절감 연계 |\n| **Carbon Footprint 리포트** | `AWS_Carbon_Footprint_Report_202401-202412.pdf` | 관리 계정들의 탄소 발자국 추이 |\n| **고객 제안서 샘플** | `Proposal_CustomerB_Migration_Sustainability.pdf` | 지속가능성 섹션이 포함된 실제 제안서 |\n| **아키텍처 리뷰 체크리스트** | `Architecture_Review_Sustainability_Checklist.xlsx` | 리뷰 시 확인하는 지속가능성 항목들 |\n\n### 📝 각 증거의 핵심 포함 내용\n\n**1. 개선 사례 보고서 (가장 중요)**\n```\n필수 섹션:\n- 고객/프로젝트 개요 (익명화 가능)\n- 개선 전 상태 (인스턴스 타입, 리전, 사용률 등)\n- 제안한 개선 사항 (구체적 서비스/설정 변경)\n- 예상/실제 효과 (에너지 효율 %, 탄소 감축 추정치)\n- 구현 일자 (12개월 이내 증명)\n- 고객 승인/구현 상태\n```\n\n**2. 지속가능성 실천 정책서**\n```\n필수 섹션:\n- Workload Placement: 리전 선택 시 탄소 집약도 고려 기준\n- Architecture for User: 사용자 위치 기반 엣지 배치 전략\n- Software Patterns: 서버리스, 컨테이너 우선 정책\n- Data Patterns: 데이터 수명주기 관리, 계층화 정책\n- Hardware Patterns: Graviton 우선 정책, Right-sizing 주기\n- Deployment Patterns: Blue/Green 배포 시 리소스 최적화\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Carbon Footprint 현황 파악 (1일)\n**담당**: Cloud Operations Lead\n\n```bash\n# AWS Console에서 Carbon Footprint Tool 접근\nAWS Console > Billing and Cost Management > Carbon Footprint\n\n# 또는 AWS CLI로 데이터 추출 (Organizations 필요)\naws ce get-cost-and-usage \\\n  --time-period Start=2024-01-01,End=2024-12-31 \\\n  --granularity MONTHLY \\\n  --metrics \"UsageQuantity\"\n```\n\n**체크포인트**: 관리하는 고객 계정들의 최근 12개월 탄소 발자국 트렌드 스크린샷 확보\n\n---\n\n### Step 2: 6가지 영역별 개선 기회 식별 (2-3일)\n**담당**: Solutions Architect\n\n| 영역 | 확인 방법 | 도구 |\n|------|-----------|------|\n| Workload Placement | 리전별 탄소 집약도 vs 현재 배치 비교 | [AWS 리전 지속가능성 페이지](https://sustainability.aboutamazon.com/) |\n| User Patterns | CloudFront 캐시 적중률, 엣지 로케이션 활용도 | CloudFront Reports |\n| Software | Lambda Cold Start 빈도, 컨테이너 활용률 | X-Ray, Container Insights |\n| Data | S3 스토리지 클래스 분포, 미사용 데이터 | S3 Storage Lens |\n| Hardware | Graviton 미사용 인스턴스, Over-provisioned 리소스 | Compute Optimizer |\n| Deployment | 배포 시 중복 리소스 존재 시간 | CodeDeploy 로그 |\n\n---\n\n### Step 3: 실제 개선 사례 2건 이상 문서화 (3-5일)\n**담당**: Technical Account Manager + Solutions Architect\n\n**사례 1 예시: Graviton 마이그레이션**\n```markdown\n## 프로젝트: Customer A - EC2 Fleet Graviton Migration\n- 기간: 2024년 3월 15일 ~ 4월 30일\n- 대상: m5.xlarge 20대 → m7g.xlarge 20대\n- 결과: \n  - 에너지 효율 40% 향상 (AWS 공식 벤치마크 기준)\n  - 비용 20% 절감 (Graviton 가격 이점)\n  - 예상 탄소 감축: 연간 2.4 metric tons CO2e\n- 증빙: 변경 요청서, 마이그레이션 완료 보고서\n```\n\n**사례 2 예시: S3 Intelligent-Tiering 적용**\n```markdown\n## 프로젝트: Customer B - Data Lake 스토리지 최적화\n- 기간: 2024년 6월 1일 ~ 6월 15일\n- 대상: 50TB S3 Standard → S3 Intelligent-Tiering\n- 결과:\n  - 30% 데이터가 Archive Access Tier로 자동 이동\n  - 스토리지 관련 에너지 소비 예상 25% 감소\n- 증빙: S3 Storage Lens 리포트, 비용 비교 분석\n```\n\n---\n\n### Step 4: 지속가능성 정책서 작성 (2일)\n**담당**: Practice Lead\n\n```markdown\n# [회사명] AWS Managed Services - Sustainability Practice Policy\n\n## 1. 목적\n본 정책은 AWS 관리 서비스 제공 시 지속가능성 모범 사례를 \n체계적으로 적용하기 위한 가이드라인을 정의합니다.\n\n## 2. 적용 범위\n- 신규 아키텍처 설계\n- 기존 워크로드 최적화 리뷰\n- 마이그레이션 프로젝트\n- 월간 운영 리포트\n\n## 3. 영역별 실천 지침\n\n### 3.1 Workload Placement\n- 리전 선택 시 AWS 탄소 집약도 데이터 참조 필수\n- 재생에너지 100% 리전 우선 권장 (예: eu-north-1, eu-west-1)\n- 고객 요구사항과 지속가능성 트레이드오프 문서화\n\n### 3.2 Hardware Patterns  \n- 신규 EC2 배포 시 Graviton 프로세서 우선 검토\n- Compute Optimizer 권장사항 분기별 리뷰 필수\n- Spot Instance 활용 가능 워크로드 식별\n\n[... 나머지 영역 계속 ...]\n```\n\n---\n\n### Step 5: 고객 제안서에 지속가능성 섹션 템플릿화 (1일)\n**담당**: Pre-sales Team\n\n```markdown\n## 제안서 템플릿 - 지속가능성 섹션 (필수 포함)\n\n### 8. 지속가능성 고려사항\n\n#### 8.1 아키텍처 설계 시 적용된 지속가능성 원칙\n- [구체적 내용 기술]\n\n#### 8.2 예상 환경적 효과\n- Graviton 프로세서 활용: 예상 에너지 효율 XX% 향상\n- 서버리스 아키텍처 적용: 유휴 리소스 제거로 XX% 효율화\n- 데이터 계층화: 스토리지 에너지 소비 XX% 감소 예상\n\n#### 8.3 향후 최적화 로드맵\n- Phase 1: [내용]\n- Phase 2: [내용]\n```\n\n---\n\n### Step 6: Well-Architected Sustainability Pillar 리뷰 수행 (2일)\n**담당**: Solutions Architect\n\n```bash\n# AWS Well-Architected Tool에서 Sustainability Pillar 리뷰 생성\nAWS Console > Well-Architected Tool > Create Workload\n> Pillars 선택 시 \"Sustainability\" 포함\n\n# 리뷰 완료 후 PDF 리포트 다운로드\n```\n\n**증거 확보**: 최소 1개 고객 워크로드에 대한 Sustainability Pillar 리뷰 완료 리포트\n\n---\n\n### Step 7: 증거 패키지 구성 및 내부 검토 (1일)\n**담당**: MSP Program Manager\n\n**폴더 구조**:\n```\nGOV-006_Sustainability/\n├── 01_Policy/\n│   └── MSP_Sustainability_Practice_Policy_v1.2.pdf\n├── 02_Case_Studies/\n│   ├── Case1_CustomerA_Graviton_Migration_202403.pdf\n│   └── Case2_CustomerB_S3_Optimization_202406.pdf\n├── 03_Carbon_Footprint/\n│   └── AWS_Carbon_Footprint_Screenshots_2024.pdf\n├── 04_Proposal_Samples/\n│   └── Proposal_Template_with_Sustainability_Section.pdf\n└── 05_WA_Reviews/\n    └── WA_Sustainability_Review_CustomerC_202407.pdf\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ 실패 사례 1: 일반적인 환경 정책만 제출\n**문제**: \"우리 회사는 환경을 중요시합니다\" 수준의 일반 정책서만 제출\n**해결**: AWS 6가지 최적화 영역(User, Software, Data, Hardware, Deployment, Workload Placement)을 **명시적으로** 다루는 정책 필요\n\n### ❌ 실패 사례 2: 12개월 이내 사례 부재\n**문제**: 2년 전 프로젝트 사례를 제출하거나, \"계획 중\"인 사례만 제출\n**해결**: **반드시 최근 12개월 이내**에 제안되었거나 구현된 사례 필요. 날짜가 명확히 기재된 문서 필수\n\n### ❌ 실패 사례 3: 비용 절감과 지속가능성 혼동\n**문제**: \"Right-sizing으로 비용 30% 절감\" - 지속가능성 관점 설명 없음\n**해결**: 동일한 활동이라도 **에너지 효율, 탄소 감축 관점**에서 재해석하여 기술\n```\n❌ \"m5.2xlarge → m5.large로 다운사이징하여 비용 50% 절감\"\n✅ \"m5.2xlarge → m5.large로 다운사이징하여 컴퓨팅 리소스 50% 감소, \n    이에 따른 에너지 소비 및 탄소 배출 비례 감소 달성\"\n```\n\n### ❌ 실패 사례 4: Carbon Footprint Tool 미활용\n**문제**: AWS에서 제공하는 공식 도구를 사용하지 않고 자체 추정치만 제시\n**해결**: AWS Customer Carbon Footprint Tool 스크린샷 또는 리포트 반드시 포함\n\n### ❌ 실패 사례 5: 고객 프로젝트와 무관한 내",
      "language": "en",
      "createdAt": "2026-01-07T02:54:38.458Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOVP-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOVP-001",
      "category": "Governance",
      "title": "Supplier Management",
      "advice": "# GOVP-001: Supplier Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\n\nAWS MSP Partners deliver managed services to customers, but rarely do so entirely in-house. You likely use **third-party monitoring tools (Datadog, New Relic)**, **ticketing systems (ServiceNow, Jira Service Management)**, **backup solutions (Veeam, Commvault)**, or **subcontract specific operations to other vendors**. AWS needs assurance that your supply chain won't become a security weak link that affects customer environments.\n\nThis requirement ensures that **risks from your suppliers don't cascade to AWS customers**. A breach at an unvetted SaaS vendor you use could expose customer data—AWS wants to see you've thought about this systematically.\n\n### 🎯 Key Points Auditors Focus On\n\n1. **Documented Selection Criteria** - Not just \"we pick good vendors\" but specific evaluation factors (security posture, compliance certifications, financial stability, data handling practices)\n\n2. **Risk-Based Categorization** - Evidence that you treat a critical infrastructure tool differently from a minor utility vendor\n\n3. **Ongoing Evaluation Mechanism** - Initial vetting isn't enough; auditors look for periodic review cycles (annual reassessment, continuous monitoring)\n\n4. **Evidence of Actual Execution** - Your SOP must show it's being followed with real supplier evaluations, not just theoretical documentation\n\n5. **Data Flow Awareness** - Clear understanding of which suppliers access/process customer data vs. those that don't\n\n### Relevant AWS Services & Features\n\n- **AWS Artifact** - Access compliance reports of AWS services you integrate with\n- **AWS Marketplace** - Many pre-vetted ISV tools with published compliance certifications\n- **AWS Security Hub** - Can integrate with third-party tools; understanding these integrations matters\n- **AWS Organizations SCPs** - Control which third-party services can be used in customer accounts\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Primary Evidence Option A: Supplier Management SOP\n\n**Document Name Example:** `MSP-PROC-007_Supplier_Selection_and_Evaluation_Procedure_v2.3.pdf`\n\n**Must Include:**\n\n| Section | Specific Content Required |\n|---------|--------------------------|\n| **Scope Definition** | Which vendor types are covered (SaaS tools, subcontractors, consultants, ISVs, cloud service resellers) |\n| **Supplier Categorization Matrix** | Tier 1 (Critical/Data Access), Tier 2 (Important/No Data), Tier 3 (Low Risk) with criteria for each |\n| **Selection Criteria Checklist** | Minimum 8-10 evaluation factors with scoring methodology |\n| **Security Assessment Requirements** | What certifications required per tier (e.g., Tier 1 must have SOC2 Type II) |\n| **Approval Workflow** | Who approves which tier (e.g., CISO for Tier 1, IT Manager for Tier 3) |\n| **Ongoing Monitoring Process** | Annual review cycle, trigger events for reassessment |\n| **Offboarding Procedure** | How to terminate supplier relationships securely |\n\n### Primary Evidence Option B: Your Own Certification\n\nIf your organization holds **ISO 27001** or **SOC2 Type II**, provide:\n- Certificate copy showing current validity\n- Relevant sections from your ISMS/controls documentation showing supplier management controls\n- **ISO 27001**: Control A.15.1 (Information security in supplier relationships)\n- **SOC2**: CC9.2 (Vendor and Business Partner Risk Management)\n\n### Supporting Evidence (Strengthens Your Submission)\n\n| Evidence Type | Example File Name | Purpose |\n|--------------|-------------------|---------|\n| Supplier Register | `Supplier_Inventory_Register_2024.xlsx` | Shows you track all suppliers |\n| Completed Assessment | `Datadog_Vendor_Assessment_2024-03.pdf` | Proves SOP is executed |\n| Supplier Certifications | `NewRelic_SOC2_TypeII_2024.pdf` | Shows suppliers meet your standards |\n| Risk Assessment Matrix | `Supplier_Risk_Matrix_Q1_2024.xlsx` | Documents risk categorization |\n| Contract Clauses Template | `Security_Addendum_Template_v1.2.docx` | Shows security requirements in contracts |\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Inventory All Current Suppliers (Week 1)\n**Responsible:** Operations Manager + Security Team\n\nCreate a comprehensive list of every third party involved in your MSP service delivery:\n\n```\nCategory Examples to Include:\n├── Monitoring Tools: Datadog, CloudWatch (native), Splunk\n├── Ticketing/ITSM: ServiceNow, Freshservice, Jira SM\n├── Backup/DR: Veeam, Commvault, Druva\n├── Security Tools: CrowdStrike, Qualys, Tenable\n├── Automation: Terraform Cloud, Ansible Tower\n├── Communication: PagerDuty, Slack, MS Teams\n├── Subcontractors: NOC providers, specialized consultants\n└── Resellers: License distributors, hardware suppliers\n```\n\n**Output:** `Supplier_Master_List.xlsx` with columns: Vendor Name, Service Type, Data Access Level, Current Contract End Date, Last Assessment Date\n\n### Step 2: Define Supplier Categorization Framework (Week 1-2)\n**Responsible:** CISO/Security Lead\n\nCreate a tiered classification system:\n\n**Tier 1 - Critical (Customer Data Access)**\n- Criteria: Processes, stores, or transmits customer data; has access to customer AWS accounts\n- Examples: Monitoring tools with agent deployment, backup solutions, SIEM platforms\n- Requirements: SOC2 Type II or ISO 27001 mandatory, annual penetration test results, security questionnaire\n\n**Tier 2 - Important (Operational Impact)**\n- Criteria: No customer data access but critical to service delivery\n- Examples: Ticketing systems (if no customer data), internal automation tools\n- Requirements: SOC2 Type I acceptable, security self-assessment questionnaire\n\n**Tier 3 - Standard (Low Risk)**\n- Criteria: No data access, easily replaceable, limited operational impact\n- Examples: Office supplies, general SaaS utilities\n- Requirements: Basic due diligence, vendor reputation check\n\n### Step 3: Develop Selection Criteria Checklist (Week 2)\n**Responsible:** Security Team + Procurement\n\nCreate a weighted scoring matrix:\n\n| Evaluation Factor | Weight | Scoring (1-5) |\n|------------------|--------|---------------|\n| Security Certifications (SOC2/ISO27001) | 20% | 5=Type II, 3=Type I, 1=None |\n| Data Encryption (transit/rest) | 15% | 5=Both AES-256, 3=Transit only |\n| Incident Response SLA | 15% | 5=<1hr, 3=<4hr, 1=>24hr |\n| Financial Stability | 10% | 5=Public/Funded, 3=Stable, 1=Unknown |\n| Geographic Data Residency | 10% | 5=Configurable, 3=Specific regions |\n| Subprocessor Transparency | 10% | 5=Published list, 3=On request |\n| Right to Audit | 10% | 5=Contractual right, 1=None |\n| Business Continuity Plan | 10% | 5=Tested annually, 3=Documented |\n\n**Minimum Score for Approval:** Tier 1: 4.0+, Tier 2: 3.0+, Tier 3: 2.0+\n\n### Step 4: Document the SOP (Week 2-3)\n**Responsible:** Documentation Lead + Security Team\n\nStructure your SOP document:\n\n```\n1. Purpose and Scope\n2. Definitions (Supplier, Subprocessor, ISV, etc.)\n3. Roles and Responsibilities\n   - Procurement Team: Initial sourcing\n   - Security Team: Risk assessment\n   - Legal: Contract review\n   - Business Owner: Functional requirements\n4. Supplier Classification Process\n5. Selection and Evaluation Process\n   5.1 New Supplier Request Form\n   5.2 Security Assessment Procedure\n   5.3 Scoring and Approval Workflow\n6. Contracting Requirements\n   6.1 Mandatory Security Clauses\n   6.2 Data Processing Addendum requirements\n7. Ongoing Management\n   7.1 Annual Reassessment Cycle\n   7.2 Continuous Monitoring (news alerts, breach notifications)\n   7.3 Performance Review\n8. Supplier Offboarding\n9. Records Retention\n10. Appendices\n    A. Supplier Assessment Questionnaire\n    B. Scoring Matrix Template\n    C. Approved Supplier Register\n```\n\n### Step 5: Execute Assessment on Key Suppliers (Week 3-4)\n**Responsible:** Security Team\n\nRun your new process on 3-5 critical suppliers to generate evidence:\n\n1. **Select suppliers:** Choose your monitoring tool, ticketing system, and one subcontractor\n2. **Request certifications:** Email vendors for current SOC2/ISO27001 certificates\n3. **Complete assessment:** Fill out your scoring matrix for each\n4. **Document approval:** Get sign-off from appropriate authority per tier\n5. **Update register:** Record assessment date and next review date\n\n**Pro Tip:** Most enterprise SaaS vendors (Datadog, ServiceNow, PagerDuty) publish their SOC2 reports in trust centers—download these directly.\n\n### Step 6: Establish Ongoing Review Mechanism (Week 4)\n**Responsible:** Operations Manager\n\nSet up calendar reminders and tracking:\n- Annual full reassessment for Tier 1 suppliers (every 12 months)\n- Biennial review for Tier 2 suppliers (every 24 months)\n- Trigger-based review: Major security incident, acquisition, significant service change\n- Subscribe to vendor security bulletins and breach notification services\n\n### Step 7: Compile Evidence Package (Week 4-5)\n**Responsible:** Compliance/Audit Lead\n\nOrganize final submission:\n```\nGOVP-001_Evidence/\n├── MSP-PROC-007_Supplier_Management_SOP_v2.3.pdf\n├── Supporting_Evidence/\n│   ├── Supplier_Register_2024.xlsx\n│   ├── Completed_Assessments/\n│   │   ├── Datadog_Assessment_2024-03.pdf\n│   │   ├── ServiceNow_Assessment_2024-02.pdf\n│   │   └── NOC_Partner_Assessment_2024-01.pdf\n│   └── Supplier_Certifications/\n│       ├── Datadog_SOC2_TypeII_2024.pdf\n│       └── ServiceNow_ISO27001_Certificate.pdf\n└── Evidence_Index.pdf (maps evidence to requirement)\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: SOP Exists But No Execution Evidence\n\n**What Goes Wrong:** Partner submits a beautifully written 20-page SOP but cannot show a single completed supplier assessment.\n\n**Auditor Question:** \"Can you show me a recent supplier evaluation using this process?\"\n\n**Solution:** Complete at least 3 supplier assessments before audit. Include assessment dates, scores, approver signatures, and next review dates.\n\n---\n\n### ❌ Mistake 2: Forgetting Internal Tools That Touch Customer Data\n\n**What Goes Wrong:** Partner lists obvious vendors (AWS, Microsoft) but forgets:\n- The Slack workspace where customer incidents are discussed\n- The shared Google Drive with customer architecture diagrams\n- The contractor who has access to customer accounts\n\n**Auditor Question:** \"I see you use Slack for incident communication. Is that in your supplier register?\"\n\n**Solution:** Conduct a data flow mapping exercise. Trace where customer data goes—every tool that touches it is a supplier requiring assessment.\n\n---\n\n### ❌ Mistake 3: Relying Solely on Vendor Self-Attestation\n\n**What Goes Wrong:** Supplier assessment consists only of \"Vendor said they're secure\" without verification.\n\n**Auditor Concern:** No independent validation of supplier security claims.\n\n**Solution:** Require third-party certifications (SOC2, ISO27001) for Tier 1 suppliers. For those without certifications, conduct deeper assessment including security questionnaire (SIG Lite, CAIQ) and potentially right-to-audit clauses.\n\n---\n\n### ❌ Mistake 4: One-Time Assessment Without Ongoing Review\n\n**What Goes Wrong:** Supplier was assessed in 2021, no updates since. SOC2 report is 3 years old.\n\n**Auditor Question:** \"When was this supplier last reviewed? Is their certification still valid?\"\n\n**Solution:** \n- SOP must specify review frequency (annual for critical suppliers)\n- Track certification expiration dates\n- Document annual review even if just confirming \"no changes, certification renewed\"\n\n---\n\n### ❌ Mistake 5: No Risk-Based Differentiation\n\n**What Goes Wrong:** Same lightweight assessment for a critical monitoring tool with root access to customer accounts and the office coffee supplier.\n\n**Auditor Concern:** Disproportionate effort doesn't reflect actual risk.\n\n**Solution:** Tiered approach with clear criteria. Tier 1 suppliers get full security assessment; Tier 3 gets basic due diligence. Document the rationale for each tier assignment.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ 1 | SOP includes supplier categorization criteria | Review SOP Section 4 | Minimum 3 tiers defined with specific criteria for each |\n| ✅ 2 | Selection criteria are specific and measurable | Check scoring matrix in SOP | At least 8 evaluation factors with numerical scoring |\n| ✅ 3 | Approval workflow is documented | Review SOP Section 5.3 | Clear approver roles per supplier tier (names/titles) |\n| ✅ 4 | Ongoing review frequency is specified | Check SOP Section 7 | Annual review for critical suppliers explicitly stated |\n| ✅ 5 | At least 3 completed supplier assessments exist | Review Supporting_Evidence folder | Assessments dated within last 12 months, fully completed |\n| ✅ 6 | Critical suppliers have valid certifications | Check expiration dates on certificates | SOC2/ISO27001 certificates not expired |\n| ✅ 7 | Supplier register is current and complete | Cross-reference with actual tools in use | All tools used in customer delivery are listed |\n| ✅ 8 | SOP has version control and approval | Check document header | Version number, effective date, approver signature present |\n\n### Quality Gate Questions (Ask Yourself Before Submission)\n\n1. **\"If an auditor asked me to show how we selected our monitoring tool, can I walk through the exact process with documentation?\"** → If no, complete an assessment for that tool.\n\n2. **\"Are there any tools with customer data access missing from our supplier register?\"** → Do a final sweep of all integrations, API connections, and third-party agents.\n\n3. **\"Can I prove this SOP was followed, not just written?\"** → Ensure assessment dates, approver names, and decision records exist.\n\n4. **\"What happens if a supplier has a breach tomorrow—does our SOP tell us what to do?\"** → Include incident response triggers and reassessment criteria.\n\n---\n\n## 📌 Quick Reference: Minimum Viable Evidence Package\n\nFor a **passing submission**, you need at minimum:\n\n1. ✅ Supplier Management SOP (8+ pages, specific criteria, tiered approach)\n2. ✅ Supplier Register showing all vendors used in MSP delivery\n3. ✅ 3 completed supplier assessments (preferably Tier 1 suppliers)\n4. ✅ Current SOC2/ISO27001 certificates for critical suppliers\n\n**OR**\n\n1. ✅ Your organization's valid ISO 27001 certificate\n2. ✅ Extract of ISMS showing A.15.1 controls implementation\n3. ✅ Evidence of supplier management execution under your ISMS",
      "language": "en",
      "createdAt": "2026-01-07T02:29:35.393Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOVP-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOVP-002",
      "category": "Governance",
      "title": "Operations Improvement",
      "advice": "# GOVP-002: Operations Improvement - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nOperations Improvement (GOVP-002) is the **core requirement demonstrating MSP maturity**. AWS wants to verify that partners don't just \"maintain\" customer environments but continuously evolve and optimize them. This item proves you have a systematic approach to identifying inefficiencies, learning from incidents, and proactively enhancing service delivery.\n\nUnlike one-time certifications, this requirement demands **evidence of ongoing cycles** - showing that improvement is embedded in your organizational DNA, not a checkbox exercise.\n\n### 🔎 What Auditors Specifically Look For\n\n1. **Defined Review Cadence with Proof of Execution**\n   - Not just \"we do monthly reviews\" but actual meeting minutes, action items, and completion tracking\n   - Auditors want to see at least 3-6 months of historical review records\n\n2. **Multi-Domain Coverage**\n   - Evidence that reviews span ALL mentioned areas: incident management, cost optimization, architecture patterns, performance, AND security\n   - Single-focus improvement programs (e.g., only cost optimization) will fail\n\n3. **Prioritization Framework**\n   - Clear methodology for ranking improvement opportunities (impact vs. effort matrix, RICE scoring, etc.)\n   - Evidence that not everything gets done - showing conscious prioritization decisions\n\n4. **Closed-Loop Tracking**\n   - Improvement opportunities must flow from identification → prioritization → implementation → validation\n   - Auditors check if identified issues actually get resolved\n\n5. **Customer Impact Linkage**\n   - Improvements should connect to customer outcomes, not just internal efficiency\n   - Evidence showing how improvements benefit managed customers\n\n### Relevant AWS Services & Features\n\n| Domain | AWS Services for Improvement Identification |\n|--------|---------------------------------------------|\n| Incident Management | AWS Systems Manager OpsCenter, CloudWatch Alarms history, AWS Health Dashboard |\n| Cost Management | AWS Cost Explorer, Cost Anomaly Detection, Trusted Advisor cost checks |\n| Architecture | AWS Well-Architected Tool, AWS Config conformance packs |\n| Performance | CloudWatch Performance Insights, X-Ray service maps |\n| Security | Security Hub findings trends, GuardDuty findings, IAM Access Analyzer |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### 📄 Document 1: Operations Improvement Governance Framework\n**Filename:** `OPS-IMPROVEMENT-GOVERNANCE-FRAMEWORK-v2.1.pdf`\n\n**Must Include:**\n- Improvement review meeting structure (who, when, what frequency)\n- Domain-specific review schedules:\n  ```\n  Weekly: Incident trends, security alerts\n  Monthly: Cost optimization, performance metrics\n  Quarterly: Architecture patterns, process efficiency\n  ```\n- Escalation paths for critical improvements\n- Roles: Improvement Champion, Domain Leads, Executive Sponsor\n- Integration points with customer governance (QBRs, service reviews)\n\n#### 📄 Document 2: Improvement Opportunity Register (Active Backlog)\n**Filename:** `IMPROVEMENT-BACKLOG-2024-Q4.xlsx`\n\n**Required Columns:**\n| Column | Purpose |\n|--------|---------|\n| Opportunity ID | Unique tracking reference |\n| Domain | Incident/Cost/Architecture/Performance/Security |\n| Source | How identified (review meeting, incident post-mortem, customer feedback) |\n| Description | Specific improvement needed |\n| Impact Score | Quantified benefit (cost savings, MTTR reduction, etc.) |\n| Effort Estimate | T-shirt sizing or story points |\n| Priority Rank | Based on your prioritization framework |\n| Status | Backlog/In Progress/Completed/Deferred |\n| Owner | Assigned individual |\n| Target Date | Expected completion |\n| Actual Completion | When closed |\n| Validation Method | How success was measured |\n\n#### 📄 Document 3: Review Meeting Records (Last 6 Months)\n**Filename:** `OPS-REVIEW-MINUTES-[YYYY-MM].pdf` (6 files minimum)\n\n**Each Meeting Record Must Show:**\n- Date, attendees, duration\n- Metrics reviewed per domain (with actual numbers)\n- New opportunities identified (with IDs linking to backlog)\n- Status updates on in-flight improvements\n- Decisions made and rationale\n- Action items with owners and due dates\n\n#### 📄 Document 4: Improvement Implementation Evidence\n**Filename:** `IMPROVEMENT-CASE-STUDIES-2024.pdf`\n\n**Include 5-8 Completed Improvements:**\n- Before/after metrics\n- Implementation approach\n- Customer impact statement\n- Lessons learned\n\n#### 📄 Document 5: Prioritization Framework Documentation\n**Filename:** `IMPROVEMENT-PRIORITIZATION-METHODOLOGY.pdf`\n\n**Must Define:**\n- Scoring criteria (e.g., customer impact, revenue protection, risk reduction)\n- Weighting factors\n- Decision authority matrix\n- Examples of prioritization decisions made\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Establish Domain-Specific Data Sources (Week 1-2)\n**⏱️ Time: 8-10 hours | 👤 Owner: Technical Operations Lead**\n\nConfigure automated data collection for each improvement domain:\n\n```bash\n# Example: Set up Cost Anomaly Detection for improvement identification\naws ce create-anomaly-monitor \\\n    --anomaly-monitor '{\n        \"MonitorName\": \"MSP-Cost-Improvement-Monitor\",\n        \"MonitorType\": \"DIMENSIONAL\",\n        \"MonitorDimension\": \"SERVICE\"\n    }'\n\n# Create SNS topic for improvement opportunity alerts\naws sns create-topic --name ops-improvement-opportunities\n```\n\n**Domain Setup Checklist:**\n- [ ] Security Hub aggregation enabled across all managed accounts\n- [ ] Well-Architected Tool reviews scheduled quarterly per customer\n- [ ] CloudWatch dashboards created for performance trending\n- [ ] Cost Explorer reports automated for anomaly identification\n- [ ] OpsCenter configured to aggregate operational issues\n\n### Step 2: Design the Improvement Review Cadence (Week 2)\n**⏱️ Time: 4-6 hours | 👤 Owner: Service Delivery Manager**\n\nCreate a tiered review structure:\n\n| Review Type | Frequency | Duration | Attendees | Focus Areas |\n|-------------|-----------|----------|-----------|-------------|\n| Ops Standup | Daily | 15 min | On-call team | Immediate issues, blockers |\n| Tactical Review | Weekly | 60 min | Domain leads | Incident trends, security alerts, quick wins |\n| Strategic Review | Monthly | 90 min | Leadership + Domain leads | Cost optimization, performance patterns, backlog grooming |\n| Governance Board | Quarterly | 2 hours | Exec sponsor + All leads | Architecture evolution, process changes, resource allocation |\n\n### Step 3: Build the Improvement Backlog System (Week 2-3)\n**⏱️ Time: 6-8 hours | 👤 Owner: Process Improvement Lead**\n\n**Option A: Jira Configuration**\n```\nProject: OPS-IMPROVEMENT\nIssue Types: \n  - Improvement Opportunity\n  - Process Enhancement\n  - Automation Initiative\n\nCustom Fields:\n  - Domain (dropdown: Incident/Cost/Architecture/Performance/Security)\n  - Impact Score (number 1-10)\n  - Effort Score (number 1-10)\n  - Priority Score (calculated: Impact × 2 - Effort)\n  - Source (dropdown: Review Meeting/Post-Mortem/Customer Feedback/Proactive Discovery)\n  - Customer Impact (text)\n  - Validation Metric (text)\n```\n\n**Option B: AWS-Native Using Systems Manager OpsCenter**\n- Create OpsItem categories for improvement tracking\n- Use runbooks for standardized improvement implementation\n\n### Step 4: Implement Prioritization Framework (Week 3)\n**⏱️ Time: 4 hours | 👤 Owner: Service Delivery Manager**\n\nDocument your RICE-based prioritization:\n\n```\nPriority Score = (Reach × Impact × Confidence) / Effort\n\nReach: Number of customers/workloads affected (1-10)\nImpact: Magnitude of improvement (1-10)\n  - 10: Critical security/compliance fix\n  - 7-9: Significant cost savings (>20%)\n  - 4-6: Performance/efficiency gains\n  - 1-3: Minor enhancements\nConfidence: How certain is the benefit? (0.5-1.0)\nEffort: Person-weeks required (1-10)\n```\n\n### Step 5: Execute First Full Review Cycle (Week 4-5)\n**⏱️ Time: 8-10 hours | 👤 Owner: All Domain Leads**\n\nRun your first documented improvement review:\n\n**Pre-Meeting Preparation (Each Domain Lead):**\n1. Pull metrics from AWS services for their domain\n2. Identify 2-3 potential improvement opportunities\n3. Prepare brief analysis (problem statement, proposed solution, estimated impact)\n\n**During Meeting:**\n1. Review each domain's metrics (15 min per domain)\n2. Discuss identified opportunities\n3. Score and prioritize new items\n4. Update status on existing backlog items\n5. Assign owners and target dates\n\n**Post-Meeting:**\n1. Publish minutes within 24 hours\n2. Update backlog system\n3. Send action item reminders\n\n### Step 6: Implement and Document 3-5 Improvements (Week 5-8)\n**⏱️ Time: Variable | 👤 Owner: Assigned Improvement Owners**\n\nSelect quick wins to demonstrate closed-loop execution:\n\n**Example Improvement Documentation:**\n\n```markdown\n## Improvement Case Study: IMP-2024-042\n\n### Problem Identified\nMonthly review (Oct 2024) identified that 67% of P2 incidents \nwere related to EBS volume capacity alerts firing too late.\n\n### Source\nIncident Management trend analysis - Weekly tactical review\n\n### Solution Implemented\n- Modified CloudWatch alarm thresholds from 90% to 80%\n- Added predictive alarms using anomaly detection\n- Created automated remediation via Systems Manager\n\n### Before/After Metrics\n| Metric | Before | After |\n|--------|--------|-------|\n| EBS-related P2 incidents/month | 12 | 3 |\n| Average detection time | 45 min | 8 min |\n| Customer impact hours | 18 hrs | 2.5 hrs |\n\n### Validation\nTracked for 60 days post-implementation. \nImprovement sustained across all managed accounts.\n```\n\n### Step 7: Compile Evidence Package (Week 8-9)\n**⏱️ Time: 6-8 hours | 👤 Owner: MSP Program Lead**\n\nAssemble final documentation:\n- Export 6 months of meeting minutes (or simulate if new process)\n- Generate backlog report showing full lifecycle\n- Create executive summary of improvement program\n- Gather screenshots of AWS service configurations used\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Presenting a \"Wish List\" Instead of Active Backlog\n**What Goes Wrong:** Partners submit a document listing potential improvements without evidence of prioritization, ownership, or progress tracking.\n\n**Auditor Red Flag:** \"This looks like a brainstorming output, not a managed improvement program.\"\n\n**Fix:** Ensure your backlog shows items in various states - some completed, some in progress, some deliberately deferred with rationale.\n\n### ❌ Mistake 2: Single-Domain Focus\n**What Goes Wrong:** Partners excel at cost optimization but have no documented improvements in security or incident management domains.\n\n**Auditor Red Flag:** \"Where are the security and performance improvements? The requirement explicitly lists multiple domains.\"\n\n**Fix:** Ensure your evidence shows at least 2 improvements per domain (incident, cost, architecture, performance, security) over the review period.\n\n### ❌ Mistake 3: No Customer Linkage\n**What Goes Wrong:** Improvements focus entirely on internal MSP efficiency (e.g., \"reduced our ticket handling time\") without connecting to customer outcomes.\n\n**Auditor Red Flag:** \"How do these improvements benefit your managed customers?\"\n\n**Fix:** Every improvement should articulate customer impact - even internal efficiency gains should translate to faster response times or better service quality for customers.\n\n### ❌ Mistake 4: Missing the \"Continuous\" in Continuous Improvement\n**What Goes Wrong:** Partners show a one-time improvement initiative or project rather than an ongoing cyclical process.\n\n**Auditor Red Flag:** \"This appears to be a project with an end date, not an embedded operational practice.\"\n\n**Fix:** Evidence must show recurring reviews over time (minimum 3 cycles, ideally 6+ months), with new opportunities continuously entering the pipeline.\n\n### ❌ Mistake 5: No Validation of Implemented Improvements\n**What Goes Wrong:** Partners implement changes but don't measure whether they actually improved anything.\n\n**Auditor Red Flag:** \"How do you know this improvement worked? Where's the before/after comparison?\"\n\n**Fix:** Each completed improvement must have defined success metrics and post-implementation validation data.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Quality Gates\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Multi-domain coverage documented** | Review backlog for domain tags | All 5 domains (incident, cost, architecture, performance, security) have at least 2 items each |\n| 2 | **Review cadence evidence spans 3+ months** | Count meeting minutes files | Minimum 3 monthly reviews OR 12 weekly reviews with dates clearly visible |\n| 3 | **Prioritization decisions visible** | Check backlog for priority scores and deferred items | At least 3 items marked as \"deferred\" with documented rationale |\n| 4 | **Closed-loop completion demonstrated** | Filter backlog for completed items | Minimum 5 improvements showing full lifecycle: identified → prioritized → implemented → validated |\n| 5 | **Quantified impact on completed improvements** | Review case studies for metrics | Each completed improvement has before/after metrics (not just \"improved\" but specific numbers) |\n| 6 | **Customer impact articulated** | Search documents for customer references | Each improvement explicitly states customer benefit or affected customer count |\n| 7 | **AWS services integrated into process** | Check for AWS service references | Evidence shows use of at least 3 AWS services (e.g., Cost Explorer, Security Hub, Well-Architected Tool) as data sources for improvement identification |\n\n### 📋 Document Completeness Check\n\n```\n□ Governance Framework document includes:\n  □ Review meeting structure with frequencies\n  □ Roles and responsibilities defined\n  □ Escalation paths documented\n  □ Integration with customer governance mentioned\n\n□ Improvement Backlog includes:\n  □ Unique IDs for tracking\n  □ Domain classification for each item\n  □ Source/origin documented\n  □ Priority scores calculated\n  □ Status progression visible\n  □ Owner assignments\n  □ Target and actual completion dates\n\n□ Meeting Minutes include:\n  □ Attendee lists\n  □ Metrics reviewed (with actual numbers)\n  □ New opportunities identified (with backlog IDs)\n  □ Decisions and rationale\n  □ Action items with owners\n\n□ Case Studies include:\n  □ Problem statement\n  □ Solution implemented\n  □ Before/after metrics\n  □ Validation methodology\n  □ Lessons learned\n```\n\n### 🎯 Final Quality Criteria\n\n**Your evidence passes when an auditor can:**\n1. Trace an improvement from initial identification in a review meeting → backlog entry → prioritization decision → implementation → measured outcome\n2. See that your organization makes conscious trade-off decisions (not everything gets done)\n3. Understand how AWS services feed data into your improvement identification process\n4. Recognize this as an ongoing operational practice, not a one-time project\n5. Connect improvements to tangible customer benefits\n\n---\n\n**💡 Pro Tip:** Before submission, have someone unfamiliar with your improvement program review the evidence. If they can follow the story of how you identify, prioritize, implement, and validate improvements without asking questions, your evidence is ready.",
      "language": "en",
      "createdAt": "2026-01-07T02:30:44.943Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "GOVP-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "GOVP-003",
      "category": "Governance",
      "title": "Sustainability Commitment",
      "advice": "# GOVP-003: Sustainability Commitment - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Matters in AWS MSP Program\n\nAWS has made sustainability a core pillar of their corporate strategy (targeting 100% renewable energy by 2025 and net-zero carbon by 2040). As an MSP partner, you're expected to align with AWS's sustainability vision and demonstrate that you can help customers optimize their cloud footprint for environmental impact—not just cost. This requirement validates that sustainability is embedded in your company's DNA, not just a checkbox exercise.\n\n### 🔎 What Auditors Specifically Look For\n\n1. **Executive-Level Ownership**: Evidence that a C-level executive (CEO, COO, or Chief Sustainability Officer) has personally endorsed the sustainability commitment—not just a department head or manager\n2. **Long-Term Strategic Integration**: Proof that sustainability is part of multi-year business planning, not a standalone initiative or one-time statement\n3. **AWS Cloud-Specific Sustainability Actions**: Concrete references to how you leverage AWS's sustainability tools (Carbon Footprint Tool, Graviton processors, right-sizing) in customer engagements\n4. **Measurable Goals**: Specific targets with timelines (e.g., \"reduce customer workload carbon footprint by 20% by 2025\")\n5. **Customer-Facing Commitment**: Evidence that you communicate sustainability value to customers as part of your MSP services\n\n### Relevant AWS Services & Features\n- **AWS Customer Carbon Footprint Tool** (in Cost & Usage Reports)\n- **AWS Graviton processors** (up to 60% less energy for same performance)\n- **Amazon EC2 Auto Scaling** (eliminate idle resources)\n- **AWS Compute Optimizer** (right-sizing recommendations)\n- **AWS Well-Architected Framework - Sustainability Pillar**\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Documents\n\n| Document Type | Format | Key Contents |\n|--------------|--------|--------------|\n| **Sustainability Policy Document** | PDF (signed) | Company-wide sustainability vision, goals, governance structure |\n| **CxO Commitment Letter/Statement** | PDF with signature or email from executive | Personal endorsement from CEO/COO with specific commitments |\n| **Board/Leadership Meeting Minutes** | PDF excerpt | Discussion and approval of sustainability strategy |\n| **Customer-Facing Sustainability Collateral** | PDF/webpage screenshot | How you communicate sustainability to MSP customers |\n\n### 📄 Key Content Requirements for Each Evidence\n\n**Sustainability Policy Document Must Include:**\n- Publication date and version number\n- Explicit mention of cloud operations and AWS partnership\n- Specific sustainability goals with target dates\n- Governance structure (who owns sustainability initiatives)\n- Review cycle (annual review commitment)\n- Connection to customer service delivery\n\n**CxO Commitment Communication Must Include:**\n- Executive's name, title, and signature (digital acceptable)\n- Date within last 12 months\n- Reference to sustainability as \"strategic priority\" or \"long-term commitment\"\n- At least one specific action or investment the company is making\n- Mention of AWS cloud sustainability alignment\n\n### 📁 Example File Names\n- `ABC_MSP_Sustainability_Policy_v2.1_2024.pdf`\n- `CEO_Sustainability_Commitment_Letter_March2024.pdf`\n- `Board_Minutes_Excerpt_Sustainability_Strategy_Q1_2024.pdf`\n- `MSP_Customer_Sustainability_Services_Overview.pdf`\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Secure Executive Sponsorship (Week 1)\n**Action**: Schedule a 30-minute meeting with your CEO or COO to discuss AWS MSP sustainability requirements\n\n**Talking Points to Prepare:**\n- AWS's sustainability goals and why partner alignment matters\n- Competitive advantage of sustainability positioning\n- Minimal effort required (policy + commitment letter)\n\n**Deliverable**: Executive agreement to sign commitment letter\n**Responsible**: MSP Program Lead + Executive Assistant\n\n---\n\n### Step 2: Draft Sustainability Policy Document (Week 1-2)\n**Action**: Create a 3-5 page sustainability policy using this structure:\n\n```\n1. Executive Summary & Vision Statement\n2. Scope (internal operations + customer services)\n3. Strategic Pillars:\n   - Cloud Infrastructure Optimization\n   - Customer Workload Sustainability\n   - Internal Operations\n4. Goals & Targets (with dates)\n5. Governance & Accountability\n6. Measurement & Reporting\n7. Review Schedule\n```\n\n**AWS-Specific Content to Include:**\n- Commitment to use AWS Customer Carbon Footprint Tool for all managed customers\n- Policy to recommend Graviton-based instances where applicable\n- Right-sizing reviews as part of standard MSP service delivery\n- Reference to AWS Well-Architected Sustainability Pillar reviews\n\n**Tool**: Use AWS Well-Architected Sustainability Pillar whitepaper as reference\n**Responsible**: Operations Lead + Marketing/Communications\n\n---\n\n### Step 3: Create CxO Commitment Letter (Week 2)\n**Action**: Draft a 1-page letter for executive signature\n\n**Template Structure:**\n```\n[Company Letterhead]\n[Date]\n\nSubject: [Company Name] Commitment to Sustainable Cloud Operations\n\nAs [Title] of [Company], I am pleased to affirm our organization's \ncommitment to environmental sustainability as a core element of our \nlong-term business strategy.\n\n[Paragraph on company sustainability vision]\n\n[Paragraph on AWS partnership and cloud sustainability alignment]\n\n[Specific commitments - at least 3 bullet points with dates]\n\n[Closing with personal accountability statement]\n\n[Signature]\n[Name, Title]\n```\n\n**Responsible**: MSP Program Lead drafts, CEO/COO reviews and signs\n**Time**: 2-3 days including review cycle\n\n---\n\n### Step 4: Document Board/Leadership Approval (Week 2-3)\n**Action**: Add sustainability strategy discussion to next leadership meeting agenda\n\n**Meeting Agenda Item:**\n- Present sustainability policy for approval\n- Record formal adoption in meeting minutes\n- Assign sustainability champion/owner\n\n**Evidence to Capture:**\n- Screenshot or excerpt of meeting minutes showing:\n  - Date of meeting\n  - Attendees (must include CxO)\n  - Motion to adopt sustainability policy\n  - Approval recorded\n\n**Responsible**: Executive Assistant + MSP Program Lead\n\n---\n\n### Step 5: Create Customer-Facing Sustainability Materials (Week 3)\n**Action**: Develop materials showing how sustainability is part of your MSP offering\n\n**Options (choose at least one):**\n- Website page on sustainability services\n- Customer presentation deck slide(s)\n- Service catalog entry for \"Sustainability Optimization\"\n- Case study showing customer carbon footprint reduction\n\n**Content to Include:**\n- AWS Carbon Footprint Tool reporting for customers\n- Graviton migration services\n- Right-sizing and optimization as sustainability benefit\n- Well-Architected Sustainability Pillar reviews\n\n**Tool**: AWS Partner Marketing Central for co-branded materials\n**Responsible**: Marketing + Technical Team\n\n---\n\n### Step 6: Compile and Format Evidence Package (Week 4)\n**Action**: Assemble all documents with clear naming and index\n\n**Package Contents:**\n1. Cover sheet with document index\n2. Sustainability Policy (signed/dated)\n3. CxO Commitment Letter (signed/dated)\n4. Leadership Meeting Minutes excerpt\n5. Customer-facing materials (screenshots or PDFs)\n\n**Quality Check**: Ensure all dates are within 12 months of audit\n**Responsible**: MSP Program Lead\n\n---\n\n### Step 7: Internal Review Before Submission (Week 4)\n**Action**: Have someone unfamiliar with the documents review for clarity\n\n**Review Questions:**\n- Can a stranger understand our sustainability commitment in 2 minutes?\n- Is executive ownership crystal clear?\n- Are AWS-specific actions mentioned?\n- Are goals specific and time-bound?\n\n**Responsible**: Quality/Compliance Team or peer MSP Program Lead\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic Environmental Statement Without Cloud Focus\n**Problem**: Submitting a general corporate environmental policy that mentions recycling and energy efficiency but nothing about cloud operations or AWS\n\n**Solution**: Explicitly reference AWS services, cloud workload optimization, and customer cloud sustainability in your policy\n\n**Example of What NOT to Submit:**\n> \"Our company is committed to reducing paper usage and recycling...\"\n\n**Example of What TO Submit:**\n> \"We commit to leveraging AWS's sustainability tools including the Customer Carbon Footprint Tool to measure and reduce the environmental impact of all managed cloud workloads...\"\n\n---\n\n### ❌ Mistake 2: Commitment Letter Signed by Non-Executive\n**Problem**: Having a VP of Operations, Director, or Sustainability Manager sign instead of a true C-level executive\n\n**Audit Failure Reason**: AWS specifically requires \"CxO office\" commitment to demonstrate organizational priority\n\n**Solution**: Must be CEO, COO, CFO, CTO, or Chief Sustainability Officer. If your company doesn't have traditional C-suite titles, use the equivalent highest-level executive with company-wide authority\n\n---\n\n### ❌ Mistake 3: Outdated Documents\n**Problem**: Submitting a sustainability policy dated 2+ years ago without evidence of recent review or reaffirmation\n\n**Audit Failure Reason**: Auditors question whether sustainability remains a current priority\n\n**Solution**: \n- Add \"Last Reviewed: [Date within 6 months]\" to policy footer\n- Include annual review clause in policy\n- Have executive re-sign or issue new commitment letter annually\n\n---\n\n### ❌ Mistake 4: No Measurable Goals or Timelines\n**Problem**: Vague commitments like \"we will work toward sustainability\" without specific targets\n\n**Audit Failure Reason**: Cannot verify genuine commitment without measurable outcomes\n\n**Solution**: Include at least 2-3 specific goals:\n- \"Conduct AWS Well-Architected Sustainability Pillar reviews for 100% of managed customers by Q4 2024\"\n- \"Achieve 30% Graviton adoption across managed workloads by 2025\"\n- \"Provide quarterly carbon footprint reports to all enterprise customers starting Q2 2024\"\n\n---\n\n### ❌ Mistake 5: No Connection to Customer Services\n**Problem**: Sustainability policy focuses only on internal operations (office energy, travel) without linking to MSP service delivery\n\n**Audit Failure Reason**: AWS wants to see that you're helping customers achieve sustainability, not just your own operations\n\n**Solution**: Dedicate a section of your policy to \"Customer Sustainability Services\" describing how you integrate sustainability into your MSP offerings\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ | Executive signature present on commitment letter | Visual inspection | CEO, COO, CFO, CTO, or CSO signature with title clearly stated |\n| ✅ | Document dates within 12 months | Check all document dates | Policy and commitment letter dated within 12 months of audit submission |\n| ✅ | AWS/cloud sustainability explicitly mentioned | Ctrl+F search for \"AWS\", \"cloud\", \"carbon footprint\" | At least 3 specific references to AWS services or cloud sustainability |\n| ✅ | Measurable goals with timelines included | Review goals section | Minimum 2 specific, time-bound sustainability targets |\n| ✅ | Customer service connection documented | Review policy scope section | Clear statement on how sustainability applies to MSP customer engagements |\n| ✅ | Governance/ownership defined | Check accountability section | Named role or individual responsible for sustainability program |\n| ✅ | Evidence package is complete and organized | Cross-reference against requirements | All 4 document types present with clear file naming |\n\n### 🎯 Quality Criteria Summary\n\n**Minimum Passing Standard:**\n- Signed policy document + CxO commitment letter\n- Both documents reference AWS cloud sustainability\n- At least one measurable goal with timeline\n- Evidence of leadership approval (meeting minutes or equivalent)\n\n**Strong Submission Includes:**\n- All above plus customer-facing sustainability materials\n- Multiple specific AWS service references (Carbon Footprint Tool, Graviton, Compute Optimizer)\n- Integration with Well-Architected Framework\n- Evidence of sustainability in actual customer engagements (anonymized examples)\n\n---\n\n### 💡 Pro Tip for Audit Success\n\nWhen the auditor reviews your sustainability evidence, they're asking one core question: **\"Is this company genuinely committed to sustainability as a business strategy, or is this just paperwork for the audit?\"**\n\nThe difference shows in specificity. Generic policies feel like checkbox exercises. Policies that mention specific AWS tools, specific customer outcomes, and specific timelines demonstrate authentic commitment. Spend extra time making your evidence specific to your actual business operations and AWS MSP services.",
      "language": "en",
      "createdAt": "2026-01-07T02:31:42.379Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-001",
      "category": "Operations",
      "title": "Service Level Management",
      "advice": "# OPS-001: Service Level Management - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nService Level Management is the **foundation of MSP business**. AWS wants to verify that partners are not just \"managing infrastructure\" but operating as **professional service providers with measurable commitments**. This requirement demonstrates that you have mature operational processes that differentiate you from basic resellers.\n\n### 🔍 Key Points Auditors Specifically Look For\n\n1. **Tiered SLA Structure**: Auditors expect to see differentiated response times based on severity levels (P1/P2/P3/P4) - a flat \"24-hour response\" for all issues is a red flag\n\n2. **AWS-Specific Metrics**: SLAs must include cloud-native KPIs like:\n   - CloudWatch alarm response time\n   - Auto-remediation success rate\n   - AWS Support case escalation timelines\n   - Infrastructure provisioning turnaround\n\n3. **Customer Review Cadence**: Evidence of **regular SLA performance reviews** with customers (monthly/quarterly) - not just the SLA document itself\n\n4. **Measurement Mechanism**: How you actually track SLA compliance (ITSM tool integration, dashboards, reporting)\n\n5. **Penalty/Credit Clauses**: Mature MSPs have service credits or remediation plans when SLAs are missed\n\n### Relevant AWS Services\n- **Amazon CloudWatch**: For defining measurable performance thresholds\n- **AWS Service Health Dashboard**: Integration for incident tracking\n- **AWS Support API**: For tracking support case metrics\n- **Amazon QuickSight**: For SLA performance dashboards\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Document Name Example | Format |\n|--------------|----------------------|--------|\n| SLA Master Document | `MSP_Service_Level_Agreement_v2.3.pdf` | PDF (signed) |\n| SLA Performance Report | `SLA_Performance_Report_Q3_2024.xlsx` | Excel/PDF |\n| Customer Review Meeting Minutes | `ABC_Corp_Monthly_Service_Review_Oct2024.pdf` | PDF |\n| SLA Dashboard Screenshot | `CloudWatch_SLA_Dashboard_Screenshot.png` | PNG/PDF |\n| Customer Sign-off Evidence | `SLA_Acceptance_Email_Chain.pdf` | PDF |\n\n### 📄 Key Content for Each Evidence\n\n**1. SLA Master Document Must Include:**\n```\n├── Service Scope Definition\n│   └── Specifically: \"AWS infrastructure managed under this agreement\"\n├── Severity Classification Matrix\n│   ├── P1: Production down (Response: 15 min, Resolution target: 4 hrs)\n│   ├── P2: Major degradation (Response: 30 min, Resolution target: 8 hrs)\n│   ├── P3: Minor impact (Response: 2 hrs, Resolution target: 24 hrs)\n│   └── P4: Information request (Response: 8 hrs, Resolution target: 72 hrs)\n├── Measurement Period & Reporting Frequency\n├── Exclusions (e.g., AWS regional outages, customer-caused issues)\n├── Service Credits/Remediation Process\n└── Review & Amendment Process\n```\n\n**2. SLA Performance Report Must Show:**\n- Actual vs. Target metrics for the reporting period\n- Ticket volume breakdown by severity\n- Mean Time to Respond (MTTR) and Mean Time to Resolve (MTTR)\n- Trend analysis (improving/degrading)\n- Root cause summary for any SLA breaches\n\n**3. Customer Review Evidence Must Demonstrate:**\n- Scheduled cadence (not ad-hoc)\n- Attendee list including customer stakeholders\n- Discussion of SLA performance data\n- Action items from previous reviews\n- Customer acknowledgment/signature\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Your Current SLA Framework (Week 1)\n**Action**: Export all existing customer contracts and extract SLA-related clauses\n- **Tool**: Use your CRM/Contract Management system\n- **Output**: Spreadsheet mapping each customer to their specific SLA terms\n- **Responsible**: Service Delivery Manager\n- **⚠️ Gap Check**: Identify customers without formal SLAs (these need immediate attention)\n\n### Step 2: Create Standardized SLA Template (Week 1-2)\n**Action**: Develop a tiered SLA template with AWS-specific metrics\n```\nTier 1 (Enterprise): 15/30/2hr/8hr response times\nTier 2 (Business): 30min/1hr/4hr/24hr response times  \nTier 3 (Standard): 1hr/4hr/8hr/48hr response times\n```\n- **Tool**: Reference AWS Support response time commitments as baseline\n- **Output**: `MSP_Standard_SLA_Template_v1.0.docx`\n- **Responsible**: Operations Lead + Legal Review\n\n### Step 3: Implement SLA Tracking Mechanism (Week 2-3)\n**Action**: Configure your ITSM tool to automatically track SLA metrics\n- **Tools**: \n  - ServiceNow/Jira Service Management/Freshservice\n  - Integration with CloudWatch for automated ticket creation\n- **Configuration Required**:\n  ```\n  - SLA clock start: When ticket is created\n  - SLA clock pause: Waiting for customer response\n  - SLA breach notification: 80% of target time\n  ```\n- **Output**: Working SLA tracking dashboard\n- **Responsible**: IT Operations + Tool Administrator\n\n### Step 4: Build SLA Performance Dashboard (Week 3)\n**Action**: Create visual dashboard showing real-time SLA compliance\n- **AWS Tools**: \n  - CloudWatch Dashboard for infrastructure metrics\n  - QuickSight for business SLA reporting\n- **Key Widgets**:\n  - Current month SLA compliance % (target: >95%)\n  - Tickets by severity pie chart\n  - Response time trend line\n  - Open tickets aging report\n- **Output**: `SLA_Performance_Dashboard` (shareable link + screenshot)\n- **Responsible**: BI/Reporting Team\n\n### Step 5: Conduct Customer SLA Review Meeting (Week 4)\n**Action**: Schedule and execute formal SLA review with at least 2-3 customers\n- **Agenda Template**:\n  ```\n  1. Previous period SLA performance summary (15 min)\n  2. Major incidents review (10 min)\n  3. Improvement initiatives update (10 min)\n  4. Customer feedback & concerns (15 min)\n  5. Next period focus areas (10 min)\n  ```\n- **Output**: Meeting minutes with customer sign-off\n- **Responsible**: Account Manager + Service Delivery Manager\n\n### Step 6: Document Review Process (Week 4)\n**Action**: Create formal documentation of your SLA review process\n- **Document Contents**:\n  - Review frequency (monthly operational, quarterly strategic)\n  - Stakeholders involved\n  - Escalation path for repeated SLA breaches\n  - SLA amendment process\n- **Output**: `SLA_Review_Process_Document.pdf`\n- **Responsible**: Process/Quality Manager\n\n### Step 7: Compile Evidence Package (Week 5)\n**Action**: Organize all evidence into audit-ready format\n- **Folder Structure**:\n  ```\n  OPS-001_Service_Level_Management/\n  ├── 01_SLA_Documentation/\n  │   ├── MSP_Master_SLA_Template.pdf\n  │   └── Customer_Specific_SLAs/\n  ├── 02_Performance_Reports/\n  │   ├── Monthly_SLA_Report_Sep2024.pdf\n  │   └── Monthly_SLA_Report_Oct2024.pdf\n  ├── 03_Customer_Reviews/\n  │   ├── ABC_Corp_Review_Minutes_Oct2024.pdf\n  │   └── XYZ_Inc_Review_Minutes_Oct2024.pdf\n  └── 04_Supporting_Evidence/\n      ├── Dashboard_Screenshots/\n      └── Process_Documentation/\n  ```\n- **Responsible**: MSP Program Lead\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic SLAs Without AWS Context\n**Problem**: Submitting SLA documents that could apply to any IT service, with no mention of AWS services\n**Solution**: Include specific references like:\n- \"Response to CloudWatch alarms triggering on EC2 instances\"\n- \"Turnaround time for AWS infrastructure change requests\"\n- \"Escalation to AWS Support for service-impacting issues\"\n\n### ❌ Mistake 2: No Evidence of Actual Measurement\n**Problem**: Having SLA documents but no proof you're actually tracking compliance\n**Audit Failure Reason**: Auditors specifically ask \"How do you know you're meeting these SLAs?\"\n**Solution**: Provide ITSM tool screenshots showing:\n- SLA timer configuration\n- Historical compliance reports\n- Breach notification examples\n\n### ❌ Mistake 3: Customer Reviews Without Structure\n**Problem**: Submitting informal email exchanges as \"review evidence\"\n**What Auditors Want**: Formal meeting minutes with:\n- Date, attendees, agenda\n- Specific SLA metrics discussed\n- Customer acknowledgment\n**Solution**: Use a standard meeting minutes template with customer signature line\n\n### ❌ Mistake 4: SLAs Not Aligned with Service Tiers\n**Problem**: Offering the same SLA to all customers regardless of service tier\n**Why It Fails**: Shows lack of mature service management\n**Solution**: Create differentiated SLA tiers (Platinum/Gold/Silver) with corresponding pricing\n\n### ❌ Mistake 5: Missing Exclusions and Dependencies\n**Problem**: SLAs that don't account for AWS-side issues\n**Risk**: Auditors question if you understand shared responsibility\n**Solution**: Include clear exclusions:\n- AWS regional/AZ outages\n- Customer-initiated changes causing issues\n- Third-party service dependencies\n- Force majeure events\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ | SLA document includes severity-based response times | Review SLA table | Minimum 3 severity levels with distinct targets |\n| ✅ | AWS-specific services/metrics mentioned | Ctrl+F search for \"AWS\", \"CloudWatch\", \"EC2\" | At least 3 AWS service references |\n| ✅ | SLA performance report covers recent period | Check report date | Within last 90 days |\n| ✅ | Report shows actual vs. target comparison | Review metrics section | Clear variance analysis included |\n| ✅ | Customer review meeting documented | Check meeting minutes | Contains date, attendees, SLA discussion, action items |\n| ✅ | Customer acknowledgment present | Look for signature/email confirmation | Written confirmation from customer stakeholder |\n| ✅ | Review process is documented | Check process document | Includes frequency, participants, escalation path |\n\n### 🎯 Quality Criteria for Passing\n\n**Minimum Threshold:**\n- At least 1 formal SLA document with AWS-specific content\n- At least 1 SLA performance report from last quarter\n- At least 1 documented customer review meeting\n\n**Strong Submission (Recommended):**\n- Standardized SLA template + 2-3 customer-specific examples\n- 3 months of SLA performance reports showing trends\n- 2+ customer review meetings with different clients\n- Live dashboard demonstration capability\n- Documented SLA breach remediation example (shows maturity)\n\n### 📌 Pre-Submission Sanity Check\nBefore submitting, ask yourself:\n1. \"If an auditor asks how we measure SLA compliance, can I show them a live system?\"\n2. \"Can I demonstrate that customers have actually seen and acknowledged these SLAs?\"\n3. \"Do our SLAs reflect that we're managing AWS infrastructure specifically?\"\n\nIf any answer is \"no,\" address that gap before submission.",
      "language": "en",
      "createdAt": "2026-01-07T03:12:16.217Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-002",
      "category": "Operations",
      "title": "AWS Support Plan for Partner owned Management and Member Account",
      "advice": "# OPS-002: AWS Support Plan for Partner owned Management and Member Account\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nThis requirement validates that MSP Partners can deliver enterprise-grade support to their managed customers. AWS requires MSPs to have appropriate support coverage because **you cannot provide 24/7 managed services to customers if you don't have 24/7 access to AWS technical support yourself**. This is foundational to the MSP value proposition—customers expect their MSP to resolve AWS issues faster than they could independently.\n\n### 🔍 Key Points Auditors Examine\n\n1. **100% Coverage Verification**: Auditors cross-reference your submitted account list against AWS Organizations data to ensure NO accounts are missing—especially newly created member accounts that may have been overlooked\n\n2. **Production Workload Classification**: They specifically look for member accounts running production workloads that might be on Developer or Basic support—this is an automatic fail condition\n\n3. **Management Account Support Level**: The payer/management account MUST have Business, Enterprise, or PLS support regardless of whether it runs workloads (it controls billing and organizational policies)\n\n4. **Support Plan Consistency**: Auditors check if support levels align with your stated SLA commitments to customers—Enterprise On-Ramp for customers with <15 min response time SLAs\n\n5. **PLS (Partner-Led Support) Documentation**: If using PLS, auditors verify you have the proper PLS agreement and understand that YOU are the first-line support\n\n### Relevant AWS Services & Features\n- **AWS Organizations** - For account structure visibility\n- **AWS Support Center** - For support plan verification\n- **AWS Support API** - `DescribeSeverityLevels` to programmatically verify support tier\n- **AWS Cost Explorer** - To identify accounts with production spending patterns\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Document | Format | Purpose |\n|----------|--------|---------|\n| **AWS Organizations Account Inventory** | Excel/CSV | Complete list of all Organizations, management accounts, and member accounts |\n| **Support Plan Screenshots** | PDF/PNG | Visual proof from AWS Support Center for each account |\n| **Consolidated Support Matrix** | Excel | Single document mapping accounts to support levels |\n\n### 📄 Key Content for Each Evidence\n\n**1. AWS Organizations Account Inventory**\n```\nRequired columns:\n- Organization ID (o-xxxxxxxxxx)\n- Organization Name/Alias\n- Management Account ID (12-digit)\n- Management Account Email\n- Member Account ID\n- Member Account Name\n- Account Purpose (Production/Non-Production/Sandbox)\n- Support Plan Level\n- Support Plan Verification Date\n```\n\n**2. Support Plan Screenshots**\nMust show:\n- Account ID visible in AWS Console header\n- Support Center page showing \"Your support plan: [Business/Enterprise/Enterprise On-Ramp]\"\n- Screenshot timestamp (use browser extension or system clock visible)\n\n**3. Consolidated Support Matrix**\n```\nExample filename: MSP_Support_Plan_Matrix_2024Q4.xlsx\n\nSheet 1: Summary\n- Total Organizations managed: X\n- Total Management Accounts: X  \n- Total Member Accounts: X\n- Accounts on Enterprise: X\n- Accounts on Business: X\n- Accounts on PLS: X\n- Accounts on Developer/Basic: 0 (must be zero for production)\n\nSheet 2: Detailed Account List\n[Full inventory with support levels]\n```\n\n### 📁 Evidence File Name Examples\n```\nOPS-002_Evidence/\n├── 01_Organizations_Inventory_20241115.xlsx\n├── 02_Support_Screenshots/\n│   ├── Org1_MgmtAcct_123456789012_Enterprise.png\n│   ├── Org1_Member_234567890123_Business.png\n│   └── Org2_MgmtAcct_345678901234_PLS.png\n├── 03_Support_Matrix_Consolidated.xlsx\n└── 04_PLS_Agreement_Copy.pdf (if applicable)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Export Complete Account Inventory (Day 1, 2-3 hours)\n**Owner**: Cloud Operations Lead\n\n```bash\n# Using AWS CLI with Organizations management account credentials\naws organizations list-accounts --output json > all_accounts.json\n\n# For each Organization you manage, run:\naws organizations describe-organization --output json > org_details.json\n```\n\n**Or use AWS Console**:\n- AWS Organizations → Accounts → Export account list (CSV)\n- Repeat for each Organization you manage as MSP\n\n### Step 2: Programmatically Verify Support Levels (Day 1-2, 3-4 hours)\n**Owner**: DevOps Engineer\n\n```python\n# Python script to check support level for each account\nimport boto3\n\ndef get_support_level(account_id, role_arn):\n    sts = boto3.client('sts')\n    credentials = sts.assume_role(\n        RoleArn=role_arn,\n        RoleSessionName='SupportCheck'\n    )['Credentials']\n    \n    support = boto3.client('support',\n        aws_access_key_id=credentials['AccessKeyId'],\n        aws_secret_access_key=credentials['SecretAccessKey'],\n        aws_session_token=credentials['SessionToken'],\n        region_name='us-east-1'  # Support API only in us-east-1\n    )\n    \n    try:\n        # If this succeeds, account has Business+ support\n        response = support.describe_severity_levels()\n        severity_count = len(response['severityLevels'])\n        if severity_count == 5:\n            return \"Enterprise\"\n        elif severity_count == 4:\n            return \"Business\"\n    except support.exceptions.SubscriptionRequiredException:\n        return \"Developer or Basic\"  # RED FLAG\n```\n\n### Step 3: Identify and Remediate Gaps (Day 2-3, Variable)\n**Owner**: Account Manager + Finance\n\nFor any accounts on Developer/Basic support:\n1. Determine if account runs production workloads\n2. If production → **Immediately upgrade to Business minimum**\n3. If truly non-production sandbox → Document justification\n\n**Upgrade via Console**:\nAWS Support Center → Change support plan → Select Business/Enterprise\n\n### Step 4: Capture Support Plan Screenshots (Day 3, 1-2 hours)\n**Owner**: Cloud Operations\n\nFor EACH account:\n1. Log into AWS Console with account credentials\n2. Navigate to Support Center (support.console.aws.amazon.com)\n3. Screenshot showing:\n   - Account ID in top-right corner\n   - Support plan name clearly visible\n4. Name file: `{OrgName}_{AccountType}_{AccountID}_{SupportLevel}.png`\n\n### Step 5: Build Consolidated Matrix (Day 4, 2-3 hours)\n**Owner**: MSP Program Lead\n\nCreate Excel workbook with:\n- **Tab 1**: Executive Summary with totals\n- **Tab 2**: Full account inventory with support levels\n- **Tab 3**: Screenshot reference index\n- **Tab 4**: PLS accounts (if any) with agreement reference\n\n### Step 6: Cross-Validate Against AWS Organizations (Day 4, 1 hour)\n**Owner**: Cloud Operations Lead\n\n```bash\n# Re-run account list to catch any new accounts created during prep\naws organizations list-accounts --query 'Accounts[*].Id' --output text | wc -w\n```\nCompare count against your matrix—numbers MUST match.\n\n### Step 7: Document PLS Arrangements (If Applicable) (Day 5, 1-2 hours)\n**Owner**: Partner Manager\n\nIf using Partner-Led Support:\n- Include copy of PLS agreement with AWS\n- Document which accounts are covered under PLS\n- Note that PLS means YOU provide Tier 1 support\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Missing Newly Created Member Accounts\n**What happens**: A member account was created 2 weeks ago for a new customer project. It defaults to Basic support and wasn't added to your tracking.\n\n**Solution**: \n- Set up AWS Config rule or EventBridge rule to alert on `CreateAccount` events\n- Run account inventory script weekly during audit prep\n- Add support plan upgrade to your new account provisioning runbook\n\n### ❌ Mistake 2: Confusing Enterprise On-Ramp with Enterprise\n**What happens**: Partner lists \"Enterprise\" but screenshots show \"Enterprise On-Ramp\"—auditor questions accuracy.\n\n**Solution**: Be precise in your matrix:\n- Enterprise (TAM included, <15 min critical response)\n- Enterprise On-Ramp (no TAM, <30 min critical response)  \n- Business (no TAM, <1 hour critical response)\n\n### ❌ Mistake 3: Assuming Linked Accounts Inherit Support Plan\n**What happens**: Partner thinks member accounts automatically get management account's support level.\n\n**Reality**: **Each account needs its own support subscription** unless:\n- Using consolidated billing AND\n- Management account has Enterprise/Business AND\n- Member accounts are explicitly covered\n\n**Verification**: Check each member account individually in Support Center\n\n### ❌ Mistake 4: Not Including Customer-Owned Accounts Under Management\n**What happens**: Partner only lists their own AWS accounts, not customer accounts they manage under MSP agreement.\n\n**Clarification for OPS-002**: This requirement is specifically for **Partner-OWNED** accounts. However, auditors may ask about customer accounts separately. Keep a separate inventory for customer-managed accounts.\n\n### ❌ Mistake 5: Screenshots Without Visible Account ID\n**What happens**: Screenshots show support plan but account ID is cropped out—auditor cannot verify which account.\n\n**Solution**: Always capture full browser window showing:\n- Account ID/alias in navigation bar\n- Support Center page with plan details\n- Timestamp visible (browser tab or system clock)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ | **All Organizations listed** | Compare against AWS Partner Central organization list | 100% of managed Organizations included |\n| ✅ | **All management accounts have Business+ support** | Screenshot of each management account's Support Center | No management account on Developer/Basic |\n| ✅ | **All production member accounts have Business+ support** | Cross-reference account purpose with support level | Zero production accounts on Developer/Basic |\n| ✅ | **Account count matches AWS Organizations** | Run `aws organizations list-accounts` and count | Matrix count = AWS count (exact match) |\n| ✅ | **Screenshots clearly show account ID AND support level** | Visual inspection of each screenshot | Both elements visible in single screenshot |\n| ✅ | **Matrix includes all required columns** | Compare against required columns list above | No missing data fields |\n| ✅ | **PLS documentation included (if applicable)** | Check for PLS agreement copy | Agreement present if any accounts use PLS |\n\n### 🎯 Quality Criteria for Passing\n\n**Minimum Bar**:\n- Every Partner-owned management account: Business, Enterprise, or PLS\n- Every Partner-owned member account with production workloads: Business, Enterprise, or PLS\n- Evidence clearly maps accounts to support levels with visual proof\n\n**Excellence Indicators** (makes audit smoother):\n- Automated script output showing support level verification\n- Clear categorization of production vs. non-production accounts\n- Documented process for maintaining support coverage on new accounts\n\n### 📊 Quick Self-Assessment\nBefore submitting, answer these questions:\n1. If auditor picks any random account from your list, can you show its support level in <30 seconds? \n2. Is there any account in your Organizations that isn't in your matrix?\n3. Are all 12-digit account IDs accurate (no typos)?\n4. Do screenshot filenames match the accounts they represent?\n\nIf any answer is \"no\" or \"unsure\"—go back and fix before submission.",
      "language": "en",
      "createdAt": "2026-01-07T03:13:12.313Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-003",
      "category": "Operations",
      "title": "AWS Support Plan for Customer owned Member Account",
      "advice": "# OPS-003: AWS Support Plan for Customer owned Member Account - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in the AWS MSP Program\nThis requirement validates that MSP Partners actively protect customer production environments. AWS Premium Support (Business/Enterprise) provides 24/7 technical support, AWS Trusted Advisor full checks, and Infrastructure Event Management - all critical for production stability. MSPs must demonstrate they're not just managing accounts but actively advocating for appropriate support coverage.\n\n### 🔍 Key Points Auditors Examine\n\n1. **Complete Account Inventory with Support Levels**: Auditors verify you maintain a real-time view of ALL managed customer accounts and their exact AWS Support tier (Basic, Developer, Business, Enterprise, Enterprise On-Ramp)\n\n2. **Production vs. Non-Production Classification**: They check if you've properly identified which accounts host production workloads - a Business Support recommendation for a dev/test account shows poor judgment\n\n3. **Proactive Communication Evidence**: Auditors specifically look for OUTBOUND communications where YOU initiated the support upgrade conversation, not just responses to customer inquiries\n\n4. **Customer Response Tracking**: Evidence that you followed up on recommendations and documented customer decisions (even if they declined)\n\n5. **Value Articulation Quality**: Communications must explain WHY Business/Enterprise support matters (response times, Trusted Advisor, TAM access) - not just \"you should upgrade\"\n\n### Relevant AWS Services & Features\n- **AWS Support Center** - Support plan verification\n- **AWS Organizations** - Account inventory management\n- **AWS Trusted Advisor** - Demonstrates Business/Enterprise value\n- **AWS Health Dashboard** - Premium support feature showcase\n- **AWS Support API** - Programmatic support level verification\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Purpose |\n|--------------|--------|---------|\n| Customer Account Support Matrix | Excel/CSV | Complete inventory with support levels |\n| Support Upgrade Communications | PDF/Email exports | Proof of proactive recommendations |\n| Support Plan Verification Screenshots | PNG/PDF | AWS Console evidence of current levels |\n| Customer Acknowledgment Records | Email/Ticket exports | Documented customer responses |\n\n### 📄 Evidence #1: Customer Account Support Matrix\n\n**File Name Example**: `OPS-003_Customer_Support_Matrix_2024Q4.xlsx`\n\n**Required Columns**:\n```\n| Customer Name | Account ID (12-digit) | Account Alias | Environment Type | Current Support Plan | Production Workload? | Recommendation Status | Last Communication Date | Customer Decision |\n```\n\n**Critical Content**:\n- Every managed account must be listed (no exceptions)\n- Environment Type: Production, Staging, Development, Sandbox\n- Support Plan must match exactly: Basic, Developer, Business, Enterprise, Enterprise On-Ramp\n- Recommendation Status: \"Compliant\", \"Recommendation Sent\", \"Upgrade In Progress\", \"Customer Declined (Documented)\"\n\n### 📄 Evidence #2: Support Recommendation Communications\n\n**File Name Examples**:\n- `OPS-003_Acme_Corp_Support_Upgrade_Recommendation_20241015.pdf`\n- `OPS-003_TechStart_Inc_Business_Support_Discussion_20241102.pdf`\n\n**Required Content in Each Communication**:\n```\n✓ Specific account ID(s) referenced\n✓ Current support level stated\n✓ Recommended support level with justification\n✓ Specific benefits for THEIR workload (not generic list)\n✓ Response time comparison (15min vs 24hr for critical)\n✓ Cost estimate or pricing discussion mention\n✓ Clear call-to-action with deadline/next steps\n```\n\n### 📄 Evidence #3: AWS Console Verification Screenshots\n\n**File Name Example**: `OPS-003_AccountID_123456789012_Support_Verification.png`\n\n**Screenshot Requirements**:\n- AWS Support Center showing current plan\n- Account ID visible in screenshot\n- Timestamp visible (browser date/time or AWS console timestamp)\n- Full page capture, not cropped\n\n### 📄 Evidence #4: Customer Response Documentation\n\n**File Name Example**: `OPS-003_Customer_Decisions_Log_2024.xlsx`\n\n**Required Fields**:\n```\n| Customer | Account ID | Recommendation Date | Response Date | Decision | Reason (if declined) | Follow-up Scheduled |\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Extract Complete Account Inventory (Day 1-2)\n**Action**: Pull all managed accounts from AWS Organizations\n\n```bash\n# Using AWS CLI with Organizations master account\naws organizations list-accounts --query 'Accounts[*].[Id,Name,Email,Status]' --output table\n```\n\n**Alternative**: Use AWS Control Tower Account Factory report if applicable\n\n**Tool**: AWS Organizations Console → Accounts → Export to CSV\n**Responsible**: Cloud Operations Lead\n**Time**: 2-4 hours\n\n---\n\n### Step 2: Verify Support Levels Per Account (Day 2-3)\n**Action**: Check each account's support plan via AWS Support API\n\n```bash\n# For each account (requires assume role)\naws support describe-severity-levels --region us-east-1\n# If this returns data, account has Business+ support\n# If AccessDeniedException, account has Basic/Developer\n```\n\n**Manual Method**: \n1. Sign into each account\n2. Navigate to Support Center\n3. Click \"Account\" → View current plan\n4. Screenshot with timestamp\n\n**Tool**: AWS Support API or Console\n**Responsible**: Technical Account Manager\n**Time**: 30 min per account (batch with scripts)\n\n---\n\n### Step 3: Classify Production vs. Non-Production (Day 3-4)\n**Action**: Document workload classification for each account\n\n**Classification Criteria**:\n- Contains customer-facing applications → Production\n- Processes real customer data → Production\n- Has SLA commitments → Production\n- Connected to production databases → Production\n- Used only for testing/development → Non-Production\n\n**Tool**: Internal CMDB, AWS Resource Groups, Tagging strategy review\n**Responsible**: Service Delivery Manager + Customer Success\n**Time**: 4-6 hours\n\n---\n\n### Step 4: Identify Gaps and Draft Communications (Day 4-5)\n**Action**: Create personalized upgrade recommendations\n\n**Template Structure** (customize per customer):\n```\nSubject: AWS Support Recommendation for [Account Name] - Production Environment\n\nDear [Customer Contact],\n\nDuring our regular account review, we identified that your production account \n[Account ID: XXXXXXXXXXXX] currently has [Basic/Developer] AWS Support.\n\nFor production workloads like your [specific workload - e.g., \"e-commerce platform\"], \nwe strongly recommend AWS Business Support because:\n\n1. **Response Time**: Critical issues get 15-minute response vs. 24+ hours\n2. **Trusted Advisor**: Full access to 115+ checks (currently limited to 7)\n3. **24/7 Access**: Phone/chat support around the clock\n4. **Infrastructure Event Management**: Included support for launches/migrations\n\nEstimated monthly cost: ~$XXX (3% of monthly AWS spend, minimum $100)\n\nWe'd like to schedule a 15-minute call to discuss this recommendation.\nAvailable times: [specific slots]\n\nBest regards,\n[Your Name]\n```\n\n**Tool**: Email client, CRM system (Salesforce, HubSpot)\n**Responsible**: Customer Success Manager\n**Time**: 30-45 min per customer communication\n\n---\n\n### Step 5: Send Communications and Track Responses (Day 5-7)\n**Action**: Send recommendations and log in tracking system\n\n**Tracking Requirements**:\n- Date sent\n- Delivery confirmation\n- Response received (Y/N)\n- Response date\n- Customer decision\n- Follow-up actions\n\n**Tool**: CRM with email tracking, or dedicated spreadsheet\n**Responsible**: Customer Success Manager\n**Time**: Ongoing\n\n---\n\n### Step 6: Document Customer Decisions (Day 7-10)\n**Action**: Record all responses including declines\n\n**For Declined Recommendations**:\n```\nCustomer: Acme Corp\nAccount: 123456789012\nDecision: Declined Business Support upgrade\nReason: \"Budget constraints for Q4, will revisit Q1 2025\"\nDocumented: Email dated 2024-10-20\nFollow-up: Scheduled for January 15, 2025\nMSP Action: Documented risk acceptance, increased monitoring frequency\n```\n\n**Tool**: CRM, Ticketing system (ServiceNow, Jira Service Management)\n**Responsible**: Service Delivery Manager\n**Time**: 2-3 hours total\n\n---\n\n### Step 7: Compile Final Evidence Package (Day 10-12)\n**Action**: Organize all evidence with clear naming convention\n\n**Folder Structure**:\n```\nOPS-003_Evidence/\n├── 01_Customer_Support_Matrix.xlsx\n├── 02_Communications/\n│   ├── Acme_Corp_Recommendation_20241015.pdf\n│   ├── TechStart_Support_Discussion_20241020.pdf\n│   └── GlobalTech_Upgrade_Confirmation_20241025.pdf\n├── 03_Console_Screenshots/\n│   ├── Account_123456789012_Support_Level.png\n│   └── Account_234567890123_Support_Level.png\n├── 04_Customer_Decisions_Log.xlsx\n└── 05_Summary_Report.pdf\n```\n\n**Tool**: File management system, SharePoint, or evidence management platform\n**Responsible**: MSP Program Lead\n**Time**: 3-4 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake #1: Missing Accounts in Inventory\n**Problem**: Auditors cross-reference your list with AWS Organizations data. Missing even one account raises red flags.\n\n**Solution**: Use AWS Organizations API to pull complete list, then reconcile with your CMDB. Run this monthly:\n```bash\naws organizations list-accounts --output json > all_accounts_$(date +%Y%m%d).json\n```\n\n---\n\n### ❌ Mistake #2: Generic \"Form Letter\" Communications\n**Problem**: Sending identical templated emails to all customers without personalization fails the audit.\n\n**What Auditors Reject**:\n```\n\"Dear Customer, AWS recommends Business Support for production accounts...\"\n```\n\n**What Auditors Accept**:\n```\n\"Dear Sarah, Your payment processing application in account 123456789012 \ncurrently runs on Basic Support. Given your PCI compliance requirements \nand 99.9% SLA commitment, Business Support's 15-minute response time \nfor critical issues is essential...\"\n```\n\n---\n\n### ❌ Mistake #3: No Evidence of Customer Responses\n**Problem**: Showing you sent recommendations but not tracking responses suggests you don't follow through.\n\n**Solution**: Create a closed-loop process:\n1. Send recommendation\n2. Log in CRM with expected response date\n3. Follow up if no response in 7 days\n4. Document final decision (including \"no response after 3 attempts\")\n\n---\n\n### ❌ Mistake #4: Recommending Business Support for Dev/Test Accounts\n**Problem**: Blanket recommendations for ALL accounts shows poor judgment and wastes customer money.\n\n**Solution**: Only recommend Business/Enterprise for:\n- Accounts with production workloads\n- Accounts with compliance requirements\n- Accounts with SLA commitments\n\nDocument WHY non-production accounts don't need upgrade.\n\n---\n\n### ❌ Mistake #5: Outdated Support Level Information\n**Problem**: Your matrix shows \"Basic\" but customer upgraded 3 months ago. Auditors verify against live AWS data.\n\n**Solution**: Implement monthly verification process:\n- Script to check support levels via API\n- Calendar reminder for manual verification\n- Customer notification process for support changes\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ 1 | All managed accounts listed | Compare matrix against AWS Organizations export | 100% match, zero missing accounts |\n| ✅ 2 | Support levels accurate | Spot-check 20% of accounts via AWS Console | All verified accounts match matrix |\n| ✅ 3 | Production accounts identified | Review classification with customer records | Clear Production/Non-Prod designation for each |\n| ✅ 4 | Communications sent for all gaps | Cross-reference gaps with communication log | Every Basic/Developer production account has outreach |\n| ✅ 5 | Communications are personalized | Read each communication for customer-specific content | Account ID, workload name, specific benefits mentioned |\n| ✅ 6 | Customer responses documented | Check decision log completeness | Every communication has response status (even \"no response\") |\n| ✅ 7 | Screenshots are current | Check timestamps on all screenshots | All within 30 days of submission |\n\n### Quality Criteria Checklist\n\n**Matrix Quality**:\n- [ ] Account IDs are 12 digits, properly formatted\n- [ ] No duplicate entries\n- [ ] Environment type filled for every row\n- [ ] Support plan matches AWS naming exactly\n\n**Communication Quality**:\n- [ ] Customer name and account ID in each communication\n- [ ] Specific workload/application mentioned\n- [ ] Clear recommendation with reasoning\n- [ ] Cost information included\n- [ ] Call-to-action with timeline\n\n**Documentation Quality**:\n- [ ] File naming convention consistent\n- [ ] All PDFs are searchable (not scanned images)\n- [ ] Screenshots show full context (not cropped)\n- [ ] Dates visible on all evidence\n\n### 🎯 Final Validation Questions\n\n1. \"If an auditor picks any account from our matrix, can we show the communication we sent?\" → Must be YES\n2. \"Can we explain why each non-production account doesn't need Business Support?\" → Must have documented reasoning\n3. \"For customers who declined, do we have their response in writing?\" → Must have email/ticket evidence\n4. \"Is our support level data current as of this month?\" → Must be within 30 days\n\n---\n\n## 📌 Pro Tips from Passed Audits\n\n💡 **Tip 1**: Include a \"Support Plan Value Summary\" one-pager that you share with customers - auditors love seeing standardized educational materials\n\n💡 **Tip 2**: If a customer declines, document that you explained the risks and they accepted them - this shows due diligence even when customers don't follow recommendations\n\n💡 **Tip 3**: Show trending data - \"6 months ago, 40% of production accounts had Business Support, now it's 85%\" demonstrates continuous improvement\n\n💡 **Tip 4**: Include at least one example of a customer who upgraded BECAUSE of your recommendation - this proves your process works",
      "language": "en",
      "createdAt": "2026-01-07T03:14:15.847Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-004_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-004",
      "category": "Operations",
      "title": "Service Desk Operations",
      "advice": "# OPS-004: Service Desk Operations - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nService Desk Operations is the **frontline touchpoint** between MSP and customer for all AWS-related incidents and requests. AWS views this as fundamental proof that partners can provide enterprise-grade managed services. Unlike internal IT support, MSP service desks must demonstrate **multi-tenant capability** while maintaining service quality across diverse AWS workloads.\n\n### 🎯 Key Points Auditors Specifically Look For\n\n1. **24x7 Coverage Model Clarity**: Auditors want to see exactly HOW you achieve 24x7 - whether it's follow-the-sun staffing, on-call rotation, or hybrid model. Vague statements like \"we provide 24x7 support\" without operational details will be questioned.\n\n2. **Multiple Communication Channels with AWS Context**: Not just phone/email, but channels appropriate for cloud operations - ticketing systems integrated with AWS, chat platforms that can receive CloudWatch alerts, etc.\n\n3. **Escalation Path to AWS Support**: Your service desk must show clear integration with AWS Support (Business/Enterprise) - how tickets escalate from your desk to AWS when needed.\n\n4. **Customer Agreement Specificity**: The SLA document must explicitly state service desk hours, response times for different severity levels, and communication methods - not buried in general terms.\n\n5. **Evidence of Actual Operation**: Auditors may ask for ticket samples or metrics showing the service desk actually operates as documented.\n\n### Relevant AWS Services & Features\n- **AWS Support API** - for programmatic case creation/tracking\n- **Amazon Connect** - cloud-based contact center (strong evidence if used)\n- **AWS Service Catalog** - for standardized service request fulfillment\n- **Amazon CloudWatch** - alert integration with service desk\n- **AWS Health Dashboard** - proactive notification integration\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Document Type | Specific Content Required | Example File Names |\n|---------------|---------------------------|-------------------|\n| **Master Service Agreement (MSA)** | Service desk clause with 24x7 commitment | `MSA_CustomerName_2024_ServiceDesk_Section.pdf` |\n| **Service Level Agreement (SLA)** | Response/resolution times by severity, coverage hours, channels | `SLA_AWSManagedServices_v2.3.pdf` |\n| **Service Desk Operations Manual** | Staffing model, shift schedules, escalation matrix | `ServiceDesk_OperationsManual_24x7.pdf` |\n| **Customer Communication** | Email/signed acknowledgment of service desk terms | `CustomerAcknowledgment_ServiceDesk_Terms.pdf` |\n\n### 📄 Key Content That MUST Be Included\n\n**In the Customer Agreement/SLA:**\n```\nRequired Elements:\n├── Service Desk Availability: \"24 hours x 7 days x 365 days\"\n├── Coverage Model: \"Staffed call center 8AM-6PM JST + After-hours on-call\"\n├── Communication Channels:\n│   ├── Phone: +81-3-XXXX-XXXX\n│   ├── Email: support@yourmsp.com\n│   ├── Portal: https://support.yourmsp.com\n│   └── Chat: Slack/Teams integration available\n├── Response Time Matrix:\n│   ├── P1 (Critical): 15 minutes response, 4 hours resolution target\n│   ├── P2 (High): 30 minutes response, 8 hours resolution target\n│   ├── P3 (Medium): 2 hours response, 24 hours resolution target\n│   └── P4 (Low): 8 hours response, 72 hours resolution target\n└── AWS Escalation: \"Direct escalation to AWS Enterprise Support when required\"\n```\n\n**Evidence Examples That Passed Audits:**\n- `ServiceDesk_SLA_Exhibit_A_CustomerXYZ_Signed_2024.pdf`\n- `OnCall_Rotation_Schedule_Q1_2024.xlsx`\n- `ServiceNow_Integration_Architecture_AWS.pdf`\n- `After_Hours_Escalation_Procedure_v1.2.pdf`\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Document Your Actual Coverage Model (2-3 days)\n**What to do:** Create a detailed diagram showing exactly how 24x7 is achieved\n\n```\nExample Coverage Model Documentation:\n┌─────────────────────────────────────────────────────────────┐\n│ Business Hours (8:00-18:00 JST)                             │\n│ → Staffed Service Desk (3 L1 engineers, 1 L2 engineer)      │\n│ → All channels active (Phone, Email, Portal, Chat)          │\n├─────────────────────────────────────────────────────────────┤\n│ After Hours (18:00-8:00 JST + Weekends)                     │\n│ → On-call rotation (2 engineers, 1 primary + 1 backup)      │\n│ → Phone + PagerDuty alerts only                             │\n│ → P1/P2 incidents only (P3/P4 queued for business hours)    │\n└─────────────────────────────────────────────────────────────┘\n```\n\n**Tool:** Use Lucidchart or draw.io for visual documentation\n**Responsible:** Service Delivery Manager\n\n### Step 2: Create/Update Customer Agreement Language (3-5 days)\n**What to do:** Draft specific service desk clause for MSA/SLA\n\n```\nSample Clause Language:\n\"Provider shall maintain a Service Desk available to Customer \ntwenty-four (24) hours per day, seven (7) days per week, \nthree hundred sixty-five (365) days per year via:\n(a) Telephone at [number]\n(b) Email at [address]  \n(c) Web portal at [URL]\n(d) Integrated chat via [platform]\n\nDuring Business Hours (defined as 08:00-18:00 JST, Monday-Friday, \nexcluding Japanese national holidays), the Service Desk shall be \nstaffed by qualified personnel. Outside Business Hours, support \nshall be provided via on-call personnel reachable within fifteen \n(15) minutes for Priority 1 and Priority 2 incidents.\"\n```\n\n**Responsible:** Legal + Service Delivery Manager\n**Tool:** Contract management system (DocuSign, Adobe Sign)\n\n### Step 3: Implement Ticketing System Integration (1-2 weeks)\n**What to do:** Configure ITSM tool with AWS integration\n\n**ServiceNow Example Configuration:**\n- Install AWS Service Management Connector\n- Configure bi-directional sync with AWS Support cases\n- Set up auto-ticket creation from CloudWatch alarms\n- Create AWS-specific incident categories\n\n**Jira Service Management Alternative:**\n- Configure Opsgenie integration for on-call management\n- Set up AWS CloudWatch → Jira automation\n- Create SLA timers matching your agreement\n\n**Responsible:** Platform Engineering Team\n\n### Step 4: Establish On-Call Rotation System (1 week)\n**What to do:** Implement formal after-hours coverage\n\n```\nPagerDuty/Opsgenie Configuration:\n├── Create \"AWS MSP On-Call\" schedule\n├── Define escalation policy:\n│   ├── Level 1: Primary on-call (5 min timeout)\n│   ├── Level 2: Secondary on-call (10 min timeout)\n│   └── Level 3: Service Delivery Manager (15 min timeout)\n├── Integrate with:\n│   ├── CloudWatch Alarms (via SNS)\n│   ├── AWS Health events\n│   └── Customer direct calls (via phone integration)\n└── Generate monthly on-call reports for evidence\n```\n\n**Responsible:** Operations Manager\n\n### Step 5: Obtain Customer Sign-off (1-2 weeks)\n**What to do:** Get documented customer acknowledgment\n\n**Options for Evidence:**\n1. **Signed SLA Amendment** - Best evidence (wet signature or DocuSign)\n2. **Email Acknowledgment** - Customer email confirming service desk terms\n3. **Portal Acceptance** - Screenshot of customer accepting terms in your portal\n4. **Meeting Minutes** - Documented service review meeting with customer sign-off\n\n**Responsible:** Account Manager + Customer Success\n\n### Step 6: Generate Operational Evidence (Ongoing)\n**What to do:** Prepare proof that service desk actually operates\n\n```\nEvidence Package:\n├── Ticket volume report (last 3 months)\n├── Response time metrics vs SLA\n├── After-hours incident samples (redacted)\n├── On-call rotation schedule (actual, not template)\n└── Customer satisfaction scores\n```\n\n**Tool:** ITSM reporting, Power BI/Tableau dashboards\n**Responsible:** Service Desk Manager\n\n### Step 7: Create Auditor-Ready Documentation Package (2-3 days)\n**What to do:** Compile all evidence in audit-friendly format\n\n```\nFolder Structure:\nOPS-004_ServiceDesk_Evidence/\n├── 01_Customer_Agreement/\n│   ├── MSA_CustomerA_Signed.pdf\n│   └── SLA_Exhibit_ServiceDesk.pdf\n├── 02_Operations_Documentation/\n│   ├── ServiceDesk_Procedures.pdf\n│   └── OnCall_Policy.pdf\n├── 03_System_Configuration/\n│   ├── ServiceNow_AWS_Integration.pdf\n│   └── PagerDuty_Schedule_Screenshot.png\n└── 04_Operational_Metrics/\n    ├── Ticket_Report_Q4_2024.pdf\n    └── SLA_Compliance_Dashboard.pdf\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: \"24x7\" Without Defining After-Hours Model\n**Problem:** Agreement says \"24x7 support\" but doesn't explain what happens at 3 AM on Sunday.\n\n**Auditor Question:** \"Show me how a P1 incident at 2 AM gets handled.\"\n\n**Solution:** Explicitly document:\n- Who is on-call (by name/role)\n- How they are contacted (PagerDuty, phone tree)\n- Response time commitment for after-hours\n- What severity levels are handled vs. queued\n\n### ❌ Mistake 2: Generic SLA Without AWS Context\n**Problem:** Using standard IT SLA template that doesn't mention AWS services.\n\n**Auditor Concern:** \"This looks like a generic IT support agreement, not AWS managed services.\"\n\n**Solution:** Include AWS-specific elements:\n- \"Support for AWS infrastructure incidents including EC2, RDS, Lambda...\"\n- \"Escalation to AWS Support (Enterprise/Business tier) when required\"\n- \"CloudWatch alarm response procedures\"\n\n### ❌ Mistake 3: No Evidence of Multiple Communication Channels\n**Problem:** Agreement mentions phone/email/portal but no proof they exist.\n\n**Auditor Request:** \"Show me the actual support portal and phone system.\"\n\n**Solution:** Prepare screenshots/documentation:\n- Support portal login page with customer branding\n- Phone system configuration (Amazon Connect dashboard, PBX config)\n- Email routing rules to ticketing system\n- Chat integration setup (Slack Connect, Teams)\n\n### ❌ Mistake 4: Customer Agreement Buried in Legal Jargon\n**Problem:** Service desk terms exist but are scattered across 50-page MSA.\n\n**Auditor Frustration:** \"I can't find where it says 24x7 service desk.\"\n\n**Solution:** Create clear exhibit/schedule specifically for service desk:\n- \"Schedule B: Service Desk and Support Services\"\n- Use tables for response times, not paragraphs\n- Include visual coverage model diagram\n\n### ❌ Mistake 5: No Proof of Actual Operation\n**Problem:** Beautiful documentation but no evidence service desk actually runs.\n\n**Auditor Question:** \"Show me tickets from the last month with timestamps.\"\n\n**Solution:** Prepare operational evidence:\n- Sample tickets (redacted) showing after-hours responses\n- On-call incident log with response times\n- Monthly service desk metrics report\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ 1 | Customer agreement explicitly states \"24x7\" or \"24 hours, 7 days\" | Search document for exact phrase | Exact wording present, not implied |\n| ✅ 2 | Multiple communication channels listed with actual contact info | Verify each channel is operational | Minimum 3 channels (phone, email, portal) documented AND working |\n| ✅ 3 | Response time matrix included for different severity levels | Check SLA table exists | P1-P4 (or equivalent) with specific time commitments |\n| ✅ 4 | After-hours coverage model documented | Review operations manual | Clear explanation of staffed vs. on-call hours |\n| ✅ 5 | Customer signature or acknowledgment present | Check for signature/email confirmation | Dated within last 12 months, authorized signer |\n| ✅ 6 | AWS escalation path mentioned | Search for \"AWS Support\" reference | Clear statement about escalation to AWS |\n| ✅ 7 | Operational evidence supports documentation | Compare metrics to SLA commitments | Actual performance meets documented SLA |\n\n### 🎯 Quality Criteria for Passing\n\n**Documentation Quality:**\n- [ ] Service desk terms are in dedicated section/exhibit (not buried)\n- [ ] Language is specific (numbers, hours, channels) not vague\n- [ ] Document is customer-specific (not generic template)\n\n**Operational Alignment:**\n- [ ] Documented hours match actual staffing/on-call schedule\n- [ ] Ticketing system configured to track SLA compliance\n- [ ] After-hours process has been tested/used\n\n**AWS Integration:**\n- [ ] Service desk can create AWS Support cases\n- [ ] CloudWatch alarms route to service desk\n- [ ] Staff trained on AWS services covered\n\n### 📞 Auditor Simulation Questions\n\nPrepare answers for these likely questions:\n1. \"Walk me through what happens when a customer calls at 11 PM with a production outage.\"\n2. \"How does your service desk interact with AWS Support?\"\n3. \"Show me your on-call schedule for last month.\"\n4. \"What's your average response time for P1 incidents?\"\n5. \"How do customers access your support portal?\"\n\n---\n\n## 💡 Pro Tips for OPS-004\n\n1. **Use Amazon Connect** if possible - auditors recognize it as AWS-native solution and it demonstrates AWS competency\n\n2. **Include service desk in customer QBRs** - meeting minutes showing service desk metrics review serves as ongoing evidence\n\n3. **Prepare a \"day in the life\" document** - showing actual ticket flow from customer contact to resolution impresses auditors\n\n4. **If using third-party NOC**, ensure your agreement with them is also documented and covers AWS workloads specifically",
      "language": "en",
      "createdAt": "2026-01-07T03:15:22.345Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-005_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-005",
      "category": "Operations",
      "title": "Implement a Comprehensive ITSM platform",
      "advice": "# OPS-005: Implement a Comprehensive ITSM Platform - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\nITSM 플랫폼은 AWS MSP 운영의 **중추 신경계** 역할을 합니다. AWS는 MSP 파트너가 고객의 클라우드 환경을 체계적으로 관리할 수 있는 성숙한 운영 체계를 갖추고 있는지 이 항목을 통해 검증합니다. 단순히 ITSM 도구를 보유하는 것이 아니라, **AWS 환경과 실질적으로 통합되어 운영되고 있는지**가 핵심입니다.\n\n### 🔍 심사관이 중점적으로 확인하는 5가지 포인트\n\n| 확인 포인트 | 심사관의 질문 예시 |\n|------------|-------------------|\n| **AWS 서비스와의 실제 연동** | \"CloudWatch 알람이 발생하면 ITSM에 어떻게 티켓이 생성되나요?\" |\n| **End-to-End 워크플로우 존재** | \"EC2 인스턴스 추가 요청부터 완료까지 전체 흐름을 보여주세요\" |\n| **변경 관리와 AWS 작업 연계** | \"AWS 콘솔 변경 작업 전 Change Ticket 승인 프로세스가 있나요?\" |\n| **SLA 기반 에스컬레이션** | \"P1 인시던트 발생 시 15분 내 대응 기록을 보여주세요\" |\n| **자동화 수준** | \"수동 개입 없이 자동으로 처리되는 요청 유형은 무엇인가요?\" |\n\n### 관련 AWS 서비스 및 통합 포인트\n- **Amazon CloudWatch** → 인시던트 자동 생성 트리거\n- **AWS Systems Manager OpsCenter** → OpsItems와 ITSM 동기화\n- **AWS Service Catalog** → 서비스 요청 자동화\n- **AWS Config** → 변경 관리 컴플라이언스 추적\n- **Amazon EventBridge** → ITSM 이벤트 라우팅\n- **AWS CloudTrail** → 변경 이력 감사 로그\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 필수 증거 목록 및 구체적 내용\n\n#### Evidence 1: ITSM 플랫폼 아키텍처 다이어그램\n**파일명 예시:** `ITSM_AWS_Integration_Architecture_v2.3.pdf`\n\n```\n포함해야 할 내용:\n├── ITSM 플랫폼 (ServiceNow/Jira SM/Freshservice 등)\n├── AWS 계정 구조와의 연결점\n├── 데이터 흐름 (양방향 화살표 필수)\n│   ├── CloudWatch → ITSM (알람 → 인시던트)\n│   ├── ITSM → AWS (승인된 변경 → 자동 실행)\n│   └── Service Catalog → ITSM (요청 추적)\n├── 통합 방식 (API/Webhook/Lambda)\n└── 인증/권한 관리 방식\n```\n\n#### Evidence 2: 인시던트 관리 프로세스 문서 + 실제 티켓 샘플\n**파일명 예시:** `INC_Process_Document_with_Samples.pdf`\n\n| 섹션 | 필수 포함 내용 |\n|------|---------------|\n| 프로세스 플로우 | Detection → Triage → Investigation → Resolution → PIR |\n| 우선순위 매트릭스 | P1-P4 정의 (AWS 서비스 영향도 기준) |\n| 에스컬레이션 경로 | 시간별 자동 에스컬레이션 규칙 |\n| **실제 티켓 3-5개** | P1, P2, P3 각각 최소 1개씩 (최근 6개월 내) |\n\n**티켓 샘플 필수 필드:**\n- 티켓 ID, 생성 시간, 해결 시간\n- 영향받은 AWS 리소스 (ARN 또는 리소스 ID)\n- Root Cause 분석 내용\n- 해결 조치 상세\n\n#### Evidence 3: 변경 관리 프로세스 및 CAB 회의록\n**파일명 예시:** `CHG_Management_Process_CAB_Records.pdf`\n\n```\n변경 유형별 워크플로우:\n├── Standard Change: 사전 승인된 변경 목록 (예: 태그 수정, 보안그룹 규칙 추가)\n├── Normal Change: CAB 승인 필요 (예: 프로덕션 인스턴스 타입 변경)\n└── Emergency Change: 긴급 승인 프로세스 (예: 보안 패치 긴급 적용)\n\nCAB 회의록 필수 포함:\n- 회의 일시, 참석자\n- 검토된 변경 요청 목록\n- 승인/거부 결정 및 사유\n- AWS 리소스 변경 영향도 평가\n```\n\n#### Evidence 4: 서비스 요청 카탈로그 및 자동화 증거\n**파일명 예시:** `Service_Request_Catalog_Automation_Demo.pdf`\n\n```\n서비스 카탈로그 항목 예시:\n├── AWS 계정 생성 요청 (AWS Control Tower 연동)\n├── EC2 인스턴스 프로비저닝 (Service Catalog 제품)\n├── S3 버킷 생성 (CloudFormation 자동 실행)\n├── IAM 사용자/역할 요청 (승인 워크플로우)\n├── 비용 리포트 요청 (Cost Explorer 자동 생성)\n└── VPN 연결 설정 요청\n```\n\n#### Evidence 5: 리포팅 및 분석 대시보드 스크린샷\n**파일명 예시:** `ITSM_Reporting_Dashboard_Screenshots.pdf`\n\n**필수 대시보드/리포트:**\n- 월간 인시던트 트렌드 (AWS 서비스별 분류)\n- SLA 달성률 리포트 (Target vs Actual)\n- 변경 성공률 및 실패 분석\n- 서비스 요청 처리 시간 분석\n- Top 10 반복 인시던트 (Problem 후보)\n\n#### Evidence 6: 통합 및 자동화 구성 증거\n**파일명 예시:** `ITSM_AWS_Integration_Configuration.pdf`\n\n```\n증거로 제출할 스크린샷/설정:\n├── CloudWatch Alarm → SNS → Lambda → ITSM API 호출 구성\n├── EventBridge Rule 설정 (ITSM 이벤트 트리거)\n├── Systems Manager Automation Runbook (ITSM 티켓 연동)\n├── Service Catalog 제품과 ITSM 요청 연결\n└── API 연동 로그 (성공적인 티켓 생성 로그)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: ITSM 플랫폼 선정 및 AWS 통합 기능 확인 (1-2주)\n**담당:** IT Operations Manager, Cloud Architect\n\n| ITSM 플랫폼 | AWS 통합 수준 | 권장 사항 |\n|-------------|--------------|----------|\n| **ServiceNow** | Native AWS Service Management Connector | Enterprise 환경 최적 |\n| **Jira Service Management** | AWS 통합 앱 (Marketplace) | 중소규모 적합 |\n| **Freshservice** | AWS CloudWatch 통합 | 비용 효율적 |\n| **PagerDuty + Jira** | 조합 사용 | 인시던트 특화 |\n\n**확인 체크리스트:**\n- [ ] CloudWatch 알람 자동 티켓 생성 지원 여부\n- [ ] AWS SSO/IAM Identity Center 연동 가능 여부\n- [ ] API를 통한 양방향 데이터 동기화 지원\n- [ ] AWS 리소스 CMDB 동기화 기능\n\n### Step 2: 인시던트 관리 워크플로우 구축 (2-3주)\n**담당:** Service Desk Lead, SRE Team\n\n```\n구축할 자동화 플로우:\n\n[CloudWatch Alarm] \n    ↓ (SNS Topic)\n[Lambda Function: incident-creator]\n    ↓ (ITSM API 호출)\n[ITSM Incident Ticket 자동 생성]\n    ↓ (우선순위 자동 분류)\n[담당자 자동 할당 + Slack/Teams 알림]\n```\n\n**Lambda 함수 핵심 로직 (Python 예시):**\n```python\ndef create_incident(alarm_data):\n    priority = map_severity_to_priority(alarm_data['NewStateValue'])\n    affected_resource = alarm_data['Trigger']['Dimensions']\n    \n    incident = {\n        'short_description': f\"AWS Alert: {alarm_data['AlarmName']}\",\n        'description': alarm_data['NewStateReason'],\n        'priority': priority,\n        'configuration_item': affected_resource,\n        'category': 'Cloud Infrastructure',\n        'subcategory': 'AWS'\n    }\n    return itsm_api.create_incident(incident)\n```\n\n### Step 3: 변경 관리 프로세스 AWS 연동 (2주)\n**담당:** Change Manager, DevOps Engineer\n\n**구현해야 할 핵심 통제:**\n\n1. **Pre-Change Validation**\n   - AWS Config Rule로 변경 전 컴플라이언스 체크\n   - 변경 티켓 번호 없이 AWS 콘솔 변경 시 알림\n\n2. **Change Execution Tracking**\n   ```\n   CloudTrail Event → EventBridge → Lambda → ITSM Change Ticket 업데이트\n   ```\n\n3. **Post-Change Verification**\n   - Systems Manager Automation으로 변경 후 상태 검증\n   - 검증 결과 자동으로 Change Ticket에 첨부\n\n### Step 4: 서비스 요청 카탈로그 구축 (2-3주)\n**담당:** Service Catalog Admin, ITSM Admin\n\n**AWS Service Catalog와 ITSM 연동 구조:**\n```\n[ITSM Service Request]\n    ↓ (승인 완료)\n[Lambda: catalog-provisioner]\n    ↓ (Service Catalog API)\n[AWS Service Catalog Product Launch]\n    ↓ (CloudFormation Stack)\n[리소스 생성 완료]\n    ↓ (EventBridge)\n[ITSM Request 자동 완료 처리]\n```\n\n**최소 구현해야 할 서비스 요청 항목:**\n- [ ] AWS 계정 생성/삭제 요청\n- [ ] EC2 인스턴스 생성 요청\n- [ ] S3 버킷 생성 요청\n- [ ] IAM 사용자/역할 생성 요청\n- [ ] 보안 그룹 규칙 변경 요청\n\n### Step 5: 리포팅 및 대시보드 구성 (1-2주)\n**담당:** BI Analyst, ITSM Admin\n\n**필수 구현 대시보드:**\n\n| 대시보드 | 데이터 소스 | 갱신 주기 |\n|---------|------------|----------|\n| 인시던트 현황 | ITSM + CloudWatch | 실시간 |\n| SLA 달성률 | ITSM 티켓 데이터 | 일간 |\n| 변경 성공률 | ITSM + AWS Config | 주간 |\n| 비용 영향 분석 | ITSM + Cost Explorer | 월간 |\n\n**QuickSight 연동 옵션:**\n- ITSM 데이터를 S3로 Export → Athena → QuickSight\n- AWS 비용 데이터와 ITSM 티켓 상관관계 분석\n\n### Step 6: Problem Management 프로세스 구축 (1-2주)\n**담당:** Problem Manager, SRE Lead\n\n```\nProblem 식별 기준:\n├── 동일 알람 3회 이상 반복 (30일 내)\n├── 동일 리소스 관련 인시던트 2회 이상\n├── P1/P2 인시던트 발생 시 자동 Problem 생성\n└── 월간 인시던트 분석 시 패턴 식별\n```\n\n**자동화 구현:**\n- CloudWatch Logs Insights로 반복 패턴 탐지\n- Lambda로 ITSM Problem 티켓 자동 생성\n\n### Step 7: 통합 테스트 및 데모 준비 (1주)\n**담당:** 전체 팀\n\n**데모 시나리오 준비 (심사 시 라이브 데모용):**\n\n1. **시나리오 A: 인시던트 자동 생성**\n   - EC2 CPU 알람 트리거 → 티켓 자동 생성 → 담당자 알림\n\n2. **시나리오 B: 서비스 요청 처리**\n   - S3 버킷 생성 요청 → 승인 → 자동 프로비저닝 → 완료\n\n3. **시나리오 C: 변경 관리**\n   - 변경 요청 → CAB 승인 → 실행 → CloudTrail 기록 연동\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ 실패 사례 1: \"도구만 있고 통합이 없는 경우\"\n**문제 상황:**\n> \"ServiceNow 라이선스는 있는데, AWS 알람이 발생하면 수동으로 티켓을 생성합니다\"\n\n**심사관 반응:** 즉시 불합격 판정\n\n**",
      "language": "en",
      "createdAt": "2026-01-07T03:16:23.169Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-006_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-006",
      "category": "Operations",
      "title": "Release Management",
      "advice": "# OPS-006: Release Management - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nRelease Management is the **operational backbone** that demonstrates your MSP's ability to safely and consistently deliver changes to customer production environments. AWS views this as a fundamental differentiator between mature MSPs and basic service providers. This requirement validates that you have industrialized your deployment processes—not just for your own infrastructure, but provably for customer workloads.\n\n**The core philosophy AWS expects**: Changes to production should be boring, predictable, and reversible. If your releases are exciting events requiring heroic efforts, you'll fail this audit.\n\n### 🎯 What Auditors Specifically Look For\n\n1. **Traceability Chain**: Can they follow a single change from developer commit → code review → testing → approval → production deployment → validation? Auditors will pick a random release and trace it end-to-end.\n\n2. **Separation of Environments**: Evidence that non-production testing isn't just a checkbox—they want to see that your staging environment meaningfully resembles production (same IaC templates, similar data patterns).\n\n3. **Approval Gates with Accountability**: Not just \"someone approved\"—they want to see WHO approved, WHEN, and based on WHAT criteria. Slack messages saying \"LGTM\" don't count.\n\n4. **Infrastructure as Code Maturity**: They specifically check whether infrastructure changes go through the same rigor as application code. Many MSPs fail here by having great CI/CD for apps but manual console clicks for infrastructure.\n\n5. **Rollback Evidence**: At least one example where a release was rolled back, and the process worked as designed. This proves your process isn't just theoretical.\n\n### Relevant AWS Services & Features\n\n| Category | AWS Services |\n|----------|-------------|\n| Version Control | **AWS CodeCommit**, GitHub/GitLab (integrated with AWS) |\n| CI/CD Pipeline | **AWS CodePipeline**, **CodeBuild**, **CodeDeploy** |\n| IaC Tools | **AWS CloudFormation**, **AWS CDK**, **Terraform** (with S3 backend) |\n| Approval Management | **CodePipeline Manual Approval Actions**, **AWS Service Catalog** |\n| Testing | **CodeBuild** test stages, **AWS Device Farm**, **CloudFormation StackSets** for multi-account |\n| Audit Trail | **AWS CloudTrail**, **CodePipeline execution history**, **S3 versioning** |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### 📁 Document 1: Release Management Policy & Procedure\n**Filename**: `[CustomerName]_Release_Management_Procedure_v2.3.pdf`\n\n**Must Include**:\n- Release categorization (Standard, Emergency, Major) with different approval paths\n- Environment promotion workflow (Dev → QA → Staging → Prod)\n- Rollback criteria and procedures\n- Release calendar/freeze periods\n- RACI matrix for release activities\n\n#### 📁 Document 2: Pipeline Architecture Documentation\n**Filename**: `[CustomerName]_CICD_Pipeline_Architecture.pdf`\n\n**Must Include**:\n- Visual diagram showing CodePipeline stages\n- Branch strategy (GitFlow, trunk-based, etc.)\n- Integration points between tools\n- Security scanning stage placement\n- Artifact storage and versioning approach\n\n#### 📁 Document 3: End-to-End Release Evidence (CRITICAL)\n**Filename**: `[CustomerName]_Release_[ReleaseID]_Evidence_Package.pdf`\n\n**Must Include**:\n- Git commit history with PR/MR approval screenshots\n- CodeBuild test execution logs (unit, integration, security)\n- Staging deployment evidence with test results\n- Manual approval action screenshot from CodePipeline (showing approver identity and timestamp)\n- Production deployment CloudTrail events\n- Post-deployment validation evidence (health checks, smoke tests)\n\n#### 📁 Document 4: Infrastructure as Code Repository Evidence\n**Filename**: `[CustomerName]_IaC_Repository_Structure.pdf`\n\n**Must Include**:\n- Repository structure screenshot showing CloudFormation/CDK/Terraform files\n- Example PR showing infrastructure change review\n- CloudFormation StackPolicy or Terraform state locking configuration\n- Drift detection setup (AWS Config rules or CloudFormation drift detection)\n\n#### 📁 Document 5: Rollback Evidence (Often Missed!)\n**Filename**: `[CustomerName]_Rollback_Incident_[Date].pdf`\n\n**Must Include**:\n- Incident that triggered rollback\n- Rollback execution evidence (CodeDeploy rollback or CloudFormation stack rollback)\n- Timeline showing rollback completed within SLA\n- Post-mortem confirming process worked\n\n### Evidence Examples by Scenario\n\n| Scenario | Good Evidence | Weak Evidence |\n|----------|---------------|---------------|\n| Approval Gate | CodePipeline screenshot showing \"Approved by john.smith@customer.com at 2024-01-15 14:32 UTC\" | Email chain saying \"approved\" |\n| Testing | CodeBuild report showing 847 tests passed, 0 failed, with coverage metrics | \"QA signed off\" document |\n| IaC | CloudFormation changeset preview + execution in pipeline | Console screenshot of stack update |\n| Version Control | GitHub PR with 2 reviewers, linked Jira ticket, passing CI checks | Commit history without context |\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Select the Right Customer Example (Week 1)\n**⏱️ Time**: 2-3 days | **👤 Owner**: Delivery Manager\n\n**Specific Actions**:\n- Choose a customer with **at least 6 months of release history** in your pipeline\n- Verify they have both application AND infrastructure deployments through CI/CD\n- Confirm you have at least one documented rollback incident\n- Ensure customer has signed off on using sanitized evidence\n\n**AWS Tools**: Review CodePipeline execution history in the customer's account\n\n**Selection Criteria Checklist**:\n```\n☐ Customer uses CodePipeline or equivalent with AWS integration\n☐ At least 20+ successful production releases documented\n☐ Infrastructure managed via CloudFormation/CDK/Terraform\n☐ Manual approval stage exists in pipeline\n☐ At least 1 rollback event occurred and was documented\n```\n\n### Step 2: Document Pipeline Architecture (Week 1-2)\n**⏱️ Time**: 3-4 days | **👤 Owner**: DevOps Engineer\n\n**Specific Actions**:\n1. Export CodePipeline definition: \n   ```bash\n   aws codepipeline get-pipeline --name CustomerProdPipeline > pipeline-definition.json\n   ```\n2. Create visual diagram using draw.io or Lucidchart showing:\n   - Source stage (CodeCommit/GitHub webhook)\n   - Build stage (CodeBuild projects)\n   - Test stages (unit, integration, security scanning)\n   - Staging deployment + approval gate\n   - Production deployment + post-deployment validation\n\n3. Document branch-to-environment mapping:\n   ```\n   feature/* → Dev environment (auto-deploy)\n   develop → QA environment (auto-deploy)  \n   release/* → Staging (auto-deploy, manual approval to prod)\n   main → Production (requires approval)\n   ```\n\n### Step 3: Capture End-to-End Release Evidence (Week 2)\n**⏱️ Time**: 2-3 days | **👤 Owner**: DevOps Engineer + Release Manager\n\n**Specific Actions**:\n1. Select a recent production release (within last 60 days)\n2. Gather evidence chain:\n\n   **a) Version Control Evidence**:\n   - Screenshot of PR showing: title, description, linked ticket, reviewers, approval status\n   - Git log showing merge commit to release branch\n   \n   **b) Build & Test Evidence**:\n   ```bash\n   aws codebuild batch-get-builds --ids <build-id> > build-evidence.json\n   ```\n   - Export CodeBuild logs showing test execution\n   - Screenshot of test report (if using CodeBuild test reports feature)\n   \n   **c) Approval Evidence**:\n   - CodePipeline execution view showing manual approval stage\n   - Screenshot must show: Approver email, approval time, comments\n   \n   **d) Deployment Evidence**:\n   ```bash\n   aws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=UpdateStack --start-time 2024-01-15T00:00:00Z\n   ```\n   - CloudTrail events for CloudFormation/CodeDeploy actions\n   \n   **e) Validation Evidence**:\n   - Post-deployment health check results\n   - CloudWatch alarm status showing green after deployment\n\n### Step 4: Document IaC Practices (Week 2-3)\n**⏱️ Time**: 2-3 days | **👤 Owner**: Cloud Architect\n\n**Specific Actions**:\n1. Export CloudFormation template from a recent infrastructure change:\n   ```bash\n   aws cloudformation get-template --stack-name CustomerProdVPC > vpc-template.yaml\n   ```\n\n2. Show changeset workflow evidence:\n   - Screenshot of changeset creation in pipeline\n   - Changeset review showing what will be modified\n   - Execution evidence\n\n3. Document state management:\n   - For Terraform: S3 backend configuration with DynamoDB locking\n   - For CloudFormation: Stack policies preventing accidental deletion\n\n4. Show drift detection:\n   ```bash\n   aws cloudformation detect-stack-drift --stack-name CustomerProdVPC\n   ```\n\n### Step 5: Prepare Rollback Evidence (Week 3)\n**⏱️ Time**: 2 days | **👤 Owner**: Incident Manager + DevOps\n\n**Specific Actions**:\n1. Locate a historical rollback event (check incident tickets)\n2. Gather evidence showing:\n   - What triggered the rollback decision\n   - CodeDeploy rollback execution OR CloudFormation stack rollback\n   - Timeline from detection to rollback completion\n   - Verification that rollback restored service\n\n**If No Rollback Exists**: \n- Schedule a controlled rollback drill\n- Deploy a known-bad version to staging, execute rollback, document everything\n- This is acceptable evidence if clearly labeled as a drill\n\n### Step 6: Create Consolidated Evidence Package (Week 3-4)\n**⏱️ Time**: 3-4 days | **👤 Owner**: MSP Program Lead\n\n**Specific Actions**:\n1. Create master document with table of contents\n2. Add narrative explaining your release management philosophy\n3. Include timeline diagram showing the specific release's journey\n4. Sanitize customer-sensitive information (but keep enough context)\n5. Add annotations explaining what each screenshot demonstrates\n\n### Step 7: Internal Audit Simulation (Week 4)\n**⏱️ Time**: 1 day | **👤 Owner**: QA/Compliance Team\n\n**Specific Actions**:\n1. Have someone unfamiliar with the project review evidence\n2. Ask them to trace a release from commit to production\n3. Verify they can answer:\n   - Who approved this release?\n   - What tests were run?\n   - How would you rollback?\n   - Where is the infrastructure code?\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Showing Your Internal Pipeline, Not Customer's\n**What Goes Wrong**: MSPs submit evidence of their own internal release process, not a customer-managed workload.\n\n**Why Auditors Reject This**: The requirement explicitly states \"customer example.\" Your internal DevOps maturity doesn't prove you deliver this for customers.\n\n**Fix**: Always use customer account evidence. If you manage pipelines in your own account for customers, show the customer workload deployment, not your internal tools.\n\n---\n\n### ❌ Mistake 2: Manual Approval = Email Thread\n**What Goes Wrong**: Showing email approvals or Slack messages instead of pipeline-integrated approval gates.\n\n**Why Auditors Reject This**: Manual approvals outside the pipeline can be bypassed. AWS expects approval to be a **blocking stage** in the automated pipeline.\n\n**Fix**: Implement CodePipeline Manual Approval Action:\n```yaml\n- Name: ProductionApproval\n  Actions:\n    - Name: ApproveDeployment\n      ActionTypeId:\n        Category: Approval\n        Owner: AWS\n        Provider: Manual\n        Version: '1'\n      Configuration:\n        NotificationArn: arn:aws:sns:us-east-1:123456789:release-approvals\n        CustomData: \"Release v2.3.1 - Review staging test results before approving\"\n```\n\n---\n\n### ❌ Mistake 3: No Infrastructure in the Pipeline\n**What Goes Wrong**: Great CI/CD for application code, but infrastructure changes are done via console or CLI outside the pipeline.\n\n**Why Auditors Reject This**: Requirement #4 explicitly requires \"automated infrastructure deployment tools.\" Console changes aren't auditable or repeatable.\n\n**Fix**: Show CloudFormation/CDK deployment as a pipeline stage:\n```yaml\n- Name: DeployInfrastructure\n  Actions:\n    - Name: DeployVPCChanges\n      ActionTypeId:\n        Category: Deploy\n        Owner: AWS\n        Provider: CloudFormation\n        Version: '1'\n      Configuration:\n        ActionMode: CREATE_UPDATE\n        StackName: customer-prod-vpc\n        TemplatePath: BuildOutput::infrastructure/vpc.yaml\n```\n\n---\n\n### ❌ Mistake 4: Testing Evidence Shows Only \"Passed\"\n**What Goes Wrong**: Submitting a green checkmark without showing what was actually tested.\n\n**Why Auditors Reject This**: They need to see test coverage is meaningful—not just that some test ran.\n\n**Fix**: Include CodeBuild test reports showing:\n- Number of tests executed\n- Test categories (unit, integration, security)\n- Code coverage percentage\n- At least one example of test output\n\n---\n\n### ❌ Mistake 5: No Rollback Evidence\n**What Goes Wrong**: Claiming you have rollback capability but never demonstrating it worked.\n\n**Why Auditors Reject This**: Untested rollback procedures fail when needed. AWS wants proof your safety net actually works.\n\n**Fix**: Either provide a real rollback incident OR conduct a documented rollback drill. Include:\n- Trigger event\n- Rollback execution command/action\n- Time to recovery\n- Verification of restored state\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Before Submission, Verify Each Item:\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **End-to-end traceability exists** | Pick the release ID, trace from commit SHA to production CloudTrail event | Every stage has timestamped evidence linking to the same release |\n| 2 | **Approval shows identity and timestamp** | Review approval screenshot | Approver's email/name visible, UTC timestamp shown, approval is in pipeline (not external) |\n| 3 | **Non-production testing is substantive** | Review test evidence | Shows test count >50, includes multiple test types, coverage >60% |\n| 4 | **Infrastructure changes go through pipeline** | Find IaC deployment evidence | CloudFormation/Terraform execution triggered by pipeline, not console |\n| 5 | **Rollback capability is proven** | Locate rollback evidence | Shows actual rollback execution (not just documentation of how it would work) |\n| 6 | **Evidence is from customer environment** | Check AWS account IDs in screenshots | Account ID matches customer, not MSP internal account |\n| 7 | **Version control shows code review** | Review PR/MR evidence | At least 1 reviewer approved, CI checks passed before merge |\n\n### Quality Gate Questions (Ask Yourself):\n\n1. **\"If I were an auditor seeing this for the first time, could I understand the complete release flow in under 10 minutes?\"**\n   - If no: Add a narrative summary and timeline diagram\n\n2. **\"Does every screenshot have context explaining what it demonstrates?\"**\n   - If no: Add annotations or captions\n\n3. **\"Could someone replicate this process for a different release?\"**\n   - If no: Your procedure documentation needs more detail\n\n4. **\"Is there any evidence of manual/console intervention in the release?\"**\n   - If yes: Either remove it or explain why it was exceptional (with process to prevent recurrence)\n\n### Final Evidence Package Structure:\n```\n📁 OPS-006_Release_Management_Evidence/\n├── 01_Release_Management_Policy_v2.3.pdf\n├── 02_Pipeline_Architecture_Diagram.pdf\n├── 03_Release_Evidence/\n│   ├── 3.1_PR_Approval_Screenshot.png\n│   ├── 3.2_CodeBuild_Test_Report.pdf\n│   ├── 3.3_Staging_Deployment_Evidence.pdf\n│   ├── 3.4_Manual_Approval_Screenshot.png\n│   ├── 3.5_Production_CloudTrail_Events.json\n│   └── 3.6_Post_Deployment_Validation.pdf\n├── 04_IaC_",
      "language": "en",
      "createdAt": "2026-01-07T03:17:38.024Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-007_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-007",
      "category": "Operations",
      "title": "Configuration Management",
      "advice": "# OPS-007: Configuration Management - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nConfiguration Management는 MSP의 운영 성숙도를 직접적으로 보여주는 핵심 요구사항입니다. AWS 환경에서 \"누가, 언제, 무엇을\" 변경했는지 추적할 수 없다면, 장애 발생 시 원인 분석이 불가능하고 보안 사고 대응도 어렵습니다. 이 항목은 단순한 로깅이 아닌 **체계적인 변경 추적 시스템**의 존재를 증명해야 합니다.\n\n### 🎯 Auditor가 집중적으로 확인하는 5가지 포인트\n\n1. **리소스 변경의 완전한 가시성**: EC2, RDS, VPC, IAM 등 주요 리소스 변경이 빠짐없이 기록되는지\n2. **변경 승인 워크플로우**: 변경 전 승인 프로세스가 존재하고 실제로 작동하는지 (ITSM 연동)\n3. **Rollback 상태 추적**: 변경 후 문제 발생 시 롤백 여부와 현재 상태가 명확히 표시되는지\n4. **실행자 식별**: IAM User/Role이 아닌 **실제 담당자 이름**까지 매핑되는지\n5. **실시간 알림 체계**: 변경 발생 시 관련자에게 즉시 통보되는 메커니즘\n\n### 🔧 관련 AWS 서비스 및 도구\n- **AWS Config**: 리소스 구성 변경 기록의 핵심 서비스\n- **AWS CloudTrail**: API 호출 기록 및 실행자 추적\n- **AWS Systems Manager Change Manager**: 승인 워크플로우 구현\n- **Amazon EventBridge**: 변경 이벤트 감지 및 알림 트리거\n- **AWS Service Catalog**: 승인된 구성만 배포 가능하도록 제한\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 필수 증거 목록\n\n| 증거 유형 | 파일명 예시 | 핵심 포함 내용 |\n|-----------|-------------|----------------|\n| AWS Config 대시보드 스크린샷 | `CustomerA_Config_Dashboard_2024Q1.png` | 리소스 타임라인, 변경 이력, 규정 준수 상태 |\n| Change Request 티켓 | `CR-2024-0156_EC2_ScaleUp_Approved.pdf` | 요청자, 승인자, 변경 내용, 승인 일시 |\n| 변경 실행 기록 | `CustomerA_ChangeLog_Jan2024.xlsx` | 리소스ID, 변경유형, 실행자, 상태(Deployed/Rolled Back) |\n| 승인 워크플로우 다이어그램 | `Change_Approval_Workflow_v2.1.pdf` | 승인 단계, 역할별 권한, 긴급 변경 프로세스 |\n| 알림 설정 증거 | `EventBridge_SNS_Config_Screenshot.png` | 변경 감지 규칙, 알림 대상, 알림 내용 |\n\n### 📌 각 증거의 핵심 포함 요소\n\n**1. AWS Config 리소스 타임라인 (필수)**\n```\n✓ 특정 리소스(예: EC2 인스턴스)의 Configuration Timeline 화면\n✓ 변경 전/후 구성 비교(Diff) 화면\n✓ 최소 3개월 이상의 변경 이력 표시\n✓ 고객사 식별 가능한 Account ID 또는 리소스 태그\n```\n\n**2. Change Request 티켓 샘플 (3건 이상)**\n```\n✓ 변경 요청 제목 및 상세 설명\n✓ 영향받는 리소스 목록 (ARN 또는 Resource ID)\n✓ 요청자 이름 + 승인자 이름 (IAM User가 아닌 실명)\n✓ 승인 일시 타임스탬프\n✓ 현재 상태: Deployed / Rolled Back / Pending\n✓ 롤백 시 롤백 사유 및 일시\n```\n\n**3. 실시간 알림 증거**\n```\n✓ Slack/Teams/Email로 전송된 변경 알림 스크린샷\n✓ 알림 내용에 리소스명, 변경 유형, 실행자 포함\n✓ EventBridge Rule 설정 화면\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: AWS Config 활성화 및 규칙 설정 (2-3일)\n**담당**: Cloud Engineer\n\n```bash\n# AWS Config 활성화 확인\naws configservice describe-configuration-recorders\n\n# 모든 리소스 타입 기록 활성화\naws configservice put-configuration-recorder \\\n  --configuration-recorder name=default,roleARN=arn:aws:iam::ACCOUNT:role/ConfigRole \\\n  --recording-group allSupported=true,includeGlobalResourceTypes=true\n```\n\n**체크포인트**:\n- [ ] 모든 리전에서 Config 활성화\n- [ ] S3 버킷에 Config 스냅샷 저장 확인\n- [ ] 최소 90일 이상 보존 설정\n\n---\n\n### Step 2: CloudTrail과 Config 연동 확인 (1일)\n**담당**: Security Engineer\n\nCloudTrail 이벤트와 Config 변경 기록이 연결되어 \"누가 변경했는지\" 추적 가능해야 합니다.\n\n```bash\n# CloudTrail에서 Config 변경 이벤트 조회\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=EventSource,AttributeValue=config.amazonaws.com \\\n  --start-time 2024-01-01\n```\n\n**핵심 설정**:\n- CloudTrail → S3 → Athena 쿼리 가능하도록 구성\n- IAM User/Role → 실제 담당자 매핑 테이블 유지\n\n---\n\n### Step 3: 변경 승인 워크플로우 구축 (3-5일)\n**담당**: DevOps Lead + ITSM Admin\n\n**Option A: AWS Systems Manager Change Manager 사용**\n```yaml\n# Change Template 예시\nChangeTemplateName: \"EC2-Instance-Modification\"\nApprovalWorkflow:\n  - Level1: TeamLead (자동 승인 조건: 개발 환경)\n  - Level2: ServiceOwner (운영 환경 필수)\n  - Emergency: SecurityTeam + OnCall Manager\n```\n\n**Option B: ServiceNow/Jira Service Management 연동**\n- AWS Service Management Connector 활용\n- Change Request → AWS 리소스 변경 자동 연결\n\n---\n\n### Step 4: 변경 상태 추적 대시보드 구성 (2일)\n**담당**: Cloud Engineer\n\n**QuickSight 또는 Grafana 대시보드 구성 요소**:\n```\n┌─────────────────────────────────────────────────┐\n│  Configuration Change Dashboard - CustomerA     │\n├─────────────────────────────────────────────────┤\n│ 📊 Today's Changes: 12  │ 🔄 Rolled Back: 2    │\n├─────────────────────────────────────────────────┤\n│ Recent Changes (Last 7 Days)                    │\n│ ─────────────────────────────────────────────── │\n│ EC2 i-0abc123  │ Modified │ John Kim │ Deployed │\n│ RDS mydb-prod  │ Updated  │ Jane Lee │ Deployed │\n│ VPC vpc-xyz    │ Created  │ Auto-TF  │ Deployed │\n│ SG sg-web      │ Modified │ John Kim │ RolledBack│\n└─────────────────────────────────────────────────┘\n```\n\n---\n\n### Step 5: 알림 체계 구성 (1일)\n**담당**: DevOps Engineer\n\n```python\n# EventBridge Rule for Config Changes\n{\n  \"source\": [\"aws.config\"],\n  \"detail-type\": [\"Config Configuration Item Change\"],\n  \"detail\": {\n    \"configurationItem\": {\n      \"resourceType\": [\"AWS::EC2::Instance\", \"AWS::RDS::DBInstance\", \n                       \"AWS::EC2::SecurityGroup\", \"AWS::IAM::Role\"]\n    }\n  }\n}\n```\n\n**알림 채널 설정**:\n- 일반 변경: Slack #aws-changes 채널\n- 보안 관련 변경 (IAM, SG): PagerDuty + Email\n- 긴급 변경: SMS + Phone Call\n\n---\n\n### Step 6: 고객 데모 환경 준비 (2일)\n**담당**: Account Manager + Cloud Engineer\n\n**데모 시나리오 준비**:\n1. EC2 인스턴스 타입 변경 요청 → 승인 → 실행 → 기록 확인\n2. Security Group 규칙 변경 → 문제 발생 → 롤백 → 상태 업데이트\n3. 변경 알림 수신 확인\n\n---\n\n### Step 7: 증거 문서화 및 검증 (1-2일)\n**담당**: Compliance Manager\n\n**증거 패키지 구성**:\n```\n📁 OPS-007_Configuration_Management/\n├── 01_AWS_Config_Setup/\n│   ├── Config_Dashboard_Overview.png\n│   ├── Resource_Timeline_EC2_Example.png\n│   └── Config_Rules_Compliance.png\n├── 02_Change_Requests/\n│   ├── CR-2024-0156_Approved.pdf\n│   ├── CR-2024-0189_RolledBack.pdf\n│   └── CR-2024-0201_Deployed.pdf\n├── 03_Approval_Workflow/\n│   ├── Change_Approval_Process.pdf\n│   └── SSM_Change_Manager_Config.png\n├── 04_Alerting/\n│   ├── EventBridge_Rules.png\n│   └── Slack_Notification_Sample.png\n└── 05_Demo_Recording/\n    └── Config_Management_Demo_CustomerA.mp4\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ 실패 원인 #1: CloudTrail만 제출하고 Config 없음\n**문제**: CloudTrail은 API 호출 기록이지, 리소스 구성 상태 변경 기록이 아닙니다.\n**해결**: AWS Config의 Configuration Timeline이 반드시 포함되어야 함\n\n```\n❌ 잘못된 증거: CloudTrail 로그만 제출\n   \"RunInstances API called by user:john at 2024-01-15\"\n\n✅ 올바른 증거: Config + CloudTrail 연동\n   \"EC2 i-0abc123 configuration changed:\n    - Instance Type: t3.medium → t3.large\n    - Changed by: john@company.com (via CloudTrail correlation)\n    - Status: Deployed\n    - Approval: CR-2024-0156 (Approved by manager@company.com)\"\n```\n\n---\n\n### ❌ 실패 원인 #2: 승인 워크플로우 증거 부재\n**문제**: 변경 기록은 있지만 \"승인 프로세스\"가 없음\n**해결**: \n- ITSM 도구(ServiceNow, Jira SM)의 승인 이력 스크린샷\n- 또는 AWS SSM Change Manager의 승인 워크플로우 설정\n\n**Auditor 질문 예시**:\n> \"이 EC2 변경이 승인 없이 실행될 수 있나요? 승인 우회 방지 메커니즘은?\"\n\n---\n\n### ❌ 실패 원인 #3: Rollback 상태 추적 불가\n**문제**: 변경 기록에 \"Deployed\" 상태만 있고 \"Rolled Back\" 케이스가 없음\n**해결**: 의도적으로 롤백 시나리오를 만들어 증거 확보\n\n```\n✅ 롤백 증거 예시:\nCR-2024-0189: Security Group Rule Change\n- Initial Status: Deployed (2024-01-20 14:30)\n- Issue Detected: Application connectivity failure\n- Rollback Executed: 2024-01-20 15:45\n- Current Status: Rolled Back\n- Rollback Approver: oncall-manager@company.com\n```\n\n---\n\n### ❌ 실패 원인 #4: IAM Role만 기록되고 실제 담당자 불명\n**문제**: \"AssumedRole/AdminRole\"만 기록되어 실제 누가 변경했는지 알 수 없음\n**해결**: \n- IAM Identity Center(SSO) 사용 시 사용자 이름 자동 기록\n- 또는 IAM User → 담당자 매핑 테이블 유지 및 제출\n\n---\n\n### ❌ 실패 원인 #5: 테스트 환경 증거만 제출\n**문제**: 실제 고객 환경이 아닌 내부 테스트 계정 증거 제출\n**해결**: \n- 반드시 **실제 고객 환경**의 증거 필요\n- 고객 동의서(NDA 범위 내 증거 사용 승인) 확보\n- 민감 정보 마스킹 후 제출\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### 제출 전 최종 점검 항목\n\n| # | 점검 항목 | 검증 방법 | 통과 기준 |\n|---|----------|----------|----------|\n| 1 | AWS Config가 모든 주요 리소스 타입을 기록하는가? | Config Recorder 설정 확인 | EC2, RDS, VPC, IAM, S3 최소 포함 |\n| 2 | 변경 기록에 5가지 필수 요소가 모두 있는가? | 샘플 3건 검토",
      "language": "en",
      "createdAt": "2026-01-07T03:18:45.542Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-008_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-008",
      "category": "Operations",
      "title": "Patch Management",
      "advice": "# OPS-008: Patch Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nPatch Management is a **core competency that demonstrates MSP's operational maturity**. AWS requires MSPs to prove they can systematically protect customer infrastructure from security vulnerabilities and maintain compliance. This isn't just about having a patching tool—it's about demonstrating an **end-to-end automated lifecycle** from vulnerability detection to patch deployment and verification.\n\n### 🎯 5 Key Points Auditors Specifically Look For\n\n1. **Automation Scope Coverage**: Auditors verify patching covers OS-level (Windows/Linux), application-level (middleware, databases), and security-specific patches—not just one category\n\n2. **Multi-Account/Multi-Customer Orchestration**: Evidence must show you manage patching across multiple AWS accounts using AWS Organizations or centralized management, not just single-account demos\n\n3. **Maintenance Window Governance**: Proof that patches are deployed during customer-approved maintenance windows with proper change management integration\n\n4. **Compliance Baseline Enforcement**: Demonstration that you define and enforce patch compliance baselines (e.g., \"Critical patches within 72 hours, High within 7 days\")\n\n5. **Rollback and Exception Handling**: Auditors check for documented procedures when patches fail or customers request exceptions\n\n### 🔧 Relevant AWS Services\n- **AWS Systems Manager Patch Manager** (Primary)\n- **AWS Systems Manager State Manager** (Compliance enforcement)\n- **AWS Systems Manager Maintenance Windows**\n- **AWS Organizations** (Multi-account management)\n- **Amazon Inspector** (Vulnerability assessment integration)\n- **AWS Security Hub** (Compliance aggregation)\n- **Amazon EventBridge** (Automation triggers)\n- **AWS Lambda** (Custom automation logic)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|---------------------------|\n| Live Demo Recording | MP4/WebM (15-25 min) | Full patch lifecycle demonstration |\n| Patch Policy Document | PDF | Baseline definitions, SLAs, exception process |\n| Compliance Dashboard Screenshots | PNG/PDF | Multi-customer patch status views |\n| Automation Architecture Diagram | Visio/Draw.io PDF | End-to-end automation flow |\n| Sample Patch Reports | PDF/Excel | Actual customer reports (anonymized) |\n\n### 📄 Detailed Evidence Specifications\n\n**Evidence 1: Live Technology Demonstration (MANDATORY)**\n```\nFilename: OPS-008_PatchManagement_LiveDemo_[Date].mp4\nDuration: 15-25 minutes\nMust Include:\n├── Patch baseline configuration in SSM Patch Manager\n├── Maintenance window setup with customer-specific schedules\n├── Patch deployment execution (or scheduled execution view)\n├── Real-time compliance dashboard showing multiple accounts\n├── Patch status report generation\n└── Exception/exclusion handling demonstration\n```\n\n**Evidence 2: Patch Management Policy & Procedures**\n```\nFilename: OPS-008_PatchManagement_Policy_v[X.X].pdf\nMust Include:\n├── Patch classification definitions (Critical/High/Medium/Low)\n├── SLA matrix by patch severity:\n│   ├── Critical: 24-72 hours\n│   ├── High: 7 days\n│   ├── Medium: 30 days\n│   └── Low: Next maintenance cycle\n├── Customer approval workflow\n├── Emergency patch procedures (zero-day response)\n├── Exception request and approval process\n└── Rollback procedures\n```\n\n**Evidence 3: Patch Compliance Dashboard Export**\n```\nFilename: OPS-008_ComplianceDashboard_[CustomerCode]_[Date].pdf\nMust Show:\n├── Compliance percentage by customer/account\n├── Patch pending vs. installed breakdown\n├── Historical compliance trend (minimum 3 months)\n├── Non-compliant instance details\n└── Patch failure analysis\n```\n\n**Evidence 4: Automation Architecture Documentation**\n```\nFilename: OPS-008_PatchAutomation_Architecture.pdf\nMust Include:\n├── Multi-account patch orchestration flow\n├── Integration with change management (ServiceNow/Jira)\n├── Notification and approval workflow\n├── Compliance data aggregation method\n└── AWS service integration diagram\n```\n\n**Evidence 5: Sample Customer Patch Reports**\n```\nFilename: OPS-008_MonthlyPatchReport_Sample_[Month].pdf\nMust Include:\n├── Executive summary with compliance metrics\n├── Patches applied during reporting period\n├── Outstanding patches with remediation timeline\n├── Exceptions and justifications\n└── Next maintenance window schedule\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Configure AWS Systems Manager Patch Manager Baselines (Week 1)\n**⏱️ Time: 8-12 hours | 👤 Role: Cloud Engineer**\n\n```bash\n# Create custom patch baseline for Windows\naws ssm create-patch-baseline \\\n    --name \"MSP-Windows-Security-Baseline\" \\\n    --operating-system \"WINDOWS\" \\\n    --approval-rules \"PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=MSRC_SEVERITY,Values=[Critical,Important]},{Key=CLASSIFICATION,Values=[SecurityUpdates,CriticalUpdates]}]},ApproveAfterDays=3,ComplianceLevel=CRITICAL}]\" \\\n    --description \"MSP Standard Windows Security Patch Baseline\"\n\n# Create custom patch baseline for Amazon Linux 2\naws ssm create-patch-baseline \\\n    --name \"MSP-AmazonLinux2-Security-Baseline\" \\\n    --operating-system \"AMAZON_LINUX_2\" \\\n    --approval-rules \"PatchRules=[{PatchFilterGroup={PatchFilters=[{Key=SEVERITY,Values=[Critical,Important]},{Key=CLASSIFICATION,Values=[Security]}]},ApproveAfterDays=3,ComplianceLevel=CRITICAL}]\"\n```\n\n**Checklist:**\n- [ ] Create baselines for each OS type in customer environments\n- [ ] Define approval delays aligned with your SLA policy\n- [ ] Set compliance levels (CRITICAL, HIGH, MEDIUM, LOW, UNSPECIFIED)\n- [ ] Register baselines as default for patch groups\n\n### Step 2: Implement Multi-Account Patch Orchestration (Week 1-2)\n**⏱️ Time: 16-20 hours | 👤 Role: Cloud Architect**\n\n```yaml\n# CloudFormation StackSet for cross-account patch management\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: MSP Patch Management Cross-Account Setup\n\nResources:\n  PatchManagerRole:\n    Type: AWS::IAM::Role\n    Properties:\n      RoleName: MSP-PatchManager-CrossAccount-Role\n      AssumeRolePolicyDocument:\n        Version: '2012-10-17'\n        Statement:\n          - Effect: Allow\n            Principal:\n              AWS: !Sub 'arn:aws:iam::${ManagementAccountId}:root'\n            Action: 'sts:AssumeRole'\n      ManagedPolicyArns:\n        - arn:aws:iam::aws:policy/AmazonSSMFullAccess\n```\n\n**Key Actions:**\n- [ ] Deploy IAM roles via StackSets to all customer accounts\n- [ ] Configure Resource Data Sync for centralized compliance data\n- [ ] Set up Systems Manager Explorer for multi-account visibility\n- [ ] Create OpsCenter integration for patch-related incidents\n\n### Step 3: Configure Maintenance Windows with Customer Schedules (Week 2)\n**⏱️ Time: 6-8 hours | 👤 Role: Operations Engineer**\n\n```bash\n# Create maintenance window for Customer A (Saturday 2 AM JST)\naws ssm create-maintenance-window \\\n    --name \"CustomerA-PatchWindow-Weekly\" \\\n    --schedule \"cron(0 17 ? * SAT *)\" \\\n    --duration 4 \\\n    --cutoff 1 \\\n    --allow-unassociated-targets \\\n    --tags \"Key=Customer,Value=CustomerA\" \"Key=Environment,Value=Production\"\n\n# Register patch task to maintenance window\naws ssm register-task-with-maintenance-window \\\n    --window-id \"mw-0123456789abcdef0\" \\\n    --task-arn \"AWS-RunPatchBaseline\" \\\n    --task-type \"RUN_COMMAND\" \\\n    --targets \"Key=tag:PatchGroup,Values=CustomerA-Prod\" \\\n    --task-invocation-parameters '{\n        \"RunCommand\": {\n            \"Parameters\": {\n                \"Operation\": [\"Install\"],\n                \"RebootOption\": [\"RebootIfNeeded\"]\n            }\n        }\n    }'\n```\n\n### Step 4: Build Compliance Reporting Dashboard (Week 2-3)\n**⏱️ Time: 12-16 hours | 👤 Role: DevOps Engineer**\n\n**Option A: AWS-Native Solution**\n```python\n# Lambda function to aggregate patch compliance across accounts\nimport boto3\nimport json\nfrom datetime import datetime\n\ndef lambda_handler(event, context):\n    ssm = boto3.client('ssm')\n    \n    # Query patch compliance summary\n    response = ssm.list_compliance_summaries(\n        Filters=[\n            {\n                'Key': 'ComplianceType',\n                'Values': ['Patch'],\n                'Type': 'EQUAL'\n            }\n        ]\n    )\n    \n    compliance_data = {\n        'timestamp': datetime.now().isoformat(),\n        'compliant_count': response['ComplianceSummaryItems'][0]['CompliantSummary']['CompliantCount'],\n        'non_compliant_count': response['ComplianceSummaryItems'][0]['NonCompliantSummary']['NonCompliantCount'],\n        'severity_breakdown': response['ComplianceSummaryItems'][0]['NonCompliantSummary']['SeveritySummary']\n    }\n    \n    # Store in S3 for historical tracking\n    s3 = boto3.client('s3')\n    s3.put_object(\n        Bucket='msp-compliance-data',\n        Key=f'patch-compliance/{datetime.now().strftime(\"%Y/%m/%d\")}/summary.json',\n        Body=json.dumps(compliance_data)\n    )\n    \n    return compliance_data\n```\n\n**Option B: Third-Party Integration (for demo)**\n- Configure integration with tools like Datadog, Splunk, or custom Grafana dashboards\n- Ensure real-time compliance visibility across all managed accounts\n\n### Step 5: Integrate with Change Management System (Week 3)\n**⏱️ Time: 8-12 hours | 👤 Role: ITSM Engineer**\n\n```python\n# EventBridge rule to create ServiceNow change request before patching\n{\n    \"source\": [\"aws.ssm\"],\n    \"detail-type\": [\"Maintenance Window Execution State-change Notification\"],\n    \"detail\": {\n        \"status\": [\"PENDING\"]\n    }\n}\n\n# Lambda to create ServiceNow change request\ndef create_change_request(event):\n    servicenow_payload = {\n        \"short_description\": f\"Scheduled Patch Maintenance - {event['detail']['window-id']}\",\n        \"type\": \"Standard\",\n        \"category\": \"Maintenance\",\n        \"assignment_group\": \"Cloud Operations\",\n        \"start_date\": event['detail']['window-execution-time'],\n        \"end_date\": calculate_end_time(event),\n        \"cmdb_ci\": get_affected_instances(event)\n    }\n    # POST to ServiceNow API\n```\n\n### Step 6: Prepare Live Demonstration Script (Week 3-4)\n**⏱️ Time: 4-6 hours | 👤 Role: Solutions Architect**\n\n**Demo Script Outline:**\n```\n[0:00-2:00] Introduction\n- Show multi-account structure in AWS Organizations\n- Navigate to Systems Manager console\n\n[2:00-6:00] Patch Baseline Configuration\n- Display custom patch baselines for Windows/Linux\n- Explain approval rules and compliance levels\n- Show patch groups and instance associations\n\n[6:00-10:00] Maintenance Window Demonstration\n- Show configured maintenance windows per customer\n- Display scheduled tasks and target groups\n- Explain cutoff times and duration settings\n\n[10:00-15:00] Compliance Dashboard\n- Navigate to Systems Manager Compliance\n- Show multi-account compliance summary\n- Drill down into non-compliant instances\n- Demonstrate filtering by severity\n\n[15:00-20:00] Reporting and Automation\n- Generate patch compliance report\n- Show historical compliance trends\n- Demonstrate automated notification workflow\n\n[20:00-25:00] Exception Handling\n- Show patch exception process\n- Demonstrate approved exclusions\n- Explain rollback procedures\n```\n\n### Step 7: Conduct Internal Audit and Refinement (Week 4)\n**⏱️ Time: 8-10 hours | 👤 Role: Compliance Manager**\n\n- [ ] Run mock audit with internal team\n- [ ] Verify all demo components work end-to-end\n- [ ] Ensure compliance data is current (within 7 days)\n- [ ] Validate customer data anonymization in reports\n- [ ] Test demo recording quality and audio clarity\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Demonstrating Only Manual Patch Scanning\n**Problem:** Showing `aws ssm send-command` with AWS-RunPatchBaseline in \"Scan\" mode only\n**Why It Fails:** Auditors require evidence of automated **installation**, not just scanning\n**Solution:** Demonstrate complete automation including:\n- Scheduled maintenance windows with Install operation\n- Automatic reboot handling\n- Post-patch compliance verification\n\n### ❌ Mistake 2: Single-Account Demo Environment\n**Problem:** Showing patch management in only one AWS account\n**Why It Fails:** MSPs must demonstrate multi-customer/multi-account orchestration capability\n**Solution:** \n- Set up minimum 3 accounts (Management + 2 Customer accounts)\n- Use Resource Data Sync to aggregate compliance data\n- Show cross-account IAM role assumption for patch operations\n\n### ❌ Mistake 3: Missing Application-Level Patching Evidence\n**Problem:** Demonstrating only OS patching (Windows Update, yum update)\n**Why It Fails:** Requirement explicitly states \"operating systems, **applications**, and security\"\n**Solution:** Include evidence of:\n- Application patching (Java, .NET, Apache, nginx)\n- Database patching (RDS automated patching configuration)\n- Container image patching (ECR image scanning + rebuild pipelines)\n\n### ❌ Mistake 4: No Historical Compliance Data\n**Problem:** Showing only current point-in-time compliance status\n**Why It Fails:** Auditors want to see consistent patch management over time\n**Solution:**\n- Maintain minimum 90 days of compliance history\n- Show trend graphs demonstrating sustained compliance\n- Include month-over-month improvement metrics\n\n### ❌ Mistake 5: Ignoring Patch Failure Scenarios\n**Problem:** Presenting only successful patch deployments\n**Why It Fails:** Auditors assess your ability to handle failures and exceptions\n**Solution:** Prepare evidence showing:\n- Patch failure notification and escalation workflow\n- Root cause analysis for failed patches\n- Exception approval process with documented justifications\n- Rollback execution evidence (even if from test environment)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Patch baselines cover all customer OS types** | Review SSM Patch Manager console → Patch baselines | Baselines exist for Windows Server 2016/2019/2022, Amazon Linux 2, Ubuntu, RHEL |\n| 2 | **Maintenance windows configured per customer** | List maintenance windows with customer tags | Each customer has dedicated maintenance window with appropriate schedule |\n| 3 | **Compliance data is current** | Check last sync time in Resource Data Sync | Data updated within last 24 hours |\n| 4 | **Multi-account visibility functional** | Navigate Systems Manager Explorer | Can view compliance across minimum 3 accounts from single console |\n| 5 | **Demo recording quality** | Play full recording on different device | Audio clear, screen readable at 1080p, no sensitive data visible |\n| 6 | **Patch policy SLAs documented** | Review policy document section 3 | Specific timeframes defined for Critical/High/Medium/Low patches |\n| 7 | **Exception process demonstrated** | Check for approved exception in SSM | At least one documented exception with approval trail |\n\n### 📊 Quality Criteria Matrix\n\n```\nEvidence Component          | Minimum Acceptable | Recommended\n----------------------------|-------------------|",
      "language": "en",
      "createdAt": "2026-01-07T03:19:51.593Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-009_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-009",
      "category": "Operations",
      "title": "Customer Deployment Pipelines",
      "advice": "# OPS-009: Customer Deployment Pipelines - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nCustomer Deployment Pipelines is a **mandatory requirement** that validates MSP partners can deliver modern DevOps practices to customers. AWS views automated deployment capability as fundamental to operational excellence - manual deployments introduce human error, inconsistency, and slow down customer innovation velocity. This requirement separates traditional \"lift-and-shift\" providers from true cloud-native MSPs.\n\n### 🎯 5 Key Points Auditors Specifically Evaluate\n\n1. **End-to-End Automation Flow**: Auditors trace the complete path from code commit → build → test → deploy. They verify no manual SSH sessions, console clicks, or script executions are required between stages.\n\n2. **Rollback Mechanism Proof**: Not just \"we can rollback\" - auditors want to see actual rollback execution logs or demonstrated rollback capability. They check if rollback is automated or requires manual intervention.\n\n3. **Consistent Usage Evidence**: Single deployment isn't enough. Auditors look for deployment history showing the pipeline has been used repeatedly (minimum 3-5 deployments over time).\n\n4. **Environment Parity**: Pipeline should deploy to multiple environments (dev → staging → prod) using the same artifacts, proving consistency.\n\n5. **Manual Approval vs Manual Deployment**: Auditors understand the difference - manual approval gates (e.g., production deployment approval) are acceptable; manual deployment steps (e.g., running scripts by hand) are not.\n\n### 🔧 Relevant AWS Services\n\n| Service | Role in Pipeline |\n|---------|------------------|\n| **AWS CodePipeline** | Orchestration - primary evidence source |\n| **AWS CodeBuild** | Build and test automation |\n| **AWS CodeDeploy** | Deployment automation with rollback |\n| **Amazon ECR** | Container image versioning |\n| **AWS CloudFormation/CDK** | Infrastructure deployment |\n| **Amazon ECS/EKS** | Container deployment targets |\n| **AWS Lambda** | Serverless deployment |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 Required Evidence Package\n\n#### Evidence Option A: Live Demonstration (Recommended)\n| Evidence Item | Format | Key Content |\n|---------------|--------|-------------|\n| Demo Recording | MP4/WebM (15-20 min) | Screen recording of full pipeline execution |\n| Pipeline Architecture Diagram | PDF/PNG | Visual flow showing all stages |\n| Rollback Demonstration | MP4 (5-10 min) | Separate recording showing rollback trigger and execution |\n\n#### Evidence Option B: Customer Example with Logs\n| Evidence Item | Format | Key Content |\n|---------------|--------|-------------|\n| Deployment History Export | PDF/CSV | CodePipeline execution history (30+ days) |\n| Pipeline Configuration | JSON/YAML export | buildspec.yml, appspec.yml, pipeline definition |\n| Customer Authorization Letter | PDF | Permission to share anonymized deployment data |\n\n### 📄 Specific Document Examples\n\n**File Naming Convention:**\n```\nOPS-009_CustomerDeploymentPipeline_[CustomerCode]_[Date].pdf\nOPS-009_PipelineDemo_Recording_2024-01.mp4\nOPS-009_DeploymentHistory_CustomerABC_30days.csv\nOPS-009_RollbackDemo_ECS-BlueGreen_2024-01.mp4\n```\n\n**Deployment History CSV Must Include:**\n```csv\nExecutionID,StartTime,EndTime,Status,CommitID,DeployedVersion,Environment,TriggerType\nexec-abc123,2024-01-15T10:30:00Z,2024-01-15T10:45:00Z,Succeeded,a1b2c3d,v2.3.1,production,Automatic\nexec-def456,2024-01-14T14:20:00Z,2024-01-14T14:22:00Z,Failed,e4f5g6h,v2.3.0,staging,Automatic\nexec-ghi789,2024-01-14T15:00:00Z,2024-01-14T15:12:00Z,Succeeded,e4f5g6h-fix,v2.3.0-hotfix,staging,Automatic\n```\n\n### 🎬 Demo Recording Must Show\n\n1. **Pipeline Trigger**: Git push or manual trigger initiation\n2. **Build Stage**: CodeBuild logs showing compilation/testing\n3. **Artifact Creation**: S3 upload or ECR push confirmation\n4. **Deployment Stage**: CodeDeploy or ECS service update\n5. **Health Check**: Application responding post-deployment\n6. **Rollback Execution**: Either automatic (failed health check) or manual trigger\n7. **Rollback Completion**: Previous version restored and healthy\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Select Your Evidence Scenario (Day 1)\n**⏱️ Time: 2 hours | 👤 Role: DevOps Lead**\n\nChoose between:\n- **Sandbox Demo**: Build a reference pipeline in your AWS demo account\n- **Customer Example**: Identify a customer with active, well-documented pipeline\n\n**For Sandbox Demo - Recommended Stack:**\n```bash\n# Quick-start architecture\nApplication: Sample Node.js/Python API\nRepository: AWS CodeCommit or GitHub\nBuild: AWS CodeBuild with buildspec.yml\nDeploy Target: Amazon ECS Fargate (Blue/Green)\nOrchestration: AWS CodePipeline\n```\n\n**Decision Matrix:**\n| Scenario | Pros | Cons |\n|----------|------|------|\n| Sandbox Demo | Full control, can show any feature | Need to build from scratch |\n| Customer Example | Real-world credibility | Need customer approval, may have gaps |\n\n---\n\n### Step 2: Build/Document Pipeline Architecture (Days 2-4)\n**⏱️ Time: 8-16 hours | 👤 Role: DevOps Engineer**\n\n**For Sandbox Pipeline - Create These Components:**\n\n```yaml\n# buildspec.yml - Must include test phase\nversion: 0.2\nphases:\n  install:\n    runtime-versions:\n      nodejs: 18\n  pre_build:\n    commands:\n      - echo \"Running unit tests...\"\n      - npm test\n  build:\n    commands:\n      - echo \"Building application...\"\n      - npm run build\n      - docker build -t $ECR_REPO:$CODEBUILD_RESOLVED_SOURCE_VERSION .\n  post_build:\n    commands:\n      - docker push $ECR_REPO:$CODEBUILD_RESOLVED_SOURCE_VERSION\n      - printf '{\"ImageURI\":\"%s\"}' $ECR_REPO:$CODEBUILD_RESOLVED_SOURCE_VERSION > imageDetail.json\nartifacts:\n  files:\n    - imageDetail.json\n    - appspec.yml\n    - taskdef.json\n```\n\n```yaml\n# appspec.yml for ECS Blue/Green\nversion: 0.0\nResources:\n  - TargetService:\n      Type: AWS::ECS::Service\n      Properties:\n        TaskDefinition: <TASK_DEFINITION>\n        LoadBalancerInfo:\n          ContainerName: \"app-container\"\n          ContainerPort: 8080\nHooks:\n  - AfterAllowTestTraffic: \"arn:aws:lambda:region:account:function:ValidateDeployment\"\n```\n\n**Create Pipeline with Rollback Configuration:**\n```bash\n# AWS CLI to create CodeDeploy deployment group with auto-rollback\naws deploy create-deployment-group \\\n  --application-name MyApp \\\n  --deployment-group-name Production \\\n  --deployment-config-name CodeDeployDefault.ECSLinear10PercentEvery1Minutes \\\n  --auto-rollback-configuration enabled=true,events=DEPLOYMENT_FAILURE,DEPLOYMENT_STOP_ON_ALARM \\\n  --alarm-configuration enabled=true,alarms=[{name=HighErrorRate}]\n```\n\n---\n\n### Step 3: Generate Deployment History (Days 5-10)\n**⏱️ Time: 30 min/day for 5 days | 👤 Role: DevOps Engineer**\n\n**Critical**: Auditors want to see consistent usage, not a one-time demo.\n\n**Daily Actions:**\n```bash\n# Day 5: Initial deployment\ngit commit -m \"feat: add health endpoint\" && git push\n\n# Day 6: Feature update\ngit commit -m \"feat: add metrics endpoint\" && git push\n\n# Day 7: Bug fix (shows pipeline handles fixes)\ngit commit -m \"fix: correct response format\" && git push\n\n# Day 8: Intentional failure + rollback\n# Deploy code that fails health check to trigger auto-rollback\n\n# Day 9-10: Normal deployments\ngit commit -m \"feat: add caching\" && git push\n```\n\n**Export History:**\n```bash\n# Export CodePipeline execution history\naws codepipeline list-pipeline-executions \\\n  --pipeline-name MyPipeline \\\n  --query 'pipelineExecutionSummaries[*].{ID:pipelineExecutionId,Status:status,Start:startTime,Trigger:trigger.triggerType}' \\\n  --output table > deployment_history.txt\n```\n\n---\n\n### Step 4: Record Demonstration Video (Day 11)\n**⏱️ Time: 3-4 hours | 👤 Role: DevOps Lead + Solutions Architect**\n\n**Recording Checklist:**\n\n```markdown\n## Demo Script - OPS-009 Customer Deployment Pipeline\n\n### Part 1: Pipeline Overview (3 min)\n- [ ] Show CodePipeline console with pipeline visualization\n- [ ] Explain each stage: Source → Build → Deploy-Staging → Approval → Deploy-Prod\n- [ ] Show deployment history (last 10 executions)\n\n### Part 2: Trigger New Deployment (5 min)\n- [ ] Make code change in IDE (visible on screen)\n- [ ] Commit and push to repository\n- [ ] Show pipeline automatically triggered\n- [ ] Narrate: \"No manual intervention required to start deployment\"\n\n### Part 3: Build Stage (3 min)\n- [ ] Show CodeBuild logs streaming\n- [ ] Highlight test execution output\n- [ ] Show artifact uploaded to S3/ECR\n\n### Part 4: Deployment Stage (5 min)\n- [ ] Show CodeDeploy deployment in progress\n- [ ] For ECS: Show Blue/Green traffic shifting\n- [ ] Show health checks passing\n- [ ] Verify new version responding (curl/browser)\n\n### Part 5: Rollback Demonstration (5 min)\n- [ ] Option A: Trigger manual rollback via CodeDeploy console\n- [ ] Option B: Show auto-rollback from previous failed deployment\n- [ ] Show previous version restored\n- [ ] Verify rolled-back version responding\n```\n\n**Recording Tools:**\n- OBS Studio (free) or Loom\n- Resolution: 1920x1080 minimum\n- Include audio narration explaining each step\n\n---\n\n### Step 5: Prepare Supporting Documentation (Day 12)\n**⏱️ Time: 4 hours | 👤 Role: Technical Writer/Solutions Architect**\n\n**Create Pipeline Architecture Document:**\n\n```markdown\n# Customer Deployment Pipeline Architecture\n\n## Overview\nThis document describes the automated CI/CD pipeline implemented for [Customer/Demo].\n\n## Pipeline Stages\n\n### 1. Source Stage\n- **Repository**: AWS CodeCommit / GitHub\n- **Branch**: main (production), develop (staging)\n- **Trigger**: Push event via CloudWatch Events\n\n### 2. Build Stage\n- **Service**: AWS CodeBuild\n- **Build Spec**: buildspec.yml\n- **Actions**: \n  - Run unit tests (Jest/pytest)\n  - Build Docker image\n  - Push to Amazon ECR\n  - Generate deployment artifacts\n\n### 3. Deploy to Staging\n- **Service**: AWS CodeDeploy\n- **Strategy**: Blue/Green\n- **Auto-rollback**: Enabled on deployment failure\n\n### 4. Manual Approval\n- **Approvers**: DevOps Team, Product Owner\n- **SLA**: 4 business hours\n- **Note**: This is approval, not manual deployment\n\n### 5. Deploy to Production\n- **Service**: AWS CodeDeploy\n- **Strategy**: Blue/Green with 10% linear rollout\n- **Auto-rollback**: Enabled on CloudWatch alarm trigger\n\n## Rollback Mechanism\n- Automatic rollback on failed health checks\n- Manual rollback available via CodeDeploy console\n- Rollback completes in <5 minutes\n```\n\n---\n\n### Step 6: Compile and Review Evidence Package (Day 13-14)\n**⏱️ Time: 4 hours | 👤 Role: MSP Program Manager**\n\n**Final Package Structure:**\n```\nOPS-009_CustomerDeploymentPipelines/\n├── 01_Demo_Recording/\n│   ├── OPS-009_FullPipelineDemo_2024-01-15.mp4\n│   └── OPS-009_RollbackDemo_2024-01-15.mp4\n├── 02_Deployment_History/\n│   ├── CodePipeline_ExecutionHistory_30days.pdf\n│   └── CodeDeploy_DeploymentHistory.csv\n├── 03_Configuration/\n│   ├── buildspec.yml\n│   ├── appspec.yml\n│   └── pipeline-definition.json\n├── 04_Architecture/\n│   ├── Pipeline_Architecture_Diagram.pdf\n│   └── Pipeline_Documentation.pdf\n└── 05_Customer_Authorization/ (if using customer example)\n    └── Customer_DataSharing_Authorization.pdf\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Showing Manual Script Execution as \"Automated\"\n**What Goes Wrong:**\nPipeline triggers, but then someone runs `./deploy.sh` manually on a bastion host.\n\n**Auditor Red Flag:**\n\"I see the pipeline completed, but how did the application actually get deployed to the servers?\"\n\n**Solution:**\nEnsure CodeDeploy agent or ECS service update handles the actual deployment. No SSH required.\n\n---\n\n### ❌ Mistake 2: No Rollback Evidence\n**What Goes Wrong:**\nDemo shows successful deployments only. When asked \"show me a rollback,\" presenter says \"we haven't needed one yet.\"\n\n**Auditor Red Flag:**\n\"The requirement specifically states 'supports automated deployments AND rollbacks.' I need to see rollback capability.\"\n\n**Solution:**\nIntentionally trigger a rollback before the audit:\n```bash\n# Deploy a version that fails health checks\n# Or manually trigger rollback via:\naws deploy stop-deployment --deployment-id d-ABC123 --auto-rollback-enabled\n```\n\n---\n\n### ❌ Mistake 3: Single Deployment in History\n**What Goes Wrong:**\nPipeline was built specifically for the audit. History shows only 1-2 executions.\n\n**Auditor Red Flag:**\n\"This pipeline was created last week with only one execution. I need to see consistent usage.\"\n\n**Solution:**\n- For sandbox: Run 5-10 deployments over 1-2 weeks before audit\n- For customer example: Export 30+ days of history\n\n---\n\n### ❌ Mistake 4: Confusing Infrastructure Pipeline with Application Pipeline\n**What Goes Wrong:**\nShowing CloudFormation/Terraform pipeline that deploys infrastructure, not application code.\n\n**Auditor Red Flag:**\n\"This deploys VPCs and EC2 instances. Where's the application deployment pipeline?\"\n\n**Solution:**\nShow application deployment (code → build → deploy). Infrastructure-as-Code pipelines are great but don't satisfy this requirement alone.\n\n---\n\n### ❌ Mistake 5: Manual Deployment Disguised as Approval\n**What Goes Wrong:**\n\"Approval\" stage actually requires someone to manually copy files or run deployment commands.\n\n**Auditor Red Flag:**\n\"What happens after approval is granted? Does the pipeline automatically continue, or does someone need to do something?\"\n\n**Solution:**\nAfter approval click in CodePipeline, deployment must proceed automatically:\n```\nApproval Granted → CodeDeploy Automatically Triggered → Deployment Completes\n```\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Pipeline triggers automatically on code push** | Push a commit, observe pipeline start without manual action | Pipeline execution starts within 2 minutes of push |\n| 2 | **Build stage includes automated testing** | Review buildspec.yml and CodeBuild logs | Test commands visible in build logs, tests pass/fail affects build status |\n| 3 | **Deployment requires zero manual commands** | Trace from build completion to running application | No SSH, no manual script execution, no console clicks for deployment |\n| 4 | **Rollback capability demonstrated** | Execute rollback (manual trigger or auto-triggere",
      "language": "en",
      "createdAt": "2026-01-07T03:21:08.490Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-010_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-010",
      "category": "Operations",
      "title": "Event Management and Dynamic Monitoring",
      "advice": "# OPS-010: Event Management and Dynamic Monitoring - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nEvent Management and Dynamic Monitoring is the **core of MSP operational capability**. AWS views this as the most fundamental requirement for determining whether a partner can truly \"manage\" customer workloads. This item evaluates whether you can detect issues before they become problems and respond proactively, rather than simply reacting to customer complaints.\n\n### 🔍 5 Key Points Auditors Evaluate\n\n1. **End-to-End Observability Architecture**\n   - Auditors verify whether metrics, logs, and traces are integrated to provide a complete picture, not just collected separately\n   - They check if you can correlate application-level issues with infrastructure-level metrics\n\n2. **Threshold Setting Rationale**\n   - They evaluate whether alarm thresholds are set based on actual workload characteristics, not arbitrary values like \"CPU 80%\"\n   - Baseline-based dynamic threshold application is highly valued\n\n3. **Tagging Strategy Consistency**\n   - They verify whether tagging is consistently applied across all customer accounts\n   - They check if tags are actually used for cost allocation, access control, and operational automation\n\n4. **Alert-to-Action Flow**\n   - They evaluate whether alerts are integrated with incident management systems and actually trigger response processes\n   - They verify alert fatigue prevention measures (noise reduction)\n\n5. **Customer-Specific Customization**\n   - They check whether monitoring is customized per customer rather than one-size-fits-all\n   - They evaluate whether business KPIs are reflected, not just technical metrics\n\n### 🛠️ Core AWS Services\n- **Amazon CloudWatch** (Metrics, Logs, Alarms, Dashboards, Synthetics, RUM)\n- **AWS X-Ray** (Distributed Tracing)\n- **Amazon OpenSearch Service** (Log Analytics)\n- **AWS CloudTrail** (API Activity Monitoring)\n- **Amazon EventBridge** (Event Routing)\n- **AWS Systems Manager** (OpsCenter, Explorer)\n- **AWS Resource Groups & Tag Editor**\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 Required Evidence List\n\n#### Evidence 1: Monitoring Architecture Design Document\n**File Name Example:** `MSP_Monitoring_Architecture_v2.3.pdf`\n\n**Required Content:**\n```\n- Multi-account monitoring architecture diagram (Central Monitoring Account structure)\n- Data flow: Agent → CloudWatch → Cross-account aggregation → Dashboard\n- Log retention policy per customer (hot/warm/cold tier)\n- Metrics collection interval and resolution settings rationale\n- Integration points with third-party tools (if applicable)\n```\n\n#### Evidence 2: Tagging Policy and Implementation Status\n**File Name Example:** `Tagging_Policy_and_Compliance_Report.xlsx`\n\n**Required Content:**\n| Tag Key | Purpose | Mandatory | Example Value | Compliance Rate |\n|---------|---------|-----------|---------------|-----------------|\n| Environment | Environment classification | Yes | prod/stg/dev | 98.5% |\n| CostCenter | Cost allocation | Yes | CC-12345 | 97.2% |\n| Owner | Resource owner | Yes | team-platform | 95.8% |\n| Application | Application identification | Yes | payment-api | 96.1% |\n| ManagedBy | Management entity | Yes | MSP-CompanyName | 99.9% |\n\n#### Evidence 3: Alarm Configuration Standards Document\n**File Name Example:** `CloudWatch_Alarm_Standards_Catalog.md`\n\n**Required Content:**\n```yaml\n# EC2 Instance Standard Alarms\nec2_cpu_utilization:\n  threshold_type: \"anomaly_detection\"  # Not static threshold\n  baseline_period: \"2_weeks\"\n  sensitivity: \"medium\"\n  evaluation_periods: 3\n  datapoints_to_alarm: 2\n  actions:\n    - sns_topic: \"ops-alerts-p2\"\n    - auto_remediation: \"scale_out_trigger\"\n  \nec2_status_check:\n  threshold: 1\n  comparison: \"GreaterThanThreshold\"\n  period: 60\n  evaluation_periods: 2\n  actions:\n    - sns_topic: \"ops-alerts-p1\"\n    - pagerduty_integration: true\n```\n\n#### Evidence 4: Live Dashboard Demo Recording\n**File Name Example:** `Dashboard_Demo_Recording_20240115.mp4` (10-15 minutes)\n\n**Required Demo Scenario:**\n1. Customer workload overview dashboard display (30 seconds)\n2. Drill-down from specific metric to related logs (2 minutes)\n3. X-Ray trace analysis for error investigation (2 minutes)\n4. Alarm triggering and notification confirmation (2 minutes)\n5. Tag-based resource filtering demonstration (1 minute)\n6. Cross-account dashboard switching (1 minute)\n7. Custom metric and business KPI display (2 minutes)\n\n#### Evidence 5: Log Export and Analysis Configuration\n**File Name Example:** `Log_Export_Configuration_Guide.pdf`\n\n**Required Content:**\n```\nApplication Log Export Configuration:\n├── CloudWatch Logs Agent Configuration (unified agent config)\n├── Log Group Naming Convention: /aws/{service}/{customer}/{environment}/{application}\n├── Metric Filter Examples (Error rate, Latency percentiles)\n├── Subscription Filter → Kinesis → OpenSearch Pipeline\n├── S3 Export for Long-term Retention (Lifecycle policy)\n└── Log Insights Query Library (20+ saved queries)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Build Central Monitoring Account Structure (Week 1-2)\n**Responsible:** Cloud Architect + Security Team\n\n```bash\n# Create CloudWatch Cross-Account Observability configuration\n# In Monitoring Account:\naws cloudwatch put-metric-stream \\\n  --name \"cross-account-metrics\" \\\n  --firehose-arn \"arn:aws:firehose:region:account:deliverystream/metrics-stream\" \\\n  --output-format \"opentelemetry0.7\"\n\n# In Source Account (customer workload account):\naws cloudwatch put-cross-account-access-policy \\\n  --policy-document file://cross-account-policy.json\n```\n\n**Deliverable:** Cross-account monitoring architecture operational and documented\n\n### Step 2: Implement Tagging Enforcement (Week 2-3)\n**Responsible:** Platform Team\n\n```python\n# AWS Config Rule for Tag Compliance\n# required-tags-config-rule.json\n{\n  \"ConfigRuleName\": \"required-tags-compliance\",\n  \"Source\": {\n    \"Owner\": \"AWS\",\n    \"SourceIdentifier\": \"REQUIRED_TAGS\"\n  },\n  \"InputParameters\": {\n    \"tag1Key\": \"Environment\",\n    \"tag2Key\": \"CostCenter\", \n    \"tag3Key\": \"Owner\",\n    \"tag4Key\": \"Application\",\n    \"tag5Key\": \"ManagedBy\"\n  },\n  \"Scope\": {\n    \"ComplianceResourceTypes\": [\n      \"AWS::EC2::Instance\",\n      \"AWS::RDS::DBInstance\",\n      \"AWS::Lambda::Function\",\n      \"AWS::S3::Bucket\"\n    ]\n  }\n}\n```\n\n**Deliverable:** Tag compliance rate 95%+ achieved and weekly report automated\n\n### Step 3: Configure Standard Application Log Export (Week 3-4)\n**Responsible:** DevOps Team\n\n```yaml\n# CloudWatch Agent Configuration Template\n# amazon-cloudwatch-agent.json\n{\n  \"logs\": {\n    \"logs_collected\": {\n      \"files\": {\n        \"collect_list\": [\n          {\n            \"file_path\": \"/var/log/application/*.log\",\n            \"log_group_name\": \"/aws/ec2/{customer_id}/{environment}/application\",\n            \"log_stream_name\": \"{instance_id}_{hostname}\",\n            \"timestamp_format\": \"%Y-%m-%d %H:%M:%S\",\n            \"multi_line_start_pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2}\",\n            \"retention_in_days\": 30\n          }\n        ]\n      }\n    },\n    \"log_stream_name\": \"default\",\n    \"force_flush_interval\": 5\n  }\n}\n```\n\n**Deliverable:** Log export configured for all managed workloads with standardized format\n\n### Step 4: Build Intelligent Alarm System (Week 4-5)\n**Responsible:** SRE Team\n\n```python\n# CloudWatch Anomaly Detection Alarm Creation Script\nimport boto3\n\ncloudwatch = boto3.client('cloudwatch')\n\n# Create anomaly detection model-based alarm\ncloudwatch.put_anomaly_detector(\n    Namespace='AWS/EC2',\n    MetricName='CPUUtilization',\n    Dimensions=[{'Name': 'InstanceId', 'Value': 'i-1234567890abcdef0'}],\n    Stat='Average',\n    Configuration={\n        'ExcludedTimeRanges': [\n            {\n                'StartTime': '2024-01-01T02:00:00Z',  # Exclude batch processing time\n                'EndTime': '2024-01-01T04:00:00Z'\n            }\n        ]\n    }\n)\n\n# Create alarm using anomaly detection\ncloudwatch.put_metric_alarm(\n    AlarmName='EC2-CPU-AnomalyDetection-i-1234567890abcdef0',\n    MetricsAndExpressions=[\n        {\n            'Id': 'm1',\n            'MetricStat': {\n                'Metric': {\n                    'Namespace': 'AWS/EC2',\n                    'MetricName': 'CPUUtilization',\n                    'Dimensions': [{'Name': 'InstanceId', 'Value': 'i-1234567890abcdef0'}]\n                },\n                'Period': 300,\n                'Stat': 'Average'\n            }\n        },\n        {\n            'Id': 'ad1',\n            'Expression': 'ANOMALY_DETECTION_BAND(m1, 2)',  # 2 standard deviations\n            'Label': 'CPUUtilization (expected)'\n        }\n    ],\n    ThresholdMetricId='ad1',\n    ComparisonOperator='LessThanLowerOrGreaterThanUpperThreshold',\n    EvaluationPeriods=3,\n    DatapointsToAlarm=2,\n    AlarmActions=['arn:aws:sns:region:account:ops-alerts']\n)\n```\n\n**Deliverable:** Anomaly detection-based intelligent alarms applied to all critical resources\n\n### Step 5: Build Real-Time Dashboard (Week 5-6)\n**Responsible:** Operations Team\n\n```json\n// CloudWatch Dashboard Definition Example\n{\n  \"widgets\": [\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"🔴 Critical Services Health\",\n        \"metrics\": [\n          [\"AWS/ApplicationELB\", \"HealthyHostCount\", \"TargetGroup\", \"tg-prod-api\"],\n          [\".\", \"UnHealthyHostCount\", \".\", \".\"]\n        ],\n        \"view\": \"timeSeries\",\n        \"stacked\": false,\n        \"period\": 60,\n        \"annotations\": {\n          \"horizontal\": [\n            {\"label\": \"Minimum Healthy\", \"value\": 2, \"color\": \"#ff0000\"}\n          ]\n        }\n      }\n    },\n    {\n      \"type\": \"log\",\n      \"properties\": {\n        \"title\": \"📋 Recent Errors (Last 1 hour)\",\n        \"query\": \"SOURCE '/aws/lambda/prod-api' | filter @message like /ERROR/ | stats count(*) as error_count by bin(5m)\",\n        \"region\": \"ap-northeast-2\",\n        \"view\": \"table\"\n      }\n    },\n    {\n      \"type\": \"metric\",\n      \"properties\": {\n        \"title\": \"💰 Business KPI - Orders per Minute\",\n        \"metrics\": [\n          [\"Custom/Business\", \"OrdersProcessed\", \"Environment\", \"prod\"]\n        ],\n        \"view\": \"singleValue\",\n        \"sparkline\": true\n      }\n    }\n  ]\n}\n```\n\n**Deliverable:** Customer-specific dashboards created with business KPIs included\n\n### Step 6: Demo Recording and Documentation (Week 6-7)\n**Responsible:** Technical Writer + Operations Lead\n\n**Demo Script Structure:**\n```\n[00:00-00:30] Opening: \"This is the monitoring system for Customer ABC's e-commerce platform\"\n[00:30-02:30] Overview Dashboard: Show overall health status and key metrics\n[02:30-05:00] Incident Investigation Scenario: \n  - Detect error spike in dashboard\n  - Drill-down to specific service\n  - Trace analysis with X-Ray\n  - Identify root cause in logs\n[05:00-07:00] Alarm System Demo:\n  - Show alarm configuration\n  - Demonstrate test alarm triggering\n  - Show notification in Slack/PagerDuty\n[07:00-09:00] Tag-based Operations:\n  - Filter resources by customer tag\n  - Show cost allocation by tag\n  - Demonstrate automated actions based on tags\n[09:00-10:00] Closing: Summary of monitoring capabilities\n```\n\n**Deliverable:** 10-15 minute demo video with clear narration\n\n### Step 7: Validation and Gap Analysis (Week 7-8)\n**Responsible:** MSP Program Lead\n\n```bash\n# Self-assessment checklist execution\naws cloudwatch describe-alarms --query 'MetricAlarms[?StateValue==`INSUFFICIENT_DATA`]' \n# → Alarms with INSUFFICIENT_DATA should be 0\n\naws resourcegroupstaggingapi get-resources --query 'ResourceTagMappingList[?Tags==`[]`]'\n# → Untagged resources should be 0\n\naws logs describe-log-groups --query 'logGroups[?retentionInDays==`null`]'\n# → Log groups without retention policy should be 0\n```\n\n**Deliverable:** Gap analysis report and remediation plan completed\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Alarm Threshold Justification Missing\n**Problem:** Setting CPU 80%, Memory 85% without explanation\n```\nAuditor: \"Why is the threshold 80%?\"\nBad Answer: \"It's a common industry standard\"\nGood Answer: \"Based on 3-month baseline analysis, this workload averages 45% CPU \nwith peaks at 72% during batch processing. We set 80% to allow 10% headroom \nabove peak while triggering before performance degradation occurs at 85%.\"\n```\n\n**Solution:** Document baseline analysis results and threshold derivation logic for each alarm\n\n### ❌ Mistake 2: Dashboard Without Context\n**Problem:** Showing only raw metrics without business context\n```\nBad: Dashboard showing only CPU, Memory, Network graphs\nGood: Dashboard with sections like:\n  - \"Customer Impact\" (Error rate, Response time affecting users)\n  - \"Business Metrics\" (Orders/min, Revenue impact)\n  - \"Infrastructure Health\" (Resource utilization)\n  - \"Cost Efficiency\" (Spend vs budget)\n```\n\n**Solution:** Structure dashboards around business impact, not just technical metrics\n\n### ❌ Mistake 3: Logs Collected But Not Analyzed\n**Problem:** Logs going to CloudWatch but no metric filters or insights queries\n```\nAuditor: \"Show me how you use these logs operationally\"\nBad: \"We store them for compliance and search when needed\"\nGood: \"We have 15 metric filters extracting error rates, latency percentiles, \nand business events. Here are our saved Insights queries for common \ninvestigation scenarios, and this subscription filter sends critical \nerrors to our SIEM in real-time.\"\n```\n\n**Solution:** Create at least 10+ metric filters and 20+ saved Log Insights queries\n\n### ❌ Mistake 4: Tagging Exists But Not Enforced\n**Problem:** Tagging policy documented but compliance is 60-70%\n```\nAuditor: \"What's your current tag compliance rate?\"\nBad: \"We have a policy and remind teams to tag resources\"\nGood: \"We enforce tagging through AWS Config rules and Service Control Policies. \nCurrent compliance is 97.2%. Non-compliant resources trigger automated \nnotifications and are flagged in our weekly operations review.\"\n```\n\n**Solution:** Implement preventive controls (SCPs) and detective controls (Config Rules) with automated remediation\n\n### ❌ Mistake 5: No Alert-to-Incident Integration\n**Problem:** Alarms exist but no clear path to incident response\n```\nAuditor: \"What happens when this alarm fires?\"\nBad: \"It sends an email to the ops team\"\nGoo",
      "language": "en",
      "createdAt": "2026-01-07T03:22:13.899Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-011_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-011",
      "category": "Operations",
      "title": "Operational Runbooks",
      "advice": "# OPS-011: Operational Runbooks - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\nOperational Runbooks are the **backbone of consistent, repeatable operations** in managed services. AWS requires MSP partners to demonstrate that their operations aren't dependent on individual knowledge (\"tribal knowledge\") but are systematized into documented procedures. This directly impacts:\n- **Service quality consistency** across different engineers and shifts\n- **Incident response speed** - no time wasted figuring out what to do\n- **Customer confidence** - proving you have mature operational processes\n\n### 🎯 What Auditors Specifically Look For\n\n1. **Alert-to-Action Mapping**: Each runbook must clearly link to specific CloudWatch alarms, EventBridge rules, or third-party monitoring alerts. Auditors check if \"Alert X triggers Runbook Y\" is explicitly documented.\n\n2. **Executable Steps, Not Concepts**: Auditors will verify runbooks contain actual CLI commands, console navigation paths, or API calls - not just \"check the instance status.\"\n\n3. **Evidence of Active Use**: Version history, last-modified dates within 6 months, or execution logs showing runbooks are actually used in production.\n\n4. **Coverage Across Three Domains**: \n   - Infrastructure alerts (EC2, RDS, networking)\n   - Security alerts (GuardDuty, Security Hub, IAM)\n   - Application/workload alerts (custom metrics, APM)\n\n5. **Escalation Paths**: Clear decision trees showing when to escalate, to whom, and through what channel.\n\n### 🔧 Relevant AWS Services\n- **AWS Systems Manager Documents (SSM Documents)**: Automated runbook execution\n- **AWS Systems Manager Automation**: Runbook orchestration\n- **Amazon CloudWatch Alarms**: Alert triggers\n- **AWS Security Hub**: Security alert aggregation\n- **Amazon EventBridge**: Event-driven runbook triggers\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|--------------------------|\n| **Infrastructure Runbooks** | PDF/Wiki Export/SSM Document | EC2, RDS, VPC, ELB alert responses |\n| **Security Runbooks** | PDF/Wiki Export | GuardDuty finding responses, IAM incident handling |\n| **Workload-Specific Runbooks** | PDF/Wiki Export | Customer application alerts |\n| **Runbook Index/Catalog** | Spreadsheet/Wiki | Master list mapping alerts to runbooks |\n| **Usage Evidence** | Screenshots/Logs | Proof of actual execution |\n\n### 📄 Specific Document Examples\n\n**Infrastructure Runbooks:**\n```\nRB-INF-001_EC2_HighCPU_Response_v2.3.pdf\nRB-INF-002_RDS_StorageFull_Remediation_v1.8.pdf\nRB-INF-003_ALB_5xxErrors_Triage_v3.1.pdf\nRB-INF-004_VPC_FlowLog_Anomaly_Investigation_v1.2.pdf\nRB-INF-005_EBS_IOPSThrottling_Resolution_v2.0.pdf\n```\n\n**Security Runbooks:**\n```\nRB-SEC-001_GuardDuty_UnauthorizedAccess_v2.1.pdf\nRB-SEC-002_IAM_RootAccountUsage_Response_v1.5.pdf\nRB-SEC-003_SecurityHub_CriticalFinding_Triage_v2.0.pdf\nRB-SEC-004_S3_PublicAccess_Remediation_v1.3.pdf\nRB-SEC-005_Compromised_Credentials_Response_v2.2.pdf\n```\n\n**Workload Runbooks:**\n```\nRB-WL-001_WebApp_HighLatency_Diagnosis_v1.4.pdf\nRB-WL-002_Database_ConnectionPool_Exhaustion_v2.0.pdf\nRB-WL-003_Lambda_Throttling_Response_v1.1.pdf\n```\n\n### 📋 Required Runbook Content Structure\n\nEach runbook MUST include:\n\n```markdown\n1. HEADER SECTION\n   - Runbook ID & Version\n   - Last Updated Date (within 6 months)\n   - Owner/Author\n   - Linked Alert(s): [CloudWatch Alarm ARN / GuardDuty Finding Type]\n\n2. TRIGGER CONDITIONS\n   - Exact alert threshold that triggers this runbook\n   - Example: \"CPUUtilization > 80% for 5 minutes\"\n\n3. IMPACT ASSESSMENT\n   - Severity classification criteria\n   - Business impact description\n\n4. DIAGNOSTIC STEPS\n   - Specific CLI commands with placeholders\n   - Console navigation: Service > Section > Specific Setting\n   - Expected outputs and interpretation\n\n5. REMEDIATION ACTIONS\n   - Step-by-step resolution procedures\n   - Rollback procedures if remediation fails\n\n6. ESCALATION CRITERIA\n   - When to escalate (time-based, severity-based)\n   - Escalation contacts with actual role names\n\n7. POST-INCIDENT\n   - Documentation requirements\n   - Metrics to record\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Alert Inventory Creation (3-4 days)\n**Responsible**: Operations Lead + Security Lead\n\n```bash\n# Export all CloudWatch Alarms across accounts\naws cloudwatch describe-alarms --query 'MetricAlarms[*].[AlarmName,MetricName,Threshold,ComparisonOperator]' --output table\n\n# List GuardDuty finding types you've encountered\naws guardduty list-findings --detector-id <detector-id> --query 'FindingIds'\n\n# Export Security Hub findings summary\naws securityhub get-findings --query 'Findings[*].[Title,Severity.Label,ProductName]'\n```\n\nCreate a spreadsheet mapping each alert to required runbook:\n| Alert Name | Service | Severity | Runbook Required | Status |\n|------------|---------|----------|------------------|--------|\n\n### Step 2: Runbook Gap Analysis (2 days)\n**Responsible**: Operations Manager\n\nCompare your alert inventory against existing documentation:\n- ✅ Documented with executable steps\n- ⚠️ Documented but needs update (>6 months old)\n- ❌ No runbook exists\n\n**Minimum coverage required for audit:**\n- 100% of P1/Critical alerts\n- 80% of P2/High alerts\n- Key security findings (Top 10 GuardDuty types)\n\n### Step 3: Runbook Development/Update (2-3 weeks)\n**Responsible**: Senior Engineers (domain experts)\n\n**For each runbook, capture:**\n\n```markdown\n## Example: EC2 High CPU Runbook\n\n### Linked Alert\nCloudWatch Alarm: `prod-web-ec2-high-cpu`\nThreshold: CPUUtilization > 85% for 10 minutes\n\n### Diagnostic Commands\n```bash\n# Get instance details\naws ec2 describe-instances --instance-ids i-xxxx --query 'Reservations[*].Instances[*].[InstanceId,InstanceType,State.Name]'\n\n# Check CPU metrics for last hour\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/EC2 \\\n  --metric-name CPUUtilization \\\n  --dimensions Name=InstanceId,Value=i-xxxx \\\n  --start-time $(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ) \\\n  --end-time $(date -u +%Y-%m-%dT%H:%M:%SZ) \\\n  --period 300 \\\n  --statistics Average\n\n# SSH and check top processes\ntop -bn1 | head -20\n```\n\n### Remediation Options\n1. **If caused by runaway process**: Kill process, investigate root cause\n2. **If legitimate load**: Trigger Auto Scaling or vertical scaling\n3. **If attack**: Engage security runbook RB-SEC-006\n```\n\n### Step 4: SSM Document Conversion (1 week)\n**Responsible**: DevOps Engineer\n\nConvert key runbooks to executable SSM Automation Documents:\n\n```yaml\n# Example: SSM Document for EC2 High CPU Response\nschemaVersion: '0.3'\ndescription: 'Automated response to EC2 High CPU alert'\nassumeRole: '{{AutomationAssumeRole}}'\nparameters:\n  InstanceId:\n    type: String\n    description: 'EC2 Instance ID'\nmainSteps:\n  - name: GetInstanceDetails\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: ec2\n      Api: DescribeInstances\n      InstanceIds:\n        - '{{InstanceId}}'\n  - name: CreateSnapshot\n    action: 'aws:executeAwsApi'\n    inputs:\n      Service: ec2\n      Api: CreateSnapshot\n      VolumeId: '{{GetInstanceDetails.Reservations[0].Instances[0].BlockDeviceMappings[0].Ebs.VolumeId}}'\n```\n\n### Step 5: Runbook Catalog Creation (2 days)\n**Responsible**: Operations Manager\n\nCreate master index showing alert-to-runbook mapping:\n\n| Alert Source | Alert Name | Severity | Runbook ID | Last Updated | Owner |\n|--------------|------------|----------|------------|--------------|-------|\n| CloudWatch | prod-rds-storage-80 | P2 | RB-INF-002 | 2024-01-15 | DBA Team |\n| GuardDuty | UnauthorizedAccess:IAMUser/ConsoleLogin | P1 | RB-SEC-001 | 2024-02-01 | SecOps |\n| Security Hub | S3.2 - Public Read Access | P1 | RB-SEC-004 | 2024-01-20 | SecOps |\n\n### Step 6: Usage Evidence Collection (Ongoing)\n**Responsible**: NOC/Operations Team\n\nCapture evidence of runbook usage:\n- **Ticket screenshots** showing runbook reference in incident resolution\n- **SSM Automation execution history** exports\n- **Confluence/Wiki page view statistics**\n- **Git commit history** showing runbook updates\n\n```bash\n# Export SSM Automation execution history\naws ssm describe-automation-executions \\\n  --filters Key=DocumentNamePrefix,Values=Runbook \\\n  --query 'AutomationExecutionMetadataList[*].[AutomationExecutionId,DocumentName,ExecutionStartTime,AutomationExecutionStatus]'\n```\n\n### Step 7: Review and Quality Assurance (3-4 days)\n**Responsible**: Operations Lead + Peer Review\n\n- Conduct tabletop exercises using runbooks\n- Verify all commands execute correctly\n- Update any outdated screenshots or console paths\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: \"Conceptual\" Runbooks Without Executable Steps\n**Problem**: Runbooks that say \"Check the instance health\" without specifying HOW.\n\n**Auditor Feedback**: *\"Runbook lacks actionable detail. An engineer unfamiliar with the system could not execute this.\"*\n\n**Fix**: Every step must include:\n```markdown\n❌ Bad: \"Check RDS performance\"\n✅ Good: \n1. Open CloudWatch Console > RDS > [Instance Name]\n2. Review these metrics for last 1 hour:\n   - CPUUtilization (threshold: >80%)\n   - FreeableMemory (threshold: <1GB)\n   - ReadLatency (threshold: >20ms)\n3. Run: `aws rds describe-db-instances --db-instance-identifier <name>`\n```\n\n### ❌ Mistake 2: Runbooks Without Alert Linkage\n**Problem**: Runbooks exist but don't specify WHICH alerts trigger them.\n\n**Auditor Feedback**: *\"Unable to determine how operations team knows when to use this runbook.\"*\n\n**Fix**: Add explicit trigger section:\n```markdown\n## Trigger\nThis runbook is activated when:\n- CloudWatch Alarm `prod-api-5xx-errors` transitions to ALARM state\n- PagerDuty incident created with tag `api-errors`\n- Alert threshold: HTTPCode_Target_5XX_Count > 100 in 5 minutes\n```\n\n### ❌ Mistake 3: Outdated Runbooks (Last Updated >12 Months)\n**Problem**: Runbooks reference deprecated services, old console UI, or removed features.\n\n**Auditor Feedback**: *\"Evidence suggests runbooks are not actively maintained. Version dated 18 months ago.\"*\n\n**Fix**: \n- Implement quarterly runbook review cycle\n- Add \"Last Validated\" date separate from \"Last Modified\"\n- Use SSM Documents with version control\n\n### ❌ Mistake 4: Missing Security Runbooks\n**Problem**: Only infrastructure runbooks provided; no security incident response procedures.\n\n**Auditor Feedback**: *\"Requirement specifies security alerts. No evidence of GuardDuty or Security Hub response procedures.\"*\n\n**Required Security Runbooks (minimum):**\n- GuardDuty high-severity finding response\n- Compromised IAM credentials response\n- S3 public access remediation\n- Security group modification investigation\n- Root account activity response\n\n### ❌ Mistake 5: No Evidence of Actual Usage\n**Problem**: Beautiful runbooks that have never been used in production.\n\n**Auditor Feedback**: *\"Unable to verify runbooks are used in day-to-day operations as required.\"*\n\n**Fix**: Provide at least 3 examples of:\n- Incident tickets referencing specific runbook IDs\n- SSM Automation execution logs\n- Post-incident reports citing runbook usage\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Alert Coverage Completeness** | Cross-reference runbook catalog against CloudWatch/GuardDuty/Security Hub alerts | ≥90% of P1/P2 alerts have linked runbooks |\n| 2 | **Executable Commands Present** | Random sample 5 runbooks, verify CLI/console steps | Every runbook has copy-paste ready commands |\n| 3 | **Version Currency** | Check \"Last Updated\" dates on all runbooks | No runbook older than 6 months without validation note |\n| 4 | **Three-Domain Coverage** | Count runbooks by category | Minimum: 5 Infrastructure, 5 Security, 3 Workload |\n| 5 | **Escalation Paths Defined** | Review escalation sections | Every runbook has specific escalation criteria and contacts |\n| 6 | **Usage Evidence Available** | Collect ticket/execution screenshots | Minimum 3 incidents showing runbook usage in last 90 days |\n| 7 | **SSM Integration Demonstrated** | Export SSM Document list | At least 3 runbooks converted to SSM Automation Documents |\n\n### 📊 Quality Scoring Matrix\n\n**Score each runbook 1-5:**\n\n| Criteria | 1 (Fail) | 3 (Acceptable) | 5 (Excellent) |\n|----------|----------|----------------|---------------|\n| Alert Linkage | No trigger specified | Alert name mentioned | Full ARN + threshold documented |\n| Actionability | Conceptual only | Some commands | Complete CLI + console steps |\n| Escalation | None | Time-based only | Decision tree with multiple criteria |\n| Maintenance | >12 months old | 6-12 months | <6 months + validation record |\n\n**Minimum passing score**: Average 3.5 across all submitted runbooks\n\n### ✅ Final Evidence Package Checklist\n\n```\n📁 OPS-011_Operational_Runbooks/\n├── 📄 Runbook_Catalog_Index.xlsx\n├── 📁 Infrastructure_Runbooks/\n│   ├── RB-INF-001_EC2_HighCPU_v2.3.pdf\n│   ├── RB-INF-002_RDS_Storage_v1.8.pdf\n│   └── ... (minimum 5)\n├── 📁 Security_Runbooks/\n│   ├── RB-SEC-001_GuardDuty_Response_v2.1.pdf\n│   ├── RB-SEC-002_IAM_Compromise_v1.5.pdf\n│   └── ... (minimum 5)\n├── 📁 Workload_Runbooks/\n│   ├── RB-WL-001_AppLatency_v1.4.pdf\n│   └── ... (minimum 3)\n├── 📁 SSM_Documents/\n│",
      "language": "en",
      "createdAt": "2026-01-07T03:23:17.904Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-012_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-012",
      "category": "Operations",
      "title": "Anomaly Detection",
      "advice": "# OPS-012: Anomaly Detection - Practical Implementation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\n\nAnomaly Detection은 MSP의 **운영 성숙도를 판단하는 핵심 지표**입니다. 단순 임계값(threshold) 기반 알람은 워크로드 특성을 반영하지 못해 불필요한 알람(noise)을 발생시키고, 실제 문제를 놓치는 경우가 많습니다. AWS는 MSP가 **통계적/ML 기반 이상 탐지**를 통해 고객에게 proactive한 운영 서비스를 제공할 수 있는지 검증합니다.\n\n### 🎯 Auditor가 중점적으로 확인하는 5가지 포인트\n\n| 확인 포인트 | 구체적 검증 내용 |\n|------------|-----------------|\n| **1. ML/통계 모델 사용 여부** | 단순 static threshold가 아닌 CloudWatch Anomaly Detection, Amazon DevOps Guru, 또는 자체 ML 모델 사용 증거 |\n| **2. 다양한 메트릭 커버리지** | CPU, Memory뿐 아니라 Application-level metrics, Business metrics까지 anomaly detection 적용 |\n| **3. False Positive 감소 효과** | 기존 static alarm 대비 알람 수 감소 데이터, alarm fatigue 개선 지표 |\n| **4. 실제 이상 탐지 사례** | Anomaly detection이 실제 문제를 조기 발견한 incident 사례 |\n| **5. 고객 환경 적용 증거** | 내부 테스트가 아닌 실제 고객 프로덕션 환경에서의 구현 |\n\n### 🔧 관련 AWS 서비스 및 기능\n\n```\nPrimary Services:\n├── Amazon CloudWatch Anomaly Detection (ANOMALY_DETECTION_BAND)\n├── Amazon DevOps Guru (ML-powered insights)\n├── Amazon Lookout for Metrics (standalone anomaly detection)\n└── AWS X-Ray Analytics (trace anomaly detection)\n\nSupporting Services:\n├── Amazon CloudWatch Contributor Insights\n├── Amazon CloudWatch Logs Insights (anomaly queries)\n├── Amazon Managed Service for Prometheus (with Grafana ML)\n└── AWS Lambda (custom anomaly detection logic)\n```\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 필수 증거 목록\n\n#### Evidence 1: Anomaly Detection 아키텍처 문서\n**파일명 예시:** `CustomerA_AnomalyDetection_Architecture_v2.1.pdf`\n\n```yaml\n필수 포함 내용:\n  - 고객명 및 환경 개요 (anonymized 가능)\n  - 적용된 anomaly detection 서비스/도구 명시\n  - 메트릭 수집 → 이상 탐지 → 알림 흐름도\n  - 탐지 대상 메트릭 목록 (최소 10개 이상)\n  - Band/Model 설정 파라미터 (training period, sensitivity)\n  \n권장 형식: \n  - Lucidchart/Draw.io 아키텍처 다이어그램 포함\n  - 2-3페이지 분량\n```\n\n#### Evidence 2: CloudWatch Anomaly Detection 설정 스크린샷\n**파일명 예시:** `CustomerA_CW_AnomalyDetection_Console_Screenshots.pdf`\n\n```yaml\n필수 스크린샷:\n  1. CloudWatch Alarms 목록 - \"Anomaly detection\" 타입 필터링\n  2. 개별 Anomaly Detection Alarm 상세 설정 화면\n     - ANOMALY_DETECTION_BAND 함수 사용 확인\n     - Training period 설정 값\n     - Threshold 설정 (standard deviations)\n  3. Anomaly Detection Band가 표시된 메트릭 그래프\n     - 회색 band와 실제 메트릭 라인이 함께 보이는 화면\n  4. 최근 알람 히스토리 (실제 trigger 기록)\n```\n\n#### Evidence 3: DevOps Guru 또는 Lookout for Metrics 대시보드\n**파일명 예시:** `CustomerA_DevOpsGuru_Insights_Report.pdf`\n\n```yaml\n필수 포함 내용:\n  - DevOps Guru Insights 목록 (최근 30일)\n  - 탐지된 anomaly 상세 내용 (root cause 분석 포함)\n  - Recommendations 및 조치 내역\n  - 모니터링 대상 리소스 범위 (Resource coverage)\n```\n\n#### Evidence 4: Alarm Fatigue 개선 효과 보고서\n**파일명 예시:** `CustomerA_AlarmOptimization_BeforeAfter_Report.xlsx`\n\n```yaml\n필수 데이터:\n  Before (Static Threshold):\n    - 월별 총 알람 발생 건수\n    - False positive 비율 (조치 불필요 알람)\n    - 평균 알람 대응 시간\n    \n  After (Anomaly Detection):\n    - 월별 총 알람 발생 건수 (감소율 %)\n    - True positive 비율 향상\n    - 실제 incident 조기 탐지 사례 수\n    \n  비교 기간: 최소 3개월 전후 데이터\n```\n\n#### Evidence 5: Anomaly Detection으로 탐지한 실제 Incident 사례\n**파일명 예시:** `CustomerA_AnomalyDetection_IncidentCase_INC-2024-0892.pdf`\n\n```yaml\n필수 포함 내용:\n  - Incident 개요 및 비즈니스 영향\n  - Anomaly detection이 탐지한 시점 (timestamp)\n  - 탐지된 메트릭 및 anomaly 패턴 설명\n  - Static threshold였다면 놓쳤을 이유\n  - 조치 내역 및 해결 시간\n  - 고객 피드백 또는 감사 메시지 (있는 경우)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: 고객 환경 선정 및 현황 분석 (Day 1-2)\n**담당:** Cloud Operations Lead  \n**예상 소요:** 4시간\n\n```bash\n# 현재 CloudWatch Alarms 분석\naws cloudwatch describe-alarms \\\n  --query 'MetricAlarms[?TreatMissingData!=`notBreaching`].[AlarmName,Threshold,ComparisonOperator]' \\\n  --output table\n\n# Anomaly Detection 알람 현황 확인\naws cloudwatch describe-alarms \\\n  --query 'MetricAlarms[?Metrics[?Expression!=`null` && contains(Expression, `ANOMALY_DETECTION_BAND`)]]' \\\n  --output json\n```\n\n**선정 기준:**\n- 프로덕션 환경 (dev/test 제외)\n- 다양한 워크로드 타입 (EC2, RDS, Lambda, ECS 등)\n- 최소 6개월 이상 운영 이력 (ML 모델 학습 데이터 확보)\n\n---\n\n### Step 2: CloudWatch Anomaly Detection 알람 구성 (Day 3-5)\n**담당:** Cloud Engineer  \n**예상 소요:** 8시간\n\n```yaml\n# CloudFormation Template 예시\nAWSTemplateFormatVersion: '2010-09-09'\nResources:\n  CPUAnomalyAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      AlarmName: !Sub '${CustomerName}-EC2-CPU-AnomalyDetection'\n      AlarmDescription: 'CPU utilization anomaly detected using ML model'\n      Metrics:\n        - Id: cpu\n          MetricStat:\n            Metric:\n              Namespace: AWS/EC2\n              MetricName: CPUUtilization\n              Dimensions:\n                - Name: InstanceId\n                  Value: !Ref TargetInstance\n            Period: 300\n            Stat: Average\n          ReturnData: false\n        - Id: anomaly_detection_band\n          Expression: 'ANOMALY_DETECTION_BAND(cpu, 2)'\n          Label: CPUUtilization (expected range)\n          ReturnData: true\n      ThresholdMetricId: anomaly_detection_band\n      ComparisonOperator: LessThanLowerOrGreaterThanUpperThreshold\n      EvaluationPeriods: 3\n      DatapointsToAlarm: 2\n      TreatMissingData: missing\n      ActionsEnabled: true\n      AlarmActions:\n        - !Ref AlertSNSTopic\n```\n\n**적용 대상 메트릭 (최소 10개):**\n| 카테고리 | 메트릭 | Anomaly Detection 적용 이유 |\n|---------|--------|---------------------------|\n| Compute | EC2 CPUUtilization | 워크로드 패턴에 따른 정상 범위 학습 |\n| Compute | EC2 NetworkIn/Out | 트래픽 패턴 기반 이상 탐지 |\n| Database | RDS DatabaseConnections | 시간대별 연결 패턴 학습 |\n| Database | RDS ReadLatency | 정상 지연 시간 범위 자동 설정 |\n| Application | ALB RequestCount | 비즈니스 시간대별 트래픽 패턴 |\n| Application | ALB TargetResponseTime | 응답 시간 baseline 자동 조정 |\n| Lambda | Duration | 함수별 실행 시간 패턴 학습 |\n| Lambda | ConcurrentExecutions | 호출 패턴 기반 이상 탐지 |\n| Custom | BusinessTransactionCount | 비즈니스 메트릭 anomaly 탐지 |\n| Custom | ErrorRate | 에러율 급증 조기 탐지 |\n\n---\n\n### Step 3: Amazon DevOps Guru 활성화 (Day 6-7)\n**담당:** Cloud Operations Lead  \n**예상 소요:** 4시간\n\n```bash\n# DevOps Guru 활성화 (CloudFormation Stack 기반)\naws devops-guru update-resource-collection \\\n  --action ADD \\\n  --resource-collection '{\n    \"CloudFormation\": {\n      \"StackNames\": [\"CustomerA-Production-Stack\", \"CustomerA-Database-Stack\"]\n    }\n  }'\n\n# 또는 태그 기반 활성화\naws devops-guru update-resource-collection \\\n  --action ADD \\\n  --resource-collection '{\n    \"Tags\": {\n      \"AppBoundaryKey\": \"Application\",\n      \"TagValues\": [\"CustomerA-Production\"]\n    }\n  }'\n```\n\n**DevOps Guru 설정 체크리스트:**\n- [ ] SNS Topic 연결 (알림 수신)\n- [ ] Cost estimation 확인 (리소스 수 기반)\n- [ ] 최소 2주 학습 기간 확보\n\n---\n\n### Step 4: Baseline 데이터 수집 및 비교 분석 (Day 8-14)\n**담당:** Cloud Analyst  \n**예상 소요:** 6시간\n\n```python\n# Before/After 알람 분석 스크립트\nimport boto3\nfrom datetime import datetime, timedelta\n\ncloudwatch = boto3.client('cloudwatch')\n\ndef analyze_alarm_history(alarm_name, days=30):\n    response = cloudwatch.describe_alarm_history(\n        AlarmName=alarm_name,\n        HistoryItemType='StateUpdate',\n        StartDate=datetime.now() - timedelta(days=days),\n        EndDate=datetime.now()\n    )\n    \n    alarm_count = len([h for h in response['AlarmHistoryItems'] \n                       if 'ALARM' in h['HistorySummary']])\n    return alarm_count\n\n# Static vs Anomaly Detection 비교\nstatic_alarms = ['CPU-High-80', 'Memory-High-90']\nanomaly_alarms = ['CPU-AnomalyDetection', 'Memory-AnomalyDetection']\n\nprint(\"=== Alarm Fatigue Analysis ===\")\nprint(f\"Static Threshold Alarms (30 days): {sum(analyze_alarm_history(a) for a in static_alarms)}\")\nprint(f\"Anomaly Detection Alarms (30 days): {sum(analyze_alarm_history(a) for a in anomaly_alarms)}\")\n```\n\n---\n\n### Step 5: 실제 Anomaly 탐지 사례 문서화 (Day 15-20)\n**담당:** Incident Manager  \n**예상 소요:** 4시간\n\n**사례 문서 템플릿:**\n\n```markdown\n## Anomaly Detection Success Case\n\n### Incident Overview\n- **Incident ID:** INC-2024-0892\n- **Detection Time:** 2024-01-15 14:23:45 KST\n- **Customer Impact:** Prevented potential 2-hour outage\n\n### Anomaly Detection Details\n- **Metric:** RDS DatabaseConnections\n- **Normal Range (ML-predicted):** 45-120 connections\n- **Detected Value:** 187 connections (outside band)\n- **Static Threshold (if used):** 200 connections (would NOT have triggered)\n\n### Root Cause\nConnection pool leak in application after deployment at 14:00\n\n### Resolution\n- Identified problematic deployment within 15 minutes\n- Rollback completed at 14:45\n- Connection count normalized by 15:00\n\n### Business Value\n- Estimated prevented downtime: 2 hours\n- Estimated cost savings: $15,000 (based on customer's revenue impact model)\n```\n\n---\n\n### Step 6: 증거 패키지 구성 및 검증 (Day 21-23)\n**담당:** MSP Program Manager  \n**예상 소요:** 4시간\n\n```\nOPS-012_AnomalyDetection_Evidence/\n├── 01_Architecture/\n│   └── CustomerA_AnomalyDetection_Architecture_v2.1.pdf\n├── 02_Configuration/\n│   ├── CloudWatch_AnomalyDetection_Alarms_Screenshots.pdf\n│   ├── DevOpsGuru_Configuration_Screenshots.pdf\n│   └── CloudFormation_Templates/\n│       └── anomaly-detection-alarms.yaml\n├── 03_Effectiveness/\n│   ├── AlarmFatigue_BeforeAfter_Analysis.xlsx\n│   └── FalsePositive_Reduction_Report.pdf\n├── 04_IncidentCases/\n│   ├── INC-2024-0892_AnomalyDetection_Case.pdf\n│   └── INC-2024-1045_AnomalyDetection_Case.pdf\n└── 05_Summary/\n    └── OPS-012_Evidence_Summary.pdf\n```\n\n---\n\n### Step 7: 내부 리뷰 및 최종 ",
      "language": "en",
      "createdAt": "2026-01-07T03:24:15.090Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-013_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-013",
      "category": "Operations",
      "title": "Predictive Monitoring and AIOps",
      "advice": "# OPS-013: Predictive Monitoring and AIOps - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Important in AWS MSP Program\nThis item evaluates whether your organization has **evolved beyond reactive monitoring to proactive/predictive operations**. AWS positions this as a differentiator for advanced MSPs, demonstrating the ability to prevent issues before they impact customers rather than just responding to alerts.\n\n### 🔎 Key Points Auditors Look For\n\n1. **Actual \"Prediction\" Evidence**: Not just anomaly detection after the fact, but proof that the system predicted issues *before* threshold breaches occurred\n2. **Automated Action or Alert Trigger**: Evidence that predictions led to automated remediation or proactive alerts (not just dashboards)\n3. **ML/Statistical Model Usage**: Demonstration of actual machine learning models or statistical forecasting (not just static thresholds)\n4. **Business Impact Documentation**: Clear narrative showing how predictive capability prevented customer-impacting incidents\n5. **Continuous Learning Loop**: Evidence that models are refined based on outcomes (false positive/negative tracking)\n\n### 🛠️ Relevant AWS Services\n- **Amazon DevOps Guru**: Primary AWS service for ML-powered operational insights\n- **Amazon CloudWatch Anomaly Detection**: ML-based anomaly detection for metrics\n- **Amazon Lookout for Metrics**: Automated anomaly detection across multiple data sources\n- **Amazon Forecast**: Time-series forecasting for capacity planning\n- **AWS Lambda + SageMaker**: Custom predictive models\n- **Amazon EventBridge**: Automated action triggering based on predictions\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Key Content |\n|--------------|--------|-------------|\n| Customer Case Study Document | PDF (3-5 pages) | End-to-end predictive monitoring implementation story |\n| Prediction Alert Screenshots | PNG/PDF | Actual alerts triggered *before* threshold breach |\n| Timeline Comparison | Diagram | Side-by-side showing prediction time vs. actual incident time |\n| Automated Remediation Logs | CloudWatch Logs export | Lambda/SSM execution logs triggered by predictions |\n| Model Configuration | JSON/YAML + Screenshots | DevOps Guru or CloudWatch Anomaly Detection settings |\n\n### 📄 Specific Evidence Examples\n\n**1. Customer Case Study Document**\n- Filename: `AIOps_CustomerCase_[CustomerName]_[Date].pdf`\n- Must include:\n  - Customer environment overview (workload type, scale)\n  - Specific problem that predictive monitoring solved\n  - Technical architecture diagram showing prediction flow\n  - Quantified results (e.g., \"Predicted disk exhaustion 4 hours before occurrence\")\n\n**2. Prediction-to-Action Timeline**\n- Filename: `Predictive_Alert_Timeline_[IncidentID].pdf`\n- Content:\n  ```\n  T-4h: DevOps Guru anomaly insight generated (CPU pattern deviation)\n  T-3h: EventBridge triggered Lambda for capacity analysis\n  T-2h: Auto Scaling adjustment executed proactively\n  T-0h: Predicted traffic spike occurred - no customer impact\n  ```\n\n**3. DevOps Guru Insights Export**\n- Filename: `DevOpsGuru_Proactive_Insights_[CustomerName].pdf`\n- Screenshots showing:\n  - Proactive insights (not just reactive)\n  - Recommendations generated before incidents\n  - Associated CloudFormation stacks/resources\n\n**4. Automated Remediation Evidence**\n- Filename: `AIOps_Automation_Runbook_[CustomerName].pdf`\n- Include:\n  - EventBridge rule configuration\n  - Lambda function code snippets\n  - SSM Automation document\n  - Execution history logs\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Select the Right Customer Case (Week 1)\n**Action**: Identify a customer where you've implemented predictive capabilities with documented success\n\n**Selection Criteria**:\n- ✅ Has DevOps Guru or CloudWatch Anomaly Detection enabled for 3+ months\n- ✅ Has at least one documented case where prediction preceded actual issue\n- ✅ Customer willing to be referenced (anonymized is acceptable)\n- ✅ Automated action was triggered (not just alert sent to humans)\n\n**Tool**: Query DevOps Guru insights API to find proactive insights\n```bash\naws devops-guru list-insights --status-filter CLOSED --type PROACTIVE\n```\n\n**Time**: 3-4 hours | **Owner**: Technical Account Manager\n\n---\n\n### Step 2: Gather Prediction-Before-Incident Evidence (Week 1-2)\n**Action**: Collect specific timestamps proving prediction occurred before threshold breach\n\n**Specific Steps**:\n1. Export DevOps Guru insight with `InsightTimeRange`\n2. Cross-reference with CloudWatch alarm history\n3. Document the delta (prediction time minus incident time)\n\n**AWS CLI Command**:\n```bash\naws devops-guru describe-insight --id [insight-id] --output json > insight_detail.json\naws cloudwatch describe-alarm-history --alarm-name [related-alarm] --output json > alarm_history.json\n```\n\n**Critical**: Auditors will verify timestamps - ensure prediction timestamp is clearly *earlier* than when traditional monitoring would have alerted\n\n**Time**: 4-6 hours | **Owner**: Cloud Operations Engineer\n\n---\n\n### Step 3: Document the Automated Action Chain (Week 2)\n**Action**: Create visual flow showing prediction → automated response\n\n**Required Components**:\n```\n[DevOps Guru Insight] \n    → [EventBridge Rule] \n    → [Lambda Function / SSM Automation] \n    → [Remediation Action]\n    → [Verification Check]\n```\n\n**Evidence to Capture**:\n- EventBridge rule JSON configuration\n- Lambda function CloudWatch Logs showing execution\n- SSM Automation execution history\n- Before/after metric graphs\n\n**Tool**: AWS Step Functions if you have orchestrated workflows - export execution history\n\n**Time**: 6-8 hours | **Owner**: DevOps Engineer\n\n---\n\n### Step 4: Build the Customer Case Study Narrative (Week 2-3)\n**Action**: Write compelling story with specific metrics\n\n**Required Sections**:\n1. **Challenge**: What unpredictable operational issue existed?\n2. **Solution**: Which AWS AIOps services were implemented?\n3. **Prediction Example**: Specific incident that was predicted\n4. **Outcome**: Quantified business impact\n\n**Metric Examples to Include**:\n- \"Reduced MTTR from 45 minutes to 0 (prevented incidents)\"\n- \"Predicted 12 capacity issues over 6 months, all remediated automatically\"\n- \"False positive rate: 8% (acceptable threshold)\"\n\n**Time**: 4-5 hours | **Owner**: Solutions Architect + Technical Writer\n\n---\n\n### Step 5: Capture Model Configuration Evidence (Week 3)\n**Action**: Document how predictive models are configured and tuned\n\n**For DevOps Guru**:\n- Screenshot of enabled services/stacks\n- Cost anomaly detection settings\n- SNS notification configuration\n\n**For CloudWatch Anomaly Detection**:\n- Anomaly detection band configuration\n- Training period settings\n- Associated alarm configurations\n\n**Screenshot Requirements**:\n- Include timestamps in screenshots\n- Show customer account ID (can be partially redacted)\n- Display model training status\n\n**Time**: 2-3 hours | **Owner**: Cloud Operations Engineer\n\n---\n\n### Step 6: Create Continuous Improvement Documentation (Week 3)\n**Action**: Show that AIOps is not \"set and forget\"\n\n**Evidence Needed**:\n- False positive review meeting notes\n- Model tuning changelog\n- Feedback loop documentation\n\n**Example Format**:\n```markdown\n## AIOps Model Tuning Log - [Customer]\n| Date | Issue | Action | Result |\n|------|-------|--------|--------|\n| 2024-01 | High false positives on batch jobs | Excluded batch window from anomaly detection | FP rate dropped 60% |\n| 2024-02 | Missing predictions for gradual degradation | Adjusted sensitivity threshold | Caught 2 additional issues |\n```\n\n**Time**: 3-4 hours | **Owner**: Operations Manager\n\n---\n\n### Step 7: Compile and Review Evidence Package (Week 4)\n**Action**: Assemble all evidence with clear labeling\n\n**Folder Structure**:\n```\nOPS-013_Predictive_Monitoring/\n├── 01_Customer_Case_Study.pdf\n├── 02_Prediction_Timeline_Evidence/\n│   ├── DevOpsGuru_Insight_Export.json\n│   ├── Timeline_Diagram.png\n│   └── CloudWatch_Alarm_History.json\n├── 03_Automation_Evidence/\n│   ├── EventBridge_Rule_Config.json\n│   ├── Lambda_Execution_Logs.pdf\n│   └── Remediation_Screenshots.pdf\n├── 04_Model_Configuration/\n│   └── AnomalyDetection_Settings.pdf\n└── 05_Continuous_Improvement/\n    └── Model_Tuning_Log.pdf\n```\n\n**Time**: 2-3 hours | **Owner**: MSP Program Lead\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Reactive Anomaly Detection as \"Predictive\"\n**Problem**: Showing CloudWatch alarms that triggered *after* threshold breach\n**Why It Fails**: Auditors specifically look for prediction *before* traditional detection would trigger\n**Solution**: Ensure evidence shows clear time delta - prediction must precede the issue\n\n### ❌ Mistake 2: No Automated Action Component\n**Problem**: Showing dashboards and alerts but no automated remediation\n**Why It Fails**: AWS MSP expects AIOps to include automation, not just visualization\n**Solution**: Implement at minimum: EventBridge → Lambda → remediation action chain\n\n### ❌ Mistake 3: Using Only Static Threshold Alerting\n**Problem**: Presenting traditional monitoring with fixed thresholds as \"predictive\"\n**Why It Fails**: This is basic monitoring, not AIOps - no ML/statistical modeling involved\n**Solution**: Must use CloudWatch Anomaly Detection, DevOps Guru, or custom ML models\n\n### ❌ Mistake 4: No Customer Context\n**Problem**: Showing internal/demo environment instead of actual customer implementation\n**Why It Fails**: Requirement explicitly states \"customer example\"\n**Solution**: Must be production customer environment (anonymization is acceptable)\n\n### ❌ Mistake 5: Missing Business Impact Quantification\n**Problem**: Technical evidence without business outcome metrics\n**Why It Fails**: Auditors want to see value delivered, not just technology deployed\n**Solution**: Include metrics like: incidents prevented, downtime avoided, cost savings\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Prediction precedes incident** | Compare timestamps in DevOps Guru insight vs. CloudWatch alarm | Prediction timestamp is ≥30 minutes before traditional alert would trigger |\n| 2 | **ML-based detection is used** | Verify CloudWatch Anomaly Detection or DevOps Guru is source | Evidence shows anomaly bands or ML insights, not static thresholds |\n| 3 | **Automated action is triggered** | Lambda/SSM execution logs present with matching timestamps | Execution log timestamp within 15 minutes of prediction |\n| 4 | **Customer environment confirmed** | Account ID visible (partial redaction OK), production workload described | Not a demo/sandbox account, real customer workload |\n| 5 | **Business impact documented** | Case study includes quantified outcomes | At least 2 specific metrics (e.g., incidents prevented, time saved) |\n| 6 | **Continuous improvement shown** | Model tuning log or feedback documentation present | At least 2 tuning actions documented with dates |\n| 7 | **End-to-end flow documented** | Architecture diagram shows prediction → action → verification | Complete chain visible, no gaps in automation flow |\n\n### 🎯 Quality Criteria Summary\n- **Minimum Bar**: One customer example with DevOps Guru or CloudWatch Anomaly Detection showing prediction before incident + automated response\n- **Strong Evidence**: Multiple prediction examples, quantified business impact, documented model tuning history\n- **Excellent Evidence**: Custom ML models (SageMaker), integration with ITSM tools, demonstrated reduction in false positives over time\n\n---\n\n## 💡 Pro Tips for This Item\n\n1. **DevOps Guru is Your Friend**: If you haven't implemented AIOps yet, DevOps Guru is the fastest path - enable it on a customer's CloudFormation stacks and wait 2-3 weeks for insights\n\n2. **Capture Evidence Proactively**: Set up a process to screenshot/export every proactive insight when it occurs - reconstructing evidence later is difficult\n\n3. **The \"Prediction Delta\" is Key**: Auditors love seeing specific numbers like \"predicted 4 hours before traditional monitoring would have alerted\"\n\n4. **Anonymization is Acceptable**: If customer won't allow naming, redact company name but keep technical details - auditors understand confidentiality constraints",
      "language": "en",
      "createdAt": "2026-01-07T03:25:11.066Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-014_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-014",
      "category": "Operations",
      "title": "Knowledge Management",
      "advice": "# OPS-014: Knowledge Management - Practical Advice\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nKnowledge Management is the **core infrastructure that determines MSP operational quality**. AWS views this as a key indicator of whether an MSP can provide consistent service quality and enable rapid onboarding of new engineers. Without a well-organized knowledge management system, customer workload operations become dependent on specific individuals, creating significant risk.\n\n### 5 Key Points Auditors Evaluate\n\n1. **Searchability** - Can engineers quickly find the information they need? Auditors will actually search for specific topics during the demo\n2. **Currency** - Is there a process for regular updates? Check last modified dates and version history\n3. **Coverage** - Does it cover both internal operational processes AND customer-specific workload details?\n4. **Structure** - Is information organized logically with clear taxonomy and navigation?\n5. **Accessibility** - Can all relevant team members access appropriate content based on their roles?\n\n### Relevant AWS Services & Tools\n\n- **AWS Systems Manager Documents (SSM Documents)** - For operational runbooks\n- **AWS Service Catalog** - For standardized provisioning procedures\n- **Amazon WorkDocs** - AWS's native documentation platform\n- **AWS Well-Architected Tool** - For customer workload documentation\n- Integration with tools like Confluence, Notion, SharePoint, or GitBook\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Format\n**Live Demonstration** - This is NOT a document submission item. You must show the actual system in operation.\n\n### Demo Content Structure\n\n| Category | Required Content | Example File/Page Names |\n|----------|-----------------|------------------------|\n| Internal Operations | SOPs, escalation procedures, on-call guides | `SOP-Incident-Response-P1.md`, `Escalation-Matrix-2024.xlsx` |\n| Customer Workloads | Architecture docs, runbooks, contact info | `[CustomerA]-Architecture-Overview.md`, `[CustomerB]-Deployment-Runbook.md` |\n| AWS Service Guides | Service-specific operational procedures | `Aurora-Failover-Procedure.md`, `EKS-Upgrade-Playbook.md` |\n| Troubleshooting | Known issues, resolution steps | `KB-001-EC2-Instance-Connect-Failure.md` |\n| Onboarding | New engineer guides, training materials | `Engineer-Onboarding-Week1-Checklist.md` |\n\n### Specific Evidence Examples\n\n```\n📁 Knowledge Base Structure (Example)\n├── 📂 Internal-Operations/\n│   ├── 📄 Change-Management-Process-v2.3.md\n│   ├── 📄 Incident-Classification-Guide.md\n│   ├── 📄 On-Call-Rotation-Handbook.md\n│   └── 📄 Security-Incident-Response-Playbook.md\n├── 📂 Customer-Workloads/\n│   ├── 📂 Acme-Corp/\n│   │   ├── 📄 Architecture-Diagram-Current.drawio\n│   │   ├── 📄 Monthly-Maintenance-Runbook.md\n│   │   ├── 📄 Key-Contacts-Escalation.md\n│   │   └── 📄 Known-Issues-Workarounds.md\n│   └── 📂 Beta-Industries/\n│       ├── 📄 Multi-Region-DR-Procedure.md\n│       └── 📄 Cost-Optimization-Recommendations.md\n├── 📂 AWS-Service-Playbooks/\n│   ├── 📄 RDS-Aurora-Operations.md\n│   ├── 📄 EKS-Cluster-Management.md\n│   └── 📄 Lambda-Troubleshooting-Guide.md\n└── 📂 Training-Onboarding/\n    ├── 📄 New-Engineer-30-60-90-Plan.md\n    └── 📄 Tool-Access-Setup-Guide.md\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Select and Configure Platform (Week 1)\n**Time: 3-5 days | Owner: Operations Manager**\n\nChoose a platform that supports:\n- Full-text search with filters\n- Version history and change tracking\n- Role-based access control\n- Integration with ticketing systems\n\n**Recommended Options:**\n- Confluence + Jira integration (most common for audits)\n- Notion with workspace permissions\n- GitBook connected to GitHub repos\n- AWS WorkDocs with proper folder structure\n\n```bash\n# If using Git-based approach, set up structure:\nmkdir -p knowledge-base/{internal-ops,customer-workloads,aws-playbooks,training}\ngit init\necho \"# MSP Knowledge Base\" > README.md\n```\n\n### Step 2: Create Internal Operations Documentation (Week 2-3)\n**Time: 5-7 days | Owner: Senior Engineers + Process Owners**\n\nDocument these mandatory processes:\n1. **Incident Management** - P1/P2/P3/P4 classification, response times, escalation paths\n2. **Change Management** - CAB process, emergency change procedures\n3. **Problem Management** - Root cause analysis templates, known error database\n4. **Access Management** - Customer account access procedures, credential rotation\n\n**Template for Runbooks:**\n```markdown\n# [Process Name] Runbook\n\n## Purpose\n[One sentence describing when to use this]\n\n## Prerequisites\n- [ ] Required access/permissions\n- [ ] Required tools\n\n## Procedure\n1. Step with specific commands/actions\n2. Expected output/result\n3. Verification step\n\n## Rollback\n[Steps if something goes wrong]\n\n## Related Documents\n- Link to related KB articles\n\n## Revision History\n| Date | Author | Changes |\n|------|--------|---------|\n| 2024-01-15 | J.Smith | Initial version |\n```\n\n### Step 3: Document Customer Workloads (Week 3-4)\n**Time: 5-7 days | Owner: Assigned Customer Engineers**\n\nFor each managed customer, create:\n1. **Architecture Overview** - Current state diagram, key services used\n2. **Operational Runbook** - Daily/weekly/monthly tasks\n3. **Contact Matrix** - Customer contacts, escalation paths\n4. **Environment Details** - Account IDs, regions, naming conventions\n\n**Critical: Include at least 3 different customer workloads to demonstrate scalability**\n\n### Step 4: Build AWS Service Playbooks (Week 4-5)\n**Time: 4-5 days | Owner: Technical Leads**\n\nCreate playbooks for your most commonly managed services:\n- **Compute**: EC2 instance recovery, ASG troubleshooting, EKS node issues\n- **Database**: RDS failover, Aurora scaling, DynamoDB throttling\n- **Networking**: VPC connectivity issues, Direct Connect failover\n- **Security**: GuardDuty finding response, IAM access issues\n\n**Link to AWS documentation but add MSP-specific context:**\n```markdown\n## Aurora Failover Procedure\n\n### AWS Reference\n[Aurora Failover Documentation](https://docs.aws.amazon.com/...)\n\n### MSP-Specific Steps\n1. Before initiating failover, notify customer via [Slack channel/PagerDuty]\n2. Check current replication lag in CloudWatch: `AuroraReplicaLag`\n3. [Your specific commands and verification steps]\n```\n\n### Step 5: Implement Search and Navigation (Week 5)\n**Time: 2-3 days | Owner: Platform Admin**\n\nConfigure:\n- **Tags/Labels**: `customer:acme`, `service:rds`, `type:runbook`, `priority:critical`\n- **Search filters**: By category, last updated, author\n- **Quick links**: Most accessed documents on homepage\n- **Related articles**: Cross-linking between documents\n\n### Step 6: Establish Governance Process (Week 5-6)\n**Time: 2-3 days | Owner: Operations Manager**\n\nCreate and document:\n1. **Review Schedule** - Quarterly review of all documents\n2. **Ownership Matrix** - Who owns which sections\n3. **Update Triggers** - When documents must be updated (post-incident, architecture change, etc.)\n4. **Quality Standards** - Minimum requirements for new articles\n\n### Step 7: Prepare Demo Script (Week 6)\n**Time: 1-2 days | Owner: Demo Presenter**\n\nCreate a 15-minute demo script covering:\n1. Homepage/dashboard overview (2 min)\n2. Search functionality demonstration (3 min)\n3. Internal operations documentation walkthrough (3 min)\n4. Customer workload documentation example (4 min)\n5. Update/governance process explanation (3 min)\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Empty or Placeholder Content\n**Problem**: Creating folder structures with \"Coming Soon\" or template-only content\n**Impact**: Immediate audit failure - auditors will click into random articles\n**Solution**: Every visible article must have substantive, real content. Hide incomplete sections.\n\n### ❌ Mistake 2: No Customer-Specific Documentation\n**Problem**: Only showing generic AWS procedures without customer workload details\n**Impact**: Fails the \"customer workload-specific details\" requirement explicitly stated\n**Solution**: Include sanitized but real customer documentation for at least 3 customers\n\n### ❌ Mistake 3: Outdated Information\n**Problem**: Documents showing \"Last updated: 18 months ago\" or referencing deprecated services\n**Impact**: Suggests knowledge base is not actively maintained\n**Solution**: Update timestamps on all demo-visible documents within 90 days. Remove references to deprecated services (like EC2-Classic).\n\n### ❌ Mistake 4: No Search Demonstration\n**Problem**: Only showing navigation/browsing without demonstrating search capability\n**Impact**: Auditors specifically want to see how engineers find information quickly\n**Solution**: Practice searching for specific scenarios: \"How do I handle an RDS failover for Customer X?\"\n\n### ❌ Mistake 5: Single-Person Knowledge\n**Problem**: All documents authored by one person, no collaborative editing visible\n**Impact**: Suggests knowledge isn't truly shared across the team\n**Solution**: Ensure multiple authors are visible, show comment/review history\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Demo Verification\n\n| Check Item | Verification Method | Pass Criteria |\n|------------|-------------------|---------------|\n| ✅ Search returns relevant results | Search \"incident response\" - verify results | Top 3 results are relevant documents |\n| ✅ Customer workloads documented | Navigate to 3 different customer sections | Each has architecture, runbook, contacts |\n| ✅ Internal processes complete | Check incident, change, problem management | All have complete, actionable procedures |\n| ✅ Recent updates visible | Sort by \"last modified\" | At least 10 documents updated in last 30 days |\n| ✅ Multiple contributors | Check author metadata | Minimum 3 different authors visible |\n| ✅ AWS services covered | Navigate to service playbooks | At least 5 AWS services with operational guides |\n| ✅ Access controls configured | Show permission settings | Demonstrate role-based access (customer data restricted) |\n\n### Demo Dry Run Checklist\n\n- [ ] **Internet connectivity** - Test on demo day network\n- [ ] **Login credentials** - Verify presenter has access\n- [ ] **Screen sharing** - Test resolution and readability\n- [ ] **Backup plan** - Have screenshots/recording if live demo fails\n- [ ] **Sample searches prepared** - 3-4 search queries ready to demonstrate\n- [ ] **Customer data sanitized** - No real customer names/sensitive data visible (or have NDA confirmation)\n\n### Quality Criteria for Passing\n\n| Criteria | Minimum Standard |\n|----------|-----------------|\n| Document count | 50+ substantive articles |\n| Customer coverage | 3+ customer workloads documented |\n| AWS service coverage | 5+ services with operational playbooks |\n| Update frequency | Evidence of updates within 90 days |\n| Search effectiveness | Relevant results in <3 seconds |\n| Navigation depth | No more than 3 clicks to any document |\n\n---\n\n## 💡 Pro Tips for Demo Success\n\n1. **Start with a real scenario**: \"Last week, we had a P1 incident. Let me show you how an engineer would find the response procedure...\"\n\n2. **Show the feedback loop**: Demonstrate how post-incident learnings get added to the knowledge base\n\n3. **Highlight integrations**: If your KB links to monitoring dashboards, ticketing systems, or AWS console - show it\n\n4. **Prepare for auditor questions**:\n   - \"How do you ensure documentation stays current?\"\n   - \"How do new engineers get trained using this system?\"\n   - \"Show me documentation for a specific customer's DR procedure\"\n\n5. **Have a backup**: Record a video walkthrough in case of technical issues during live demo",
      "language": "en",
      "createdAt": "2026-01-07T03:26:16.824Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-015_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-015",
      "category": "Operations",
      "title": "Disaster Recovery",
      "advice": "# OPS-015: Disaster Recovery - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nDisaster Recovery (DR) capability is a **core differentiator** that separates MSPs from basic resellers. AWS expects MSP Partners to demonstrate they can protect customer workloads against data loss and service disruption with **measurable, tested recovery capabilities**. This isn't about having backup policies on paper—auditors want proof that your DR automation actually works and meets committed SLAs.\n\n### 🎯 Key Points Auditors Specifically Evaluate\n\n1. **RTO/RPO Definition Alignment**: Auditors verify that backup frequency and recovery procedures mathematically align with stated RPO/RTO targets (e.g., if RPO is 1 hour, backup jobs must run at least hourly)\n\n2. **Automation Evidence**: Manual backup processes are insufficient—auditors look for AWS Backup plans, automated snapshots, or scripted backup jobs with scheduling proof\n\n3. **Recovery Test Execution Records**: Not just backup completion logs, but actual **restoration test documentation** showing data was successfully recovered and validated\n\n4. **Cross-Service Coverage**: Evidence must cover **2 different AWS services** (e.g., EC2 + RDS, not just two EC2 instances)\n\n5. **Time-Stamped Proof**: Recovery tests must include timestamps proving the actual recovery time achieved vs. the RTO target\n\n### 🛠️ Relevant AWS Services\n- **AWS Backup** (primary service for centralized backup management)\n- **Amazon RDS Automated Backups & Snapshots**\n- **Amazon EBS Snapshots**\n- **Amazon S3 Cross-Region Replication**\n- **AWS Elastic Disaster Recovery (DRS)**\n- **Amazon DynamoDB Point-in-Time Recovery**\n- **AWS CloudFormation** (for infrastructure recovery)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Purpose |\n|--------------|--------|---------|\n| Backup Policy Document | PDF/Word | Shows RTO/RPO definitions per workload tier |\n| AWS Backup Plan Screenshots | PNG/PDF | Proves automated backup configuration |\n| Backup Job Completion Reports | CSV/PDF export | Shows backup execution history |\n| Recovery Test Runbook | Word/Confluence export | Documents step-by-step recovery procedure |\n| Recovery Test Execution Log | Spreadsheet with timestamps | Proves actual recovery time achieved |\n| Post-Recovery Validation Checklist | PDF with signatures | Confirms data integrity after restore |\n\n### 📁 Specific File Name Examples\n\n```\nEvidence_OPS015_DR/\n├── 01_DR_Policy_CustomerX_TierDefinitions_v2.1.pdf\n├── 02_AWS_Backup_Plan_Production_EC2_Config.png\n├── 03_AWS_Backup_Plan_Production_RDS_Config.png\n├── 04_Backup_Job_Report_EC2_Jan2024.csv\n├── 05_Backup_Job_Report_RDS_Jan2024.csv\n├── 06_Recovery_Test_Runbook_EC2_v1.3.pdf\n├── 07_Recovery_Test_Runbook_RDS_v1.2.pdf\n├── 08_Recovery_Test_Log_EC2_20240115_RPO4h_RTO2h.xlsx\n├── 09_Recovery_Test_Log_RDS_20240120_RPO1h_RTO30min.xlsx\n├── 10_Post_Recovery_Validation_Checklist_Signed.pdf\n└── 11_Customer_DR_SLA_Agreement_Excerpt.pdf\n```\n\n### 📌 Key Content Required in Each Evidence\n\n**Backup Policy Document Must Include:**\n- Workload classification tiers (Tier 1: Mission Critical, Tier 2: Business Critical, etc.)\n- Specific RPO/RTO targets per tier (e.g., Tier 1: RPO 1hr/RTO 4hr)\n- Backup retention periods\n- Customer approval/sign-off section\n\n**Recovery Test Log Must Include:**\n- Test date and time (start/end timestamps)\n- Backup source identifier (snapshot ID, backup vault ARN)\n- Target RTO vs. Actual Recovery Time\n- Target RPO vs. Actual Data Loss Window\n- Pass/Fail determination with calculation\n- Tester name and validation steps performed\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Define RTO/RPO Tiers in Writing (Day 1-2)\n**Action**: Create a formal DR Policy document with tiered recovery objectives\n\n```markdown\nExample Tier Structure:\n- Tier 1 (Mission Critical): RPO ≤ 1 hour, RTO ≤ 4 hours\n- Tier 2 (Business Critical): RPO ≤ 4 hours, RTO ≤ 8 hours  \n- Tier 3 (Standard): RPO ≤ 24 hours, RTO ≤ 24 hours\n```\n\n**Tool**: Use AWS Well-Architected Tool's Reliability Pillar questions to validate tier definitions\n**Owner**: Solutions Architect + Customer Success Manager\n**Time**: 4-6 hours\n\n---\n\n### Step 2: Configure AWS Backup Plans per Tier (Day 3-5)\n**Action**: Create AWS Backup plans that mathematically satisfy each tier's RPO\n\n```bash\n# Example: Tier 1 backup plan (RPO 1 hour)\naws backup create-backup-plan --backup-plan '{\n  \"BackupPlanName\": \"Tier1-MissionCritical-Hourly\",\n  \"Rules\": [{\n    \"RuleName\": \"HourlyBackup\",\n    \"TargetBackupVaultName\": \"Production-Vault\",\n    \"ScheduleExpression\": \"cron(0 * * * ? *)\",\n    \"StartWindowMinutes\": 60,\n    \"CompletionWindowMinutes\": 120,\n    \"Lifecycle\": {\"DeleteAfterDays\": 35}\n  }]\n}'\n```\n\n**Screenshot Requirements**:\n- Backup plan summary showing schedule frequency\n- Resource assignments showing tagged resources\n- Backup vault settings\n\n**Owner**: Cloud Operations Engineer\n**Time**: 8-12 hours\n\n---\n\n### Step 3: Assign Resources Using Tags (Day 5-6)\n**Action**: Tag customer resources with backup tier classification\n\n```bash\n# Tag EC2 instance for Tier 1 backup\naws ec2 create-tags --resources i-0abc123def456 \\\n  --tags Key=BackupTier,Value=Tier1 Key=BackupEnabled,Value=true\n\n# Verify AWS Backup resource assignment\naws backup list-backup-selections --backup-plan-id <plan-id>\n```\n\n**Evidence to Capture**: Screenshot of AWS Backup > Backup plans > [Plan Name] > Resource assignments\n\n**Owner**: Cloud Operations Engineer\n**Time**: 2-4 hours\n\n---\n\n### Step 4: Collect 30+ Days of Backup Job History (Day 7-37)\n**Action**: Let backup jobs run, then export completion reports\n\n```bash\n# Export backup jobs for evidence\naws backup list-backup-jobs \\\n  --by-resource-type EC2 \\\n  --by-state COMPLETED \\\n  --by-created-after 2024-01-01 \\\n  --output json > ec2_backup_jobs_jan2024.json\n```\n\n**From AWS Console**: AWS Backup > Jobs > Backup jobs > Export to CSV\n\n**Key Data Points to Highlight**:\n- Job completion timestamps\n- Backup size\n- Resource ARN\n- Zero failed jobs (or documented remediation for failures)\n\n**Owner**: Cloud Operations Engineer\n**Time**: Ongoing (30+ days collection period)\n\n---\n\n### Step 5: Execute Recovery Test for Service #1 - EC2 (Day 38-39)\n**Action**: Perform documented recovery test with timestamp logging\n\n**Recovery Test Execution Log Template**:\n```\n| Metric | Value |\n|--------|-------|\n| Test Date | 2024-01-15 |\n| Source Backup | snap-0abc123def456789 |\n| Backup Timestamp | 2024-01-15 02:00:00 UTC |\n| Recovery Start Time | 2024-01-15 10:00:00 UTC |\n| Recovery End Time | 2024-01-15 11:23:00 UTC |\n| Actual Recovery Time | 1 hour 23 minutes |\n| Target RTO | 4 hours |\n| RTO Met? | ✅ YES (1.38h < 4h) |\n| Data Loss Window | 8 hours (last backup to test start) |\n| Target RPO | 4 hours |\n| RPO Met? | ⚠️ Exceeded (8h > 4h) - See notes |\n```\n\n**Validation Steps to Document**:\n1. Instance launched successfully\n2. OS boots and services start\n3. Application responds to health check\n4. Sample data query returns expected results\n\n**Owner**: Cloud Operations Engineer + Application Owner\n**Time**: 4-6 hours\n\n---\n\n### Step 6: Execute Recovery Test for Service #2 - RDS (Day 40-41)\n**Action**: Restore RDS from automated backup or snapshot\n\n```bash\n# Restore RDS instance from snapshot\naws rds restore-db-instance-from-db-snapshot \\\n  --db-instance-identifier restored-prod-db-test \\\n  --db-snapshot-identifier rds:prod-db-2024-01-20-04-00 \\\n  --db-instance-class db.r5.large\n```\n\n**RDS-Specific Validation**:\n1. Database endpoint becomes available\n2. Connection test succeeds\n3. Row count matches expected (compare to source)\n4. Application connectivity test passes\n\n**Time Tracking**:\n- Snapshot restore initiation: 10:00:00\n- DB instance available: 10:18:00\n- Application validation complete: 10:32:00\n- **Total Recovery Time: 32 minutes** (vs. RTO target of 30 minutes)\n\n**Owner**: DBA + Cloud Operations Engineer\n**Time**: 3-4 hours\n\n---\n\n### Step 7: Compile Evidence Package with Narrative (Day 42-43)\n**Action**: Create summary document connecting all evidence pieces\n\n**Summary Document Structure**:\n```\nDR Evidence Summary - Customer X\n\n1. DR Policy Reference: See Document 01 (Tier definitions)\n2. Backup Automation Proof:\n   - EC2: AWS Backup Plan \"Tier1-Hourly\" (Document 02)\n   - RDS: AWS Backup Plan \"Tier2-Daily\" (Document 03)\n3. Backup Execution History: 30-day reports (Documents 04-05)\n4. Recovery Test Results:\n   - EC2 Test: RTO 1h23m vs Target 4h ✅ (Document 08)\n   - RDS Test: RTO 32m vs Target 30m ⚠️ (Document 09)\n5. Lessons Learned: RDS recovery slightly exceeded RTO; \n   remediation plan to use Multi-AZ for faster failover\n```\n\n**Owner**: MSP Program Lead\n**Time**: 4-6 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake #1: Backup Jobs Exist But No Recovery Test\n**Problem**: Partners show AWS Backup plans and job history but never actually tested restoration\n**Auditor Response**: \"Backup without tested recovery is not disaster recovery—it's hope\"\n**Fix**: Execute and document at least one recovery test per service type within 90 days of audit\n\n### ❌ Mistake #2: RTO/RPO Numbers Don't Match Backup Frequency\n**Problem**: Policy states RPO of 1 hour, but backup plan runs daily\n**Auditor Calculation**: Daily backup = 24-hour maximum data loss = RPO of 24 hours, not 1 hour\n**Fix**: Ensure backup schedule frequency ≤ stated RPO (hourly backups for 1-hour RPO)\n\n### ❌ Mistake #3: Using Same Service Type Twice\n**Problem**: Submitting EC2 backup + EC2 recovery test AND another EC2 instance as \"2 services\"\n**Auditor Response**: \"We need 2 different AWS services, not 2 instances of the same service\"\n**Fix**: Choose distinct services: EC2 + RDS, or DynamoDB + S3, or EBS + Aurora\n\n### ❌ Mistake #4: Recovery Test Without Timestamps\n**Problem**: Recovery test document says \"recovery completed successfully\" without time proof\n**Auditor Question**: \"How do we know you met the RTO if there are no timestamps?\"\n**Fix**: Include start time, end time, and calculated duration in every recovery test log\n\n### ❌ Mistake #5: No Customer-Specific RTO/RPO Definition\n**Problem**: Using generic \"best practice\" numbers without customer agreement\n**Auditor Concern**: \"Are these the customer's actual requirements or your assumptions?\"\n**Fix**: Include excerpt from customer SLA or signed DR requirements document\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | RTO/RPO targets are explicitly defined per workload tier | Review DR Policy document Section 2 | Numeric targets stated (e.g., \"RPO: 4 hours\") not vague (\"minimize data loss\") |\n| 2 | Backup frequency mathematically satisfies RPO | Compare AWS Backup plan schedule to stated RPO | Schedule interval ≤ RPO target |\n| 3 | AWS Backup plans show automated scheduling | Screenshot includes \"Schedule expression\" field | Cron expression or rate expression visible |\n| 4 | Backup job history covers minimum 30 days | Check date range in exported job report | Earliest job date ≥ 30 days before submission |\n| 5 | Recovery tests cover 2 different AWS services | List services in evidence summary | Two distinct service types (EC2≠EC2, must be EC2+RDS or similar) |\n| 6 | Recovery test logs include start/end timestamps | Review test execution spreadsheet | Both timestamps present with timezone |\n| 7 | Actual recovery time vs. RTO target is calculated | Check \"RTO Met?\" field in test log | Explicit Pass/Fail with calculation shown |\n| 8 | Post-recovery data validation is documented | Review validation checklist | Specific checks performed (row counts, checksums, app tests) |\n| 9 | Evidence files are clearly named and organized | Review folder structure | File names indicate content; logical numbering |\n| 10 | Summary document connects all evidence pieces | Read narrative summary | Each evidence file referenced with explanation |\n\n### ✅ Quality Gate: Ready for Submission When:\n- [ ] Both recovery tests show RTO achieved (or documented remediation plan if exceeded)\n- [ ] Backup job reports show <5% failure rate over 30 days\n- [ ] All screenshots are legible with timestamps visible\n- [ ] Customer name/workload is consistently referenced across documents\n- [ ] No conflicting information between policy and actual configuration\n\n---\n\n## 💡 Pro Tips from Passed Audits\n\n1. **Use AWS Backup Audit Manager**: Generate compliance reports automatically—auditors love seeing AWS-native compliance evidence\n\n2. **Include a \"Near Miss\" with Remediation**: If one test slightly exceeded RTO, document what you learned and how you improved. This shows maturity over perfection.\n\n3. **Cross-Region Recovery Bonus**: If you demonstrate cross-region restore capability, it significantly strengthens your evidence even though not strictly required\n\n4. **Tag Everything**: Consistent tagging (BackupTier, BackupEnabled, RPO, RTO) shows systematic approach rather than ad-hoc backup configuration",
      "language": "en",
      "createdAt": "2026-01-07T03:27:23.487Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-016_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-016",
      "category": "Operations",
      "title": "Cloud Financial Management",
      "advice": "# OPS-016: Cloud Financial Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nCloud Financial Management (FinOps) is a **core differentiator** that distinguishes MSPs from simple resellers. AWS views this capability as essential because:\n- It directly impacts customer ROI and long-term AWS adoption success\n- Demonstrates the MSP's ability to provide ongoing value beyond initial migration\n- Shows maturity in operating AWS environments at scale with financial accountability\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **TCO Analysis Methodology Completeness**\n   - Does it include on-premises hidden costs (facilities, power, cooling, admin overhead)?\n   - Are AWS-specific factors calculated (Reserved Instances, Savings Plans, Spot pricing)?\n   - Is there a 3-5 year projection model with realistic growth assumptions?\n\n2. **Cost Monitoring Proactiveness**\n   - Real-time alerting vs. monthly bill shock discovery\n   - Anomaly detection capabilities (not just threshold alerts)\n   - Tagging strategy enforcement and compliance tracking\n\n3. **Reseller Cost Transparency (if applicable)**\n   - Ability to show customer-specific rates vs. list prices\n   - Margin management and discount pass-through visibility\n   - Multi-customer cost allocation accuracy\n\n4. **Actionable Recommendations Engine**\n   - Right-sizing recommendations with actual implementation tracking\n   - RI/Savings Plans utilization and coverage optimization\n   - Waste identification (idle resources, unattached EBS, unused Elastic IPs)\n\n5. **Customer-Facing Reporting**\n   - Self-service dashboards for customers\n   - Business-context cost views (by application, environment, team)\n\n### 🔧 Relevant AWS Services & Tools\n- **AWS Cost Explorer** (with Cost Anomaly Detection)\n- **AWS Budgets** (with Actions)\n- **AWS Cost and Usage Reports (CUR)** - critical for detailed analysis\n- **AWS Pricing Calculator** (for TCO)\n- **AWS Migration Evaluator** (formerly TSO Logic) - for TCO\n- **AWS Compute Optimizer**\n- **AWS Organizations** (consolidated billing)\n- **AWS Resource Groups & Tag Editor**\n- **QuickSight** (for custom dashboards)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### A. TCO Analysis Methodology & Demo\n| Evidence | Format | Key Contents |\n|----------|--------|--------------|\n| `TCO_Analysis_Methodology_v2.3.pdf` | PDF Document | Step-by-step process, data collection templates, calculation formulas |\n| `TCO_Calculator_Template.xlsx` | Excel Workbook | On-prem cost inputs, AWS cost projections, comparison charts |\n| `TCO_Demo_Recording_CustomerX.mp4` | Video (10-15 min) | Live walkthrough of actual customer TCO analysis |\n| `Migration_Evaluator_Report_Sample.pdf` | PDF Export | AWS Migration Evaluator output showing discovery-based TCO |\n\n**TCO Template Must Include:**\n```\nOn-Premises Costs:\n├── Hardware (servers, storage, network) - depreciation schedule\n├── Software licenses (OS, database, middleware)\n├── Data center (power, cooling, rack space, physical security)\n├── Personnel (FTE hours for admin, patching, backup)\n├── Disaster recovery infrastructure\n└── Refresh cycles (3-5 year hardware replacement)\n\nAWS Projected Costs:\n├── Compute (EC2, Lambda, containers)\n├── Storage (EBS, S3, Glacier)\n├── Network (data transfer, Direct Connect)\n├── Database (RDS, DynamoDB)\n├── Support plan\n└── Optimization assumptions (RI/SP coverage targets)\n```\n\n#### B. Cost Monitoring Strategy & Tools\n| Evidence | Format | Key Contents |\n|----------|--------|--------------|\n| `FinOps_Operating_Procedures.docx` | Word Document | Daily/weekly/monthly review cadence, escalation paths |\n| `Cost_Monitoring_Dashboard_Screenshots.pdf` | PDF with screenshots | AWS Cost Explorer views, custom QuickSight dashboards |\n| `Budget_Alert_Configuration.png` | Screenshots | AWS Budgets setup with actual/forecasted thresholds |\n| `Anomaly_Detection_Demo.mp4` | Video (5-10 min) | AWS Cost Anomaly Detection configuration and alert response |\n| `Tagging_Policy_Enforcement.pdf` | PDF Document | Required tags, AWS Config rules, compliance reports |\n\n**Tagging Strategy Must Show:**\n```yaml\nRequired Tags:\n  - Environment: [Production, Staging, Development, Sandbox]\n  - CostCenter: [CC-XXXX format]\n  - Application: [Application name from CMDB]\n  - Owner: [Email of responsible party]\n  - Project: [Project code]\n  \nEnforcement:\n  - AWS Config Rule: required-tags\n  - Service Control Policy: Deny untagged resource creation\n  - Weekly compliance report to customer\n```\n\n#### C. Usage Cost Reporting (Resellers)\n| Evidence | Format | Key Contents |\n|----------|--------|--------------|\n| `Customer_Billing_Portal_Demo.mp4` | Video (10 min) | Self-service portal showing customer-specific rates |\n| `CUR_Processing_Architecture.pdf` | Architecture diagram | How CUR data flows to customer dashboards |\n| `Sample_Customer_Invoice_Breakdown.pdf` | Redacted invoice | Shows agreed rates, usage breakdown, discounts applied |\n| `Multi-Tenant_Cost_Allocation.xlsx` | Excel/CSV | Shared resource allocation methodology |\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Establish CUR Data Pipeline (Week 1-2)\n**Responsible:** Cloud Architect + Data Engineer  \n**Time:** 8-12 hours\n\n```bash\n# Enable CUR in master payer account\n1. AWS Console → Billing → Cost & Usage Reports\n2. Create report with:\n   - Include resource IDs: YES\n   - Time granularity: Hourly\n   - Versioning: Overwrite existing report\n   - Compression: Parquet (for Athena efficiency)\n   - S3 bucket: s3://[company]-cur-data/\n\n# Set up Athena for CUR queries\n3. Use AWS-provided CloudFormation template for CUR Athena integration\n4. Verify queries work:\n   SELECT line_item_product_code, \n          SUM(line_item_unblended_cost) as cost\n   FROM cur_database.cur_table\n   WHERE month = '12' AND year = '2024'\n   GROUP BY line_item_product_code\n   ORDER BY cost DESC\n```\n\n### Step 2: Build TCO Analysis Capability (Week 2-3)\n**Responsible:** Solutions Architect + Pre-Sales  \n**Time:** 16-20 hours\n\n1. **Register for AWS Migration Evaluator**\n   - Partner Central → Programs → Migration Evaluator\n   - Complete certification training (2 hours)\n   - Run collector on at least 2 customer environments\n\n2. **Create Custom TCO Template**\n   - Download AWS TCO Calculator methodology\n   - Add your MSP-specific factors:\n     - Your managed services pricing\n     - Typical optimization savings (show historical data)\n     - Regional pricing variations\n\n3. **Document Your Process**\n   ```\n   TCO Engagement Process:\n   Day 1-5: Discovery (Migration Evaluator deployment or manual inventory)\n   Day 6-10: Data analysis and AWS mapping\n   Day 11-15: TCO model creation with 3 scenarios (lift-shift, optimize, modernize)\n   Day 16-20: Customer presentation and refinement\n   ```\n\n### Step 3: Implement Cost Monitoring Framework (Week 3-4)\n**Responsible:** FinOps Lead + Operations Team  \n**Time:** 20-24 hours\n\n1. **Configure AWS Budgets for All Customers**\n   ```python\n   # Example budget structure per customer\n   budgets = {\n       \"monthly_total\": {\"amount\": X, \"alert_thresholds\": [50, 80, 100, 120]},\n       \"forecasted\": {\"alert_threshold\": 110},  # Alert if forecast exceeds 110%\n       \"service_specific\": {\n           \"EC2\": {\"amount\": Y},\n           \"RDS\": {\"amount\": Z}\n       }\n   }\n   ```\n\n2. **Enable Cost Anomaly Detection**\n   - Create monitors for each customer account/OU\n   - Set up SNS → Lambda → Slack/PagerDuty integration\n   - Document response playbook for anomaly alerts\n\n3. **Build QuickSight Dashboard** (or alternative tool)\n   - Connect to Athena CUR database\n   - Create views: Daily spend trend, Service breakdown, Tag compliance, RI utilization\n\n### Step 4: Develop Customer-Facing Portal (Week 4-5)\n**Responsible:** Development Team + FinOps Lead  \n**Time:** 24-32 hours (if building custom) or 8 hours (if using COTS)\n\n**Option A: Custom Portal**\n- Frontend: React/Vue dashboard\n- Backend: API Gateway + Lambda querying Athena\n- Auth: Cognito with customer-specific access\n\n**Option B: Third-Party Tools** (acceptable for audit)\n- CloudHealth by VMware\n- Cloudability\n- Spot.io (formerly Spotinst)\n- Apptio Cloudability\n\n**Key Features Required:**\n- [ ] Customer can see only their costs\n- [ ] Drill-down from account → service → resource\n- [ ] Agreed rates displayed (not list prices)\n- [ ] Export capability (CSV, PDF)\n- [ ] Historical trend (minimum 6 months)\n\n### Step 5: Create Optimization Recommendation Engine (Week 5-6)\n**Responsible:** FinOps Lead + Cloud Architects  \n**Time:** 16-20 hours\n\n1. **Integrate AWS Compute Optimizer**\n   - Enable in all customer accounts\n   - Create weekly export to S3\n   - Build summary report template\n\n2. **RI/Savings Plans Analysis Process**\n   ```\n   Monthly RI/SP Review:\n   1. Pull current coverage from Cost Explorer\n   2. Analyze usage patterns (last 30/60/90 days)\n   3. Generate recommendations with break-even analysis\n   4. Present to customer with ROI projection\n   5. Execute purchases (with customer approval)\n   6. Track actual vs. projected savings\n   ```\n\n3. **Waste Identification Automation**\n   - AWS Config rules for: unattached EBS, unused Elastic IPs, idle load balancers\n   - Trusted Advisor checks integration\n   - Weekly \"waste report\" to customers\n\n### Step 6: Prepare Demo Environment (Week 6-7)\n**Responsible:** Demo Lead + FinOps Team  \n**Time:** 12-16 hours\n\n1. **Create Demo Script**\n   ```\n   Demo Flow (20-25 minutes total):\n   \n   Part 1: TCO Analysis (7 min)\n   - Show Migration Evaluator report\n   - Walk through TCO calculator\n   - Demonstrate 3-year projection\n   \n   Part 2: Cost Monitoring (8 min)\n   - Live AWS Cost Explorer navigation\n   - Show Budget alerts and actions\n   - Demonstrate anomaly detection alert\n   - Display tagging compliance dashboard\n   \n   Part 3: Customer Portal (5 min)\n   - Login as sample customer\n   - Show cost breakdown by agreed rates\n   - Demonstrate drill-down capability\n   - Export sample report\n   \n   Part 4: Optimization (5 min)\n   - Show Compute Optimizer recommendations\n   - Display RI/SP coverage analysis\n   - Present waste identification report\n   ```\n\n2. **Prepare Demo Data**\n   - Use sanitized real customer data (with permission) OR\n   - Create realistic synthetic data (minimum 3 months history)\n   - Ensure demo account has diverse services for interesting visuals\n\n### Step 7: Record and Document (Week 7-8)\n**Responsible:** Technical Writer + Demo Lead  \n**Time:** 8-12 hours\n\n- Record demo video with clear audio narration\n- Create written methodology documents\n- Compile all screenshots and exports\n- Package evidence with clear naming convention\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: TCO Analysis Missing Hidden Costs\n**Problem:** TCO only compares server costs, ignoring facilities, personnel, and opportunity costs.\n\n**Auditor Red Flag:** \"Your TCO shows AWS is 40% cheaper, but you haven't accounted for the customer's existing VMware licenses or their data center lease commitment.\"\n\n**Solution:**\n- Use Migration Evaluator for comprehensive discovery\n- Include explicit line items for: power/cooling (typically $500-1000/server/year), admin FTE allocation, software license true-up, DR infrastructure\n- Show \"sunk cost\" handling methodology\n\n### ❌ Mistake 2: Reactive-Only Cost Monitoring\n**Problem:** Showing only monthly bill review without proactive alerting.\n\n**Auditor Red Flag:** \"How would you know if a customer's spend suddenly doubled mid-month?\"\n\n**Solution:**\n- Demonstrate AWS Budgets with Actions (auto-stop instances, notify via SNS)\n- Show Cost Anomaly Detection with actual alert examples\n- Present documented escalation procedures with SLAs\n\n### ❌ Mistake 3: No Tagging Enforcement\n**Problem:** Having a tagging policy document but no enforcement mechanism.\n\n**Auditor Red Flag:** \"You have a tagging standard, but 60% of resources in this account are untagged. How do you allocate costs?\"\n\n**Solution:**\n- Implement AWS Config rule `required-tags`\n- Show SCP that denies resource creation without required tags\n- Present weekly tagging compliance reports with trend improvement\n\n### ❌ Mistake 4: Reseller Rates Not Visible to Customers\n**Problem:** Customers only see list prices, not agreed discounted rates.\n\n**Auditor Red Flag:** \"If I'm a customer with a 10% discount, where do I see that reflected in my cost reports?\"\n\n**Solution:**\n- Build rate card management into billing portal\n- Show sample invoice with: List price, Discount %, Customer rate, Final charge\n- Demonstrate how rate changes are applied and communicated\n\n### ❌ Mistake 5: No Optimization Tracking\n**Problem:** Providing recommendations without tracking implementation or savings.\n\n**Auditor Red Flag:** \"You recommended right-sizing 3 months ago. Was it implemented? What were the actual savings?\"\n\n**Solution:**\n- Create recommendation tracking system (JIRA, ServiceNow, or custom)\n- Show closed-loop process: Recommend → Customer approve → Implement → Verify savings\n- Present \"savings realized\" dashboard with historical data\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### TCO Analysis Verification\n| Check Item | Verification Method | Pass Criteria |\n|------------|---------------------|---------------|\n| ☐ TCO includes minimum 10 cost categories | Review template line items | On-prem: Hardware, Software, Facilities, Personnel, DR, Network, Security, Compliance, Opportunity cost, Refresh |\n| ☐ AWS projection uses realistic pricing | Compare to AWS Pricing Calculator | Within 10% of calculator output for same configuration |\n| ☐ 3-5 year model with growth assumptions | Check projection tabs | Year-over-year growth rate documented and adjustable |\n| ☐ Migration Evaluator capability demonstrated | Show partner portal access | Can initiate new assessment, show completed report |\n\n### Cost Monitoring Verification\n| Check Item | Verification Method | Pass Criteria |\n|------------|---------------------|---------------|\n| ☐ Budgets configured with multiple thresholds | AWS Console screenshot | Minimum 3 thresholds (50%, 80%, 100%) with SNS actions |\n| ☐ Anomaly Detection active | Show Cost Anomaly Detection console | Monitors created for each customer, alert history visible |\n| ☐ Tagging compliance > 80% | Run Config rule compliance report | Documented improvement trend over 3+ months |\n| ☐ Daily/weekly review cadence documented | Show runbook/SOP | Named responsible parties, specific review steps |\n\n### Customer Portal Verification\n| Check Item | Verification Method | Pass Criteria |\n|------------|---------------------|---------------|\n| ☐ Customer-specific login works | Live demo | Isolated view showing only that customer's data |\n| ☐ Agreed rates displayed | Compare portal to rate card | Rates match contracted amounts |\n| ☐ Drill-down to resource level | Navigate in demo | Account → Service → Resource ID with cost attribution |\n| ☐ Historical data available | Check date range | Minimum 6 months of historical data accessible |\n\n### Optimization Capability Verification\n| Check Item | Verification Method | Pass Criteria |\n|------------|---------------------|---------------|\n| ☐ Compute Optimizer integrated | Show recommendations | Active recommendations with estimated savings |\n| ☐ RI/SP coverage analysis available | Cost",
      "language": "en",
      "createdAt": "2026-01-07T03:28:50.347Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-017_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-017",
      "category": "Operations",
      "title": "Migrations",
      "advice": "# OPS-017: Migrations - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Requirement Matters for AWS MSP\nMigration capability is the **core value proposition** that differentiates MSPs from simple resellers. AWS wants to verify that partners can safely migrate customer workloads to AWS and deliver tangible business outcomes. This requirement validates your ability to execute the entire migration lifecycle—from initial assessment through post-migration operations—using AWS's proven methodologies.\n\n### 🔍 Key Points Auditors Evaluate\n\n1. **7Rs Strategy Application Evidence**: Auditors verify you didn't just \"lift and shift\" everything. They look for documented decision rationale for each application—why you chose Rehost vs. Refactor vs. Retire. The decision matrix must show business and technical criteria used.\n\n2. **Refactor/Replatform Depth**: At least one project must demonstrate actual architecture transformation. Simply moving from on-premises Oracle to RDS Oracle doesn't qualify as replatforming—you need to show meaningful modernization (e.g., Oracle → Aurora PostgreSQL, monolith → containers).\n\n3. **Migration Governance Maturity**: Communication plans with actual stakeholder meeting minutes, change control board decisions, and cutover runbooks with rollback procedures. Generic templates without project-specific content will fail.\n\n4. **Landing Zone Implementation**: Evidence of multi-account strategy, network architecture, security baseline, and operational tooling deployed BEFORE migration began—not retrofitted afterward.\n\n5. **Post-Migration Operational Handoff**: Runbooks, monitoring dashboards, and incident response procedures that prove you didn't just migrate and abandon the customer.\n\n### Relevant AWS Services & Tools\n- **AWS Migration Hub** - Central tracking and portfolio visibility\n- **AWS Application Discovery Service** - Dependency mapping\n- **AWS Migration Evaluator** (formerly TSO Logic) - Business case development\n- **AWS Control Tower** - Landing zone deployment\n- **AWS Database Migration Service (DMS)** - Database migrations\n- **AWS Application Migration Service (MGN)** - Server migrations\n- **AWS App2Container** - Containerization for refactoring projects\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Documentation Package (Per Customer Project)\n\n#### 📁 Document Set A: Portfolio Discovery & Strategy\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Application_Portfolio_Assessment.xlsx` | Excel | Complete application inventory with 7Rs classification, business criticality, technical complexity scores |\n| `[Customer]_Migration_Wave_Plan.pdf` | PDF | Wave groupings based on dependencies, risk, and business priority |\n| `[Customer]_Business_Case_Analysis.pptx` | PowerPoint | TCO comparison, migration ROI, timeline projections |\n\n**Must Include:**\n- Application Discovery Service export or equivalent discovery tool output\n- Dependency mapping visualization (not just a list)\n- 7Rs decision matrix with weighted scoring criteria\n- Business stakeholder sign-off on strategy\n\n#### 📁 Document Set B: Migration Governance\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Migration_Governance_Charter.docx` | Word | Steering committee structure, escalation paths, decision authority matrix |\n| `[Customer]_Communication_Plan.xlsx` | Excel | Stakeholder matrix, communication cadence, channel definitions |\n| `[Customer]_Cutover_Runbook_[AppName].docx` | Word | Step-by-step cutover procedures with rollback triggers |\n\n**Must Include:**\n- Meeting minutes from at least 3 governance meetings\n- Change Advisory Board (CAB) approval records\n- Cutover checklist with actual timestamps from execution\n- Rollback procedure that was tested (test evidence required)\n\n#### 📁 Document Set C: People & Skills\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Migration_RACI.xlsx` | Excel | Role assignments for every migration phase and activity |\n| `[Customer]_Training_Plan.pdf` | PDF | Skills gap analysis, training schedule, completion tracking |\n| `[Customer]_Knowledge_Transfer_Log.xlsx` | Excel | Session topics, attendees, materials delivered |\n\n**Must Include:**\n- Named individuals (can be anonymized but must show real assignments)\n- Training completion certificates or attendance records\n- Knowledge transfer session recordings or detailed notes\n\n#### 📁 Document Set D: Landing Zone\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Landing_Zone_Design.pdf` | PDF | Multi-account structure, OU hierarchy, network topology |\n| `[Customer]_Security_Baseline.xlsx` | Excel | SCPs, IAM policies, GuardDuty/Security Hub configurations |\n| `[Customer]_Network_Architecture.vsdx` | Visio/Draw.io | VPC design, Transit Gateway, connectivity to on-premises |\n\n**Must Include:**\n- AWS Control Tower deployment evidence OR custom landing zone IaC (CloudFormation/Terraform)\n- Account vending process documentation\n- Network connectivity test results\n\n#### 📁 Document Set E: Operations\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Operational_Runbooks/` | Folder | Individual runbooks for common operational tasks |\n| `[Customer]_Monitoring_Dashboard_Screenshots.pdf` | PDF | CloudWatch dashboards, alarm configurations |\n| `[Customer]_Incident_Response_Procedure.docx` | Word | Escalation matrix, severity definitions, response SLAs |\n\n**Must Include:**\n- At least 5 operational runbooks (backup, patching, scaling, incident response, DR)\n- CloudWatch alarm configurations (JSON exports acceptable)\n- Evidence of runbook execution (ticket references, execution logs)\n\n#### 📁 Document Set F: Security, Risk & Compliance\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Security_Assessment.pdf` | PDF | Pre-migration security posture, identified risks, remediation plan |\n| `[Customer]_Compliance_Mapping.xlsx` | Excel | Regulatory requirements mapped to AWS controls |\n| `[Customer]_Risk_Register.xlsx` | Excel | Identified risks, mitigation strategies, residual risk acceptance |\n\n**Must Include:**\n- Security Hub findings summary (before/after migration)\n- Compliance framework mapping (SOC2, HIPAA, PCI-DSS as applicable)\n- Risk acceptance sign-offs from customer\n\n#### 📁 Document Set G: Application Migration (Refactor/Replatform Project)\n| Document | Format | Key Content |\n|----------|--------|-------------|\n| `[Customer]_Modernization_Architecture.pdf` | PDF | Before/after architecture diagrams showing transformation |\n| `[Customer]_Pilot_MVP_Results.docx` | Word | Pilot scope, success criteria, test results, lessons learned |\n| `[Customer]_Refactoring_Technical_Design.pdf` | PDF | Detailed technical approach for modernization |\n\n**Must Include for Refactor:**\n- Code repository evidence showing containerization or serverless transformation\n- CI/CD pipeline configuration\n- Performance comparison (before/after)\n\n**Must Include for Replatform:**\n- Database migration evidence (DMS task configurations, schema conversion reports)\n- Platform change documentation (e.g., Windows → Linux, Oracle → PostgreSQL)\n- Compatibility testing results\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Select Qualifying Customer Projects (Week 1)\n**Objective:** Identify 2 projects that meet all 7 capability areas\n\n**Specific Actions:**\n1. Create a project qualification matrix scoring each past migration against the 7 required areas\n2. Verify at least one project includes genuine refactoring (containers, serverless) or replatforming (database engine change, OS change)\n3. Confirm customer consent for using anonymized project documentation\n\n**Tools:** Internal project database, customer contracts review\n\n**Output:** `MSP_Migration_Project_Selection_Matrix.xlsx`\n\n**⚠️ Critical Check:** A simple EC2 lift-and-shift does NOT qualify as refactor/replatform. Moving from VMware to EC2 is Rehost. You need architecture transformation evidence.\n\n---\n\n### Step 2: Reconstruct Portfolio Discovery Evidence (Week 2)\n**Objective:** Document the discovery and 7Rs classification process\n\n**Specific Actions:**\n1. Export Application Discovery Service data or recreate discovery spreadsheet with:\n   - Server specifications (CPU, memory, storage, utilization)\n   - Application dependencies (network flows, database connections)\n   - Business metadata (owner, criticality, compliance requirements)\n\n2. Create 7Rs decision matrix showing:\n   ```\n   | Application | Current State | 7R Decision | Rationale | Complexity | Wave |\n   |-------------|---------------|-------------|-----------|------------|------|\n   | CRM System  | On-prem .NET  | Replatform  | Move to containers for scalability | High | 3 |\n   | File Server | Windows 2012  | Retire      | Replaced by SharePoint Online | Low | 1 |\n   ```\n\n3. Generate dependency visualization using Migration Hub or draw.io\n\n**Tools:** AWS Application Discovery Service, Migration Hub, Migration Evaluator\n\n**Estimated Time:** 15-20 hours per project\n\n**Responsible:** Migration Architect, Business Analyst\n\n---\n\n### Step 3: Compile Governance Documentation (Week 3)\n**Objective:** Demonstrate structured migration management\n\n**Specific Actions:**\n1. Gather or recreate governance artifacts:\n   - Steering committee meeting minutes (minimum 3 meetings)\n   - Status report examples showing RAG status tracking\n   - Change request forms with approval signatures\n\n2. Document cutover procedures with specific detail:\n   ```\n   Cutover Step 4.3: Database Sync Verification\n   - Execute: SELECT MAX(transaction_id) FROM orders;\n   - Expected: Value matches source within 60 seconds\n   - Rollback Trigger: Lag exceeds 5 minutes\n   - Responsible: DBA Team Lead\n   - Duration: 15 minutes\n   ```\n\n3. Include rollback evidence—show that rollback was tested, not just documented\n\n**Tools:** Project management system exports, email archives, SharePoint\n\n**Estimated Time:** 10-15 hours per project\n\n**Responsible:** Project Manager, Migration Lead\n\n---\n\n### Step 4: Document Landing Zone Implementation (Week 4)\n**Objective:** Show pre-migration infrastructure preparation\n\n**Specific Actions:**\n1. Export or recreate landing zone architecture:\n   - AWS Organizations structure screenshot\n   - OU hierarchy diagram\n   - Account list with purposes\n\n2. Document security baseline:\n   ```yaml\n   # Example SCP Evidence\n   SCP Name: Deny-Region-Outside-Approved\n   Applied To: Production OU\n   Effect: Prevents resource creation outside us-east-1, eu-west-1\n   Deployment Date: 2024-01-15\n   ```\n\n3. Include network architecture with:\n   - VPC CIDR allocations\n   - Transit Gateway route tables\n   - Direct Connect/VPN configurations\n   - Security group strategy\n\n**Tools:** AWS Control Tower, CloudFormation/Terraform exports, AWS Config\n\n**Estimated Time:** 8-12 hours per project\n\n**Responsible:** Cloud Architect, Security Engineer\n\n---\n\n### Step 5: Prepare Operational Readiness Package (Week 5)\n**Objective:** Prove post-migration operational capability\n\n**Specific Actions:**\n1. Create or compile runbooks for:\n   - **Backup & Restore:** AWS Backup policies, restore testing procedures\n   - **Patching:** Systems Manager Patch Manager configurations, maintenance windows\n   - **Scaling:** Auto Scaling policies, manual scaling procedures\n   - **Incident Response:** PagerDuty/SNS integration, escalation matrix\n   - **Disaster Recovery:** Cross-region failover procedures, RTO/RPO validation\n\n2. Export CloudWatch dashboard configurations:\n   ```json\n   {\n     \"DashboardName\": \"Customer-Production-Overview\",\n     \"Widgets\": [\n       {\"type\": \"metric\", \"properties\": {\"metrics\": [[\"AWS/EC2\", \"CPUUtilization\"]]}}\n     ]\n   }\n   ```\n\n3. Document alarm configurations with business context:\n   | Alarm | Threshold | Action | Business Impact |\n   |-------|-----------|--------|-----------------|\n   | API-Latency-High | p99 > 500ms for 5min | Page on-call | Customer checkout affected |\n\n**Tools:** AWS Systems Manager, CloudWatch, AWS Backup\n\n**Estimated Time:** 12-18 hours per project\n\n**Responsible:** Operations Lead, SRE Team\n\n---\n\n### Step 6: Build Refactor/Replatform Evidence Package (Week 6)\n**Objective:** Demonstrate modernization capability for at least one project\n\n**For Refactoring (Containerization) Evidence:**\n1. Document architecture transformation:\n   - Before: Monolithic application architecture diagram\n   - After: Microservices/container architecture on ECS/EKS\n\n2. Include technical artifacts:\n   - Dockerfile examples\n   - ECS Task Definitions or Kubernetes manifests\n   - CI/CD pipeline configuration (CodePipeline, GitHub Actions)\n   - Container image repository (ECR) screenshots\n\n3. Pilot/MVP documentation:\n   ```\n   Pilot Scope: Order Processing Module\n   Success Criteria:\n   - Response time < 200ms (achieved: 145ms)\n   - Zero data loss during migration (validated)\n   - Rollback capability tested (completed 2024-02-10)\n   Lessons Learned:\n   - Database connection pooling required tuning for container environment\n   ```\n\n**For Replatforming (Database Migration) Evidence:**\n1. Document platform change:\n   - Before: Oracle 12c on-premises\n   - After: Amazon Aurora PostgreSQL\n\n2. Include DMS artifacts:\n   - Schema Conversion Tool assessment report\n   - DMS replication task configuration\n   - Data validation reports\n   - Performance comparison benchmarks\n\n**Tools:** AWS App2Container, DMS, Schema Conversion Tool, ECR, ECS/EKS\n\n**Estimated Time:** 20-25 hours for the refactor/replatform project\n\n**Responsible:** Application Architect, Database Engineer, DevOps Engineer\n\n---\n\n### Step 7: Final Package Assembly and Quality Review (Week 7)\n**Objective:** Organize evidence for auditor review\n\n**Specific Actions:**\n1. Create master index document:\n   ```\n   OPS-017 Migration Evidence Package\n   \n   Customer A: [Industry] - Replatform Project\n   ├── A1_Portfolio_Discovery/\n   │   ├── Application_Inventory.xlsx\n   │   ├── 7Rs_Decision_Matrix.xlsx\n   │   └── Dependency_Map.pdf\n   ├── A2_Governance/\n   │   ├── Governance_Charter.docx\n   │   ├── Meeting_Minutes_20240115.pdf\n   │   └── Cutover_Runbook.docx\n   [...]\n   \n   Customer B: [Industry] - Rehost + Refactor Project\n   [...]\n   ```\n\n2. Verify cross-references between documents (e.g., applications in inventory appear in wave plan)\n\n3. Redact sensitive information consistently (use [CUSTOMER], [EMPLOYEE] placeholders)\n\n4. Create executive summary highlighting how each of the 7 areas is addressed\n\n**Estimated Time:** 8-10 hours\n\n**Responsible:** MSP Program Lead, Documentation Specialist\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Claiming Replatform When It's Actually Rehost\n**What Goes Wrong:** Partner submits evidence of migrating Oracle on EC2 to Oracle on RDS and calls it \"replatforming.\"\n\n**Why It Fails:** AWS defines replatforming as making optimizations to achieve tangible benefits without changing core architecture. Simply moving to a managed service of the SAME database engine is borderline. Auditors expect platform changes like:\n- Oracle → Aurora PostgreSQL\n- SQL Server → Aurora MySQL\n- Windows → Linux\n- Self-managed Kubernetes → EKS\n\n**Solution:** If your project was truly rehost, find a different project. If it included OS changes, database engine changes, or significant architecture optimization, document those specific changes prominently.\n\n---\n\n### ❌ Mistake 2: Generic Cutover Runbooks Without Project Specifics\n**What Goes Wrong:** Partner submits a template cutover runbook with placeholders like \"[Insert application name]\" or generic steps like \"Verify application functionality.\"\n\n**Why It Fails:** Auditors look for evidence that you actually executed a structured cutover. Generic templates suggest you're submitting documentation created for the audit, not from real projects.\n\n**Solution:** Include:\n- Actual timestamps from cutover execution\n- Specific commands and expected outputs\n- Named team members who performed each step\n- Screenshots from the actual cutover night\n- Post-cutover validation results with real data\n\n---\n\n### ❌ Mistake 3: Missing Landing Zone Evidence\n**What Goes Wrong:** Partner focuses heavily on application migration but provides minimal evidence of landing zone setup, assuming it's less important.\n\n**Why It Fails:** AWS specifically lists \"Landing zone setup\" as one of the 7 require",
      "language": "en",
      "createdAt": "2026-01-07T03:30:04.604Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPS-018_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPS-018",
      "category": "Operations",
      "title": "Artificial Intelligence",
      "advice": "# OPS-018: Artificial Intelligence - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters for AWS MSP Program\n\nAWS is strategically positioning MSP partners as **AI transformation enablers** for end customers. This requirement validates that your organization isn't just managing traditional infrastructure but is actively leveraging AI/ML capabilities to:\n- Enhance operational efficiency in managed services delivery\n- Reduce ticket resolution times through intelligent automation\n- Provide customers with access to cutting-edge Generative AI solutions\n- Demonstrate forward-thinking technical capabilities that differentiate from competitors\n\nWhile this is a **Recommended** (not Mandatory) item, completing it signals to AWS that you're aligned with their AI-first strategy and positions you favorably for AWS AI/ML co-sell opportunities.\n\n### 🔍 Key Points Auditors Evaluate\n\n1. **Practical Implementation Evidence** - Auditors want to see AI/GenAI actually deployed, not just theoretical plans. They look for production usage or active customer engagements.\n\n2. **AWS-Native AI Services Integration** - Strong preference for evidence showing use of Amazon Bedrock, Amazon Q, SageMaker, or other AWS AI services rather than purely third-party solutions.\n\n3. **Business Impact Documentation** - Quantifiable outcomes: reduced MTTR, decreased ticket volume, improved customer satisfaction, cost savings from automation.\n\n4. **Responsible AI Practices** - Evidence of governance, data handling policies, and ethical considerations in AI deployment.\n\n5. **Scalable Approach** - Demonstration that AI capabilities can be offered to multiple customers, not just a one-off experiment.\n\n### 🛠️ Relevant AWS Services\n\n| Service | Use Case for MSPs |\n|---------|-------------------|\n| **Amazon Bedrock** | Customer-facing GenAI applications, document processing, chatbots |\n| **Amazon Q Business** | Internal knowledge management, documentation search |\n| **Amazon Q Developer** | Code generation, IaC automation, troubleshooting assistance |\n| **Amazon SageMaker** | Custom ML models for anomaly detection, capacity planning |\n| **Amazon Comprehend** | Ticket classification, sentiment analysis |\n| **Amazon Lex** | Automated customer support bots |\n| **Amazon Textract** | Invoice processing, document extraction |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Documentation Package\n\n#### A. Internal AI Usage Evidence\n\n| Document | Format | Key Contents |\n|----------|--------|--------------|\n| **AI Operations Playbook** | PDF/Confluence | How AI tools are integrated into daily MSP operations |\n| **Amazon Q Developer Usage Report** | Screenshots + Metrics | Code suggestions accepted rate, time saved on IaC development |\n| **AI-Powered Runbook Examples** | Markdown/PDF | Automated incident response procedures using AI |\n| **Internal Chatbot Implementation** | Architecture diagram + Demo video | Knowledge base bot for L1 support escalation reduction |\n\n**Example File Names:**\n- `MSP_AI_Operations_Playbook_v2.1.pdf`\n- `AmazonQ_Developer_Usage_Metrics_Q4_2024.xlsx`\n- `Bedrock_KnowledgeBase_Architecture_Internal.png`\n- `AI_Incident_Triage_Runbook_Demo.mp4`\n\n#### B. Customer Project Evidence\n\n| Document | Format | Key Contents |\n|----------|--------|--------------|\n| **GenAI Project SOW** | Signed PDF | Scope, deliverables, AWS services used, timeline |\n| **Sprint Plans/Jira Export** | PDF/CSV | AI-specific user stories, acceptance criteria |\n| **Architecture Decision Record (ADR)** | Markdown/PDF | Why specific AI services were chosen |\n| **Customer Success Metrics** | Dashboard screenshot | Before/after KPIs showing AI impact |\n\n**Example File Names:**\n- `SOW_CustomerABC_GenAI_Chatbot_Implementation_2024.pdf`\n- `Sprint_Plan_Bedrock_RAG_Implementation_Sprint3.pdf`\n- `ADR_007_Bedrock_vs_SageMaker_Selection.md`\n- `CustomerXYZ_AI_ROI_Dashboard_Dec2024.png`\n\n#### C. Governance & Responsible AI Documentation\n\n| Document | Format | Key Contents |\n|----------|--------|--------------|\n| **AI Acceptable Use Policy** | PDF | Data handling, model selection criteria, prohibited uses |\n| **Prompt Engineering Guidelines** | Wiki/PDF | Standardized prompts, guardrails configuration |\n| **AI Security Review Checklist** | Template | Pre-deployment security validation steps |\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current AI/GenAI Usage (Week 1)\n**⏱️ Time: 3-4 hours | 👤 Role: Technical Lead**\n\n```bash\n# If using Amazon Q Developer, export usage metrics\n# Check AWS Cost Explorer for AI service usage\naws ce get-cost-and-usage \\\n  --time-period Start=2024-01-01,End=2024-12-31 \\\n  --granularity MONTHLY \\\n  --filter '{\"Dimensions\":{\"Key\":\"SERVICE\",\"Values\":[\"Amazon Bedrock\",\"Amazon SageMaker\",\"Amazon Comprehend\",\"Amazon Q\"]}}' \\\n  --metrics \"UnblendedCost\" \"UsageQuantity\"\n```\n\n**Actions:**\n- Survey engineering teams on AI tool usage (Amazon Q, Copilot, ChatGPT)\n- Identify existing customer projects with AI components\n- Document any automated processes using ML/AI\n\n### Step 2: Implement Quick-Win Internal AI Solution (Weeks 2-3)\n**⏱️ Time: 15-20 hours | 👤 Role: Solutions Architect + DevOps Engineer**\n\n**Recommended Quick Win: Amazon Bedrock Knowledge Base for Internal Documentation**\n\n```python\n# Example: Create a Bedrock Knowledge Base for runbook search\nimport boto3\n\nbedrock_agent = boto3.client('bedrock-agent', region_name='us-east-1')\n\n# Create knowledge base with your runbook S3 bucket\nresponse = bedrock_agent.create_knowledge_base(\n    name='MSP-Runbook-KnowledgeBase',\n    description='Internal runbooks and troubleshooting guides',\n    roleArn='arn:aws:iam::123456789012:role/BedrockKBRole',\n    knowledgeBaseConfiguration={\n        'type': 'VECTOR',\n        'vectorKnowledgeBaseConfiguration': {\n            'embeddingModelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1'\n        }\n    },\n    storageConfiguration={\n        'type': 'OPENSEARCH_SERVERLESS',\n        'opensearchServerlessConfiguration': {\n            'collectionArn': 'arn:aws:aoss:us-east-1:123456789012:collection/xxx',\n            'fieldMapping': {\n                'metadataField': 'metadata',\n                'textField': 'text',\n                'vectorField': 'vector'\n            }\n        }\n    }\n)\n```\n\n**Deliverable:** Working internal chatbot that L1 engineers can query for troubleshooting steps\n\n### Step 3: Document a Customer AI Engagement (Week 3)\n**⏱️ Time: 4-5 hours | 👤 Role: Project Manager + Account Manager**\n\nIf you have an existing customer AI project:\n- Extract SOW sections related to AI/GenAI scope\n- Export sprint plans showing AI-specific work items\n- Collect before/after metrics\n\nIf no existing project, create a **pilot proposal** for an existing customer:\n- Draft a mini-SOW for a Bedrock-powered FAQ bot\n- Create a 2-sprint plan with specific deliverables\n- Get customer sign-off (even for a free pilot)\n\n### Step 4: Create AI Operations Playbook (Week 4)\n**⏱️ Time: 6-8 hours | 👤 Role: Technical Lead + Documentation Specialist**\n\n**Playbook Structure:**\n```markdown\n# MSP AI Operations Playbook\n\n## 1. AI-Assisted Incident Triage\n- Amazon Comprehend for ticket classification\n- Bedrock for suggested resolution steps\n- Escalation criteria when AI confidence < 80%\n\n## 2. Automated Capacity Analysis\n- SageMaker anomaly detection for resource utilization\n- Predictive scaling recommendations\n\n## 3. Code Review & IaC Generation\n- Amazon Q Developer integration with IDE\n- Terraform/CloudFormation generation workflows\n- Security scanning with AI-suggested remediations\n\n## 4. Customer Communication\n- AI-generated incident summaries\n- Automated RCA draft generation\n```\n\n### Step 5: Establish AI Governance Framework (Week 4)\n**⏱️ Time: 3-4 hours | 👤 Role: Security Lead + Compliance Manager**\n\nCreate `AI_Acceptable_Use_Policy.pdf` covering:\n- Approved AI services and models\n- Data classification rules (no PII in prompts without guardrails)\n- Bedrock Guardrails configuration requirements\n- Human-in-the-loop requirements for customer-facing outputs\n\n### Step 6: Capture Metrics & ROI (Week 5)\n**⏱️ Time: 2-3 hours | 👤 Role: Operations Manager**\n\nBuild a simple dashboard showing:\n- Tickets auto-classified by AI: X per month\n- Average time saved per incident: Y minutes\n- Amazon Q Developer suggestions accepted: Z%\n- Customer project AI deliverables completed: N\n\n### Step 7: Compile Evidence Package (Week 5)\n**⏱️ Time: 2-3 hours | 👤 Role: MSP Program Manager**\n\nOrganize into folder structure:\n```\nOPS-018_AI_Evidence/\n├── 01_Internal_Usage/\n│   ├── AI_Operations_Playbook_v1.0.pdf\n│   ├── AmazonQ_Developer_Metrics.xlsx\n│   └── Bedrock_KB_Architecture.png\n├── 02_Customer_Projects/\n│   ├── SOW_CustomerABC_GenAI.pdf\n│   └── Sprint_Plan_AI_Implementation.pdf\n├── 03_Governance/\n│   ├── AI_Acceptable_Use_Policy.pdf\n│   └── Prompt_Engineering_Guidelines.md\n└── 04_Metrics/\n    └── AI_ROI_Dashboard_Screenshot.png\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Only ChatGPT/Third-Party AI Usage\n**Problem:** Auditors specifically look for AWS AI service adoption. Evidence showing only OpenAI API or Anthropic direct usage doesn't demonstrate AWS ecosystem competency.\n\n**Solution:** Even if you use third-party models, access them through **Amazon Bedrock** to show AWS integration. Document why Bedrock was chosen (security, single API, enterprise features).\n\n### ❌ Mistake 2: Vague \"We Plan to Use AI\" Documentation\n**Problem:** Roadmaps and future plans don't satisfy this requirement. Auditors want evidence of actual implementation.\n\n**Solution:** If you're starting from scratch, implement a small internal use case first (Amazon Q Developer adoption, Bedrock knowledge base) before the audit. A working demo beats a detailed plan.\n\n### ❌ Mistake 3: Missing Customer Consent for AI Project Evidence\n**Problem:** Submitting customer SOWs or project plans without redaction or permission can raise confidentiality concerns.\n\n**Solution:** \n- Redact customer names if needed (use \"Customer A\" or get written permission)\n- Include a note: \"Customer name redacted per NDA - original available upon request\"\n- Ensure SOW doesn't contain sensitive pricing or proprietary customer data\n\n### ❌ Mistake 4: No Governance or Responsible AI Documentation\n**Problem:** Showing AI usage without guardrails suggests immature implementation. AWS is increasingly focused on responsible AI practices.\n\n**Solution:** Include your AI Acceptable Use Policy even if brief. Show Bedrock Guardrails configuration if using Bedrock. Document human review processes for AI outputs.\n\n### ❌ Mistake 5: Generic Architecture Without MSP Context\n**Problem:** Submitting a standard Bedrock architecture diagram that could apply to any company doesn't show MSP-specific value.\n\n**Solution:** Explicitly connect AI usage to MSP operations:\n- \"AI reduces L1 escalations by 30%\"\n- \"Automated incident classification enables 24/7 coverage\"\n- \"GenAI accelerates customer onboarding documentation\"\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ | **AWS AI Service Evidence** | Review all documents for AWS service mentions | At least one AWS AI service (Bedrock, SageMaker, Q, Comprehend) is documented with actual usage |\n| ✅ | **Internal Usage Demonstrated** | Check for screenshots, metrics, or playbooks | Clear evidence that your MSP team uses AI in daily operations |\n| ✅ | **Customer Project Documentation** | Verify SOW or Sprint Plan exists | At least one customer-facing AI engagement documented (can be pilot) |\n| ✅ | **Quantifiable Impact** | Look for numbers in evidence | At least 2-3 metrics showing AI impact (time saved, tickets reduced, etc.) |\n| ✅ | **Governance Documentation** | Review AI policy document | AI Acceptable Use Policy exists with data handling and approval processes |\n| ✅ | **Architecture Clarity** | Review diagrams | Architecture shows how AI integrates with MSP operations (not standalone) |\n| ✅ | **Confidentiality Compliance** | Check customer documents | Customer names redacted OR permission documented; no sensitive data exposed |\n\n### 🎯 Quality Criteria Summary\n\n**Minimum Passing Evidence Package:**\n1. One internal AI implementation with AWS service (screenshot + brief description)\n2. One customer AI engagement document (SOW, sprint plan, or proposal)\n3. AI governance policy (even 1-2 pages is acceptable)\n\n**Strong Evidence Package (Recommended):**\n- All of the above, plus:\n- Metrics dashboard showing AI impact\n- Multiple customer projects or reusable AI offering documentation\n- Detailed playbook showing AI integration into incident management\n\n---\n\n## 💡 Pro Tips for This Requirement\n\n1. **Start with Amazon Q Developer** - It's the fastest path to demonstrable AI usage. Enable it for your engineering team, collect usage metrics for 30 days, and you have solid evidence.\n\n2. **Leverage AWS AI Service Credits** - If you're an AWS Partner, you likely have credits. Use them for Bedrock experimentation to build evidence.\n\n3. **Create a Reusable AI Offering** - Document a \"GenAI Starter Package\" you can offer customers. Even if not yet sold, it shows maturity and scalability.\n\n4. **Record a Demo Video** - A 3-5 minute video showing your internal AI chatbot or automated triage system is compelling evidence that's hard to dispute.",
      "language": "en",
      "createdAt": "2026-01-07T03:31:08.516Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-001",
      "category": "Operations",
      "title": "Incident Management",
      "advice": "# OPSP-001: Incident Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nIncident Management is the **foundation of MSP operational capability**. AWS views this as a core indicator of whether a partner can reliably manage customer cloud environments. This isn't just about having documentation—AWS wants to see a **mature, battle-tested process** that handles both routine IT issues and critical security events.\n\nThe distinction between IT incidents (service outages, performance degradation) and Security incidents (unauthorized access, data breaches) is crucial. AWS auditors specifically verify that your process treats these differently while maintaining a unified framework.\n\n### 🎯 Key Points Auditors Examine\n\n1. **Separation of IT vs Security incident workflows** - Auditors check if your playbooks have distinct escalation paths for security events (involving Security Operations) versus IT incidents (involving NOC/Operations)\n\n2. **Integration with AWS-native detection services** - They look for explicit references to CloudWatch Alarms, GuardDuty findings, Security Hub alerts, and AWS Health events as incident triggers\n\n3. **Customer communication SLAs by severity** - Specific timeframes for initial notification, updates, and resolution communication based on incident priority (P1: 15min, P2: 30min, etc.)\n\n4. **Evidence of actual incident handling** - Not just process documents, but proof the process is actively used (redacted incident tickets, post-mortems)\n\n5. **Defined RACI matrix** - Clear ownership for each phase: who detects, who triages, who communicates, who resolves, who approves closure\n\n### Relevant AWS Services\n\n| Detection | Response | Documentation |\n|-----------|----------|---------------|\n| Amazon CloudWatch | AWS Systems Manager Incident Manager | AWS Audit Manager |\n| Amazon GuardDuty | AWS Lambda (automated response) | Amazon S3 (evidence storage) |\n| AWS Security Hub | AWS Step Functions (runbooks) | AWS CloudTrail |\n| AWS Config | Amazon SNS (notifications) | Amazon QuickSight (metrics) |\n| AWS Health Dashboard | AWS Chatbot (Slack/Teams) | - |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Documents\n\n| Document | Format | Key Contents |\n|----------|--------|--------------|\n| **Incident Management Policy** | PDF (10-15 pages) | Scope, definitions, roles, compliance requirements |\n| **Incident Management Procedure** | PDF/Wiki (20-30 pages) | Step-by-step workflows for each incident phase |\n| **IT Incident Playbooks** | PDF/Runbook format | 5-10 scenario-specific response guides |\n| **Security Incident Playbooks** | PDF/Runbook format | NIST-aligned response procedures |\n| **Incident Severity Matrix** | Excel/PDF (1-2 pages) | Priority definitions with response SLAs |\n| **Customer Communication Templates** | Word/PDF | Initial notification, updates, RCA templates |\n| **Sample Incident Records** | Redacted tickets (3-5 examples) | Actual incidents showing process adherence |\n\n### 📄 Document Content Specifications\n\n**Incident Management Policy** must include:\n```\n- Purpose and scope (covering managed customer environments)\n- Definition of \"incident\" vs \"event\" vs \"problem\"\n- Regulatory compliance references (SOC2, ISO27001 if applicable)\n- Annual review cycle and document owner\n- Integration with Change Management (OPSP-002)\n```\n\n**IT Incident Playbooks** - Minimum scenarios:\n```\n1. EC2 instance unreachable\n2. RDS database performance degradation  \n3. Application load balancer 5xx errors\n4. AWS service health event impact\n5. Network connectivity loss (VPC/Direct Connect)\n6. Storage capacity threshold breach\n7. Certificate expiration incident\n```\n\n**Security Incident Playbooks** - Required scenarios:\n```\n1. GuardDuty high-severity finding response\n2. Compromised IAM credentials\n3. Unauthorized S3 bucket access\n4. Cryptomining detection (EC2)\n5. DDoS attack response\n6. Data exfiltration indicators\n7. Ransomware indicators in workloads\n```\n\n### Evidence File Examples\n\n```\n📁 OPSP-001_Incident_Management/\n├── POL-INC-001_Incident_Management_Policy_v2.3.pdf\n├── PRO-INC-001_Incident_Management_Procedure_v3.1.pdf\n├── PB-IT-001_EC2_Instance_Failure_Playbook.pdf\n├── PB-IT-002_RDS_Performance_Degradation_Playbook.pdf\n├── PB-SEC-001_GuardDuty_HighSeverity_Response.pdf\n├── PB-SEC-002_Compromised_Credentials_Response.pdf\n├── MTX-INC-001_Severity_Priority_Matrix.xlsx\n├── TPL-INC-001_Customer_Notification_Templates.docx\n├── EVD-INC-001_Sample_P1_Incident_Redacted.pdf\n├── EVD-INC-002_Sample_Security_Incident_Redacted.pdf\n└── RPT-INC-001_Monthly_Incident_Metrics_Dashboard.pdf\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Map Current State to AWS Requirements (Week 1)\n**Time: 8-12 hours | Owner: Operations Manager**\n\n```\nActions:\n□ Export last 6 months of incident tickets from your ITSM tool\n□ Categorize existing incidents into IT vs Security\n□ Identify gaps in current process against 9 required elements\n□ Document which AWS services trigger incidents today\n\nTools: ServiceNow/Jira Service Management export, Excel analysis\nOutput: Gap analysis spreadsheet with remediation priorities\n```\n\n### Step 2: Design Severity Matrix with AWS Context (Week 1-2)\n**Time: 4-6 hours | Owner: Service Delivery Lead**\n\nCreate a matrix that explicitly references AWS impact:\n\n| Priority | Definition | AWS Examples | Response SLA | Update Frequency |\n|----------|------------|--------------|--------------|------------------|\n| P1-Critical | Complete service outage | Multi-AZ RDS failure, Production VPC down | 15 min | Every 30 min |\n| P2-High | Major degradation | Single AZ impact, GuardDuty Critical | 30 min | Every 1 hour |\n| P3-Medium | Limited impact | Single instance, non-prod security finding | 2 hours | Every 4 hours |\n| P4-Low | Minimal impact | Monitoring alert, informational finding | 8 hours | Daily |\n\n### Step 3: Develop IT Incident Playbooks (Week 2-3)\n**Time: 16-24 hours | Owner: Cloud Operations Team**\n\nEach playbook must follow this structure:\n```\n1. TRIGGER: What activates this playbook\n   - CloudWatch Alarm: [specific alarm name pattern]\n   - AWS Health Event: [event type codes]\n   - Customer report: [intake channel]\n\n2. INITIAL TRIAGE (First 5 minutes):\n   - Verify alert authenticity via AWS Console/CLI\n   - Check AWS Service Health Dashboard\n   - Determine blast radius (single resource vs multi-resource)\n\n3. INVESTIGATION STEPS:\n   - Specific CLI commands to run\n   - CloudWatch Logs Insights queries\n   - X-Ray trace analysis steps\n\n4. RESOLUTION ACTIONS:\n   - Automated remediation (if available)\n   - Manual intervention steps\n   - Rollback procedures\n\n5. CUSTOMER COMMUNICATION:\n   - Template to use\n   - Information to include\n   - Approval requirements\n\n6. CLOSURE CRITERIA:\n   - Verification steps\n   - Documentation requirements\n   - Post-incident review trigger\n```\n\n### Step 4: Develop Security Incident Playbooks (Week 3-4)\n**Time: 20-30 hours | Owner: Security Operations + Cloud Team**\n\nSecurity playbooks require additional elements:\n```\nAdditional Required Sections:\n- CONTAINMENT: Immediate isolation steps\n  □ IAM policy to revoke access\n  □ Security group modifications\n  □ Instance isolation procedures\n\n- EVIDENCE PRESERVATION:\n  □ EBS snapshot before termination\n  □ CloudTrail log export\n  □ VPC Flow Log capture\n  □ Memory dump procedures (if applicable)\n\n- ERADICATION:\n  □ Malware removal steps\n  □ Credential rotation procedures\n  □ Resource replacement vs remediation decision tree\n\n- REGULATORY NOTIFICATION:\n  □ Breach notification requirements by jurisdiction\n  □ Customer contractual obligations\n  □ AWS Abuse report procedures\n```\n\n### Step 5: Configure AWS Systems Manager Incident Manager (Week 4)\n**Time: 8-12 hours | Owner: Cloud Engineer**\n\n```bash\n# Create response plan for P1 incidents\naws ssm-incidents create-response-plan \\\n  --name \"P1-Production-Incident\" \\\n  --incident-template '{\n    \"title\": \"P1 Production Incident\",\n    \"impact\": 1,\n    \"summary\": \"Critical production impact requiring immediate response\"\n  }' \\\n  --engagements '[{\n    \"ssmContactId\": \"arn:aws:ssm-contacts:region:account:contact/oncall-team\"\n  }]' \\\n  --actions '[{\n    \"ssmAutomation\": {\n      \"documentName\": \"Incident-Initial-Triage\",\n      \"roleArn\": \"arn:aws:iam::account:role/IncidentManagerRole\"\n    }\n  }]'\n```\n\nDocument this configuration as evidence of AWS-native tooling integration.\n\n### Step 6: Create Customer Communication Framework (Week 4-5)\n**Time: 6-8 hours | Owner: Service Delivery Manager**\n\nDevelop templates for each communication type:\n\n**Initial Notification Template:**\n```\nSubject: [PRIORITY] Incident Notification - [Customer Name] - INC[NUMBER]\n\nDear [Customer Contact],\n\nWe are writing to inform you of an incident affecting your AWS environment.\n\nINCIDENT DETAILS:\n- Incident ID: INC[NUMBER]\n- Priority: [P1/P2/P3/P4]\n- Start Time: [UTC timestamp]\n- Affected Services: [List AWS services/resources]\n- Current Impact: [Description]\n\nCURRENT STATUS:\n[Brief description of investigation/response status]\n\nNEXT UPDATE:\nYou will receive an update by [specific time] or sooner if status changes.\n\nCONTACT:\n- Incident Bridge: [conference line]\n- Primary Contact: [Name, phone, email]\n\n[Signature]\n```\n\n### Step 7: Implement Metrics and Continuous Improvement (Week 5-6)\n**Time: 10-15 hours | Owner: Operations Manager**\n\nCreate dashboard showing:\n```\nRequired Metrics:\n- MTTD (Mean Time to Detect) by source\n- MTTA (Mean Time to Acknowledge) vs SLA\n- MTTR (Mean Time to Resolve) by priority\n- Incident volume trends (IT vs Security)\n- Repeat incident rate\n- Customer satisfaction scores\n- Playbook adherence rate\n```\n\nUse Amazon QuickSight or your ITSM tool's native reporting.\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Single Process for IT and Security Incidents\n\n**Problem:** Creating one generic process that doesn't differentiate between IT and Security incidents.\n\n**Why it fails:** AWS auditors specifically look for:\n- Different escalation paths (Security incidents → CISO/Security team)\n- Evidence preservation requirements (Security only)\n- Regulatory notification procedures (Security only)\n- Containment steps before resolution (Security only)\n\n**Solution:** Create parallel workflows that share common elements (logging, prioritization) but diverge at investigation and response phases.\n\n---\n\n### ❌ Mistake 2: Playbooks Without AWS Service Specificity\n\n**Problem:** Generic playbooks like \"Server Down Response\" without AWS context.\n\n**Why it fails:** Auditors expect to see:\n- Specific CloudWatch alarm names/patterns\n- AWS CLI commands for investigation\n- AWS Console navigation paths\n- References to AWS-specific recovery options (instance recovery, AZ failover)\n\n**Solution:** Every playbook should reference at least 3 AWS services and include actual CLI commands or Console steps.\n\n---\n\n### ❌ Mistake 3: No Evidence of Process Execution\n\n**Problem:** Submitting only policy documents without proof of actual use.\n\n**Why it fails:** AWS wants to see the process is operational, not theoretical.\n\n**Solution:** Include:\n- 3-5 redacted incident tickets showing full lifecycle\n- Post-incident review documents\n- Monthly/quarterly incident metrics reports\n- Evidence of playbook updates based on lessons learned\n\n---\n\n### ❌ Mistake 4: Missing Customer Communication SLAs\n\n**Problem:** Process describes communication steps but lacks specific timeframes.\n\n**Why it fails:** MSPs must demonstrate predictable customer experience.\n\n**Solution:** Define explicit SLAs:\n```\nP1: Initial notification within 15 minutes\nP2: Initial notification within 30 minutes\nP3: Initial notification within 2 hours\nP4: Initial notification within 8 business hours\n```\n\n---\n\n### ❌ Mistake 5: No Integration with Other ITIL Processes\n\n**Problem:** Incident Management exists in isolation.\n\n**Why it fails:** AWS expects mature ITSM integration.\n\n**Solution:** Document explicit handoffs to:\n- Problem Management (for repeat incidents)\n- Change Management (for emergency changes during incidents)\n- Configuration Management (for CMDB updates)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **IT vs Security differentiation** | Review procedure document section headers | Separate sections/workflows exist for IT and Security incidents with different escalation paths |\n| 2 | **All 9 required elements covered** | Cross-reference against requirement description | Each element (identify, log, categorize, prioritize, investigate, playbooks, communicate, resolve, close) has dedicated section |\n| 3 | **AWS service integration documented** | Search documents for AWS service names | Minimum 5 AWS services referenced (CloudWatch, GuardDuty, Security Hub, Systems Manager, SNS) |\n| 4 | **Playbook specificity** | Review 2 random playbooks for CLI commands | Each playbook contains actual AWS CLI commands or specific Console navigation |\n| 5 | **Customer communication templates** | Check template completeness | Templates exist for: initial notification, status update, resolution notification, RCA delivery |\n| 6 | **Evidence of execution** | Review sample incident records | 3+ redacted incidents showing full lifecycle with timestamps matching SLAs |\n| 7 | **Metrics and reporting** | Check for dashboard/report samples | Monthly metrics report showing MTTD, MTTA, MTTR, volume trends |\n\n### Quality Verification Questions\n\n**Ask yourself before submission:**\n\n```\n□ Can a new team member follow our playbooks without additional guidance?\n□ Do our SLAs match what we actually deliver? (Check against real incident data)\n□ Is there a clear decision tree for IT vs Security classification?\n□ Have we tested our GuardDuty response playbook with a real finding?\n□ Does our process reference AWS Shared Responsibility Model?\n□ Are customer-specific runbooks referenced in the main procedure?\n□ Is there evidence of process improvement from past incidents?\n```\n\n### Final Document Quality Check\n\n```\n□ All documents dated within last 12 months\n□ Version control evident (v2.x or higher suggests maturity)\n□ Document owner and review cycle specified\n□ No \"TBD\" or placeholder content remaining\n□ Consistent terminology throughout (incident vs event vs alert)\n□ AWS service names spelled correctly (CloudWatch not Cloudwatch)\n□ Customer-facing templates professionally formatted\n```\n\n---\n\n## 🎯 Quick Win: AWS Systems Manager Incident Manager Setup\n\nIf you need to demonstrate AWS-native tooling quickly, implement this minimum viable setup:\n\n```bash\n# 1. Create contacts\naws ssm-contacts create-contact \\\n  --alias \"oncall-primary\" \\\n  --type PERSONAL \\\n  --plan '{\n    \"Stages\": [{\n      \"DurationInMinutes\": 5,\n      \"Targets\": [{\"ChannelTargetInfo\": {\"ContactChannelId\": \"phone-channel\"}}]\n    }]\n  }'\n\n# 2. Create response plan\naws ssm-incidents create-response-plan \\\n  --name \"MSP-Standard-Response\" \\\n  --incident-template '{\"title\":\"Incident\",\"impact\":2}'\n\n# 3. Create runbook integration\n# Link to Systems Manager Automation documents for automated triage\n```\n\nScreenshot this configuration and include in your evidence package as \"AWS-Native Incident Management Tooling Configuration.\"",
      "language": "en",
      "createdAt": "2026-01-07T02:36:05.935Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-002",
      "category": "Operations",
      "title": "Problem Management",
      "advice": "# OPSP-002: Problem Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nProblem Management is fundamentally different from Incident Management (OPSP-001). While Incident Management focuses on **\"restoring service quickly\"**, Problem Management addresses **\"preventing recurrence\"**. AWS evaluates whether MSP Partners have the capability to identify root causes of customer-impacting events and implement systematic improvements.\n\nThis requirement demonstrates that your organization doesn't just \"firefight\" but operates with a **mature operational mindset** that learns from failures and continuously improves.\n\n### 🔎 Key Points Auditors Evaluate\n\n| Evaluation Point | What Auditors Look For |\n|------------------|------------------------|\n| **Root Cause Analysis Depth** | Whether analysis goes beyond surface symptoms to identify true contributing factors (not just \"server crashed\" but WHY it crashed) |\n| **Action Plan Specificity** | Concrete, measurable remediation steps with owners and deadlines - not vague \"improve monitoring\" statements |\n| **Customer Communication Quality** | Professional, transparent communication that explains impact, cause, and prevention measures in business terms |\n| **Closed-Loop Process** | Evidence that action items were actually completed, not just documented |\n| **Pattern Recognition** | Ability to identify recurring issues across incidents and address systemic problems |\n\n### Relevant AWS Services & Features\n\n- **AWS Systems Manager OpsCenter**: Aggregate and track operational issues\n- **Amazon DevOps Guru**: ML-powered anomaly detection and root cause insights\n- **AWS CloudTrail**: API activity analysis for change-related incidents\n- **Amazon CloudWatch Logs Insights**: Log analysis for root cause investigation\n- **AWS X-Ray**: Distributed tracing for application-level root cause analysis\n- **AWS Health Dashboard**: AWS service event correlation\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Key Requirements |\n|---------------|--------|------------------|\n| **Post-Incident Analysis Report (PIR)** | PDF/Word (5-15 pages) | Must show complete analysis cycle from incident to remediation |\n| **Action Plan with Tracking** | Spreadsheet or ITSM export | Must show status, owners, deadlines, and completion evidence |\n| **Customer Communication Records** | Email threads or ticket exports | Must show proactive, professional communication |\n\n### 📄 Post-Incident Analysis Report - Required Sections\n\n```\nDocument Name Example: \"PIR-2024-0047_CustomerName_DatabaseOutage_20240315.pdf\"\n```\n\n**Mandatory Content:**\n\n1. **Executive Summary**\n   - Incident reference number (link to OPSP-001 incident)\n   - Duration and business impact quantified\n   - Root cause statement (1-2 sentences)\n   - Key remediation actions summary\n\n2. **Timeline Reconstruction**\n   - Detailed chronological events with timestamps\n   - Detection point vs. actual start time (detection gap analysis)\n   - Key decision points during response\n\n3. **Impact Analysis**\n   - Affected services/resources (specific AWS resource ARNs)\n   - Customer business impact (transactions failed, revenue impact if known)\n   - SLA/SLO breach details\n\n4. **Root Cause Analysis Section**\n   - Analysis methodology used (5 Whys, Fishbone, Fault Tree)\n   - Contributing factors identified (not just one \"root cause\")\n   - Evidence supporting each finding (logs, metrics, traces)\n\n5. **Action Plan**\n   - Immediate fixes (already implemented)\n   - Short-term mitigations (1-4 weeks)\n   - Long-term improvements (1-3 months)\n   - Each item with: Owner, Deadline, Success Criteria, Status\n\n6. **Lessons Learned**\n   - What worked well\n   - What could be improved\n   - Process/tooling gaps identified\n\n### 📧 Customer Communication Evidence\n\n```\nFile Name Example: \"CustomerComms_PIR-2024-0047_Acme_Corp.pdf\"\n```\n\n**Required Communications:**\n- Initial notification of post-incident review initiation\n- PIR findings summary (customer-appropriate version)\n- Action plan commitment with timelines\n- Follow-up on completed remediation actions\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Select the Right Incident for Evidence (Day 1)\n**Time: 2-3 hours | Role: Operations Manager**\n\nChoose an incident that demonstrates analytical depth:\n\n✅ **Good Candidates:**\n- Multi-factor root cause (shows thorough analysis)\n- Required AWS service investigation (CloudTrail, X-Ray analysis)\n- Had measurable customer impact\n- Resulted in meaningful process/architecture improvements\n- Occurred within last 12 months\n\n❌ **Avoid:**\n- Simple \"restart fixed it\" incidents\n- AWS service outages where you had no control\n- Incidents with incomplete follow-through\n\n**Action:** Query your ITSM system:\n```\nFilter: Severity = P1 or P2\nAND Status = Closed\nAND Has_PIR = True\nAND Date > [12 months ago]\n```\n\n### Step 2: Reconstruct the Analysis Process (Days 2-3)\n**Time: 4-6 hours | Role: Technical Lead + Incident Responders**\n\nGather raw analysis artifacts:\n\n```bash\n# CloudWatch Logs Insights query example for incident timeline\nfields @timestamp, @message\n| filter @logStream like /application-name/\n| filter @timestamp between '2024-03-15T08:00:00Z' and '2024-03-15T12:00:00Z'\n| sort @timestamp asc\n```\n\n**AWS Tools to Use:**\n- Export CloudWatch dashboards showing anomaly period\n- Pull X-Ray service map and trace analysis\n- Extract CloudTrail events for change correlation\n- Screenshot DevOps Guru insights if applicable\n\n### Step 3: Document Root Cause Analysis Using 5 Whys (Day 4)\n**Time: 3-4 hours | Role: Technical Lead**\n\nCreate a structured analysis document:\n\n```\nProblem: Database connection pool exhaustion caused API timeouts\n\nWhy 1: Connection pool reached maximum limit\n→ Evidence: CloudWatch ConnectionCount metric hit 100 (max)\n\nWhy 2: Connections weren't being released properly\n→ Evidence: Application logs showing connection leak pattern\n\nWhy 3: Recent code deployment had missing connection.close() in error handler\n→ Evidence: Git commit diff from deployment on 2024-03-14\n\nWhy 4: Code review didn't catch the missing cleanup\n→ Evidence: PR review comments focused only on feature logic\n\nWhy 5: No automated static analysis for resource cleanup patterns\n→ Evidence: CI/CD pipeline configuration lacks SonarQube rules\n\nContributing Factors:\n- Monitoring alert threshold set too high (90% vs recommended 70%)\n- No connection pool metrics on customer dashboard\n- Deployment occurred Friday evening (reduced monitoring attention)\n```\n\n### Step 4: Build Actionable Remediation Plan (Day 5)\n**Time: 2-3 hours | Role: Operations Manager + Technical Lead**\n\nCreate SMART action items:\n\n| ID | Action | Owner | Deadline | Success Criteria | Status |\n|----|--------|-------|----------|------------------|--------|\n| A1 | Deploy hotfix for connection leak | Dev Team | 2024-03-16 | Zero connection leaks in 48hr monitoring | ✅ Complete |\n| A2 | Lower connection pool alert to 70% | SRE Team | 2024-03-18 | Alert configured in CloudWatch | ✅ Complete |\n| A3 | Add SonarQube resource cleanup rules | DevOps | 2024-04-01 | Rules active, blocking PR merges | 🔄 In Progress |\n| A4 | Update deployment policy - no Friday PM deploys | Ops Manager | 2024-03-20 | Policy documented, team trained | ✅ Complete |\n| A5 | Add connection metrics to customer dashboard | SRE Team | 2024-04-15 | Dashboard updated, customer notified | 📋 Planned |\n\n### Step 5: Draft Customer Communication (Day 6)\n**Time: 2-3 hours | Role: Service Delivery Manager**\n\n**Template Structure (customize for each incident):**\n\n```\nSubject: Post-Incident Report - [Service] Availability Issue - March 15, 2024\n\nDear [Customer Name],\n\nFollowing the service disruption on March 15th, we have completed our \npost-incident analysis. Please find below our findings and the steps \nwe are taking to prevent recurrence.\n\nINCIDENT SUMMARY\n- Duration: 08:47 - 10:23 UTC (1 hour 36 minutes)\n- Impact: API response times exceeded SLA thresholds\n- Affected Services: Order Processing API, Inventory Service\n\nROOT CAUSE\nA code deployment on March 14th introduced a database connection \nhandling issue that caused connection pool exhaustion under peak load.\n\nIMMEDIATE ACTIONS TAKEN\n✓ Deployed corrective code fix (March 15, 11:00 UTC)\n✓ Increased monitoring sensitivity for early detection\n✓ Implemented deployment freeze during investigation\n\nPREVENTIVE MEASURES\n1. Enhanced code review process with automated resource leak detection\n2. Updated deployment windows to avoid high-risk periods\n3. Added connection pool metrics to your monitoring dashboard\n\nWe take service reliability seriously and appreciate your patience. \nPlease don't hesitate to reach out with any questions.\n\n[Signature]\n```\n\n### Step 6: Compile Evidence Package (Day 7)\n**Time: 3-4 hours | Role: Operations Manager**\n\n**Folder Structure:**\n```\nOPSP-002_Problem_Management/\n├── 01_PIR_Report/\n│   └── PIR-2024-0047_AcmeCorp_DatabaseOutage_20240315.pdf\n├── 02_Action_Plan/\n│   └── ActionPlan_PIR-2024-0047_Tracking.xlsx\n├── 03_Customer_Communications/\n│   ├── Email_InitialNotification_20240316.pdf\n│   ├── Email_PIRSummary_20240322.pdf\n│   └── Email_RemediationComplete_20240420.pdf\n├── 04_Supporting_Evidence/\n│   ├── CloudWatch_Dashboard_Export.pdf\n│   ├── 5Whys_Analysis_Worksheet.pdf\n│   └── CodeReview_Enhancement_Screenshot.png\n└── 05_Process_Documentation/\n    └── Problem_Management_Procedure_v2.3.pdf\n```\n\n### Step 7: Internal Review and Gap Check (Day 8)\n**Time: 2-3 hours | Role: Quality/Compliance Lead**\n\nCross-reference against audit criteria before submission.\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Confusing Incident Reports with Problem Reports\n\n**Wrong Approach:**\nSubmitting an incident ticket that says \"Issue resolved, server restarted\" as PIR evidence.\n\n**Why It Fails:**\nAuditors specifically look for **post-incident analysis** - the investigation that happens AFTER service restoration. The PIR must answer \"why did this happen and how do we prevent it?\"\n\n**Correct Approach:**\nClearly separate incident record (OPSP-001) from problem analysis (OPSP-002). Reference the incident number in your PIR but provide distinct analytical content.\n\n---\n\n### ❌ Mistake 2: Superficial Root Cause Analysis\n\n**Wrong Approach:**\n```\nRoot Cause: The server ran out of memory and crashed.\nAction: Added more memory to the server.\n```\n\n**Why It Fails:**\nThis addresses the symptom, not the cause. Auditors will ask: \"Why did it run out of memory? What changed? Will adding memory actually prevent recurrence?\"\n\n**Correct Approach:**\n```\nRoot Cause Analysis:\n- Memory exhaustion was caused by a memory leak in the logging module\n- Leak introduced in version 2.4.1 deployed on March 10\n- Leak occurs when log rotation fails, causing unbounded buffer growth\n- Log rotation failed due to disk permission change from security hardening\n\nActions:\n1. Fix logging module memory management (addresses leak)\n2. Add memory utilization alerting at 70% threshold (early detection)\n3. Include permission validation in security hardening runbook (prevent recurrence)\n4. Add memory leak detection to CI/CD pipeline (systemic prevention)\n```\n\n---\n\n### ❌ Mistake 3: Action Plans Without Closure Evidence\n\n**Wrong Approach:**\nSubmitting action plan showing items as \"In Progress\" or \"Planned\" with no completion evidence.\n\n**Why It Fails:**\nAWS wants to see the **closed loop** - that you don't just identify actions but actually complete them. An action plan with all items \"planned\" suggests the process isn't mature.\n\n**Correct Approach:**\n- Select a PIR where at least 70% of actions are complete\n- Include evidence of completion (screenshots, change records, updated configurations)\n- For items still in progress, show clear progress and realistic timelines\n\n---\n\n### ❌ Mistake 4: Missing or Generic Customer Communication\n\n**Wrong Approach:**\n- No customer communication included\n- Generic template with placeholders visible\n- Internal-only PIR with technical jargon\n\n**Why It Fails:**\nThe requirement explicitly states \"provides communication to customers.\" Auditors verify you translate technical findings into customer-appropriate messaging.\n\n**Correct Approach:**\n- Include actual email threads or ticket communications\n- Show customer-appropriate language (business impact, not just technical details)\n- Demonstrate proactive communication (you reached out, not just responded to complaints)\n\n---\n\n### ❌ Mistake 5: No Link Between Analysis and AWS Services\n\n**Wrong Approach:**\nPIR that could apply to any infrastructure with no AWS-specific investigation or tooling mentioned.\n\n**Why It Fails:**\nAs an AWS MSP, auditors expect you to leverage AWS-native tools for investigation and remediation.\n\n**Correct Approach:**\nReference specific AWS services used in analysis:\n- \"CloudTrail analysis revealed unauthorized API call from...\"\n- \"X-Ray trace showed latency spike in Lambda function...\"\n- \"DevOps Guru proactively identified anomaly 15 minutes before customer impact...\"\n- \"Implemented AWS Config rule to prevent similar misconfiguration...\"\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Quality Gate\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ | **PIR clearly separate from incident record** | Compare OPSP-001 and OPSP-002 evidence | Different documents with cross-reference, PIR focuses on analysis not response |\n| ✅ | **Root cause analysis shows methodology** | Review PIR Section 4 | 5 Whys, Fishbone, or Fault Tree clearly documented with evidence chain |\n| ✅ | **Multiple contributing factors identified** | Count factors in PIR | Minimum 2-3 contributing factors (real incidents rarely have single cause) |\n| ✅ | **Action plan has SMART items** | Review each action item | Every item has: Specific action, Owner name, Deadline date, Measurable success criteria |\n| ✅ | **Action completion evidence included** | Check for completion artifacts | At least 60-70% of actions show completion evidence (screenshots, change records) |\n| ✅ | **Customer communication is professional** | Read from customer perspective | No internal jargon, explains impact in business terms, includes prevention commitments |\n| ✅ | **AWS services referenced in analysis** | Search for AWS service names | Minimum 2-3 AWS services mentioned in investigation or remediation |\n| ✅ | **Timeline shows detection vs. occurrence gap** | Check timeline section | Analysis includes when issue started vs. when detected (shows monitoring maturity) |\n| ✅ | **Lessons learned are actionable** | Review lessons section | Not just \"we learned X\" but \"we will do Y differently\" |\n| ✅ | **Evidence is from last 12 months** | Check dates | All evidence dated within audit eligibility window |\n\n### 📊 Quality Scoring Guide\n\n**Before submitting, score your evidence:**\n\n- **Root Cause Depth**: 1 (surface) → 5 (systemic) | Target: ≥4\n- **Action Plan Completeness**: 1 (vague) → 5 (SMART with evidence) | Target: ≥4\n- **Customer Communication**: 1 (none) → 5 (proactive, professional) | Target: ≥4\n- **AWS Integration**: 1 (generic) → 5 (AWS-native tools throughout) | Target: ≥3\n- **Closed Loop Evidence**: 1 (all planned) → 5 (all complete with proof) | Target: ≥4\n\n**Total Score Target: ≥18/25 for confident submission**\n\n---\n\n## 💡 Pro Tips from Audit Experience\n\n1. **Use a real incident, not a fabricated example** - Auditors can tell the difference. Real incidents have messy details and genuine lessons.\n\n2. **Show pattern recognition** - If your PIR references \"this is the third connection pool issue this quarter, leading to syst",
      "language": "en",
      "createdAt": "2026-01-07T02:37:36.071Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-003",
      "category": "Operations",
      "title": "Deployment Risk Management",
      "advice": "# OPSP-003: Deployment Risk Management - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nDeployment Risk Management is a **core differentiator** between basic AWS partners and MSP-level partners. AWS expects MSP Partners to demonstrate that they can deploy changes to customer production environments **without causing service disruptions**. This requirement directly reflects AWS's Well-Architected Framework's Operational Excellence pillar, specifically the \"Make frequent, small, reversible changes\" design principle.\n\nUnlike simple CI/CD pipeline requirements, this item demands **evidence of sophisticated deployment strategies** that minimize blast radius and enable rapid rollback.\n\n### 🎯 Key Points Auditors Specifically Look For\n\n1. **Concrete deployment strategy selection criteria** - Not just \"we do blue/green\" but documented decision logic for when to use canary vs. blue/green vs. rolling deployments based on risk assessment\n\n2. **Quantified traffic shifting parameters** - Specific percentages (e.g., 5% → 25% → 50% → 100%), time intervals between shifts, and metrics thresholds that trigger progression or rollback\n\n3. **Automated rollback triggers** - Evidence that rollback isn't manual-only; CloudWatch alarms or custom metrics that automatically halt or reverse deployments\n\n4. **Customer environment segregation** - Proof that deployment risk management applies across multiple customer accounts, not just internal environments\n\n5. **Post-deployment validation procedures** - Documented health checks and smoke tests that must pass before traffic shifting continues\n\n### 🔧 Relevant AWS Services\n\n| Service | Role in Deployment Risk Management |\n|---------|-----------------------------------|\n| **AWS CodeDeploy** | Blue/green, canary, linear deployment configurations |\n| **Amazon ECS/EKS** | Rolling updates, blue/green with ALB target groups |\n| **AWS Lambda** | Alias traffic shifting, CodeDeploy integration |\n| **AWS App Mesh** | Weighted routing for canary deployments |\n| **Amazon Route 53** | Weighted routing policies for DNS-level traffic shifting |\n| **AWS CloudFormation** | Stack policies, change sets for infrastructure changes |\n| **AWS Step Functions** | Orchestrating multi-stage deployment workflows |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### 📄 Document 1: Deployment Risk Management Procedure\n**File name example:** `PROC-DEPLOY-001_Deployment_Risk_Management_Procedure_v2.3.pdf`\n\n**Must include:**\n- Deployment strategy decision matrix (risk level → strategy mapping)\n- Traffic shifting configurations for each strategy type\n- Rollback criteria and procedures (automated + manual)\n- Approval gates and escalation paths\n- Customer notification requirements\n\n**Sample content structure:**\n```\nSection 3.2 - Canary Deployment Configuration Standards\n┌─────────────────┬──────────────┬─────────────────┬─────────────────┐\n│ Risk Level      │ Initial %    │ Increment       │ Bake Time       │\n├─────────────────┼──────────────┼─────────────────┼─────────────────┤\n│ Low (patch)     │ 25%          │ 25% increments  │ 5 minutes       │\n│ Medium (feature)│ 10%          │ 15% increments  │ 15 minutes      │\n│ High (breaking) │ 5%           │ 10% increments  │ 30 minutes      │\n└─────────────────┴──────────────┴─────────────────┴─────────────────┘\n```\n\n#### 📄 Document 2: Deployment Runbook with Rollback Procedures\n**File name example:** `RUNBOOK-DEPLOY-BG-001_BlueGreen_Deployment_Runbook.md`\n\n**Must include:**\n- Pre-deployment checklist\n- Step-by-step deployment execution\n- Health check validation commands\n- Rollback execution steps with estimated time\n- Post-rollback verification\n\n#### 📄 Document 3: Deployment Execution Evidence (Screenshots/Logs)\n**File name examples:**\n- `Evidence_CodeDeploy_Canary_Config_CustomerA_2024-01.png`\n- `Evidence_ECS_BlueGreen_Deployment_CustomerB_2024-02.pdf`\n- `Evidence_Lambda_TrafficShift_Execution_Log.json`\n\n**Must show:**\n- Actual deployment configuration (not just documentation)\n- Traffic shifting in progress or completed\n- Rollback execution (if available - highly valued)\n- CloudWatch metrics during deployment\n\n#### 📄 Document 4: Deployment Risk Assessment Template\n**File name example:** `TMPL-DEPLOY-RA-001_Deployment_Risk_Assessment_Form.xlsx`\n\n**Must include:**\n- Change categorization criteria\n- Impact analysis fields\n- Deployment strategy recommendation logic\n- Approval workflow based on risk level\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current Deployment Capabilities (Week 1)\n**Time:** 3-4 days | **Owner:** DevOps Lead\n\n**Specific actions:**\n```bash\n# Check existing CodeDeploy deployment configurations\naws deploy list-deployment-configs --region us-east-1\n\n# Review ECS services for deployment configuration\naws ecs describe-services --cluster production-cluster \\\n  --services service-name \\\n  --query 'services[].deploymentConfiguration'\n\n# Check Lambda alias traffic shifting configurations\naws lambda get-alias --function-name my-function --name prod\n```\n\n**Output:** Inventory spreadsheet of current deployment methods per customer/service\n\n### Step 2: Define Deployment Strategy Decision Matrix (Week 1-2)\n**Time:** 2-3 days | **Owner:** Solutions Architect + DevOps Lead\n\n**Create decision logic:**\n```\nIF database_schema_change = TRUE → Blue/Green with manual cutover\nELIF breaking_api_change = TRUE → Canary (5% → 15% → 30% → 50% → 100%)\nELIF feature_flag_controlled = TRUE → Rolling deployment acceptable\nELIF infrastructure_only = TRUE → CloudFormation change sets with review\nELSE → Standard canary (10% → 50% → 100%)\n```\n\n### Step 3: Implement CodeDeploy Deployment Configurations (Week 2-3)\n**Time:** 5-7 days | **Owner:** DevOps Engineer\n\n**Create standardized deployment configs:**\n```yaml\n# appspec.yml for ECS Blue/Green\nversion: 0.0\nResources:\n  - TargetService:\n      Type: AWS::ECS::Service\n      Properties:\n        TaskDefinition: <TASK_DEFINITION>\n        LoadBalancerInfo:\n          ContainerName: \"app-container\"\n          ContainerPort: 8080\nHooks:\n  - BeforeAllowTraffic: \"arn:aws:lambda:region:account:function:PreTrafficHook\"\n  - AfterAllowTraffic: \"arn:aws:lambda:region:account:function:PostTrafficHook\"\n```\n\n```bash\n# Create canary deployment configuration\naws deploy create-deployment-config \\\n  --deployment-config-name Canary25Percent15Minutes \\\n  --traffic-routing-config \"type=TimeBasedCanary,\\\n    timeBasedCanary={canaryPercentage=25,canaryInterval=15}\"\n```\n\n### Step 4: Configure Automated Rollback Triggers (Week 3)\n**Time:** 3-4 days | **Owner:** DevOps Engineer\n\n**CloudWatch Alarm for automatic rollback:**\n```yaml\n# CloudFormation snippet\nDeploymentRollbackAlarm:\n  Type: AWS::CloudWatch::Alarm\n  Properties:\n    AlarmName: !Sub \"${ServiceName}-deployment-error-rate\"\n    MetricName: 5XXError\n    Namespace: AWS/ApplicationELB\n    Statistic: Sum\n    Period: 60\n    EvaluationPeriods: 2\n    Threshold: 10\n    ComparisonOperator: GreaterThanThreshold\n    TreatMissingData: notBreaching\n```\n\n**CodeDeploy auto-rollback configuration:**\n```bash\naws deploy update-deployment-group \\\n  --application-name MyApp \\\n  --deployment-group-name Production \\\n  --auto-rollback-configuration \"enabled=true,events=DEPLOYMENT_FAILURE,DEPLOYMENT_STOP_ON_ALARM\"\n```\n\n### Step 5: Document Procedures and Runbooks (Week 3-4)\n**Time:** 4-5 days | **Owner:** Technical Writer + DevOps Lead\n\n**Key sections to write:**\n1. Deployment strategy selection flowchart (visual diagram required)\n2. Pre-deployment checklist (minimum 10 items)\n3. Traffic shifting monitoring dashboard setup\n4. Rollback decision criteria (quantified metrics)\n5. Post-deployment validation tests\n\n### Step 6: Execute and Capture Evidence Deployments (Week 4-5)\n**Time:** 5-7 days | **Owner:** DevOps Team\n\n**Evidence capture checklist:**\n- [ ] Screenshot of CodeDeploy deployment in \"Canary\" phase\n- [ ] CloudWatch dashboard showing traffic shift metrics\n- [ ] Deployment history showing successful canary progression\n- [ ] (Bonus) Rollback execution evidence from test or actual incident\n\n### Step 7: Create Customer-Facing Deployment SOP (Week 5)\n**Time:** 2-3 days | **Owner:** Service Delivery Manager\n\n**Demonstrate MSP capability by showing:**\n- How deployment risk management is offered to customers\n- Customer approval workflow for high-risk deployments\n- Customer notification templates for deployment windows\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Documenting Only One Deployment Strategy\n**Problem:** Submitting evidence that shows only blue/green deployments without canary or rolling options.\n\n**Why it fails:** Auditors expect MSPs to select appropriate strategies based on risk. A single strategy suggests lack of sophistication.\n\n**Solution:** Document at least 3 deployment strategies with clear selection criteria for each.\n\n### ❌ Mistake 2: No Quantified Rollback Criteria\n**Problem:** Rollback procedure states \"rollback if errors increase\" without specific thresholds.\n\n**Auditor question:** \"What error rate triggers rollback? 1%? 5%? 10%?\"\n\n**Solution:** Define specific metrics:\n```\nAutomatic rollback triggers:\n- Error rate > 5% (compared to baseline)\n- P99 latency > 2x baseline\n- Health check failures > 3 consecutive\n```\n\n### ❌ Mistake 3: Manual-Only Rollback Procedures\n**Problem:** All rollback procedures require human intervention.\n\n**Why it fails:** AWS MSP program expects automation. Manual-only rollback indicates immature operations.\n\n**Solution:** Implement CloudWatch Alarms integrated with CodeDeploy auto-rollback, then document manual procedures as \"escalation path\" when automation fails.\n\n### ❌ Mistake 4: Evidence from Internal/Demo Environments Only\n**Problem:** All deployment evidence comes from internal test accounts, not customer production environments.\n\n**Auditor concern:** \"Can they actually do this for customers?\"\n\n**Solution:** Include redacted evidence from at least 2 different customer environments (with customer names anonymized).\n\n### ❌ Mistake 5: Missing Pre-Deployment Validation\n**Problem:** Procedures jump straight to deployment without pre-checks.\n\n**What's missing:** \n- Artifact validation\n- Environment health verification\n- Dependency checks\n- Deployment window confirmation\n\n**Solution:** Create mandatory pre-deployment checklist that must be completed before any deployment starts.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Before Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Multiple deployment strategies documented** | Review procedure document Table of Contents | At least 3 strategies (blue/green, canary, rolling) with selection criteria |\n| 2 | **Traffic shifting percentages specified** | Search document for \"%\" | Specific percentages and time intervals for each strategy |\n| 3 | **Automated rollback configuration shown** | Check evidence screenshots | CloudWatch Alarm → CodeDeploy auto-rollback integration visible |\n| 4 | **Rollback time estimate documented** | Search for \"RTO\" or \"rollback time\" | Specific time (e.g., \"< 5 minutes for blue/green cutback\") |\n| 5 | **Customer environment evidence included** | Review evidence file names | At least 2 different customer contexts shown |\n| 6 | **Pre-deployment checklist exists** | Check runbook document | Minimum 10 pre-deployment validation items |\n| 7 | **Post-deployment validation defined** | Search for \"health check\" or \"smoke test\" | Specific tests with expected results documented |\n\n### Quality Verification Questions\n\n**Ask yourself before submission:**\n\n1. ✅ \"If I give this document to a new engineer, can they execute a canary deployment tomorrow?\" \n   - If no → Add more specific commands and configurations\n\n2. ✅ \"Does the evidence show deployment risk management in action, not just configuration?\"\n   - If no → Capture screenshots during actual deployments\n\n3. ✅ \"Can an auditor see the connection between risk assessment → strategy selection → execution?\"\n   - If no → Add traceability (e.g., \"This deployment used canary because risk assessment scored 'Medium'\")\n\n4. ✅ \"Is there evidence of rollback capability, not just deployment?\"\n   - If no → Execute a test rollback and capture evidence\n\n### 📊 Evidence Quality Scoring (Self-Assessment)\n\n| Criteria | Points | Your Score |\n|----------|--------|------------|\n| Procedure covers 3+ deployment strategies | 20 | ___ |\n| Quantified traffic shifting parameters | 15 | ___ |\n| Automated rollback configuration shown | 20 | ___ |\n| Customer environment evidence (2+ customers) | 15 | ___ |\n| Pre/post deployment validation documented | 15 | ___ |\n| Visual diagrams (flowcharts, architecture) | 10 | ___ |\n| Version control and approval signatures | 5 | ___ |\n| **Total** | **100** | ___ |\n\n**Passing threshold:** 75+ points\n**Recommended for submission:** 85+ points\n\n---\n\n## 📎 Quick Reference: AWS Service Configurations\n\n### CodeDeploy Canary Configuration\n```bash\naws deploy create-deployment-config \\\n  --deployment-config-name MSP-Canary-Standard \\\n  --traffic-routing-config '{\n    \"type\": \"TimeBasedCanary\",\n    \"timeBasedCanary\": {\n      \"canaryPercentage\": 10,\n      \"canaryInterval\": 15\n    }\n  }' \\\n  --compute-platform ECS\n```\n\n### ECS Blue/Green with CodeDeploy\n```bash\naws ecs create-service \\\n  --service-name my-service \\\n  --deployment-controller type=CODE_DEPLOY \\\n  --deployment-configuration \"maximumPercent=200,minimumHealthyPercent=100\"\n```\n\n### Lambda Traffic Shifting\n```bash\naws lambda update-alias \\\n  --function-name my-function \\\n  --name prod \\\n  --routing-config 'AdditionalVersionWeights={\"2\": 0.1}'\n```",
      "language": "en",
      "createdAt": "2026-01-07T02:38:36.555Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-004_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-004",
      "category": "Operations",
      "title": "Cloud Financial Management",
      "advice": "# OPSP-004: Cloud Financial Management - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nCloud Financial Management (FinOps) is a **core differentiator** that separates true MSPs from simple resellers. AWS expects MSP Partners to actively help customers optimize their cloud spend—not just provision resources. This requirement validates that you're providing ongoing financial value, not just technical support.\n\n### 🔍 Key Points Auditors Look For\n\n1. **Regularity of Cost Reviews**: Auditors verify you conduct cost assessments on a **recurring schedule** (monthly or quarterly minimum)—not just one-time reviews. They'll check timestamps and patterns across multiple reports.\n\n2. **Actionable Specificity**: Recommendations must include **concrete dollar amounts, specific resource IDs, and implementation steps**—not vague statements like \"consider rightsizing.\"\n\n3. **Customer Acknowledgment**: Evidence showing the customer **received and responded** to recommendations (email threads, signed reports, or meeting minutes).\n\n4. **Tool Utilization**: Demonstrated use of **AWS-native cost management tools** (Cost Explorer, Compute Optimizer, Trusted Advisor) rather than only third-party solutions.\n\n5. **Savings Tracking**: Follow-up documentation showing **realized savings** from previous recommendations proves your advice delivers results.\n\n### Relevant AWS Services & Features\n- **AWS Cost Explorer** (with hourly/resource-level granularity enabled)\n- **AWS Compute Optimizer**\n- **AWS Trusted Advisor** (Cost Optimization checks)\n- **AWS Cost Anomaly Detection**\n- **Savings Plans & Reserved Instance recommendations**\n- **AWS Budgets** with alerts\n- **Cost Allocation Tags**\n- **AWS Cost and Usage Reports (CUR)**\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Document Type | Format | Key Contents |\n|---------------|--------|--------------|\n| Monthly Cost Optimization Report | PDF/DOCX | Cost trends, specific recommendations, projected savings |\n| Customer Delivery Proof | Email/PDF | Timestamp, recipient acknowledgment |\n| Savings Tracking Spreadsheet | XLSX | Before/after comparisons, realized savings |\n| Meeting Minutes | PDF | Discussion of recommendations, customer decisions |\n\n### 📄 Detailed Evidence Requirements\n\n**A. Cost Optimization Report (Primary Evidence)**\nMust include:\n- Customer name and AWS Account ID(s)\n- Reporting period (e.g., \"January 2024 Cost Review\")\n- Current month spend vs. previous month/quarter\n- Top 5 cost drivers by service\n- **Minimum 3 specific recommendations** with:\n  - Resource identifier (e.g., `i-0abc123def456`)\n  - Current configuration and cost\n  - Recommended action\n  - Estimated monthly/annual savings\n  - Implementation complexity (Low/Medium/High)\n  - Priority ranking\n\n**B. Customer Acknowledgment Evidence**\n- Email thread showing report delivery\n- Customer reply or meeting confirmation\n- Signed acceptance (if formal process exists)\n\n**C. Savings Realization Tracking**\n- Spreadsheet showing recommendations implemented\n- Before/after cost comparison\n- Cumulative savings achieved\n\n### 📁 Example File Names\n```\nCustomerABC_Cost_Optimization_Report_2024-01.pdf\nCustomerABC_FinOps_Review_Meeting_Minutes_2024-01-15.pdf\nCustomerABC_Cost_Recommendations_Delivery_Email_2024-01.pdf\nCustomerABC_Savings_Tracker_Q1-2024.xlsx\nCustomerABC_Compute_Optimizer_Export_2024-01.csv\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Enable Cost Visibility Infrastructure (Day 1-3)\n**Actions:**\n- Enable **Cost Explorer** with hourly and resource-level granularity in customer accounts\n- Activate **AWS Compute Optimizer** (requires 14 days of data)\n- Set up **Cost Allocation Tags** (minimum: Environment, Project, Owner, CostCenter)\n- Enable **Cost and Usage Reports** to S3 with resource IDs\n\n**Tools:** AWS Organizations, Cost Explorer Settings, Tag Editor\n\n**Responsible:** Cloud Operations Engineer\n\n### Step 2: Configure Automated Cost Monitoring (Day 4-7)\n**Actions:**\n- Create **AWS Budgets** with threshold alerts (50%, 80%, 100%)\n- Enable **Cost Anomaly Detection** with SNS notifications\n- Set up weekly cost summary emails via Cost Explorer\n\n**Tools:** AWS Budgets, Cost Anomaly Detection, Amazon SNS\n\n**Responsible:** FinOps Analyst / Cloud Engineer\n\n### Step 3: Conduct Deep-Dive Cost Analysis (Day 8-10)\n**Actions:**\n- Export **Compute Optimizer recommendations** (EC2, EBS, Lambda, ECS)\n- Run **Trusted Advisor** Cost Optimization checks\n- Analyze **Savings Plans/RI coverage** gaps\n- Identify **idle resources** (unattached EBS, unused EIPs, stopped instances)\n- Review **data transfer costs** (cross-AZ, NAT Gateway, egress)\n\n**Tools:** AWS Compute Optimizer, Trusted Advisor, Cost Explorer\n\n**Responsible:** FinOps Analyst\n\n**Time Estimate:** 4-6 hours per customer account\n\n### Step 4: Create Customer-Facing Report (Day 11-12)\n**Actions:**\n- Use standardized template with your company branding\n- Include executive summary with total potential savings\n- Detail each recommendation with:\n  ```\n  Recommendation #1: Rightsize EC2 Instance\n  Resource: i-0abc123def456 (prod-web-server-01)\n  Current: m5.2xlarge ($280/month)\n  Recommended: m5.xlarge ($140/month)\n  Savings: $140/month ($1,680/year)\n  Basis: Compute Optimizer shows 15% average CPU utilization\n  Risk: Low - can revert within minutes\n  ```\n\n**Tools:** Microsoft Word/Google Docs, Cost Explorer screenshots\n\n**Responsible:** FinOps Analyst + Account Manager review\n\n### Step 5: Deliver and Document Customer Interaction (Day 13-14)\n**Actions:**\n- Schedule **30-minute review call** with customer\n- Screen-share Cost Explorer dashboards during call\n- Send report via email with clear subject line: `[Action Required] AWS Cost Optimization Recommendations - January 2024`\n- Request **read receipt** or acknowledgment reply\n- Document meeting minutes with attendees and decisions\n\n**Tools:** Calendar invite, Email client, Video conferencing\n\n**Responsible:** Account Manager + FinOps Analyst\n\n### Step 6: Track Implementation and Savings (Ongoing)\n**Actions:**\n- Create tracking spreadsheet with columns:\n  - Recommendation ID\n  - Date Recommended\n  - Customer Decision (Accepted/Declined/Deferred)\n  - Implementation Date\n  - Projected Savings\n  - Actual Savings (measured 30 days post-implementation)\n- Update monthly with realized savings\n\n**Tools:** Excel/Google Sheets, Cost Explorer\n\n**Responsible:** FinOps Analyst\n\n### Step 7: Archive Evidence Package (Monthly)\n**Actions:**\n- Create dated folder structure: `Evidence/OPSP-004/CustomerName/YYYY-MM/`\n- Include: Report PDF, delivery email, meeting minutes, Compute Optimizer exports\n- Maintain **minimum 3 customer examples** for audit\n\n**Responsible:** MSP Program Coordinator\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic Recommendations Without Specifics\n**Problem:** Reports stating \"Consider rightsizing your EC2 instances\" without identifying which instances.\n\n**Solution:** Always include resource IDs, current specs, recommended specs, and dollar amounts. Auditors will reject vague recommendations.\n\n### ❌ Mistake 2: One-Time Reports Without Recurring Pattern\n**Problem:** Submitting a single cost report without evidence of ongoing practice.\n\n**Solution:** Prepare **3+ consecutive monthly reports** for the same customer to demonstrate regularity. Auditors specifically check for patterns.\n\n### ❌ Mistake 3: No Proof of Customer Delivery\n**Problem:** Having internal reports but no evidence the customer received them.\n\n**Solution:** Always include email delivery confirmation with timestamps. A report the customer never saw doesn't count as \"provided to customer.\"\n\n### ❌ Mistake 4: Ignoring AWS-Native Tools\n**Problem:** Relying solely on third-party tools (CloudHealth, Spot.io) without demonstrating AWS tool proficiency.\n\n**Solution:** Include **Compute Optimizer exports** and **Cost Explorer screenshots** even if you use third-party tools. AWS wants to see you leverage their services.\n\n### ❌ Mistake 5: No Follow-Up on Previous Recommendations\n**Problem:** Making recommendations but never tracking if they were implemented or effective.\n\n**Solution:** Include a \"Previous Recommendations Status\" section in each report showing what was implemented and actual savings achieved.\n\n### 🚫 Anti-Patterns to Avoid\n- Sending automated cost reports without human analysis\n- Recommending Reserved Instances without analyzing usage patterns\n- Focusing only on compute costs while ignoring data transfer and storage\n- Using customer data from development/test accounts instead of production\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Quality Check\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Customer identification visible** | Open report, check first page | Customer name AND AWS Account ID present |\n| 2 | **Report date within last 6 months** | Check report header/footer | Date stamp between audit date and 6 months prior |\n| 3 | **Minimum 3 specific recommendations** | Count recommendations in report | Each has: Resource ID, current cost, projected savings, action steps |\n| 4 | **Dollar amounts included** | Search document for \"$\" | Every recommendation shows current spend and potential savings |\n| 5 | **AWS tool evidence present** | Look for screenshots/exports | Contains Cost Explorer, Compute Optimizer, or Trusted Advisor data |\n| 6 | **Customer delivery proof attached** | Check evidence package | Email with timestamp showing customer received report |\n| 7 | **Multiple reporting periods shown** | Review folder structure | At least 2-3 months of reports for same customer demonstrating regularity |\n\n### ✅ Quality Criteria for Passing\n\n**Minimum Passing Standard:**\n- 2+ customer examples with complete evidence packages\n- Each package includes: Report + Delivery Proof + (ideally) Meeting Minutes\n- Reports show specific, actionable recommendations with financial impact\n- Evidence of recurring process (not one-time engagement)\n\n**Excellence Standard (Recommended):**\n- 3+ customers across different industries/sizes\n- Savings tracking showing implemented recommendations\n- Customer testimonial or acknowledgment of value received\n- Integration with AWS Cost Anomaly Detection alerts\n\n### 📊 Final Verification Questions\nBefore submitting, ask yourself:\n1. \"If I were the customer, could I take action on these recommendations today?\"\n2. \"Can I prove the customer actually saw this report?\"\n3. \"Does this evidence show a pattern, not just a single event?\"\n4. \"Are AWS-native tools visibly used in the analysis?\"\n\n---\n\n## 💡 Pro Tips from Successful Audits\n\n1. **Include a \"Quick Wins\" section** in your report highlighting recommendations that can be implemented in <1 hour with immediate savings\n\n2. **Add Cost Explorer dashboard screenshots** with annotations—auditors appreciate visual evidence of tool usage\n\n3. **Create a standard naming convention** for all FinOps documents to demonstrate mature processes\n\n4. **Track savings in customer's currency** if they're international—shows attention to detail\n\n5. **Include Savings Plans recommendations** with specific commitment amounts based on actual usage patterns—this shows sophisticated FinOps capability",
      "language": "en",
      "createdAt": "2026-01-07T02:39:29.376Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "OPSP-005_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "OPSP-005",
      "category": "Operations",
      "title": "Service Continuity",
      "advice": "# OPSP-005: Service Continuity - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nService Continuity is a **mandatory requirement** that directly validates whether your MSP practice can maintain customer service delivery during disruptions. AWS views this as non-negotiable because MSP Partners manage critical customer infrastructure—if your operations fail, multiple customer environments could be left unmanaged during incidents.\n\nThis requirement specifically tests your **operational resilience**, not your customers' DR plans. Auditors want to see that YOUR monitoring systems, ticketing platforms, NOC operations, and management tools have backup capabilities.\n\n### 🎯 Key Points Auditors Specifically Look For\n\n1. **MSP-Specific Scope**: The BCP must cover YOUR operational infrastructure (monitoring tools, ticketing systems, VPN access, communication platforms), not generic corporate continuity or customer DR plans\n\n2. **Annual Test Evidence with Dates**: Auditors verify the test was conducted within exactly 12 months of audit date—a test from 13 months ago fails\n\n3. **Alternative Infrastructure Actually Tested**: Documentation showing you actually failed over to backup systems, not just a tabletop discussion\n\n4. **Customer Impact Mitigation**: How you maintain SLA commitments during your own outages (e.g., backup NOC, alternate monitoring)\n\n5. **Recovery Time Objectives for MSP Functions**: Defined RTOs for critical MSP operations like alert response, ticket handling, and customer communication\n\n### Relevant AWS Services & Features\n\n- **AWS Organizations** with backup management account\n- **Amazon Route 53** for DNS failover of monitoring endpoints\n- **AWS Backup** for configuration data\n- **Amazon Connect** as backup communication channel\n- **AWS CloudFormation/Terraform** for infrastructure-as-code recovery\n- **Cross-region replication** for critical MSP tooling\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Document | Format | Purpose |\n|----------|--------|---------|\n| MSP Business Continuity Plan | PDF (15-30 pages) | Core process documentation |\n| BCP Test Report | PDF with screenshots | Proof of annual testing |\n| Test Execution Log | Excel/CSV with timestamps | Detailed test activities |\n| Recovery Validation Evidence | Screenshots/logs | Proof systems functioned |\n\n### 📄 Document 1: MSP Business Continuity Plan\n\n**File Name Example**: `MSP_Business_Continuity_Plan_v3.2_2024.pdf`\n\n**Must Include**:\n```\nSection 1: Scope Statement\n- Explicitly state: \"This BCP covers [Company Name]'s AWS MSP practice operations\"\n- List covered systems: monitoring platform, ticketing system, NOC infrastructure, \n  customer communication tools, AWS management accounts\n\nSection 2: Critical MSP Functions Inventory\n- 24/7 Monitoring & Alerting (Primary: Datadog/CloudWatch, Backup: PagerDuty standalone)\n- Incident Management (Primary: ServiceNow, Backup: Jira Cloud)\n- Customer Communication (Primary: Slack Connect, Backup: Amazon Connect)\n- AWS Console Access (Primary: SSO via Okta, Backup: Break-glass IAM users)\n\nSection 3: Recovery Objectives\n| Function | RTO | RPO | Backup Location |\n|----------|-----|-----|-----------------|\n| Monitoring | 30 min | 5 min | us-west-2 |\n| Ticketing | 2 hours | 1 hour | Cloud-native |\n| NOC Access | 15 min | N/A | Secondary VPN |\n\nSection 4: Activation Procedures\n- Trigger criteria (e.g., primary monitoring down >15 min)\n- Decision authority matrix\n- Communication tree with phone numbers\n\nSection 5: Recovery Procedures\n- Step-by-step failover for each system\n- Validation checkpoints\n- Failback procedures\n```\n\n### 📄 Document 2: BCP Test Report\n\n**File Name Example**: `BCP_Test_Report_2024-Q2_June15.pdf`\n\n**Must Include**:\n```\n1. Test Metadata\n   - Test Date: June 15, 2024 (MUST be within 12 months)\n   - Test Type: Full failover exercise (not tabletop)\n   - Participants: [Names and roles]\n   - Duration: 09:00 - 14:00 UTC\n\n2. Test Scenario\n   \"Simulated complete failure of primary NOC facility including:\n   - Loss of primary monitoring infrastructure (Datadog in us-east-1)\n   - Unavailability of primary ticketing system\n   - Primary communication channel outage\"\n\n3. Execution Timeline\n   09:00 - Scenario initiated, primary systems disabled\n   09:12 - BCP activation declared by NOC Manager\n   09:28 - Backup monitoring operational (Target: 30 min ✓)\n   10:15 - Backup ticketing confirmed functional\n   10:45 - Test customer alert generated and processed through backup\n   \n4. Success Criteria Results\n   | Criteria | Target | Actual | Pass/Fail |\n   |----------|--------|--------|-----------|\n   | Monitoring RTO | 30 min | 28 min | ✓ PASS |\n   | Alert processing | <5 min | 3 min | ✓ PASS |\n   \n5. Issues Discovered & Remediation\n   - Issue: Backup runbook had outdated IP addresses\n   - Resolution: Updated runbook, added quarterly review task\n   - Owner: [Name], Due: July 1, 2024, Status: Complete\n```\n\n### 📄 Document 3: Test Execution Evidence\n\n**File Names**:\n- `BCP_Test_Screenshots_20240615.pdf`\n- `Backup_System_Logs_20240615.csv`\n\n**Required Screenshots**:\n- Timestamp showing primary system disabled\n- Backup monitoring dashboard receiving alerts\n- Test ticket created in backup system\n- Communication sent via backup channel\n- Validation that customer alerts were processed\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Inventory Your MSP Operational Infrastructure (Week 1)\n**Time**: 8-12 hours | **Owner**: MSP Operations Lead\n\n```\nAction Items:\n□ List all systems used to deliver MSP services:\n  - Monitoring: [Datadog/CloudWatch/Zabbix]\n  - Ticketing: [ServiceNow/Jira/Freshdesk]\n  - Communication: [Slack/Teams/PagerDuty]\n  - Access Management: [Okta/AWS SSO/VPN]\n  - Documentation: [Confluence/SharePoint]\n\n□ Document dependencies for each system\n□ Identify single points of failure\n□ Map to AWS regions if applicable\n\nOutput: MSP_Critical_Systems_Inventory.xlsx\n```\n\n### Step 2: Define Backup Solutions for Each Critical Function (Week 2)\n**Time**: 16-20 hours | **Owner**: Infrastructure Architect\n\n```\nFor each critical system, document:\n\nPrimary: Datadog (us-east-1)\nBackup Option: CloudWatch with SNS alerting\nFailover Method: Route 53 health check triggers Lambda to enable CloudWatch alarms\nData Sync: Terraform state includes both configurations\nTest Validation: Generate test alert, confirm delivery\n\n□ Ensure backup doesn't share failure domains with primary\n□ Configure cross-region where applicable\n□ Document access credentials for backup systems (secure storage)\n□ Create infrastructure-as-code for rapid deployment\n```\n\n### Step 3: Write the BCP Document (Week 3)\n**Time**: 20-30 hours | **Owner**: Operations Manager + Technical Writer\n\n```\nUse this structure (AWS auditors expect these sections):\n\n1. Purpose & Scope (2 pages)\n   - Explicitly mention \"AWS MSP practice operations\"\n   \n2. Roles & Responsibilities (2 pages)\n   - BCP Coordinator, Recovery Teams, Communication Lead\n   \n3. Business Impact Analysis (3 pages)\n   - Impact of each system failure on customer SLAs\n   \n4. Recovery Strategies (5 pages)\n   - Detailed procedures per system\n   \n5. Communication Plan (2 pages)\n   - Internal escalation + customer notification templates\n   \n6. Testing Schedule (1 page)\n   - Annual full test + quarterly partial tests\n```\n\n### Step 4: Schedule and Execute BCP Test (Week 4-5)\n**Time**: Full day test + 8 hours prep | **Owner**: BCP Coordinator\n\n```\nPre-Test (3 days before):\n□ Notify all participants with test plan\n□ Prepare test scenarios and success criteria\n□ Set up screen recording for evidence\n□ Create isolated test environment if needed\n□ Brief customers if any impact expected\n\nTest Day Execution:\n□ 09:00 - Kickoff, confirm all participants ready\n□ 09:15 - Initiate failure scenario (disable primary systems)\n□ 09:20 - Start timer, begin recovery procedures\n□ Record all actions with timestamps\n□ Capture screenshots at each milestone\n□ Process test alert through backup systems\n□ Document any deviations from plan\n\nPost-Test:\n□ Restore primary systems\n□ Debrief session with all participants\n□ Document lessons learned\n```\n\n### Step 5: Compile Test Report with Evidence (Week 6)\n**Time**: 12-16 hours | **Owner**: BCP Coordinator\n\n```\nReport Assembly Checklist:\n□ Executive summary with pass/fail determination\n□ Detailed timeline with timestamps\n□ Screenshots embedded with captions\n□ Metrics comparison (target vs actual)\n□ Issues log with remediation status\n□ Sign-off from Operations Director\n\nEvidence Package:\n□ Consolidate all screenshots into single PDF\n□ Export system logs showing failover\n□ Include email/Slack notifications sent during test\n□ Add participant attendance confirmation\n```\n\n### Step 6: Implement Remediation Items (Week 7-8)\n**Time**: Variable | **Owner**: Assigned per issue\n\n```\nFor each issue discovered:\n□ Create tracking ticket with owner and due date\n□ Implement fix\n□ Update BCP document if procedures changed\n□ Verify fix in next quarterly test\n□ Document closure with evidence\n```\n\n### Step 7: Final Package Assembly (Week 9)\n**Time**: 4-6 hours | **Owner**: Audit Coordinator\n\n```\nFinal Submission Package:\n1. MSP_Business_Continuity_Plan_v[X]_[Year].pdf\n2. BCP_Test_Report_[Date].pdf\n3. BCP_Test_Evidence_Screenshots_[Date].pdf\n4. Remediation_Tracking_Log.xlsx (showing closed items)\n\nQuality Check:\n□ All dates within 12 months of audit\n□ Scope explicitly mentions AWS MSP practice\n□ Test was actual failover, not tabletop\n□ Evidence shows systems actually functioned\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Corporate BCP Instead of MSP-Specific BCP\n\n**What Goes Wrong**: \nCompanies submit their general corporate business continuity plan that covers office facilities, HR systems, and finance applications—but doesn't mention monitoring tools, ticketing systems, or NOC operations.\n\n**Auditor Response**: \n\"The BCP provided does not address the Partner's ability to continue servicing AWS customers. Please provide documentation specific to MSP operations.\"\n\n**Fix**: \nCreate a dedicated MSP Operations BCP or add a clearly labeled section: \"Section 7: AWS MSP Practice Continuity\" that covers monitoring, alerting, ticketing, and customer communication systems.\n\n---\n\n### ❌ Mistake 2: Tabletop Exercise Instead of Actual Failover Test\n\n**What Goes Wrong**:\nTest report describes a meeting where team discussed \"what we would do if systems failed\" but never actually disabled primary systems or activated backups.\n\n**Auditor Response**:\n\"The test evidence indicates a discussion-based exercise. Please provide evidence of an actual test where backup infrastructure was activated and validated.\"\n\n**Fix**:\nExecute a real failover:\n- Actually disable primary monitoring (or route traffic away)\n- Activate backup systems\n- Process a real (test) alert through backup pipeline\n- Capture screenshots showing backup systems handling workload\n\n---\n\n### ❌ Mistake 3: Test Date Outside 12-Month Window\n\n**What Goes Wrong**:\nAudit scheduled for March 2025, but last BCP test was January 2024 (14 months prior).\n\n**Auditor Response**:\n\"The BCP test provided was conducted more than 12 months ago. Please provide evidence of a test within the required timeframe.\"\n\n**Fix**:\n- Calendar annual BCP test for same month each year\n- Set reminder 2 months before audit to verify test currency\n- If audit delayed, conduct fresh test to reset the clock\n\n---\n\n### ❌ Mistake 4: No Evidence That Backup Systems Actually Worked\n\n**What Goes Wrong**:\nReport says \"backup monitoring activated\" but no screenshots showing alerts being received, no logs showing data flow, no evidence of actual functionality.\n\n**Auditor Response**:\n\"Please provide evidence demonstrating the backup systems successfully processed operational workload during the test.\"\n\n**Fix**:\nDuring test, capture:\n- Screenshot of backup dashboard showing active alerts\n- Log export showing alert received → ticket created → notification sent\n- Email/Slack message received via backup communication channel\n- Timestamp correlation proving end-to-end flow\n\n---\n\n### ❌ Mistake 5: Missing Recovery Time Objectives or Not Measuring Against Them\n\n**What Goes Wrong**:\nBCP doesn't define RTOs, or test report doesn't compare actual recovery time against targets.\n\n**Auditor Response**:\n\"The documentation does not include defined recovery objectives or demonstrate whether the test met those objectives.\"\n\n**Fix**:\nBCP must include table like:\n| System | RTO | RPO |\n|--------|-----|-----|\n| Monitoring | 30 min | 5 min |\n\nTest report must include:\n| System | RTO Target | Actual | Result |\n|--------|------------|--------|--------|\n| Monitoring | 30 min | 28 min | PASS |\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Before Submission, Verify Each Item:\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | BCP scope explicitly mentions AWS MSP practice | Search document for \"MSP\", \"managed service\", \"customer operations\" | Terms appear in scope section, not just incidentally |\n| 2 | Critical MSP systems are inventoried | Review Section 2 of BCP | Monitoring, ticketing, communication, access management all listed |\n| 3 | RTOs defined for each critical function | Check BCP recovery objectives table | Numeric RTO/RPO for each system, not \"ASAP\" or \"minimal\" |\n| 4 | Test date within 12 months | Compare test date to expected audit date | Test date + 12 months > audit date |\n| 5 | Test was actual failover, not tabletop | Review test report methodology section | Words like \"activated\", \"failed over\", \"processed alerts through backup\" present |\n| 6 | Screenshots show backup systems operational | Review evidence screenshots | Timestamps visible, backup system UI shown with active data |\n| 7 | Test results compared against RTOs | Check test report metrics section | Table showing target vs actual with pass/fail determination |\n| 8 | Issues discovered have remediation documented | Review issues section of test report | Each issue has owner, due date, and status (ideally closed) |\n\n### 📋 Quick Quality Gate\n\nBefore submitting, answer these questions:\n\n```\n□ If our primary NOC burned down tomorrow, does this BCP tell us \n  exactly how to keep monitoring customer environments? [Y/N]\n\n□ Does the test report prove we actually did this, not just \n  talked about it? [Y/N]\n\n□ Can an auditor see screenshots of our backup systems \n  successfully processing alerts? [Y/N]\n\n□ Is the test date clearly within the last 12 months? [Y/N]\n\nAll must be YES to submit.\n```\n\n### 🏆 Evidence Quality Indicators\n\n**Strong Evidence Looks Like**:\n- Test report with minute-by-minute timeline\n- Screenshots with visible timestamps and system names\n- Metrics table showing RTO targets met\n- Lessons learned with completed remediation\n\n**Weak Evidence Looks Like**:\n- Generic BCP template with company name inserted\n- Meeting minutes from \"BCP discussion\"\n- Screenshots without timestamps or context\n- No measurement against defined objectives\n\n---\n\n## Alternative Path: ISO 22301 Certification\n\nIf your organization holds **ISO 22301** certification, this can substitute for the BCP + test evidence, but:\n\n⚠️ **Critical Requirement**: The ISO 22301 scope must explicitly include your AWS MSP practice operations. A corporate ISO 22301 that covers \"headquarters operations\" but not specifically your MSP delivery capability will be rejected.\n\n**Evidence Required**:\n- ISO 22301 certificate (current, not expired)\n- Scope statement showing MSP operations included\n- Most recent surveillance audit report",
      "language": "en",
      "createdAt": "2026-01-07T02:40:44.876Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEO-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEO-001",
      "category": "People",
      "title": "Personnel Onboarding",
      "advice": "# PEO-001: Personnel Onboarding - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nPersonnel Onboarding is the **foundation of MSP service quality**. AWS views this as verification that the partner can systematically cultivate talent to deliver consistent managed services. Unlike simple HR onboarding, this requirement specifically demands an **\"AWS Practice-specific\" onboarding process** - this distinction is where many partners fail.\n\n### 🎯 5 Key Points Auditors Focus On\n\n1. **AWS Practice Specificity**: Is the onboarding process specifically designed for the AWS managed service team, not just company-wide HR onboarding?\n\n2. **Completion Evidence**: Are there actual completed records, not just process documents or templates?\n\n3. **Technical Competency Building Path**: Does the onboarding include a clear path to AWS certifications and hands-on training?\n\n4. **Tool Access Provisioning Records**: Evidence of granting access to AWS Console, ticketing systems, monitoring tools, etc.\n\n5. **Role-Based Differentiation**: Different onboarding tracks for Cloud Engineers vs. TAMs vs. Support staff\n\n### 🔗 Relevant AWS Services & Features\n- **AWS Skill Builder**: For structured learning paths\n- **AWS Training and Certification Portal**: Certification tracking\n- **AWS IAM Identity Center (SSO)**: Access provisioning records\n- **AWS Organizations**: Account access management evidence\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence List\n\n| Evidence Type | Format | Key Contents |\n|--------------|--------|--------------|\n| AWS Practice Onboarding Checklist | PDF/Excel | Step-by-step tasks with completion dates and sign-offs |\n| Individual Onboarding Records | PDF | Completed checklists for 2-3 employees onboarded in last 12 months |\n| Training Plan Document | Word/PDF | 30-60-90 day AWS-specific training milestones |\n| Tool Access Provisioning Log | Screenshot/Export | IAM user creation, SSO assignment records |\n| Certification Roadmap | PDF | Required certifications by role with target dates |\n\n### 📄 Specific Document Examples\n\n**Example 1: Onboarding Checklist**\n```\nFilename: \"AWS_MSP_Practice_Onboarding_Checklist_v2.3.pdf\"\n\nMust Include:\n□ Day 1: AWS Console access provisioned (IAM Identity Center)\n□ Day 1: Added to AWS Practice Slack/Teams channels\n□ Day 3: Completed AWS Cloud Practitioner Essentials (Skill Builder)\n□ Week 1: Shadow 3 customer ticket resolutions\n□ Week 2: Complete internal \"Customer Environment Overview\" training\n□ Day 30: Pass AWS Solutions Architect Associate (or scheduled)\n□ Day 30: First independent ticket resolution (supervised)\n```\n\n**Example 2: Completed Individual Record**\n```\nFilename: \"Onboarding_Record_JohnSmith_CloudEngineer_2024-03.pdf\"\n\nContents:\n- Employee: John Smith\n- Role: Cloud Engineer - AWS Practice\n- Start Date: March 4, 2024\n- Onboarding Completion Date: April 5, 2024\n- Checklist with all items checked and dated\n- Manager sign-off: [Signature + Date]\n- Employee acknowledgment: [Signature + Date]\n```\n\n**Example 3: Training Plan**\n```\nFilename: \"AWS_Practice_30-60-90_Training_Plan.pdf\"\n\nDay 1-30 (Foundation):\n- AWS Skill Builder: Cloud Practitioner path (20 hours)\n- Internal: Customer ticketing system training\n- Internal: Incident escalation procedures\n- Shadowing: 10 customer calls minimum\n\nDay 31-60 (Specialization):\n- AWS Skill Builder: Solutions Architect path\n- Hands-on: Deploy standard architectures in sandbox\n- First customer-facing work (supervised)\n\nDay 61-90 (Independence):\n- AWS Certification exam\n- Independent ticket handling\n- First on-call rotation (with backup)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current Onboarding vs. Create AWS-Specific Process\n**⏱️ Time: 2-3 days | 👤 Owner: AWS Practice Lead + HR**\n\n- Pull your existing company onboarding checklist\n- Create a **separate, supplementary checklist** specifically for AWS Practice\n- Key differentiator: Include AWS-specific items like:\n  - AWS account access (which accounts, what IAM permissions)\n  - Monitoring tool access (CloudWatch dashboards, third-party tools)\n  - Customer environment documentation review\n  - AWS certification requirements and timeline\n\n**🛠️ Tool**: Use Confluence/SharePoint to create a template that auto-populates employee name and dates\n\n### Step 2: Define Role-Based Onboarding Tracks\n**⏱️ Time: 1-2 days | 👤 Owner: AWS Practice Lead**\n\nCreate distinct tracks for:\n- **Cloud Engineer Track**: Heavy on technical training, certifications, hands-on labs\n- **TAM/CSM Track**: Customer communication, AWS service updates, business reviews\n- **Support/NOC Track**: Monitoring tools, escalation procedures, shift handoffs\n\n```\nExample differentiation:\nCloud Engineer → Must complete SAA-C03 within 60 days\nTAM → Must complete AWS Business Professional training within 30 days\n```\n\n### Step 3: Build Training Plan with AWS Skill Builder Integration\n**⏱️ Time: 1 day | 👤 Owner: Training Coordinator**\n\n- Log into AWS Skill Builder (partner.aws)\n- Create learning plans for each role\n- Document the specific courses required:\n  - Course names\n  - Estimated hours\n  - Completion criteria\n\n**📸 Evidence**: Export Skill Builder learning plan assignments and completion reports\n\n### Step 4: Create Tool Access Provisioning Checklist\n**⏱️ Time: 1 day | 👤 Owner: IT/Security Team**\n\nDocument every system new AWS Practice members need access to:\n```\n□ AWS IAM Identity Center - Permission Set: \"MSP-Engineer-Base\"\n□ Customer A AWS Account - Read-only via cross-account role\n□ PagerDuty - Add to \"AWS-Practice-OnCall\" schedule\n□ Jira Service Management - Agent license, \"AWS-Support\" project\n□ Datadog/CloudWatch - Dashboard access\n□ Internal Wiki - AWS Practice space\n```\n\n### Step 5: Collect 2-3 Completed Onboarding Records\n**⏱️ Time: 2-3 days | 👤 Owner: AWS Practice Lead**\n\n**Critical**: You need COMPLETED records, not templates.\n\n- Identify employees who joined AWS Practice in last 12 months\n- If using new checklist, have them retroactively sign off on completed items\n- If no recent hires, document a current employee's \"refresher onboarding\" using the new process\n\n**⚠️ Auditor Red Flag**: Submitting only blank templates without completed examples\n\n### Step 6: Document Sign-off and Acknowledgment Process\n**⏱️ Time: 0.5 day | 👤 Owner: AWS Practice Lead**\n\nEach completed onboarding record must show:\n- Employee signature/acknowledgment (digital is fine)\n- Manager/supervisor sign-off\n- Completion date\n- Any exceptions or deviations noted\n\n### Step 7: Create Evidence Package\n**⏱️ Time: 0.5 day | 👤 Owner: MSP Program Lead**\n\nCompile into a single folder:\n```\n/PEO-001_Personnel_Onboarding/\n├── 01_AWS_Practice_Onboarding_Process.pdf\n├── 02_Onboarding_Checklist_Template.xlsx\n├── 03_Completed_Record_Employee1.pdf\n├── 03_Completed_Record_Employee2.pdf\n├── 04_Training_Plan_30-60-90.pdf\n├── 05_Tool_Access_Provisioning_Log.pdf\n└── 06_AWS_SkillBuilder_Completion_Report.pdf\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Submitting Generic HR Onboarding Only\n**Problem**: Company-wide onboarding (benefits enrollment, office tour, IT laptop setup) doesn't satisfy this requirement.\n\n**Solution**: Create a **supplementary AWS Practice-specific checklist** that runs parallel to HR onboarding. The auditor wants to see AWS/cloud-specific items.\n\n### ❌ Mistake 2: Templates Without Completed Examples\n**Problem**: Submitting beautiful checklist templates with no actual completed records.\n\n**Solution**: You MUST include 2-3 completed onboarding records with:\n- Real employee names (can be redacted to initials)\n- Actual dates\n- Signatures/acknowledgments\n- All items checked off\n\n### ❌ Mistake 3: No Differentiation by Role\n**Problem**: Same onboarding for Cloud Architects and Support staff.\n\n**Solution**: Show role-based tracks. A Cloud Engineer's onboarding should emphasize certifications and hands-on labs; a TAM's should emphasize customer communication and service knowledge.\n\n### ❌ Mistake 4: Missing Tool Access Documentation\n**Problem**: Checklist says \"Grant AWS access\" but no evidence of HOW.\n\n**Solution**: Include specific evidence:\n- IAM Identity Center user creation screenshot\n- Permission set assignments\n- Ticket showing access request approval\n\n### ❌ Mistake 5: Outdated or Inconsistent Dates\n**Problem**: Onboarding record shows completion date before start date, or training completed before employee joined.\n\n**Solution**: Review all dates for logical consistency before submission. Auditors WILL check this.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | Is onboarding process AWS Practice-specific? | Review checklist items | Contains AWS Console access, certifications, customer environment training - NOT just generic HR items |\n| 2 | Are there completed records (not just templates)? | Count completed files | Minimum 2 completed onboarding records from last 12 months |\n| 3 | Do completed records have signatures/acknowledgments? | Visual inspection | Both employee AND manager sign-off present with dates |\n| 4 | Is there a training plan with AWS Skill Builder or equivalent? | Review training document | Specific course names, hours, and completion timeline documented |\n| 5 | Are role-based differences documented? | Compare tracks | At least 2 distinct tracks (e.g., Engineer vs. TAM) with different requirements |\n| 6 | Is tool access provisioning documented? | Review access checklist | Specific systems listed (AWS accounts, monitoring tools, ticketing) with provisioning evidence |\n| 7 | Are all dates logically consistent? | Cross-reference dates | Start date → Training dates → Completion date in correct sequence |\n\n### ✅ Quality Gate: Ready for Submission When...\n\n- [ ] Process document clearly labeled as \"AWS Managed Service Practice Onboarding\"\n- [ ] At least 2 completed records with real dates within last 12 months\n- [ ] Training plan references AWS Skill Builder or AWS Training courses by name\n- [ ] Tool access includes AWS Console/IAM provisioning evidence\n- [ ] All signatures and dates present and logically consistent\n- [ ] Evidence organized in clearly labeled folder structure\n\n---\n\n## 💡 Pro Tips from Audit Experience\n\n1. **If you haven't hired recently**: Document a \"refresher onboarding\" for an existing team member transitioning to a new role or completing updated training requirements.\n\n2. **Redaction is OK**: You can redact full names to initials (J.S. instead of John Smith) for privacy, but keep dates and signatures visible.\n\n3. **Digital signatures accepted**: DocuSign, Adobe Sign, or even email acknowledgment (\"I confirm completion of onboarding\") is acceptable.\n\n4. **Connect to other requirements**: Your onboarding should reference training requirements (PEO-002) and certification requirements - auditors like seeing interconnected processes.",
      "language": "en",
      "createdAt": "2026-01-07T02:45:44.114Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEO-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEO-002",
      "category": "People",
      "title": "Cloud Center of Excellence (CCOE)",
      "advice": "# PEO-002: Cloud Center of Excellence (CCOE) - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nCCOE is the **core engine that determines MSP operational maturity**. AWS views CCOE as the central organization that systematically manages cloud best practices beyond individual project execution. This is a mandatory requirement because it's the foundation that proves MSP's sustainable service delivery capability.\n\n### 🔍 5 Key Points Auditors Focus On\n\n1. **Cross-functional Team Composition**: Whether members from technical (architects, engineers), business (sales, strategy), and operations (support, training) domains actually participate\n2. **Evidence of Regular Activities**: Whether CCOE actually operates through meeting minutes, decision records, etc., not just existing on paper\n3. **Coverage of 5 Domains**: Whether all 5 domains (Cloud Adoption, Training, Governance, Strategy, Operations/Automation) are specifically addressed\n4. **Business Impact**: Whether CCOE decisions actually influence MSP service delivery\n5. **Charter Specificity**: Whether roles, responsibilities, decision authority, and escalation paths are clearly defined\n\n### Related AWS Services & Programs\n- **AWS Well-Architected Framework**: Governance standards that CCOE should adopt\n- **AWS Control Tower**: Governance automation tool that CCOE manages\n- **AWS Organizations**: Multi-account strategy under CCOE governance\n- **AWS Service Catalog**: Standardized component management led by CCOE\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 Required Document List\n\n| Document Name | Format | Key Content |\n|--------------|--------|-------------|\n| CCOE Charter Document | PDF/Word | Mission, authority, scope, decision process |\n| CCOE Organization Chart | Visio/PDF | Member names, roles, reporting lines |\n| CCOE Operating Procedures | PDF/Word | Meeting cadence, decision methods, communication channels |\n| CCOE Activity Records | PDF/Excel | Meeting minutes, decision logs, action items |\n| Domain-specific Work Plans | PDF/Excel | Activities and outcomes for each of 5 domains |\n\n### 📄 Key Content for Each Evidence\n\n**① CCOE Charter Document**\n```\nRequired Sections:\n- Mission Statement: \"Establish and disseminate cloud best practices across the organization\"\n- Scope of Authority: Budget approval limits, technology standard decision authority\n- Governance Domains: Specific responsibilities for each of 5 domains\n- Stakeholder Engagement Model: How to interact with project teams, customers, leadership\n- Review Cycle: Quarterly charter review and update process\n```\n\n**② CCOE Organization Chart**\n```\nRequired Elements:\n- CCOE Lead/Director (executive sponsor)\n- Domain Leads for each of 5 domains\n- Core Members (full-time) vs Extended Members (part-time)\n- Dotted-line relationships with other departments\n- Actual names and titles (anonymization not accepted)\n```\n\n**③ CCOE Operating Procedures**\n```\nRequired Processes:\n- Weekly Sync Meeting: Operational issue sharing\n- Monthly Governance Review: Policy compliance review\n- Quarterly Strategy Session: Business alignment review\n- Exception Request Process: How to handle deviations from standards\n- Knowledge Sharing Mechanism: Internal wiki, Confluence, etc.\n```\n\n### 📎 Evidence File Name Examples\n```\nCCOE_Charter_v2.3_2024.pdf\nCCOE_Organization_Structure_Q1_2024.pdf\nCCOE_Operating_Procedures_Manual.pdf\nCCOE_Meeting_Minutes_2024-01_to_2024-03.pdf\nCCOE_Domain_Workplan_CloudAdoption_2024.xlsx\nCCOE_Governance_Decision_Log_2024.xlsx\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: CCOE Stakeholder Identification and Commitment (Week 1-2)\n**Responsible**: CTO/VP of Engineering\n**Tasks**:\n- Identify executive sponsor (C-level or VP level required)\n- Select domain leads from each department\n- Obtain written commitment from participants\n\n```\nRecommended Team Composition:\n- Executive Sponsor: CTO or VP Cloud Services\n- Cloud Adoption Lead: Solutions Architect Manager\n- Training Lead: Learning & Development Manager\n- Governance Lead: Security/Compliance Manager\n- Strategy Lead: Business Development Director\n- Operations Lead: DevOps/SRE Manager\n```\n\n### Step 2: Charter Document Creation (Week 2-3)\n**Responsible**: CCOE Lead\n**Tasks**:\n- Define mission and vision statements\n- Specify scope of authority and decision rights\n- Document engagement model with other departments\n\n**💡 Tip**: Include specific examples of decision authority\n```\nExample Authority Matrix:\n- Technology Standard Selection: CCOE has final decision authority\n- Tool Procurement over $10K: CCOE approval required\n- Customer Architecture Review: CCOE consultation mandatory\n```\n\n### Step 3: Domain-specific Responsibility Definition (Week 3-4)\n**Responsible**: Each Domain Lead\n**Tasks**:\n- Define specific activities for each of 5 domains\n- Set measurable KPIs\n- Create quarterly roadmap\n\n**Domain-specific Activity Examples**:\n```\n1. Cloud Adoption & Retooling:\n   - Monthly internal cloud adoption workshops\n   - New AWS service evaluation and adoption recommendations\n   - Migration methodology standardization\n\n2. Training & Change Management:\n   - AWS certification roadmap management\n   - Quarterly skill gap analysis\n   - Change communication plan execution\n\n3. Governance:\n   - AWS Control Tower landing zone management\n   - Security baseline definition and enforcement\n   - Cost management policy establishment\n\n4. Strategy:\n   - Quarterly business-technology alignment review\n   - New service offering evaluation\n   - Customer success metrics definition\n\n5. Operations & Automation:\n   - Infrastructure as Code template library management\n   - CI/CD pipeline standardization\n   - Monitoring and alerting baseline definition\n```\n\n### Step 4: Operating Procedures Establishment (Week 4-5)\n**Responsible**: CCOE Lead + Operations Lead\n**Tasks**:\n- Define meeting cadence and agenda templates\n- Establish decision-making process\n- Set up communication channels\n\n**Meeting Structure Example**:\n```\nWeekly (30 min): Operational sync - Slack/Teams channel updates\nBi-weekly (1 hour): Domain lead sync - Cross-domain coordination\nMonthly (2 hours): Governance review - Policy compliance, exceptions\nQuarterly (half-day): Strategy session - Business alignment, roadmap update\n```\n\n### Step 5: Activity Tracking System Setup (Week 5-6)\n**Responsible**: Operations Lead\n**Tasks**:\n- Configure Confluence/SharePoint workspace\n- Create decision log template\n- Set up action item tracking\n\n**Tools to Use**:\n- Confluence: Charter, procedures, knowledge base\n- Jira: Action item and initiative tracking\n- AWS Service Catalog: Approved product portfolio management\n\n### Step 6: Pilot Operation and Record Collection (Week 6-10)\n**Responsible**: All CCOE Members\n**Tasks**:\n- Conduct at least 4 weekly meetings\n- Execute at least 1 monthly governance review\n- Document at least 3 governance decisions\n\n**⚠️ Critical**: Auditors require **minimum 3 months of activity records**\n\n### Step 7: Evidence Package Compilation (Week 10-12)\n**Responsible**: CCOE Lead\n**Tasks**:\n- Compile all documents in consistent format\n- Create evidence index document\n- Conduct internal review\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Paper-only CCOE\n**Problem**: Charter exists but no actual activity records\n**Solution**: \n- Start meeting minutes from Day 1\n- Record all decisions with date, attendees, and outcomes\n- Minimum 3 months of consistent activity evidence required\n\n### ❌ Mistake 2: Missing Domain Coverage\n**Problem**: CCOE focuses only on technical operations, neglecting Strategy or Training domains\n**Solution**:\n- Assign dedicated lead for each of 5 domains\n- Include domain-specific agenda items in monthly meetings\n- Create separate work plan for each domain\n\n### ❌ Mistake 3: No Cross-functional Representation\n**Problem**: CCOE consists only of engineers without business/strategy representation\n**Solution**:\n- Include at least one member from Sales/BD\n- Include Training/HR representative\n- Document how business stakeholders are engaged\n\n### ❌ Mistake 4: Vague Authority Definition\n**Problem**: Charter doesn't specify what CCOE can actually decide\n**Solution**:\n```\nInclude specific authority statements:\n✓ \"CCOE approves all production architecture designs\"\n✓ \"CCOE has budget authority up to $50K for tooling\"\n✓ \"CCOE decisions are binding unless escalated to CTO\"\n```\n\n### ❌ Mistake 5: No Customer/Project Engagement Evidence\n**Problem**: CCOE operates in isolation without connecting to actual MSP service delivery\n**Solution**:\n- Document how CCOE standards apply to customer projects\n- Include customer architecture review records\n- Show CCOE involvement in customer escalations\n\n### 🚫 Anti-patterns to Avoid\n- Creating CCOE just for audit purposes without genuine organizational commitment\n- Copying generic CCOE templates without customization\n- Having CCOE members who don't actually participate in meetings\n- No executive sponsor or sponsor without real authority\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | Charter includes all 5 domains | Document review | Each domain has specific responsibilities defined |\n| 2 | Organization chart shows cross-functional team | Visual inspection | Members from ≥3 different departments |\n| 3 | Executive sponsor identified | Charter + Org chart | Named individual at VP/C-level |\n| 4 | Meeting cadence defined | Operating procedures | Weekly, monthly, quarterly meetings specified |\n| 5 | Activity records span ≥3 months | Meeting minutes dates | Consistent records from 3+ months |\n| 6 | Decision log shows actual decisions | Decision log review | ≥5 documented decisions with outcomes |\n| 7 | Engagement model documented | Charter/Procedures | How CCOE interacts with projects/customers |\n\n### 📋 Quality Criteria\n\n**Charter Document**:\n- [ ] Mission statement is specific to your organization (not generic)\n- [ ] Authority matrix clearly defines decision rights\n- [ ] All 5 domains have named leads\n- [ ] Review and update cycle defined\n- [ ] Signed/approved by executive sponsor\n\n**Organization Structure**:\n- [ ] Real names and titles (not roles only)\n- [ ] Reporting relationships clear\n- [ ] Core vs extended membership defined\n- [ ] Contact information included\n\n**Operating Procedures**:\n- [ ] Meeting templates included\n- [ ] Decision-making process documented\n- [ ] Escalation path defined\n- [ ] Communication channels specified\n\n**Activity Evidence**:\n- [ ] Meeting minutes include attendees, agenda, decisions\n- [ ] Action items tracked to completion\n- [ ] Domain-specific activities documented\n- [ ] Customer/project engagement examples included\n\n### ✅ Final Validation Questions\n\n1. **Can an auditor understand how CCOE actually operates from your documents?**\n2. **Is there evidence that CCOE decisions impact real MSP service delivery?**\n3. **Would a new employee understand their CCOE responsibilities from these documents?**\n4. **Are all 5 domains visibly active with specific deliverables?**\n5. **Is executive commitment evident beyond just a name on paper?**\n\n---\n\n## 💡 Pro Tips for Success\n\n1. **Start Early**: CCOE activity records take time to accumulate - begin 6 months before audit\n2. **Be Specific**: Generic statements fail audits; include real examples, names, and numbers\n3. **Show Evolution**: Include charter version history showing CCOE maturity over time\n4. **Connect to Customers**: Demonstrate how CCOE improves customer outcomes\n5. **Use AWS Language**: Reference Well-Architected Framework, Control Tower, and other AWS tools in your governance processes",
      "language": "en",
      "createdAt": "2026-01-07T02:46:43.619Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEO-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEO-003",
      "category": "People",
      "title": "Personnel Offboarding",
      "advice": "# PEO-003: Personnel Offboarding - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nPersonnel offboarding is a **security-critical control point** in the AWS MSP program. When employees with access to customer AWS environments leave the organization, incomplete access revocation creates significant security vulnerabilities. AWS auditors specifically scrutinize this because MSP partners often have privileged access (root accounts, IAM admin roles, cross-account access) to multiple customer environments simultaneously.\n\nA single departing employee at an MSP could potentially retain access to dozens of customer AWS accounts if offboarding is not properly executed. This makes PEO-003 a **high-risk audit item** with zero tolerance for gaps.\n\n### 🔎 Key Points Auditors Examine\n\n1. **Timeliness of Access Revocation**: Auditors check timestamps - was AWS console access disabled within 24 hours of termination? Same-day revocation is the gold standard.\n\n2. **Completeness Across All Access Vectors**: They verify ALL access paths are addressed:\n   - AWS IAM users/roles in Partner's own accounts\n   - Cross-account roles in customer environments\n   - AWS SSO/Identity Center assignments\n   - Programmatic access (Access Keys, CLI credentials)\n   - Third-party tools (Terraform Cloud, Datadog, CloudHealth)\n\n3. **Evidence of Systematic Process**: Random or ad-hoc offboarding fails. Auditors want to see the same checklist executed consistently across multiple departures.\n\n4. **Customer Environment Scope**: Specific attention to how customer AWS account access is tracked and revoked - not just internal systems.\n\n5. **Audit Trail Integrity**: CloudTrail logs showing the actual deletion/deactivation events, not just a signed checklist.\n\n### Relevant AWS Services\n\n- **AWS IAM** (user deletion, access key deactivation)\n- **AWS IAM Identity Center (SSO)** (user/group removal)\n- **AWS Organizations** (cross-account access management)\n- **AWS CloudTrail** (audit logging of access changes)\n- **AWS Config** (compliance tracking of IAM changes)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Document Name Example | Format |\n|--------------|----------------------|--------|\n| Offboarding Policy | `MSP-POL-007_Personnel_Offboarding_Policy_v2.3.pdf` | PDF |\n| Offboarding Checklist Template | `MSP-CHK-003_AWS_Access_Revocation_Checklist.xlsx` | Excel/PDF |\n| Completed Offboarding Records | `Offboarding_Record_JSmith_2024-08-15.pdf` | PDF with signatures |\n| CloudTrail Evidence | `CloudTrail_IAM_Deletion_JSmith_20240815.json` | JSON/Screenshot |\n| Access Inventory Before/After | `Access_Matrix_Comparison_JSmith.xlsx` | Excel |\n\n### 📄 Key Content for Each Evidence\n\n**1. Offboarding Policy Document**\n```\nMust include:\n- Scope statement explicitly mentioning \"AWS managed service practice\"\n- Maximum timeframe for access revocation (recommend: same business day)\n- Roles responsible (HR, Security, AWS Practice Lead)\n- Escalation path for emergency terminations\n- Customer notification requirements (if applicable)\n- Specific mention of AWS access types covered\n```\n\n**2. Completed Offboarding Checklist (Per Departure)**\n```\nRequired fields:\n□ Employee Name & ID\n□ Last Working Day (date)\n□ Termination Type (voluntary/involuntary)\n□ List of AWS accounts accessed (Partner + Customer)\n□ Each access type with revocation timestamp:\n  - AWS Console (IAM User): Deleted [timestamp]\n  - AWS SSO Assignment: Removed [timestamp]  \n  - Access Keys: Deactivated/Deleted [timestamp]\n  - Cross-account roles: Removed from trust policy [timestamp]\n  - Third-party integrations: [Tool name] - Revoked [timestamp]\n□ Verification signature (Security team)\n□ HR confirmation signature\n□ Manager sign-off\n```\n\n**3. CloudTrail Evidence Screenshots**\n```\nRequired events to capture:\n- DeleteUser / DeleteLoginProfile\n- DeactivateAccessKey / DeleteAccessKey\n- DeleteUserPermissionsBoundary\n- RemoveUserFromGroup\n- DetachUserPolicy\n- UpdateAssumeRolePolicy (for cross-account roles)\n```\n\n### Evidence File Examples\n```\n📁 PEO-003_Evidence/\n├── 01_Policy/\n│   └── MSP_Personnel_Offboarding_Policy_v2.3_Approved_20240601.pdf\n├── 02_Checklist_Template/\n│   └── AWS_Access_Revocation_Checklist_Template_v1.2.xlsx\n├── 03_Completed_Records/\n│   ├── Offboarding_TanakaK_20240815_Complete.pdf\n│   ├── Offboarding_SuzukiM_20240722_Complete.pdf\n│   └── Offboarding_WatanabeY_20240630_Complete.pdf\n├── 04_CloudTrail_Evidence/\n│   ├── CloudTrail_IAM_Events_TanakaK_20240815.png\n│   ├── CloudTrail_SSO_Events_SuzukiM_20240722.png\n│   └── CloudTrail_AccessKey_Events_WatanabeY_20240630.png\n└── 05_Access_Inventory/\n    └── MSP_AWS_Access_Matrix_Current.xlsx\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Create AWS Access Inventory for MSP Practice (Week 1)\n**Responsible**: AWS Practice Lead + Security Team  \n**Time**: 3-4 days\n\n```bash\n# Use AWS CLI to inventory all IAM users across accounts\naws iam list-users --query 'Users[*].[UserName,CreateDate,PasswordLastUsed]' --output table\n\n# List all SSO users and group assignments\naws identitystore list-users --identity-store-id d-xxxxxxxxxx\naws identitystore list-group-memberships --identity-store-id d-xxxxxxxxxx --group-id xxxxxxxx\n```\n\n**Deliverable**: `MSP_AWS_Access_Matrix.xlsx` with columns:\n- Employee Name | Employee ID | AWS Account ID | Account Name (Partner/Customer) | Access Type | IAM User/Role ARN | Access Keys (Y/N) | Last Activity Date\n\n### Step 2: Design Offboarding Checklist Specific to AWS Access (Week 1)\n**Responsible**: Security Team + HR  \n**Time**: 2 days\n\nCreate checklist with **AWS-specific line items**:\n```\n☐ AWS IAM Console Users - All Partner accounts\n☐ AWS IAM Console Users - All Customer accounts  \n☐ AWS IAM Identity Center (SSO) assignments\n☐ AWS Access Keys (list each Key ID)\n☐ AWS CodeCommit HTTPS Git credentials\n☐ Cross-account IAM role trust policies\n☐ AWS Secrets Manager shared credentials\n☐ Third-party tools with AWS integration:\n   ☐ Terraform Cloud/Enterprise\n   ☐ Datadog AWS integration\n   ☐ CloudHealth/Spot.io\n   ☐ PagerDuty AWS integration\n```\n\n### Step 3: Implement Automated Detection with AWS Config (Week 2)\n**Responsible**: Cloud Engineering Team  \n**Time**: 2-3 days\n\nDeploy AWS Config rule to detect orphaned IAM users:\n```yaml\n# AWS Config Custom Rule - Lambda function pseudo-code\ndef evaluate_compliance(configuration_item, rule_parameters):\n    # Compare IAM users against HR active employee list\n    # Flag any IAM user not in active employee list\n    # Return NON_COMPLIANT for orphaned users\n```\n\n### Step 4: Establish CloudTrail Log Retention for Evidence (Week 2)\n**Responsible**: Cloud Engineering Team  \n**Time**: 1 day\n\n```bash\n# Ensure CloudTrail is logging IAM events with sufficient retention\naws cloudtrail describe-trails\n# Verify S3 bucket lifecycle policy retains logs for minimum 1 year\n```\n\n**Critical**: Enable CloudTrail Insights for IAM to detect unusual access patterns from departing employees.\n\n### Step 5: Conduct Pilot Offboarding with Full Documentation (Week 3)\n**Responsible**: HR + Security + AWS Practice Lead  \n**Time**: 1-2 days per departure\n\nExecute offboarding for a recent departure (or simulate with test account):\n1. Complete every checklist item with timestamps\n2. Capture CloudTrail screenshots for each revocation action\n3. Have three parties sign off (HR, Security, Manager)\n4. Store in designated evidence repository\n\n### Step 6: Collect 2-3 Historical Offboarding Records (Week 3-4)\n**Responsible**: HR + Security Team  \n**Time**: 3-4 days\n\n**Auditors typically request 2-3 examples**. For each:\n- Reconstruct documentation if not previously captured\n- Pull CloudTrail logs from S3 archive for the termination date\n- Create \"Access Before/After\" comparison document\n\n### Step 7: Prepare Alternative Evidence Path (If Needed)\n**Responsible**: Compliance Team  \n**Time**: Varies\n\nIf you have **ISO 27001 or SOC 2 Type II** certification:\n- Obtain certificate copy showing MSP practice in scope\n- Obtain relevant audit report sections covering A.7.3.1 (ISO) or CC6.2 (SOC2)\n- Prepare mapping document showing how certification addresses PEO-003\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Forgetting Customer Account Access\n**Problem**: Checklist only covers Partner's own AWS accounts, ignoring cross-account roles in customer environments.\n\n**Solution**: Maintain a real-time mapping of `Employee → Customer Accounts Accessed`. Use tagging:\n```json\n{\n  \"Tags\": [\n    {\"Key\": \"MSP-AssignedEngineer\", \"Value\": \"tanaka.k@mspcompany.com\"},\n    {\"Key\": \"MSP-AccessGrantDate\", \"Value\": \"2024-01-15\"}\n  ]\n}\n```\n\n### ❌ Mistake 2: Access Keys Left Active\n**Problem**: IAM user deleted but access keys were created under a different user or service account and remain active.\n\n**Solution**: Run access key audit before and after offboarding:\n```bash\n# Find all access keys created by the departing user\naws cloudtrail lookup-events \\\n  --lookup-attributes AttributeKey=Username,AttributeValue=tanaka.k \\\n  --query 'Events[?contains(EventName, `CreateAccessKey`)]'\n```\n\n### ❌ Mistake 3: No Timestamp Evidence\n**Problem**: Checklist shows \"Done ✓\" but no actual timestamp or CloudTrail evidence proving WHEN access was revoked.\n\n**Audit Failure Reason**: Auditor cannot verify if revocation happened same-day or weeks later.\n\n**Solution**: Every checklist item needs:\n- Action timestamp (YYYY-MM-DD HH:MM timezone)\n- CloudTrail Event ID or screenshot\n- Person who executed the action\n\n### ❌ Mistake 4: SSO/Identity Center Overlooked\n**Problem**: Company uses AWS IAM Identity Center but offboarding only addresses legacy IAM users.\n\n**Solution**: Add explicit SSO checklist items:\n```\n☐ Remove from all SSO Groups\n☐ Remove all Permission Set assignments  \n☐ Delete SSO user from Identity Store\n☐ Capture \"User not found\" verification screenshot\n```\n\n### ❌ Mistake 5: Third-Party Tool Access Ignored\n**Problem**: Employee had Terraform Cloud access with AWS credentials, or Datadog integration role - not revoked.\n\n**Anti-pattern**: Assuming \"AWS access\" only means AWS Console/CLI.\n\n**Solution**: Map all tools with AWS integration:\n| Tool | AWS Integration Type | Revocation Method |\n|------|---------------------|-------------------|\n| Terraform Cloud | IAM User + Access Keys | Delete workspace access + rotate keys |\n| Datadog | Cross-account IAM Role | Remove user from Datadog + update role trust |\n| Slack AWS Chatbot | IAM Role | Remove Slack workspace access |\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Before Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Policy explicitly mentions AWS MSP practice scope** | Search document for \"AWS\", \"managed service\", \"MSP\" | Scope statement in Section 1 clearly includes AWS practice |\n| 2 | **Minimum 2-3 completed offboarding records provided** | Count evidence files in folder | At least 2 complete records from past 12 months |\n| 3 | **Each record includes AWS-specific access revocation** | Review checklist items | Every record has IAM/SSO/Access Key line items checked with timestamps |\n| 4 | **CloudTrail evidence matches checklist timestamps** | Compare CloudTrail eventTime with checklist | Timestamps within same business day |\n| 5 | **Customer account access addressed** | Check for customer account references | Records show customer account access revoked (or N/A documented) |\n| 6 | **Three-party sign-off present** | Check signatures on each record | HR + Security + Manager signatures with dates |\n| 7 | **No active access remains for departed employees** | Run IAM audit script | Zero IAM users/SSO assignments for terminated employees |\n\n### 🔬 Technical Verification Script\n\nRun before submission to verify no orphaned access:\n```bash\n#!/bin/bash\n# verify_offboarding_complete.sh\n\nTERMINATED_EMPLOYEES=(\"tanaka.k\" \"suzuki.m\" \"watanabe.y\")\n\nfor emp in \"${TERMINATED_EMPLOYEES[@]}\"; do\n  echo \"Checking $emp...\"\n  \n  # Check IAM users\n  aws iam get-user --user-name $emp 2>&1 | grep -q \"NoSuchEntity\" && echo \"✅ IAM User deleted\" || echo \"❌ IAM User still exists!\"\n  \n  # Check SSO (requires identity store ID)\n  aws identitystore list-users --identity-store-id d-xxxxxxxxxx \\\n    --filters AttributePath=UserName,AttributeValue=$emp \\\n    --query 'Users' | grep -q \"\\[\\]\" && echo \"✅ SSO User deleted\" || echo \"❌ SSO User still exists!\"\ndone\n```\n\n### Quality Criteria Summary\n\n✅ **Pass Conditions**:\n- Policy document dated and approved within last 12 months\n- Completed records show consistent process execution\n- Technical evidence (CloudTrail) corroborates checklist claims\n- All access vectors covered (IAM, SSO, Access Keys, Cross-account, Third-party)\n- Timestamps prove same-day or next-business-day revocation\n\n❌ **Fail Conditions**:\n- Generic IT offboarding checklist without AWS-specific items\n- Records missing timestamps or technical evidence\n- Customer account access not addressed\n- Evidence shows multi-day gap between termination and access revocation\n- Orphaned access discovered during audit verification\n\n---\n\n## 📌 Pro Tips from Audit Experience\n\n1. **Voluntary vs. Involuntary**: Have expedited process for involuntary terminations (immediate revocation before employee notified)\n\n2. **Contractor Offboarding**: Don't forget contractors/vendors - they often have temporary AWS access that's never revoked\n\n3. **Evidence Freshness**: Auditors prefer recent examples (within 6 months). If no recent departures, document a \"dry run\" with a test account\n\n4. **Cross-Reference with PEO-002**: Your offboarding records should mirror your onboarding records (PEO-002) - same access types tracked",
      "language": "en",
      "createdAt": "2026-01-07T02:48:03.587Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PEOP-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PEOP-001",
      "category": "People",
      "title": "Personnel Skills",
      "advice": "# PEOP-001: Personnel Skills - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nAWS MSP 프로그램에서 Personnel Skills는 **파트너의 지속적인 서비스 품질 보장 능력**을 평가하는 핵심 항목입니다. AWS는 클라우드 서비스가 빠르게 진화하기 때문에, MSP 파트너가 단순히 현재 역량을 보유하는 것이 아니라 **체계적인 학습 문화**를 통해 최신 기술을 지속적으로 습득하고 있는지 확인합니다.\n\n### 🔍 Auditor가 중점적으로 확인하는 5가지 포인트\n\n1. **학습 전략의 문서화 여부**: \"우리는 교육을 중시합니다\"라는 구두 설명이 아닌, 명문화된 기술 역량 개발 전략이 존재하는지\n2. **12개월 이내 실제 활동 증거**: 계획만 있는 것이 아니라 실제로 실행된 학습 활동의 구체적 기록\n3. **Managed Services 운영 인력 대상 여부**: 전사 교육이 아닌, MSP 운영에 직접 참여하는 인력의 학습 활동인지\n4. **다양한 학습 형태의 조합**: AWS 공식 인증뿐 아니라 내부 스터디, 워크샵, 컨퍼런스 참여 등 다각적 접근\n5. **학습과 업무의 연계성**: 학습 내용이 실제 MSP 서비스 제공 역량 향상과 연결되는지\n\n### 관련 AWS 서비스 및 프로그램\n- **AWS Skill Builder**: 공식 온라인 학습 플랫폼\n- **AWS Certification**: Solutions Architect, SysOps Administrator, DevOps Engineer 등\n- **AWS Partner Training**: Partner Central을 통한 파트너 전용 교육\n- **AWS re:Invent / AWS Summit**: 공식 컨퍼런스 참여\n- **AWS GameDay / Jam**: 실습 기반 학습 이벤트\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### 📁 필수 증거 목록\n\n| 증거 유형 | 파일명 예시 | 핵심 포함 내용 |\n|-----------|-------------|----------------|\n| **기술 역량 개발 전략 문서** | `MSP_Technical_Training_Strategy_2024.pdf` | 연간 교육 목표, 대상 인력 정의, 학습 경로(Learning Path), 예산, KPI |\n| **인증 취득 현황표** | `AWS_Certification_Tracker_2024.xlsx` | 취득자명, 인증 종류, 취득일, 만료일, MSP 역할 |\n| **교육 이수 기록** | `Training_Completion_Records_Q1-Q4_2024.xlsx` | 교육명, 이수자, 이수일, 시간, 플랫폼(Skill Builder 등) |\n| **내부 학습 활동 증빙** | `Internal_TechTalk_Sessions_2024.pdf` | 세션 제목, 발표자, 참석자 명단, 날짜, 자료 캡처 |\n| **외부 컨퍼런스 참여 증빙** | `AWS_Summit_Seoul_2024_Attendance.pdf` | 참가 확인서, 세션 참여 기록, 참가자 명단 |\n\n### 📄 각 증거별 상세 요구사항\n\n#### 1) 기술 역량 개발 전략 문서\n```\n필수 섹션:\n├── 1. 전략 목표 (AWS 역량 강화와 MSP 서비스 품질 연계)\n├── 2. 대상 인력 정의 (MSP 운영팀 명시적 포함)\n├── 3. 연간 학습 로드맵 (분기별 목표)\n├── 4. 학습 유형별 계획\n│   ├── AWS 공식 인증 취득 목표\n│   ├── Skill Builder 과정 이수 계획\n│   ├── 내부 기술 공유 세션\n│   └── 외부 컨퍼런스/워크샵\n├── 5. 예산 및 지원 정책\n└── 6. 성과 측정 방법 (KPI)\n```\n\n#### 2) 인증 취득 현황표 (Excel 형식 권장)\n| 이름 | 역할 | 인증명 | 인증번호 | 취득일 | 만료일 | Credly 링크 |\n|------|------|--------|----------|--------|--------|-------------|\n| 김철수 | Cloud Engineer | AWS SAA-C03 | AWS01234567 | 2024-03-15 | 2027-03-15 | https://credly.com/... |\n| 이영희 | DevOps Lead | AWS DOP-C02 | AWS07654321 | 2024-06-20 | 2027-06-20 | https://credly.com/... |\n\n#### 3) 내부 학습 활동 증빙 패키지\n```\nTechTalk_Session_Evidence/\n├── Session_Schedule_2024.pdf (연간 세션 일정표)\n├── Session_001_EKS_BestPractices/\n│   ├── attendance_list.pdf (참석자 서명 또는 Teams/Zoom 참석 로그)\n│   ├── presentation_slides.pdf\n│   └── session_photo.jpg (선택)\n├── Session_002_Cost_Optimization/\n│   └── ...\n└── Quarterly_Summary_Report.pdf (분기별 요약)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: MSP 운영 인력 명단 확정 (1일)\n**담당**: HR + MSP 팀 리더\n\n```\n실행 항목:\n□ MSP 서비스 운영에 직접 참여하는 인력 리스트 작성\n□ 각 인력의 역할 정의 (Cloud Engineer, DevOps, Security 등)\n□ 현재 보유 AWS 인증 현황 파악\n□ 인력 명단을 \"MSP_Operations_Team_Roster.xlsx\"로 저장\n```\n\n**⚠️ 주의**: 전사 인력이 아닌 **MSP 운영 인력만** 대상으로 해야 합니다.\n\n### Step 2: 기술 역량 개발 전략 문서 작성 (3-5일)\n**담당**: MSP 팀 리더 + Learning & Development\n\n```markdown\n문서 작성 시 필수 포함 문구 예시:\n\n\"본 전략은 AWS Managed Services 운영에 참여하는 인력의 \n지속적인 기술 역량 향상을 목표로 한다. \n연간 최소 [X]개의 AWS 인증 취득과 [Y]시간의 학습 활동을 \n팀 목표로 설정하며, 분기별로 진행 상황을 검토한다.\"\n```\n\n**AWS Partner Central 활용**:\n- Partner Central > Training > Partner Learning Plans 참조\n- AWS MSP 요구사항에 맞는 Learning Path 확인\n\n### Step 3: 지난 12개월 학습 활동 수집 (5-7일)\n**담당**: 각 팀원 + HR\n\n| 수집 대상 | 수집 방법 | 증빙 형태 |\n|-----------|-----------|-----------|\n| AWS 인증 | Credly 프로필 캡처 또는 PDF 다운로드 | 인증서 PDF |\n| Skill Builder 이수 | AWS Skill Builder > My Learning > Transcript | 이수 기록 캡처 |\n| 내부 세션 | 캘린더 초대, Teams/Zoom 녹화 기록 | 참석 로그 |\n| 외부 컨퍼런스 | 등록 확인 이메일, 참가 확인서 | PDF/이메일 캡처 |\n\n### Step 4: 증거 자료 표준화 및 정리 (2-3일)\n**담당**: MSP 팀 리더\n\n```\n폴더 구조 예시:\nPEOP-001_Personnel_Skills/\n├── 01_Strategy_Document/\n│   └── MSP_Technical_Training_Strategy_2024.pdf\n├── 02_Certification_Records/\n│   ├── Certification_Tracker.xlsx\n│   └── Certificates/\n│       ├── Kim_Chulsoo_SAA_Certificate.pdf\n│       └── Lee_Younghee_DOP_Certificate.pdf\n├── 03_Training_Completion/\n│   ├── SkillBuilder_Transcripts/\n│   └── External_Training_Certificates/\n├── 04_Internal_Learning_Events/\n│   ├── TechTalk_Schedule_2024.pdf\n│   └── Session_Evidence/\n└── 05_Conference_Attendance/\n    └── AWS_Summit_2024/\n```\n\n### Step 5: 학습 활동 요약 보고서 작성 (2일)\n**담당**: MSP 팀 리더\n\n```\n보고서 필수 포함 내용:\n1. Executive Summary\n   - 12개월간 총 학습 활동 건수\n   - 신규 취득 인증 수\n   - 참여 인원 비율\n\n2. 상세 활동 내역\n   - 월별/분기별 활동 타임라인\n   - 활동 유형별 분류\n\n3. MSP 서비스 역량 연계\n   - 학습 내용이 실제 서비스에 어떻게 적용되었는지 사례\n```\n\n### Step 6: Cross-check 및 Gap 분석 (1-2일)\n**담당**: Quality Assurance\n\n```\n체크 항목:\n□ 모든 MSP 운영 인력이 최소 1개 이상의 학습 활동에 참여했는가?\n□ 12개월 이내 활동만 포함되었는가? (날짜 확인)\n□ 다양한 학습 유형이 포함되었는가? (인증 + 내부 + 외부)\n□ 증빙 자료의 날짜와 트래커 기록이 일치하는가?\n```\n\n### Step 7: 최종 패키지 구성 및 제출 준비 (1일)\n**담당**: MSP Program Manager\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ 실패 사례 1: \"전사 교육 기록으로 대체\"\n```\n문제 상황:\n- 회사 전체 직원 대상 일반 IT 교육 기록 제출\n- \"AWS 기초 과정\" 같은 입문 수준 교육만 다수 포함\n\nAuditor 피드백:\n\"MSP 운영에 직접 참여하는 인력의 학습 활동이 \n명확히 구분되어 있지 않습니다.\"\n\n해결책:\n✅ MSP 운영팀 명단을 먼저 정의하고\n✅ 해당 인력의 학습 기록만 별도로 추출\n✅ 역할과 학습 내용의 연관성 명시\n```\n\n### ❌ 실패 사례 2: \"인증만 나열\"\n```\n문제 상황:\n- AWS 인증 취득 현황만 제출\n- 다른 형태의 학습 활동 증거 없음\n\nAuditor 피드백:\n\"인증 외에 continuous learning culture를 \n보여주는 다양한 활동이 필요합니다.\"\n\n해결책:\n✅ 내부 기술 공유 세션 (Tech Talk, Brown Bag)\n✅ AWS 공식 이벤트 참여 (Summit, GameDay)\n✅ 온라인 학습 (Skill Builder, Workshop Studio)\n✅ 기술 블로그 작성, 커뮤니티 활동 등 다각화\n```\n\n### ❌ 실패 사례 3: \"12개월 범위 미준수\"\n```\n문제 상황:\n- 2년 전 취득한 인증을 주요 증거로 제출\n- 최근 12개월 내 신규 활동이 거의 없음\n\nAuditor 피드백:\n\"Evidence must be within the past 12 months. \n기존 인증은 유효하나, 지속적 학습의 증거가 부족합니다.\"\n\n해결책:\n✅ 기존 인증 갱신(Recertification) 활동 포함\n✅ 최근 12개월 내 새로운 학습 활동 추가\n✅ 인증 유지를 위한 지속 학습 기록 제시\n```\n\n### ❌ 실패 사례 4: \"전략 문서 없이 활동 기록만 제출\"\n```\n문제 상황:\n- 다양한 학습 활동 기록은 있으나\n- \"defined strategy\" 문서가 없음\n\nAuditor 피드백:\n\"학습 활동은 확인되나, 이를 지원하는 \n체계적인 전략이 문서화되어 있지 않습니다.\"\n\n해결책:\n✅ 기술 역량 개발 전략 문서 별도 작성\n✅ 전략 → 계획 → 실행 → 측정의 체계 수립\n✅ 경영진 승인 또는 정책 문서 형태로 공식화\n```\n\n### ❌ 실패 사례 5: \"증빙 불일치\"\n```\n문제 상황:\n- 트래커에 기록된 인증 취득일과 실제 인증서 날짜 불일치\n- 참석자 명단에 있는 인원이 MSP 팀 명단에 없음\n\nAuditor 피드백:",
      "language": "en",
      "createdAt": "2026-01-07T02:28:23.749Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-001",
      "category": "Platform",
      "title": "Account Management",
      "advice": "# PLAT-001: Account Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nAccount Management is the **foundational requirement** of the AWS MSP program. AWS places the highest priority on ensuring customer data and resources are never exposed to other customers. This requirement exists because MSPs manage multiple customers' AWS environments, making the risk of cross-customer data leakage a significant concern.\n\n### 🔍 Key Points Auditors Focus On\n\n1. **1 Customer = 1 AWS Account Principle**: Auditors verify whether each customer is assigned a dedicated AWS account. They will ask for your actual customer list and corresponding AWS Account IDs.\n\n2. **AWS Organizations Structure**: They check if you're using AWS Organizations to manage customer accounts and whether proper OU (Organizational Unit) separation exists.\n\n3. **IAM Role Assumption Process**: How do your engineers access customer accounts? They examine whether cross-account access uses IAM Roles with proper controls rather than shared credentials.\n\n4. **New Account Provisioning Workflow**: They verify you have a standardized, documented process for creating new customer accounts - not ad-hoc creation.\n\n5. **Existing Account Onboarding Procedure**: When taking over management of a customer's existing AWS account, what security checks and handover procedures do you follow?\n\n### Related AWS Services\n- AWS Organizations\n- AWS Control Tower\n- AWS IAM (Cross-account roles)\n- AWS Service Catalog (Account Factory)\n- AWS CloudFormation StackSets\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Document #1: Customer Environment Isolation Policy\n**File Name Example**: `POL-AWS-001_Customer_Environment_Isolation_Policy_v2.1.pdf`\n\n**Must Include**:\n```\n1. Policy Statement\n   - \"Each customer shall be provisioned with a dedicated AWS account\"\n   - \"AWS accounts shall not be shared across multiple customers\"\n   - Exception clause for internal SaaS products (if applicable)\n\n2. Scope Definition\n   - Which customer types this applies to\n   - Geographic scope\n   - Service tier applicability\n\n3. Roles & Responsibilities\n   - Cloud Operations Team: Account creation execution\n   - Security Team: Isolation verification\n   - Account Manager: Customer communication\n\n4. Compliance Monitoring\n   - Quarterly review of account-to-customer mapping\n   - Annual policy review cycle\n```\n\n### Required Document #2: New Account Provisioning Procedure\n**File Name Example**: `SOP-AWS-002_New_Customer_Account_Provisioning_v1.3.pdf`\n\n**Must Include**:\n```\n1. Trigger Conditions\n   - New customer contract signed\n   - Existing customer requests additional isolated environment\n\n2. Step-by-Step Procedure\n   - Step 1: Receive account request via ServiceNow ticket\n   - Step 2: Validate customer contract and billing setup\n   - Step 3: Execute Account Factory in Control Tower\n   - Step 4: Apply baseline SCPs and security controls\n   - Step 5: Create cross-account IAM role for MSP access\n   - Step 6: Document in CMDB and notify customer\n\n3. Approval Workflow\n   - Requestor → Team Lead → Security Review → Execution\n\n4. SLA\n   - Standard: 3 business days\n   - Expedited: 24 hours\n```\n\n### Required Document #3: Existing Account Onboarding Checklist\n**File Name Example**: `CHK-AWS-003_Existing_Account_Onboarding_Checklist_v1.0.xlsx`\n\n**Must Include**:\n| Step | Task | Responsible | Verification |\n|------|------|-------------|--------------|\n| 1 | Receive AWS Account ID from customer | Account Manager | Email confirmation |\n| 2 | Verify no other customer data exists | Security Team | AWS Config rules check |\n| 3 | Invite account to AWS Organizations | Cloud Ops | Console screenshot |\n| 4 | Apply baseline SCPs | Cloud Ops | SCP attachment proof |\n| 5 | Deploy cross-account IAM role | Cloud Ops | CloudFormation output |\n| 6 | Register in CMDB | Cloud Ops | CMDB entry screenshot |\n\n### Required Document #4: Customer-Account Mapping Register\n**File Name Example**: `REG-AWS-004_Customer_Account_Mapping_Register_2024Q4.xlsx`\n\n**Format Example**:\n| Customer Name | Customer ID | AWS Account ID | Account Alias | OU Path | Onboarding Date | Status |\n|---------------|-------------|----------------|---------------|---------|-----------------|--------|\n| Acme Corp | CUST-001 | 123456789012 | acme-prod | /Customers/Enterprise | 2023-01-15 | Active |\n| Beta Inc | CUST-002 | 234567890123 | beta-prod | /Customers/SMB | 2023-03-22 | Active |\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current Account Structure (Week 1)\n**Responsible**: Cloud Operations Lead  \n**Time**: 2-3 days\n\n```bash\n# Run this AWS CLI command to export all accounts in your Organization\naws organizations list-accounts --output json > all_accounts.json\n\n# For each account, identify the customer owner\naws organizations list-tags-for-resource --resource-id <account-id>\n```\n\n**Action Items**:\n- Export complete list of AWS accounts under your Organization\n- Cross-reference with customer contracts in CRM\n- Identify any accounts without clear customer ownership\n- Flag any accounts potentially shared across customers\n\n### Step 2: Design AWS Organizations OU Structure (Week 1-2)\n**Responsible**: Cloud Architect  \n**Time**: 3-4 days\n\n**Recommended OU Structure**:\n```\nRoot\n├── Security\n│   └── Log Archive Account\n│   └── Security Tooling Account\n├── Infrastructure\n│   └── Shared Services Account\n│   └── Network Hub Account\n├── Customers\n│   ├── Enterprise\n│   │   └── Customer A Account\n│   │   └── Customer B Account\n│   └── SMB\n│       └── Customer C Account\n├── Sandbox\n│   └── Internal Testing Account\n└── Suspended\n    └── Offboarded Customer Accounts\n```\n\n### Step 3: Implement AWS Control Tower Account Factory (Week 2-3)\n**Responsible**: Cloud Operations Team  \n**Time**: 5-7 days\n\n**Configuration Steps**:\n1. Enable AWS Control Tower in management account\n2. Configure Account Factory settings:\n   - Default VPC CIDR ranges per customer\n   - Mandatory tags (CustomerID, Environment, CostCenter)\n   - Baseline CloudFormation StackSet for security controls\n3. Create Service Catalog product for self-service provisioning\n4. Test account creation workflow end-to-end\n\n### Step 4: Create Cross-Account Access IAM Role Template (Week 3)\n**Responsible**: Security Engineer  \n**Time**: 2 days\n\n**CloudFormation Template** (`msp-access-role.yaml`):\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: MSP Cross-Account Access Role\n\nParameters:\n  MSPAccountId:\n    Type: String\n    Description: AWS Account ID of MSP management account\n    Default: '999888777666'\n\nResources:\n  MSPAccessRole:\n    Type: AWS::IAM::Role\n    Properties:\n      RoleName: MSP-Operations-Role\n      AssumeRolePolicyDocument:\n        Version: '2012-10-17'\n        Statement:\n          - Effect: Allow\n            Principal:\n              AWS: !Sub 'arn:aws:iam::${MSPAccountId}:root'\n            Action: 'sts:AssumeRole'\n            Condition:\n              Bool:\n                'aws:MultiFactorAuthPresent': 'true'\n      ManagedPolicyArns:\n        - arn:aws:iam::aws:policy/ReadOnlyAccess\n      Tags:\n        - Key: Purpose\n          Value: MSP-Management-Access\n```\n\n### Step 5: Document Policies and Procedures (Week 3-4)\n**Responsible**: Compliance Manager  \n**Time**: 4-5 days\n\n**Documentation Checklist**:\n- [ ] Customer Environment Isolation Policy (executive-approved)\n- [ ] New Account Provisioning SOP with screenshots\n- [ ] Existing Account Onboarding Checklist\n- [ ] Customer-Account Mapping Register (current data)\n- [ ] Exception handling procedure (for SaaS scenarios)\n\n### Step 6: Implement Monitoring and Compliance Checks (Week 4)\n**Responsible**: Security Team  \n**Time**: 3 days\n\n**AWS Config Rule** to detect account sharing:\n```json\n{\n  \"ConfigRuleName\": \"customer-account-isolation-check\",\n  \"Description\": \"Ensures each account has unique CustomerID tag\",\n  \"Source\": {\n    \"Owner\": \"CUSTOM_LAMBDA\",\n    \"SourceIdentifier\": \"arn:aws:lambda:us-east-1:123456789012:function:CheckCustomerIsolation\"\n  },\n  \"Scope\": {\n    \"ComplianceResourceTypes\": [\"AWS::Organizations::Account\"]\n  }\n}\n```\n\n### Step 7: Conduct Internal Audit and Gap Remediation (Week 5)\n**Responsible**: Internal Audit / Compliance  \n**Time**: 2-3 days\n\n**Audit Checklist**:\n- [ ] All active customers have dedicated AWS accounts\n- [ ] No AWS account serves multiple customers\n- [ ] All accounts are registered in CMDB\n- [ ] Account creation follows documented procedure\n- [ ] Cross-account access uses IAM roles (not shared credentials)\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake #1: Using Shared \"Development\" or \"Sandbox\" Accounts\n**Problem**: MSPs sometimes create a shared development account where multiple customers' POC workloads run together.\n\n**Why This Fails Audit**: Auditors will ask to see your complete AWS Organizations structure. If they find accounts like \"dev-shared\" or \"sandbox-multi\" with resources from multiple customers, this is an immediate finding.\n\n**Solution**: Create customer-specific sandbox accounts: `customer-a-sandbox`, `customer-b-sandbox`. Use AWS Control Tower Account Factory to make this scalable.\n\n---\n\n### ❌ Mistake #2: Customer-Account Mapping Only in Engineers' Heads\n**Problem**: When auditors ask \"Which customer owns account 123456789012?\", the answer comes from memory or Slack searches rather than a formal register.\n\n**Why This Fails Audit**: AWS requires **documented** evidence. Verbal confirmation or informal tracking doesn't meet the evidence standard.\n\n**Solution**: Maintain a formal Customer-Account Mapping Register in your CMDB (ServiceNow, Freshservice, etc.) with quarterly review evidence. Export this as PDF for audit submission.\n\n---\n\n### ❌ Mistake #3: Policy Document Without Approval Evidence\n**Problem**: Submitting a policy document that lacks version control, approval signatures, or effective dates.\n\n**Why This Fails Audit**: Auditors verify that policies are formally adopted by the organization, not just drafted documents. They look for:\n- Document control number\n- Version history\n- Approver name and date\n- Next review date\n\n**Solution**: Use a document management system (Confluence, SharePoint) with approval workflows. Include a signature block or approval screenshot in the submitted evidence.\n\n---\n\n### ❌ Mistake #4: No Procedure for Existing Account Onboarding\n**Problem**: Having a great new account creation process but no documented procedure for when customers bring their existing AWS accounts to be managed.\n\n**Why This Fails Audit**: The requirement explicitly mentions \"assuming management of existing customer accounts.\" Auditors will ask specifically about this scenario.\n\n**Solution**: Create a separate SOP for existing account onboarding that includes:\n- Security assessment before accepting management\n- Verification that no other customer data exists\n- Process to invite account into your AWS Organizations\n- Baseline security control deployment\n\n---\n\n### ❌ Mistake #5: SaaS Exception Without Proper Documentation\n**Problem**: Claiming the SaaS exception for multi-tenant accounts without documenting what the SaaS product is and how tenant isolation is achieved within it.\n\n**Why This Fails Audit**: The exception is narrow - it applies only to \"multi-tenant software product they own in a software as a service (SaaS) model.\" Auditors will probe whether this truly qualifies.\n\n**Solution**: If claiming this exception, document:\n- Name and description of the SaaS product\n- Architecture diagram showing tenant isolation\n- Evidence that you own/developed the software\n- How customer data is logically separated within the shared account\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### ✅ Check #1: Policy Document Completeness\n| Verification Item | How to Verify | Pass Criteria |\n|-------------------|---------------|---------------|\n| Document has control number | Check header/footer | Format: POL-XXX-NNN |\n| Version history present | Check revision table | At least v1.0 with date |\n| Executive approval | Check signature block | Name, title, date visible |\n| \"No shared accounts\" statement | Search document | Explicit statement found |\n| Exception clause (if needed) | Search document | SaaS exception clearly defined |\n\n### ✅ Check #2: Procedure Document Actionability\n| Verification Item | How to Verify | Pass Criteria |\n|-------------------|---------------|---------------|\n| Step-by-step instructions | Read through procedure | Engineer can execute without questions |\n| Screenshots included | Visual inspection | Key console steps have screenshots |\n| Roles assigned to each step | Check RACI or responsibility column | Every step has owner |\n| Approval workflow defined | Check procedure flow | Clear escalation path |\n| SLA defined | Check timing section | Specific timeframes stated |\n\n### ✅ Check #3: Customer-Account Mapping Accuracy\n| Verification Item | How to Verify | Pass Criteria |\n|-------------------|---------------|---------------|\n| All active customers listed | Cross-reference with CRM | 100% coverage |\n| AWS Account IDs valid | Run `aws organizations list-accounts` | All IDs exist in Organization |\n| No duplicate customers per account | Filter spreadsheet | Each account has exactly one customer |\n| Recently onboarded customers included | Check last 90 days contracts | All new customers present |\n| Register has review date | Check document metadata | Dated within last quarter |\n\n### ✅ Check #4: AWS Organizations Structure Alignment\n| Verification Item | How to Verify | Pass Criteria |\n|-------------------|---------------|---------------|\n| Customer accounts in dedicated OU | AWS Console → Organizations | Not in Root or shared OUs |\n| Account naming convention followed | List account aliases | Pattern: `{customer}-{environment}` |\n| Mandatory tags applied | Check account tags | CustomerID tag present on all |\n| No orphan accounts | Compare to mapping register | All accounts have documented owner |\n\n### ✅ Check #5: Cross-Account Access Security\n| Verification Item | How to Verify | Pass Criteria |\n|-------------------|---------------|---------------|\n| IAM Role used (not IAM Users) | Check customer account IAM | MSP-Operations-Role exists |\n| MFA required for role assumption | Check role trust policy | `aws:MultiFactorAuthPresent` condition |\n| Role assumption logged | Check CloudTrail | AssumeRole events captured |\n| No shared credentials | Interview operations team | No static access keys distributed |\n\n### ✅ Check #6: Evidence Package Completeness\n| Document | Format | File Present | Content Verified |\n|----------|--------|--------------|------------------|\n| Customer Environment Isolation Policy | PDF | ☐ | ☐ |\n| New Account Provisioning SOP | PDF | ☐ | ☐ |\n| Existing Account Onboarding Checklist | PDF/Excel | ☐ | ☐ |\n| Customer-Account Mapping Register | Excel/PDF | ☐ | ☐ |\n| AWS Organizations Screenshot | PNG | ☐ | ☐ |\n| Sample Account Creation Ticket | PDF | ☐ | ☐ |\n\n---\n\n## 📎 Quick Reference: Evidence Package Summary\n\n| Evidence Type | Document Name | Key Content |\n|---------------|---------------|-------------|\n| Policy | `POL-AWS-001_Customer_Environment_Isolation_Policy.pdf` | No-sharing statement, exception clause, approval |\n| Procedure | `SOP-AWS-002_New_Customer_Account_Provisioning.pdf` | Step-by-step with screenshots, RACI, SLA |\n| Procedure | `SOP-AWS-003_Existing_Account_Onboarding.pdf` | Security checks, Organizations invitation process |\n| Register | `REG-AWS-004_Customer_Account_Mapping.xlsx` | Customer-Account ID mapping, current quarter |\n| Screenshot | `AWS_Organizations_Structure_2024Q4.png` | OU hierarchy showing customer separation |\n| Sample | `TICKET-12345_Account_Creation_Example.pdf` | Completed ticket showing",
      "language": "en",
      "createdAt": "2026-01-07T02:55:44.706Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-002",
      "category": "Platform",
      "title": "Solution Capabilities",
      "advice": "# PLAT-002: Solution Capabilities - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nThis requirement validates that your organization has **mature technical delivery capabilities** - specifically, that you can translate customer business needs into well-architected AWS solutions. AWS wants to ensure MSP Partners aren't just \"lift and shift\" operators but can design sophisticated cloud architectures that follow AWS best practices.\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **SA Certification Verification** - Auditors will cross-reference the reviewer's name against AWS Partner Central certification records. The reviewer must hold an *active* AWS Solutions Architect certification (Associate or Professional) at the time of document approval - expired certifications are rejected.\n\n2. **Requirements-to-Architecture Traceability** - Each customer requirement must clearly map to specific architectural decisions. Auditors look for explicit \"Requirement X → Design Decision Y\" connections, not just separate sections.\n\n3. **AWS-Native Design Patterns** - Documents should demonstrate use of AWS services appropriately (not just EC2 instances). Auditors flag designs that could run on any cloud without modification.\n\n4. **Customer Independence Verification** - The two customers must be genuinely unrelated (different industries, company sizes, or use cases preferred). Same parent company subsidiaries will be questioned.\n\n5. **Implementation Evidence** - These must be *implemented* designs, not proposals. Auditors may ask for proof the architecture was actually deployed.\n\n### Relevant AWS Services/Features to Reference\n- AWS Well-Architected Framework pillars (must be explicitly referenced)\n- AWS Architecture Icons (use official icons in diagrams)\n- AWS Service Quotas and limits considerations\n- Multi-AZ/Multi-Region patterns\n- AWS Landing Zone / Control Tower concepts\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Documents Package\n\n| Document | Format | Key Requirement |\n|----------|--------|-----------------|\n| Detailed Design Document #1 | PDF (30-80 pages typical) | Customer A - within 18 months |\n| Detailed Design Document #2 | PDF (30-80 pages typical) | Customer B - within 18 months |\n| SA Certification Proof | Screenshot from AWS Certification Portal | Must show active status + date |\n| Approval Records | Email/Sign-off page | SA reviewer signature with date |\n\n### 📄 Mandatory Content for Each Design Document\n\n**Section A: Customer Requirements Documentation**\n```\n✓ Business context and objectives (why migrating/building on AWS)\n✓ Functional requirements with priority ranking (MoSCoW method)\n✓ Non-functional requirements with specific metrics:\n  - Performance: \"API response time < 200ms at P99\"\n  - Availability: \"99.95% uptime SLA\"\n  - Security: \"PCI-DSS Level 1 compliance required\"\n✓ Constraints and assumptions\n✓ Success criteria with measurable KPIs\n```\n\n**Section B: Architectural Details**\n```\n✓ High-level architecture diagram (AWS official icons)\n✓ Detailed component diagrams per tier/service\n✓ Network architecture (VPC design, CIDR planning, connectivity)\n✓ Security architecture (IAM roles, encryption, compliance controls)\n✓ Data flow diagrams with AWS service touchpoints\n✓ Sizing calculations and capacity planning\n✓ Cost estimation breakdown by service\n✓ Well-Architected Framework alignment matrix\n```\n\n### 📁 Example File Names\n```\nCustomer_A_RetailCo_ECommerce_Platform_DetailedDesign_v2.1_20240315.pdf\nCustomer_B_HealthTech_DataLake_Architecture_DetailedDesign_v1.3_20240128.pdf\nSA_Certification_JohnSmith_SAP-C02_Valid_Until_20251201.png\nDesign_Approval_Email_CustomerA_SA_Signoff_20240320.pdf\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Your Certified SA Pool (Day 1-2)\n**Action:** Log into AWS Partner Central → Team → Certifications. Export list of all SA-certified employees.\n\n```\nVerification checklist:\n□ At least 2 SAs with active certifications\n□ Certification expiry dates > audit date + 3 months buffer\n□ SAs have actually reviewed customer designs (not just namesake)\n```\n\n**Tool:** AWS Partner Central Certification Dashboard\n**Owner:** Partner Alliance Manager\n**Time:** 2-4 hours\n\n---\n\n### Step 2: Inventory Recent Customer Engagements (Day 2-3)\n**Action:** Pull project list from last 18 months. Filter for engagements that included design phase.\n\n```sql\n-- Selection criteria for qualifying projects:\n- Project included architecture design deliverable\n- Customer is NOT your own company or subsidiary\n- Project is completed/implemented (not just proposed)\n- Design document exists and is retrievable\n- Two customers are in different industries OR different use cases\n```\n\n**Tool:** PSA/Project Management System (Jira, Monday, etc.)\n**Owner:** Delivery Manager\n**Time:** 4-6 hours\n\n---\n\n### Step 3: Gap Analysis on Existing Documents (Day 3-5)\n**Action:** Review selected documents against the mandatory content checklist.\n\n**Create a scoring matrix:**\n| Requirement | Doc 1 Score | Doc 2 Score | Gap Action |\n|-------------|-------------|-------------|------------|\n| Business requirements section | ✅ Complete | ⚠️ Missing KPIs | Add metrics |\n| Architecture diagrams | ⚠️ Non-AWS icons | ✅ Complete | Redraw with official icons |\n| Well-Architected alignment | ❌ Missing | ❌ Missing | Add new section |\n| SA approval signature | ❌ Missing | ✅ Present | Obtain retroactive sign-off |\n\n**Tool:** Custom checklist spreadsheet\n**Owner:** Solutions Architect Lead\n**Time:** 8-12 hours\n\n---\n\n### Step 4: Remediate Document Gaps (Day 5-12)\n**Action:** Update documents to meet all requirements. Common additions needed:\n\n**For Requirements Section:**\n```markdown\n## 2.3 Non-Functional Requirements\n\n| ID | Category | Requirement | Target Metric | Priority |\n|----|----------|-------------|---------------|----------|\n| NFR-001 | Performance | API latency | P95 < 150ms | Must Have |\n| NFR-002 | Availability | System uptime | 99.9% monthly | Must Have |\n| NFR-003 | Scalability | Concurrent users | 10,000 peak | Should Have |\n| NFR-004 | Security | Data encryption | AES-256 at rest | Must Have |\n```\n\n**For Architecture Section - Add Well-Architected Mapping:**\n```markdown\n## 5.6 AWS Well-Architected Framework Alignment\n\n| Pillar | Design Decision | Implementation |\n|--------|-----------------|----------------|\n| Operational Excellence | Infrastructure as Code | CloudFormation + CodePipeline |\n| Security | Least privilege access | IAM roles per service, no IAM users |\n| Reliability | Multi-AZ deployment | RDS Multi-AZ, ALB cross-zone |\n| Performance | Right-sizing | Compute Optimizer recommendations |\n| Cost Optimization | Reserved capacity | 1-year RI for baseline, Spot for batch |\n| Sustainability | Efficient resources | Graviton instances, S3 Intelligent-Tiering |\n```\n\n**Tool:** draw.io with AWS Architecture Icons, Microsoft Word/Google Docs\n**Owner:** Original project SA + Technical Writer\n**Time:** 16-24 hours per document\n\n---\n\n### Step 5: Obtain Formal SA Review and Approval (Day 12-14)\n**Action:** Have certified SA conduct formal review and document approval.\n\n**Required approval artifacts:**\n```\nOption A: Approval page in document\n─────────────────────────────────────\nDocument Review and Approval\n\nReviewed by: John Smith\nRole: Principal Solutions Architect  \nAWS Certification: AWS Certified Solutions Architect - Professional (SAP-C02)\nCertification ID: AWS-SAP-XXXXX\nReview Date: March 15, 2024\nSignature: [Digital signature]\n\nApproval Status: ✅ APPROVED\n─────────────────────────────────────\n\nOption B: Email approval (attach to submission)\nSubject: [APPROVED] Customer A Detailed Design Document v2.1\nBody: I have reviewed the attached design document and confirm it meets \nour architectural standards and AWS best practices.\n[Include certification details in signature]\n```\n\n**Owner:** Certified Solutions Architect\n**Time:** 4-8 hours per document review\n\n---\n\n### Step 6: Customer Data Sanitization (Day 14-15)\n**Action:** Remove or redact sensitive customer information while maintaining document integrity.\n\n**Sanitization guidelines:**\n```\nREDACT:\n- Customer legal entity names → \"Customer A (Retail Industry)\"\n- Specific IP addresses → \"10.x.x.x/24 (Production VPC)\"\n- Employee names → \"Customer IT Director\"\n- Contract values → Remove entirely\n- Proprietary business logic details → Generalize\n\nKEEP VISIBLE:\n- Industry vertical (important for showing diversity)\n- Technical requirements and metrics\n- AWS service selections and configurations\n- Architecture patterns and decisions\n- Scale indicators (users, transactions, data volumes)\n```\n\n**Tool:** Adobe Acrobat Pro (redaction feature), Word track changes\n**Owner:** Project Manager + Legal review\n**Time:** 2-4 hours per document\n\n---\n\n### Step 7: Package and Cross-Verify Submission (Day 15-16)\n**Action:** Assemble final evidence package with verification.\n\n```\n📁 PLAT-002_Solution_Capabilities/\n├── 📄 PLAT-002_Evidence_Index.pdf\n├── 📁 Customer_A/\n│   ├── DetailedDesign_CustomerA_v2.1_Final.pdf\n│   └── SA_Approval_CustomerA_20240315.pdf\n├── 📁 Customer_B/\n│   ├── DetailedDesign_CustomerB_v1.3_Final.pdf\n│   └── SA_Approval_CustomerB_20240128.pdf\n└── 📁 Certifications/\n    └── SA_Certification_JohnSmith_Active_20240401.png\n```\n\n**Owner:** MSP Program Lead\n**Time:** 2-3 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Expired SA Certification at Review Time\n**Problem:** SA certification was valid when project was delivered but expired before audit.\n**Solution:** \n- Verify certification validity extends past expected audit date\n- If expired, have a *currently certified* SA re-review and re-approve the document with a new date\n- Add note: \"Retrospective review conducted on [date] by [current SA]\"\n\n### ❌ Mistake 2: Generic \"Cloud Architecture\" Without AWS Specificity\n**Problem:** Design document reads like cloud-agnostic content. Uses terms like \"load balancer\" instead of \"Application Load Balancer\" or \"database\" instead of \"Amazon RDS for PostgreSQL.\"\n\n**Audit Red Flag Example:**\n```\n❌ BAD: \"The application tier will use auto-scaling virtual machines \n        behind a load balancer.\"\n\n✅ GOOD: \"The application tier deploys on Amazon EC2 t3.large instances \n        within an Auto Scaling Group (min: 2, max: 10, target CPU: 70%) \n        behind an Application Load Balancer with path-based routing. \n        Health checks configured at /health endpoint with 30-second intervals.\"\n```\n\n### ❌ Mistake 3: Requirements Section is Just a Bullet List\n**Problem:** Requirements lack specificity, measurability, or traceability.\n\n**Audit Red Flag Example:**\n```\n❌ BAD: \n- System should be fast\n- High availability required\n- Must be secure\n\n✅ GOOD:\n| REQ-ID | Requirement | Acceptance Criteria | Design Reference |\n|--------|-------------|---------------------|------------------|\n| FR-012 | Real-time inventory sync | Updates reflected within 5 seconds | Section 4.3 - EventBridge + Lambda |\n| NFR-003 | 99.95% availability | < 4.38 hours downtime/year | Section 5.1 - Multi-AZ RDS + ALB |\n```\n\n### ❌ Mistake 4: Same Customer or Related Entities\n**Problem:** Both documents are for subsidiaries of same parent company, or one is for your own organization.\n\n**Auditor Verification:** They may Google customer names, check LinkedIn, or ask clarifying questions.\n\n**Safe combinations:**\n- ✅ Healthcare startup + Manufacturing enterprise\n- ✅ Financial services + E-commerce retailer\n- ❌ Company A + Company A's subsidiary\n- ❌ Your MSP company + Your customer\n\n### ❌ Mistake 5: Proposal Documents Instead of Implemented Designs\n**Problem:** Submitting pre-sales proposals or RFP responses instead of actual implementation designs.\n\n**How auditors detect this:**\n- Document dated before project start\n- Future tense throughout (\"will be deployed\")\n- No specific configuration details (instance types, CIDR ranges)\n- Missing operational sections (monitoring, backup schedules)\n\n**Solution:** Include implementation-specific details:\n```\n✅ Evidence of implementation:\n- Specific resource naming conventions used\n- Actual CIDR ranges allocated\n- CloudWatch alarm thresholds configured\n- Backup retention periods set\n- Deployment pipeline stages defined\n```\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Document Completeness Check\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | SA certification is active | Screenshot from certmetrics.com or AWS Certification portal showing status + expiry date | Expiry date > audit date |\n| 2 | Document dated within 18 months | Check document date, version history, or approval date | Date between [audit date - 18 months] and audit date |\n| 3 | Customer requirements section exists | Table of contents + section review | Dedicated section with numbered requirements |\n| 4 | Requirements have measurable criteria | Scan requirements for numbers/metrics | >80% of NFRs have quantified targets |\n| 5 | Architecture diagrams use AWS icons | Visual inspection of all diagrams | Official AWS Architecture Icons used consistently |\n| 6 | Well-Architected Framework referenced | Search document for \"Well-Architected\" | Explicit mapping to at least 5 pillars |\n| 7 | SA approval signature present | Check approval page or attached email | Name + certification ID + date + signature |\n\n### Quality Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 8 | Two customers are independent | Research customer names, verify different industries | No corporate relationship, different verticals preferred |\n| 9 | AWS services specifically named | Search for generic terms (\"database\", \"server\") | <5 instances of generic terms; AWS service names used |\n| 10 | Sensitive data redacted | Review for customer names, IPs, financials | No identifiable customer data; industry context preserved |\n| 11 | Document is implementation (not proposal) | Check for past tense, specific configs | Contains actual values (IPs, instance types, schedules) |\n| 12 | Traceability exists | Verify requirements link to design sections | Cross-references between requirements and architecture |\n\n### Pre-Submission Final Verification\n\n```\n□ Both PDFs open correctly and are not corrupted\n□ All pages are legible (no cut-off diagrams)\n□ Hyperlinks in table of contents work\n□ File names follow naming convention\n□ Evidence index document lists all files with descriptions\n□ Total package size < 50MB (compress if needed)\n□ Backup copy stored in secure location\n```\n\n### 🎯 Passing Quality Indicators\n- Documents are 30-80 pages each (too short = insufficient detail; too long = may include irrelevant content)\n- At least 3-5 architecture diagrams per document\n- Minimum 10 specific AWS services referenced per design\n- Clear version control showing document maturity\n- Professional formatting consistent with customer-facing deliverables\n\n---\n\n## 💡 Pro Tips from Successful Audits\n\n1. **Include a \"Design Decisions Log\"** - A table showing alternatives considered and why specific AWS services were chosen demonstrates architectural thinking.\n\n2. **Add Cost Estimation Section** - Even if redacted, showing you provided TCO analysis demonstrates MSP maturity.\n\n3. **Reference AWS Documentation** - Citing specific AWS documentation (e.g., \"per AWS RDS best practices documentation\") shows you follow official guidance.\n\n4. **Show Iteration** - Version 2.x documents are stronger than v1.0 - they show the design evolved based on feedback.",
      "language": "en",
      "createdAt": "2026-01-07T02:57:02.242Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-003",
      "category": "Platform",
      "title": "Non-Functional Requirement",
      "advice": "# PLAT-003: Non-Functional Requirement - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nNon-Functional Requirements (NFR) documentation demonstrates that an MSP partner doesn't just \"make things work\" but engineers solutions with **measurable quality attributes**. AWS wants to ensure partners deliver enterprise-grade architectures that meet business-critical performance, availability, and capacity needs—not just functional specifications.\n\nThis requirement separates mature MSPs from basic implementation shops. It proves you can translate business requirements into **quantifiable technical specifications** and validate them through testing.\n\n### 🔍 Key Points Auditors Examine\n\n1. **Specificity of Metrics**: Auditors reject vague statements like \"high availability\" or \"good performance.\" They look for concrete numbers: \"99.95% uptime,\" \"API response time < 200ms at P95,\" \"support 10,000 concurrent users\"\n\n2. **Traceability to AWS Services**: Each NFR must map to specific AWS services/configurations that fulfill it (e.g., \"Multi-AZ RDS deployment for 99.95% database availability\")\n\n3. **Monitoring Implementation**: Not just stating goals but showing HOW you'll measure them—specific CloudWatch metrics, alarms, dashboards\n\n4. **Validation Evidence**: Auditors want to see how NFRs were tested/verified, not just documented\n\n5. **Customer Context**: Documents must show these were real customer engagements with business-driven requirements, not internal templates\n\n### Relevant AWS Services & Features\n\n| NFR Category | Key AWS Services |\n|--------------|------------------|\n| Performance | CloudWatch, X-Ray, Application Insights, Performance Insights |\n| Availability | Multi-AZ, Cross-Region, Route 53 health checks, Auto Scaling |\n| Capacity | Auto Scaling, CloudWatch Capacity Planning, Compute Optimizer |\n| Monitoring | CloudWatch Alarms, EventBridge, SNS, Grafana |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\nYou need **2 detailed design documents** from **2 different customers** within the **last 18 months**.\n\n#### Document Structure Requirements\n\n**📄 Document 1 & 2: Detailed Design Document with NFR Section**\n\nEach document MUST contain these specific sections:\n\n| Section | Required Content | Auditor Focus |\n|---------|------------------|---------------|\n| **Performance Requirements** | Response time targets (P50, P95, P99), throughput requirements, latency budgets | Specific numeric targets with measurement methodology |\n| **Capacity Requirements** | User concurrency, data volume projections, growth forecasts, scaling triggers | Baseline + projected capacity with scaling strategy |\n| **Availability Requirements** | Uptime SLA (%), RTO, RPO, maintenance windows | Alignment with AWS service SLAs |\n| **SLA Definition** | Customer-facing SLAs, internal SLOs, penalty/credit structures | Clear distinction between SLA/SLO/SLI |\n| **Monitoring Approach** | Specific metrics, alarm thresholds, dashboard designs | CloudWatch metric names, dimensions, statistics |\n| **Test/Verification Plan** | Load testing approach, chaos engineering, acceptance criteria | Tools used, test scenarios, pass/fail criteria |\n\n### Evidence File Examples\n\n```\n✅ Good File Names:\n- CustomerA_AWS_Migration_DetailedDesign_NFR_v2.1_2024-03.pdf\n- CustomerB_Ecommerce_Platform_TechnicalDesign_2024-01.docx\n- NFR_Appendix_Performance_Testing_Results_CustomerA.xlsx\n\n❌ Poor File Names:\n- design_doc_final.pdf\n- NFR_template.docx\n- customer_project.pdf\n```\n\n### Key Content Examples for Each Section\n\n**Performance Requirements Example:**\n```\nAPI Gateway Response Time Requirements:\n- P50 latency: ≤ 100ms\n- P95 latency: ≤ 250ms  \n- P99 latency: ≤ 500ms\n- Measurement: CloudWatch metric \"Latency\" with ExtendedStatistics\n- Monitoring: CloudWatch Alarm when P95 > 250ms for 3 consecutive 5-min periods\n```\n\n**Availability Requirements Example:**\n```\nSystem Availability Target: 99.95% monthly uptime\n- Calculation: (Total minutes - Downtime minutes) / Total minutes × 100\n- Exclusions: Scheduled maintenance (max 4 hours/month, announced 72h in advance)\n- AWS Service Alignment:\n  - RDS Multi-AZ: 99.95% SLA\n  - ALB: 99.99% SLA\n  - EC2 (Multi-AZ): 99.99% SLA\n- Composite SLA calculation documented\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Identify Qualifying Projects (Week 1)\n**⏱️ Time: 2-3 days | 👤 Role: Delivery Manager**\n\n- Query your PSA/project management system for projects completed in last 18 months\n- Filter for projects with:\n  - Formal design phase deliverables\n  - Production workloads (not PoCs)\n  - Customer sign-off documentation\n- Verify customer consent for using anonymized documents as evidence\n\n**🛠️ Tool Tip**: Use AWS Partner Central's opportunity tracking to identify qualifying engagements\n\n### Step 2: Audit Existing Design Documents (Week 1-2)\n**⏱️ Time: 3-4 days | 👤 Role: Solutions Architect**\n\nCreate a gap analysis matrix:\n\n| NFR Element | Customer A Doc | Customer B Doc | Gap? |\n|-------------|----------------|----------------|------|\n| Performance metrics with numbers | ✅ | ❌ Missing P95 | Add |\n| Capacity growth projections | ❌ | ✅ | Add |\n| CloudWatch alarm definitions | ❌ | ❌ | Add both |\n| Load test results | ✅ | ❌ | Add |\n| SLA with calculation method | ❌ | ✅ | Add |\n\n### Step 3: Enhance Performance & Capacity Sections (Week 2)\n**⏱️ Time: 2-3 days | 👤 Role: Solutions Architect**\n\nAdd specific CloudWatch configurations:\n\n```yaml\n# Example: Document this level of detail\nPerformance Monitoring Configuration:\n  Dashboard: \"CustomerA-Production-Performance\"\n  Key Metrics:\n    - Namespace: AWS/ApplicationELB\n      MetricName: TargetResponseTime\n      Statistic: p95\n      Period: 60\n      Threshold: 0.25 (seconds)\n    - Namespace: AWS/RDS\n      MetricName: ReadLatency\n      Statistic: Average\n      Period: 60\n      Threshold: 0.005 (seconds)\n```\n\n**🛠️ AWS Tools**: \n- Use CloudWatch Metrics Insights queries to document actual baseline metrics\n- Export CloudWatch dashboard JSON as evidence of monitoring implementation\n\n### Step 4: Document SLA Framework (Week 2-3)\n**⏱️ Time: 2 days | 👤 Role: Service Delivery Manager**\n\nCreate SLA calculation methodology:\n\n```\nMonthly Availability Calculation:\n═══════════════════════════════════════════════════════════\nAvailability % = ((43,200 - Downtime_mins) / 43,200) × 100\n\nWhere 43,200 = minutes in 30-day month\n\nService Credit Structure:\n- 99.95% - 99.00%: 10% credit\n- 99.00% - 95.00%: 25% credit\n- Below 95.00%: 50% credit\n\nMeasurement Tool: CloudWatch Synthetics Canary \"prod-availability-check\"\nReporting: Monthly SLA report generated via CloudWatch Dashboard export\n═══════════════════════════════════════════════════════════\n```\n\n### Step 5: Add Test/Verification Evidence (Week 3)\n**⏱️ Time: 3-4 days | 👤 Role: Performance Engineer/QA**\n\nDocument your testing approach with specific tools:\n\n| Test Type | Tool | What to Document |\n|-----------|------|------------------|\n| Load Testing | Locust, k6, or AWS Distributed Load Testing | Test scenarios, user journeys, ramp-up patterns |\n| Stress Testing | Same as above | Breaking point identification, degradation behavior |\n| Chaos Engineering | AWS Fault Injection Simulator | Failure scenarios tested, recovery validation |\n| Synthetic Monitoring | CloudWatch Synthetics | Canary scripts, check frequency, alerting |\n\n**Include actual test results:**\n```\nLoad Test Summary - CustomerA E-commerce Platform\nDate: 2024-02-15\nTool: AWS Distributed Load Testing Solution\nScenario: Black Friday simulation (10x normal traffic)\n\nResults:\n- Peak concurrent users: 12,500 (target: 10,000) ✅\n- P95 response time at peak: 180ms (target: <250ms) ✅\n- Error rate at peak: 0.02% (target: <0.1%) ✅\n- Auto Scaling response: New instances launched within 90 seconds\n```\n\n### Step 6: Customer Anonymization & Consent (Week 3)\n**⏱️ Time: 1-2 days | 👤 Role: Account Manager**\n\n- Replace customer names with \"Customer A\" / \"Customer B\"\n- Remove IP addresses, account IDs, specific domain names\n- Obtain written consent (email confirmation is acceptable)\n- Keep original documents internally for auditor questions\n\n### Step 7: Final Document Assembly (Week 4)\n**⏱️ Time: 2 days | 👤 Role: Solutions Architect**\n\nEnsure each document has:\n- [ ] Cover page with date (within 18 months)\n- [ ] Table of contents with NFR section clearly visible\n- [ ] Version history showing customer review/approval\n- [ ] All 4 required NFR elements (performance, capacity, availability, monitoring)\n- [ ] Test/verification section with results\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Vague Availability Statements\n\n**Wrong:**\n> \"The system will be highly available using AWS best practices.\"\n\n**Right:**\n> \"Target availability: 99.95% measured monthly. Achieved through:\n> - Multi-AZ RDS deployment (automatic failover < 60 seconds)\n> - ALB across 3 AZs with health check interval of 10 seconds\n> - Auto Scaling group min=2, desired=4, max=12 across 3 AZs\n> - Route 53 health checks with 10-second intervals, 3 failure threshold\"\n\n### ❌ Mistake 2: Missing Monitoring-to-NFR Traceability\n\n**Audit Failure Reason:** Documents state NFRs but don't show how they're monitored.\n\n**Solution:** Create explicit traceability matrix:\n\n| NFR | Target | CloudWatch Metric | Alarm Name | Action |\n|-----|--------|-------------------|------------|--------|\n| API Latency | P95 < 250ms | AWS/ApiGateway/Latency | api-latency-critical | SNS → PagerDuty |\n| DB Connections | < 80% max | AWS/RDS/DatabaseConnections | rds-connections-warning | Auto-scale read replicas |\n\n### ❌ Mistake 3: No Verification/Test Evidence\n\n**Audit Failure Reason:** NFRs documented but no proof they were validated.\n\n**Solution:** Include at minimum:\n- Load test execution summary with pass/fail against NFR targets\n- Screenshot of CloudWatch dashboard showing metrics meeting targets\n- Synthetic monitoring results showing availability over time\n\n### ❌ Mistake 4: Using Internal Templates Without Customer Context\n\n**Audit Failure Reason:** Documents look like generic templates, not customer-specific designs.\n\n**Solution:** Include customer-specific elements:\n- Business context driving each NFR (\"Black Friday requires 10x capacity\")\n- Customer's existing SLAs with their end-users\n- Industry-specific compliance requirements affecting availability\n\n### ❌ Mistake 5: Documents Older Than 18 Months\n\n**Audit Failure Reason:** Date on document or project completion outside the window.\n\n**Solution:** \n- Check document metadata (File Properties → Created/Modified date)\n- Ensure version history shows recent dates\n- If updating old documents, create new version with current date and note \"Updated for [reason]\"\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Document date within 18 months** | Check cover page date AND file metadata | Both dates after [current date - 18 months] |\n| 2 | **Two different customers** | Verify customer names/contexts are distinct | No overlapping project details, different industries preferred |\n| 3 | **Performance requirements with numbers** | Search document for \"ms\", \"seconds\", \"P95\", \"P99\" | At least 3 specific numeric performance targets |\n| 4 | **Capacity requirements with projections** | Search for \"concurrent\", \"users\", \"requests/second\", \"growth\" | Baseline capacity + growth projection + scaling triggers |\n| 5 | **Availability with SLA calculation** | Search for \"99.9\", \"uptime\", \"SLA\", \"RTO\", \"RPO\" | Specific % target + calculation methodology + AWS service mapping |\n| 6 | **Monitoring approach with CloudWatch specifics** | Search for \"CloudWatch\", \"alarm\", \"metric\", \"dashboard\" | Named metrics, alarm thresholds, notification channels |\n| 7 | **Test/verification section** | Look for \"load test\", \"performance test\", \"validation\" | Test approach + tools + results against NFR targets |\n\n### Quality Criteria Scoring\n\n**Score each document (minimum 4/5 to pass):**\n\n| Criteria | 0 Points | 1 Point | 2 Points |\n|----------|----------|---------|----------|\n| **Specificity** | Generic statements | Some specific metrics | All NFRs have numeric targets |\n| **AWS Integration** | No AWS services mentioned | Services listed | Services mapped to specific NFRs |\n| **Monitoring** | Not addressed | Tools mentioned | Full CloudWatch configuration |\n| **Verification** | No testing mentioned | Test approach described | Test results with pass/fail |\n| **Customer Context** | Template-like | Some customization | Clear business-driven requirements |\n\n### Final Validation Questions\n\nBefore submitting, answer YES to all:\n\n- [ ] Would a new team member understand exactly what metrics to monitor?\n- [ ] Can you prove these NFRs were actually tested, not just documented?\n- [ ] Is each NFR traceable to a specific AWS service configuration?\n- [ ] Would the customer recognize this as their project (if not anonymized)?\n- [ ] Are the SLA calculations reproducible from the documented methodology?\n\n---\n\n## 📎 Quick Reference: NFR Documentation Template Sections\n\n```\n1. Executive Summary\n2. Solution Overview\n3. Functional Requirements (brief)\n4. NON-FUNCTIONAL REQUIREMENTS ← Auditor Focus\n   4.1 Performance Requirements\n       - Response time targets (P50/P95/P99)\n       - Throughput requirements\n       - Latency budgets by component\n   4.2 Capacity Requirements\n       - Current baseline\n       - Growth projections (6/12/24 months)\n       - Scaling triggers and limits\n   4.3 Availability Requirements\n       - Uptime SLA target and calculation\n       - RTO/RPO requirements\n       - Maintenance window policy\n       - Disaster recovery approach\n   4.4 Service Level Agreements\n       - Customer-facing SLAs\n       - Internal SLOs\n       - Credit/penalty structure\n   4.5 Monitoring & Observability\n       - CloudWatch metrics and alarms\n       - Dashboard specifications\n       - Alerting and escalation\n   4.6 Test & Verification Approach\n       - Load testing methodology\n       - Acceptance criteria\n       - Test results summary\n5. Architecture Design\n6. Implementation Plan\n```",
      "language": "en",
      "createdAt": "2026-01-07T02:58:11.648Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-004_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-004",
      "category": "Platform",
      "title": "Well-Architected",
      "advice": "# PLAT-004: Well-Architected - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\nWell-Architected는 MSP가 단순 운영 대행이 아닌 **아키텍처 수준의 전문성**을 갖추고 있음을 증명하는 핵심 항목입니다. AWS는 MSP 파트너가 고객 워크로드를 AWS Best Practice에 맞게 설계하고 지속적으로 개선할 역량이 있는지를 이 항목으로 검증합니다.\n\n### 🔍 Auditor가 집중적으로 확인하는 5가지 포인트\n\n1. **6개 Pillar 전체 커버리지**: Security, Operational Excellence, Reliability, Performance Efficiency, Cost Optimization, Sustainability 모두 다뤄졌는지\n2. **실제 구현 증거**: 설계 문서가 실제 배포된 시스템을 반영하는지 (단순 제안서 X)\n3. **HRI(High Risk Issue) 해결 상태**: Security, Ops Excellence, Reliability 3개 pillar에서 HRI가 0인지\n4. **18개월 이내 문서**: 날짜가 명확히 기재되어 있고 최신 상태인지\n5. **고객 독립성**: 2개 고객이 실제로 별개 법인/프로젝트인지 (동일 그룹사 내 다른 부서는 인정 안 됨)\n\n### 관련 AWS 서비스 및 도구\n- **AWS Well-Architected Tool** (Console 내장)\n- **AWS Trusted Advisor**\n- **AWS Config Rules**\n- **AWS Security Hub**\n- **AWS Compute Optimizer**\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Option A: Detailed Design Documents (2개 고객)\n\n| 문서 유형 | 필수 포함 내용 | 파일명 예시 |\n|-----------|---------------|-------------|\n| **System Architecture Document** | 전체 아키텍처 다이어그램, 컴포넌트 설명, 데이터 플로우 | `CustomerA_SystemArchitecture_v2.1_20240315.pdf` |\n| **Well-Architected Design Decisions** | 각 Pillar별 설계 결정 근거와 적용된 Best Practice | `CustomerA_WA_DesignDecisions_20240315.docx` |\n| **Security Architecture** | IAM 정책 구조, 네트워크 보안, 암호화 전략 | `CustomerA_SecurityArchitecture_20240315.pdf` |\n| **Operational Runbook** | 모니터링 설정, 알람 정책, 인시던트 대응 절차 | `CustomerA_OperationalRunbook_v1.2.pdf` |\n\n### Option B: WAFR Report (권장 - 더 명확한 증거)\n\n| 문서 유형 | 필수 조건 | 파일명 예시 |\n|-----------|----------|-------------|\n| **Exported WAFR Report (PDF)** | Security/Ops Excellence/Reliability pillar HRI = 0 | `CustomerA_WAFR_Export_20240401.pdf` |\n| **Workload Summary Screenshot** | HRI 카운트가 명확히 보이는 대시보드 캡처 | `CustomerA_WAFR_Dashboard_20240401.png` |\n| **Improvement Plan (Optional)** | Medium/Low risk 개선 계획 (MSP 역량 어필) | `CustomerA_WAFR_ImprovementPlan.xlsx` |\n\n### 📌 각 Evidence에 반드시 포함되어야 할 내용\n\n**Detailed Design Document 필수 섹션:**\n```\n1. Document Control\n   - Version: 2.1\n   - Date: 2024-03-15\n   - Author: [MSP Company Name]\n   - Customer: [Customer Legal Name]\n   - Status: Implemented ← 반드시 \"Implemented\" 명시\n\n2. Architecture Overview\n   - High-level architecture diagram\n   - AWS Region/AZ 배치 전략\n   - 주요 서비스 목록 및 선택 근거\n\n3. Well-Architected Pillar Analysis\n   [각 6개 Pillar별 섹션 필수]\n   \n4. Implementation Evidence\n   - 실제 배포된 리소스 스크린샷\n   - CloudFormation/Terraform 코드 발췌\n   - AWS Config 규정 준수 현황\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: 적합한 고객 워크로드 선정 (Day 1-2)\n**담당**: Delivery Manager / Solutions Architect\n\n```\n선정 기준 체크리스트:\n□ 18개월 이내 구축 완료된 프로젝트\n□ Production 환경에서 실제 운영 중\n□ 최소 3개 이상 AWS 서비스 사용\n□ 고객사가 증거 제출에 동의 (NDA 확인)\n□ 2개 고객이 완전히 별개 법인\n```\n\n**⚠️ 피해야 할 워크로드:**\n- 단순 EC2 + RDS만 있는 Lift & Shift\n- PoC/Dev 환경만 있는 프로젝트\n- 고객사 내부 IT팀이 주도하고 MSP는 지원만 한 경우\n\n### Step 2: AWS Well-Architected Tool에서 WAFR 수행 (Day 3-7)\n**담당**: Solutions Architect\n\n```bash\n# AWS Console 접속 경로\nAWS Console → Well-Architected Tool → Define workload\n\n# Workload 정의 시 필수 입력\n- Workload name: [Customer]_[Project]_Production\n- Description: Production workload for [specific use case]\n- Environment: Production ← 반드시 Production 선택\n- AWS Regions: 실제 배포된 리전 선택\n- AWS account IDs: 실제 계정 ID 입력\n```\n\n**Review 수행 시 주의사항:**\n- 모든 질문에 \"Does not apply\"를 남발하지 말 것\n- 각 답변에 Notes 섹션에 구체적 구현 내용 기록\n- Trusted Advisor 연동하여 자동 검증 활용\n\n### Step 3: HRI(High Risk Issue) 식별 및 해결 (Day 8-21)\n**담당**: Solutions Architect + DevOps Engineer\n\n**Security Pillar 주요 HRI 해결 예시:**\n```\nHRI: \"IAM policies are not following least privilege\"\n해결:\n1. IAM Access Analyzer 실행\n2. 미사용 권한 식별\n3. 권한 축소 적용\n4. AWS Config rule: iam-policy-no-statements-with-admin-access 활성화\n```\n\n**Operational Excellence Pillar 주요 HRI 해결 예시:**\n```\nHRI: \"Workload does not have runbooks for operational procedures\"\n해결:\n1. Systems Manager Automation Documents 생성\n2. 주요 운영 시나리오별 Runbook 작성\n   - 인스턴스 재시작 절차\n   - 로그 수집 절차\n   - 스케일링 절차\n3. SSM Documents를 Runbook에 연결\n```\n\n**Reliability Pillar 주요 HRI 해결 예시:**\n```\nHRI: \"Single points of failure exist in the architecture\"\n해결:\n1. Multi-AZ 배포 확인 (RDS, ElastiCache)\n2. Auto Scaling Group 최소 인스턴스 2개 이상\n3. Route 53 health check 설정\n4. 장애 복구 테스트 수행 및 문서화\n```\n\n### Step 4: WAFR Report Export 또는 Design Document 작성 (Day 22-28)\n**담당**: Solutions Architect + Technical Writer\n\n**WAFR Export 방법:**\n```\nAWS Console → Well-Architected Tool → Workloads → [선택]\n→ Generate report → PDF 다운로드\n\nExport 전 확인:\n□ Security pillar: 0 HRIs\n□ Operational Excellence pillar: 0 HRIs  \n□ Reliability pillar: 0 HRIs\n□ Workload status: Active\n□ Last review date: 18개월 이내\n```\n\n### Step 5: 증거 문서 품질 검증 (Day 29-30)\n**담당**: QA Lead / Peer Architect\n\n**Design Document 품질 체크:**\n```\n□ 고객명이 문서 전체에 일관되게 표기\n□ 날짜가 18개월 이내\n□ \"Implemented\" 또는 \"Production\" 상태 명시\n□ 아키텍처 다이어그램에 AWS 서비스 아이콘 사용\n□ 각 Pillar별 최소 3개 이상 Best Practice 적용 설명\n□ 민감 정보(계정 ID, IP 등) 마스킹 처리\n```\n\n### Step 6: 고객 승인 및 최종 제출 준비 (Day 31-35)\n**담당**: Account Manager + Delivery Manager\n\n```\n고객 승인 요청 이메일 템플릿:\nSubject: AWS MSP 인증 증거 제출 승인 요청\n\n[고객명] 담당자님,\n\n당사의 AWS MSP 파트너 인증 갱신을 위해 \n귀사 프로젝트의 아키텍처 문서를 AWS에 제출하고자 합니다.\n\n제출 문서: [문서명]\n제출 목적: AWS MSP Partner 인증 심사\n공개 범위: AWS 심사팀에 한정\n\n승인 회신 부탁드립니다.\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: 제안서를 Design Document로 제출\n```\n문제: \"Proposed Architecture\" 또는 \"To-Be Architecture\" 문서 제출\n결과: 즉시 Reject\n\n해결: \n- 문서에 \"Implemented Architecture\" 명시\n- 실제 배포된 리소스의 스크린샷 포함\n- CloudFormation Stack 또는 Terraform State 증거 첨부\n```\n\n### ❌ Mistake 2: WAFR에서 HRI를 \"Not Applicable\"로 회피\n```\n문제: 어려운 질문을 N/A로 처리하여 HRI 회피\n결과: Auditor가 Notes 확인 시 적발, 신뢰도 하락\n\n해결:\n- N/A 선택 시 반드시 합리적 근거 Notes에 기록\n- 예: \"This workload does not process PII data, \n       therefore encryption at rest for PII is not applicable\"\n```\n\n### ❌ Mistake 3: 동일 그룹사 내 2개 프로젝트를 별개 고객으로 제출\n```\n문제: 삼성전자, 삼성SDS를 2개 독립 고객으로 주장\n결과: Reject - 동일 그룹사는 1개 고객으로 간주\n\n해결:\n- 완전히 별개 법인의 프로젝트 선정\n- 고객 법인등록번호가 다른지 확인\n```\n\n### ❌ Mistake 4: 18개월 기준 날짜 계산 오류\n```\n문제: 문서 작성일 기준 vs 시스템 구축 완료일 기준 혼동\n결과: 심사 시점에 18개월 초과로 Reject\n\n해결:\n- 심사 예상 시점 기준으로 역산\n- 예: 2024년 10월 심사 예정 → 2023년 4월 이후 문서만 유효\n- 안전 마진 2개월 확보 권장\n```\n\n### ❌ Mistake 5: WAFR Report에서 Medium Risk를 HRI로 오인\n```\n문제: Medium Risk Issue가 있어서 추가 해결 작업 진행\n결과: 불필요한 시간 소요\n\n정확한 기준:\n- High Risk Issue (HRI)만 0이면 됨\n- Medium Risk, Low Risk는 있어도 통과\n- 단, Improvement Plan 제시하면 가산점\n```\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### 문서 기본 요건 (5점 만점 기준)\n\n| # | 체크 항목 | 검증 방법 | 통과 기준 |\n|---|----------|----------|----------|\n| 1 | 고객 2개가 독립 법인인가? | 각 고객의 법인명/사업자등록번호 확인 | 완전히 별개 법인 |\n| 2 | 문서 날짜가 18개월 이내인가? | Document Control 섹션의 Date 확인 | 심사일 기준 18개월 이내 |\n| 3 | Production 환경 문서인가? | Environment 필드 또는 문서 제목 확인 | \"Production\" 또는 \"Implemented\" 명시 |\n\n### WAFR Report 제출 시 (Option B)\n\n| # | 체크 항목 | 검증 방법 | 통과 기준 |\n|---|----------|----------|----------|\n| 4 | Security Pillar HRI = 0? | WAFR Report의 Risk Summary 섹션 | High Risk: 0 |\n| 5 | Operational Excellence Pillar HRI = 0? | WAFR Report의 Risk Summary 섹션 | High Risk: 0 |\n| 6 | Reliability Pillar HRI = 0? | WAFR Report의 Risk Summary 섹션 | High Risk: 0 |\n| 7 | Workload가 Active 상태인가? | WAFR Dashboard 스크린샷 | Status: Active |\n\n### Design Document 제출 시 (Option A)\n\n| # | 체크 항목 | 검증 방법 | 통과 기준 |\n|---|----------|----------|----------|\n| 4 | 6개 Pillar 모두 다뤄졌는가? | 목차 및 본문 섹션 확인 | 각 Pillar별 최소 1개 섹션 |\n| 5 |",
      "language": "en",
      "createdAt": "2026-01-07T02:59:12.615Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLAT-005_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLAT-005",
      "category": "Platform",
      "title": "AWS Service Expertise",
      "advice": "# PLAT-005: AWS Service Expertise - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nThis requirement validates that your organization goes beyond basic AWS infrastructure (EC2, S3, RDS) and can architect sophisticated solutions using AWS's broader service portfolio. AWS wants MSP Partners who can guide customers toward modern, cloud-native architectures rather than simple lift-and-shift migrations. This differentiates true cloud experts from basic infrastructure providers.\n\n### 🎯 Key Points Auditors Evaluate\n\n1. **Service Selection Justification**: Auditors verify that each AWS service was chosen for a specific business or technical reason—not just to meet the \"4 services\" threshold. They look for logical connections between customer requirements and service choices.\n\n2. **Integration Depth**: Simply using 4+ services isn't enough. Auditors examine how services interact—are they loosely coupled? Do they form a cohesive architecture? Is there event-driven communication between components?\n\n3. **Business Outcome Documentation**: Each workload must show measurable customer value—cost reduction percentages, performance improvements, or operational efficiency gains tied to the service choices.\n\n4. **Architecture Evolution**: For rearchitected workloads, auditors want to see before/after comparisons demonstrating how advanced services replaced or enhanced legacy approaches.\n\n5. **Operational Maturity**: Evidence should show you didn't just deploy services but also implemented proper monitoring, alerting, and operational runbooks for the advanced services used.\n\n### Relevant AWS Services (Qualifying Examples)\n**Compute & Containers**: Lambda, ECS, EKS, Fargate, App Runner, Batch\n**Analytics**: Athena, Kinesis, EMR, QuickSight, Glue, OpenSearch Service\n**Application Integration**: SNS, SQS, Step Functions, EventBridge, API Gateway\n**Machine Learning**: SageMaker, Rekognition, Comprehend, Textract, Bedrock\n**Database (Advanced)**: DynamoDB, ElastiCache, Neptune, DocumentDB, Aurora Serverless\n**Security**: Secrets Manager, KMS, WAF, Shield, GuardDuty, Security Hub\n**Developer Tools**: CodePipeline, CodeBuild, CodeDeploy, X-Ray\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package (Per Workload)\n\n#### Document 1: Architecture Design Document\n**Filename**: `PLAT-005_CustomerA_Architecture_Design_v2.1.pdf`\n\n**Must Include**:\n- Customer name (anonymized if needed) and industry context\n- Business problem statement with specific pain points\n- Architecture diagram (AWS Architecture Icons compliant)\n- Detailed service inventory table:\n  | Service | Purpose | Configuration | Integration Points |\n  |---------|---------|---------------|-------------------|\n  | Lambda | Order processing | 512MB, 30s timeout | Triggered by SQS |\n- Data flow diagrams showing inter-service communication\n- Security architecture overlay\n\n#### Document 2: Technical Implementation Summary\n**Filename**: `PLAT-005_CustomerA_Implementation_Summary.pdf`\n\n**Must Include**:\n- Deployment timeline and phases\n- Infrastructure as Code snippets (CDK/Terraform) showing service configurations\n- Integration patterns implemented (e.g., fan-out, saga pattern)\n- Performance benchmarks achieved\n- Cost optimization decisions made\n\n#### Document 3: Business Outcome Report\n**Filename**: `PLAT-005_CustomerA_Business_Outcomes.pdf`\n\n**Must Include**:\n- Quantified metrics (before/after):\n  - Processing time: 45 minutes → 3 minutes (93% reduction)\n  - Monthly cost: $12,000 → $4,500 (62% savings)\n  - Error rate: 2.3% → 0.1%\n- Customer testimonial or sign-off (redacted if confidential)\n- ROI calculation\n\n#### Document 4: Service Utilization Evidence\n**Filename**: `PLAT-005_CustomerA_Service_Screenshots.pdf`\n\n**Must Include**:\n- AWS Console screenshots showing active services in customer account\n- CloudWatch dashboards displaying service metrics\n- Cost Explorer breakdown by service\n- X-Ray service map (if applicable)\n\n### Evidence Examples by Workload Type\n\n**Example Workload A: E-commerce Order Processing**\n```\nServices Used (6 qualifying):\n├── API Gateway (REST API for order intake)\n├── Lambda (Order validation, inventory check)\n├── SQS (Order queue for async processing)\n├── DynamoDB (Order state management)\n├── Step Functions (Order fulfillment orchestration)\n└── SNS (Customer notification dispatch)\n```\n\n**Example Workload B: Data Analytics Platform**\n```\nServices Used (5 qualifying):\n├── Kinesis Data Streams (Real-time ingestion)\n├── Kinesis Data Firehose (S3 delivery)\n├── Glue (ETL jobs and Data Catalog)\n├── Athena (Ad-hoc querying)\n└── QuickSight (Business dashboards)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Your Project Portfolio (Week 1)\n**Action**: Create a service inventory spreadsheet for all customer projects from the past 24 months\n\n```\n| Project | Customer | Services Used | Qualifying Services | Business Outcome |\n|---------|----------|---------------|--------------------|--------------------|\n| Proj-A  | Acme Inc | Lambda, DynamoDB, SQS, SNS, API GW | 5 ✅ | 70% cost reduction |\n| Proj-B  | Beta Corp| EC2, RDS, S3, CloudWatch | 0 ❌ | N/A |\n```\n\n**Tool**: Export from your PSA/project management system, cross-reference with AWS Cost Explorer reports from customer accounts\n**Owner**: Solutions Architect Lead\n**Time**: 3-4 hours\n\n### Step 2: Select Two Strongest Workloads (Week 1)\n**Selection Criteria**:\n- ✅ Minimum 4 qualifying services with clear integration\n- ✅ Documented business outcomes with metrics\n- ✅ Customer willing to provide testimonial or sign-off\n- ✅ Architecture demonstrates modern patterns (serverless, event-driven, microservices)\n- ✅ Project completed within last 18 months\n\n**Anti-pattern to avoid**: Don't choose projects where you used many services but they're disconnected (e.g., Lambda for one function, Athena for unrelated reporting)\n\n**Owner**: Delivery Manager + Solutions Architect\n**Time**: 2 hours\n\n### Step 3: Reconstruct Architecture Documentation (Weeks 2-3)\n**Action**: Create AWS-compliant architecture diagrams using official tools\n\n**Tools**:\n- **draw.io** with AWS Architecture Icons 2023\n- **Cloudcraft** for 3D isometric diagrams\n- **AWS Application Composer** for serverless architectures\n\n**Diagram Requirements**:\n- Use official AWS icon set (latest version)\n- Show all service connections with protocol labels (HTTPS, SQS polling, EventBridge rules)\n- Include availability zone placement\n- Add security boundaries (VPC, subnets, security groups)\n\n**Owner**: Solutions Architect\n**Time**: 4-6 hours per workload\n\n### Step 4: Gather Quantitative Evidence (Week 3)\n**Action**: Extract metrics from customer environments\n\n**For Each Workload, Collect**:\n```bash\n# Cost data (AWS CLI)\naws ce get-cost-and-usage \\\n  --time-period Start=2024-01-01,End=2024-06-30 \\\n  --granularity MONTHLY \\\n  --metrics BlendedCost \\\n  --group-by Type=SERVICE\n\n# Service utilization (CloudWatch)\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/Lambda \\\n  --metric-name Invocations \\\n  --dimensions Name=FunctionName,Value=OrderProcessor \\\n  --start-time 2024-01-01T00:00:00Z \\\n  --end-time 2024-06-30T00:00:00Z \\\n  --period 2592000 \\\n  --statistics Sum\n```\n\n**Screenshots to Capture**:\n- X-Ray Service Map showing service interactions\n- CloudWatch Dashboard with key metrics\n- Cost Explorer service breakdown\n- Step Functions execution history (if used)\n\n**Owner**: Cloud Engineer + FinOps Analyst\n**Time**: 3-4 hours per workload\n\n### Step 5: Document Business Outcomes (Week 4)\n**Action**: Create outcome narratives with customer validation\n\n**Template Structure**:\n```markdown\n## Business Challenge\n[Customer] faced [specific problem] resulting in [quantified impact]\n\n## Solution Approach\nWe designed a [architecture pattern] using:\n- [Service 1]: [specific purpose]\n- [Service 2]: [specific purpose]\n...\n\n## Measurable Results\n| Metric | Before | After | Improvement |\n|--------|--------|-------|-------------|\n| Processing Time | 45 min | 3 min | 93% faster |\n| Monthly Cost | $12,000 | $4,500 | 62% savings |\n| Error Rate | 2.3% | 0.1% | 96% reduction |\n\n## Customer Validation\n[Quote or sign-off from customer stakeholder]\n```\n\n**Owner**: Account Manager + Solutions Architect\n**Time**: 2-3 hours per workload\n\n### Step 6: Compile Evidence Package (Week 5)\n**Action**: Organize all documents in submission-ready format\n\n**Folder Structure**:\n```\nPLAT-005_AWS_Service_Expertise/\n├── Workload_1_CustomerA/\n│   ├── 01_Architecture_Design.pdf\n│   ├── 02_Implementation_Summary.pdf\n│   ├── 03_Business_Outcomes.pdf\n│   ├── 04_Service_Screenshots.pdf\n│   └── 05_Customer_Testimonial.pdf\n├── Workload_2_CustomerB/\n│   ├── 01_Architecture_Design.pdf\n│   ├── 02_Implementation_Summary.pdf\n│   ├── 03_Business_Outcomes.pdf\n│   ├── 04_Service_Screenshots.pdf\n│   └── 05_Customer_Testimonial.pdf\n└── PLAT-005_Evidence_Index.xlsx\n```\n\n**Owner**: MSP Program Manager\n**Time**: 2 hours\n\n### Step 7: Internal Review and Gap Analysis (Week 5)\n**Action**: Conduct peer review against audit criteria\n\n**Review Checklist**:\n- [ ] Each workload uses ≥4 qualifying services (not EC2, VPC, RDS, S3, EBS, IAM, CloudWatch, CloudTrail, CloudFormation)\n- [ ] Services are integrated, not standalone\n- [ ] Business outcomes are quantified\n- [ ] Architecture diagrams use current AWS icons\n- [ ] Customer consent obtained for evidence sharing\n\n**Owner**: Technical Director\n**Time**: 2-3 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Counting Excluded Services\n**Problem**: Submitting workloads that heavily rely on EC2, RDS, S3, VPC as the \"core\" with only 2-3 qualifying services as add-ons.\n\n**Example of Failure**:\n```\n❌ Failed Submission:\n- EC2 (excluded) - Main compute\n- RDS (excluded) - Database\n- S3 (excluded) - Storage\n- Lambda - Just for one scheduled task\n- SNS - Just for email alerts\n- CloudWatch (excluded) - Monitoring\n```\n\n**Solution**: Redesign evidence around workloads where qualifying services are central to the architecture, not peripheral.\n\n### ❌ Mistake 2: Service Islands (No Integration)\n**Problem**: Listing services that exist in the same account but don't interact.\n\n**Example of Failure**:\n```\n❌ \"We use Lambda, DynamoDB, SQS, and Athena\"\nBut: Lambda writes to DynamoDB, SQS is for a different app, \nAthena queries unrelated S3 data\n```\n\n**Solution**: Draw explicit integration arrows. If you can't show data/event flow between services, they don't count as a cohesive workload.\n\n### ❌ Mistake 3: Missing Business Context\n**Problem**: Providing technical architecture without explaining WHY services were chosen or WHAT business problem was solved.\n\n**Auditor Question**: \"Why did you use Step Functions instead of Lambda orchestration?\"\n\n**Bad Answer**: \"Because we wanted to use Step Functions\"\n**Good Answer**: \"The order fulfillment process has 7 steps with conditional branching and human approval gates. Step Functions' visual workflow, built-in retry logic, and state persistence reduced our error handling code by 80% and provided audit trails required for compliance.\"\n\n### ❌ Mistake 4: Outdated Architecture Diagrams\n**Problem**: Using old AWS icons, hand-drawn diagrams, or generic cloud shapes.\n\n**Auditor Perception**: \"This partner isn't current with AWS standards\"\n\n**Solution**: Always use the latest AWS Architecture Icons (updated annually). Download from AWS Architecture Center. Use tools like draw.io with AWS icon libraries.\n\n### ❌ Mistake 5: No Proof of Production Usage\n**Problem**: Submitting POC or demo architectures that were never deployed to production.\n\n**Red Flags Auditors Look For**:\n- No CloudWatch metrics history\n- Cost Explorer shows minimal usage\n- No customer testimonial or sign-off\n- Architecture doc dated recently but claims \"18 months in production\"\n\n**Solution**: Include 3-6 months of CloudWatch metrics, Cost Explorer trends, and dated customer communications.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | **Service Count Validation** | Count qualifying services in each workload against excluded list | Each workload has ≥4 services NOT in: EC2, VPC, RDS, S3, EBS, IAM, CloudWatch, CloudTrail, CloudFormation |\n| 2 | **Service Integration Proof** | Review architecture diagram for connection arrows between all qualifying services | Every qualifying service has at least one integration point with another service in the workload |\n| 3 | **Business Outcome Quantification** | Check outcome document for specific numbers | Contains ≥3 metrics with before/after comparison and percentage improvement |\n| 4 | **Architecture Diagram Compliance** | Visual inspection of icons and layout | Uses official AWS Architecture Icons 2023+, includes legend, shows AZs/regions |\n| 5 | **Customer Validation Present** | Locate customer sign-off or testimonial | Written acknowledgment from customer stakeholder (can be anonymized but must exist) |\n| 6 | **Production Evidence** | Review CloudWatch/Cost Explorer screenshots | Shows ≥3 months of active usage metrics, not just deployment spike |\n| 7 | **Exemption Check** | Verify Partner Central for existing designations | If you have 3+ Competencies or Service Deliveries, document this instead of workloads |\n\n### Quality Gates\n\n**🟢 Ready to Submit**:\n- Both workloads pass all 6 checks above\n- Internal architect has signed off on technical accuracy\n- Customer has approved evidence sharing (written consent)\n\n**🟡 Needs Revision**:\n- One workload passes, one needs additional services or documentation\n- Business outcomes exist but lack quantification\n- Architecture diagram needs icon updates\n\n**🔴 Not Ready**:\n- Neither workload has 4 qualifying services\n- No customer validation obtained\n- Services are not integrated (service islands)\n\n### Final Verification Command\nBefore submission, run this mental test for each workload:\n\n> \"If an auditor asked me to explain on a call why we chose [Service X] and how it connects to [Service Y] to solve [Business Problem Z], can I answer confidently with specific technical and business details?\"\n\nIf yes for all services in both workloads → **Submit with confidence** ✅",
      "language": "en",
      "createdAt": "2026-01-07T03:00:19.649Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "PLATP-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "PLATP-001",
      "category": "Platform",
      "title": "Expert Design Review",
      "advice": "# PLATP-001: Expert Design Review - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nExpert Design Review is positioned as a **core quality assurance mechanism** in the AWS MSP program. AWS wants to verify that MSP Partners don't just deploy cloud infrastructure, but that **certified experts review architecture** to ensure best practices, security, and cost optimization are embedded from the design phase.\n\nThis requirement directly relates to the **AWS Well-Architected Framework** philosophy - catching design flaws early prevents costly rework and security incidents for end customers.\n\n### 🎯 Key Points Auditors Specifically Evaluate\n\n1. **Certification Tier Escalation Logic**: Auditors check if your policy clearly defines WHEN a Professional/Specialty certified reviewer is required vs. when Associate-level is sufficient (e.g., workloads involving >$50K monthly spend, regulated industries, multi-region architectures)\n\n2. **Reviewer Independence**: Evidence that the reviewer is NOT the same person who created the design - auditors look for different names/signatures on design vs. review sections\n\n3. **Timing of Review Gates**: Policy must specify reviews occur BEFORE implementation, not as post-deployment documentation exercise\n\n4. **Certification Verification Trail**: Auditors verify that reviewers' certifications were ACTIVE at the time of review (not expired)\n\n5. **Actionable Feedback Loop**: Evidence that review findings were actually addressed, not just documented and ignored\n\n### Relevant AWS Services & Features\n- **AWS Well-Architected Tool** - For structured review documentation\n- **AWS Certification Digital Badges (Credly)** - For certification verification\n- **AWS Architecture Icons** - For standardized design documentation\n- **AWS Trusted Advisor** - Often referenced in review checklists\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Document Name Example | Format |\n|--------------|----------------------|--------|\n| Policy Document | `MSP-POL-007_Expert_Design_Review_Policy_v2.3.pdf` | PDF with version control |\n| Review Record | `PROJ-2024-0142_Architecture_Review_Record.pdf` | Signed PDF |\n| Certification Proof | `Reviewer_Certification_Matrix_Q1_2024.xlsx` | Excel with Credly links |\n| Customer Project Doc | `CustomerX_AWS_Migration_HLD_Reviewed.pdf` | PDF with review stamps |\n\n### 📄 Policy Document - Must Include Content\n\n```\nRequired Sections:\n├── 1. Purpose & Scope\n│   └── Explicitly state: \"All customer AWS projects require certified review\"\n├── 2. Reviewer Qualification Matrix\n│   ├── Associate-level: Standard workloads, single-region, <$20K/month\n│   ├── Professional-level: Multi-region, >$20K/month, production critical\n│   └── Specialty-level: Security-sensitive, ML/AI, specific domain expertise\n├── 3. Review Timing Requirements\n│   ├── Initial Design Review: Before customer sign-off\n│   ├── Implementation Review: Before production deployment\n│   └── Change Review: For modifications >20% of original scope\n├── 4. Review Process Steps\n│   └── Submission → Assignment → Review → Feedback → Remediation → Approval\n├── 5. Documentation Requirements\n│   └── What must be recorded for each review\n└── 6. Exception Handling\n    └── Process when certified reviewer unavailable (escalation path)\n```\n\n### 📋 Customer Project Review Record - Key Elements\n\n```\nARCHITECTURE REVIEW RECORD\n─────────────────────────────────────────\nProject ID: PROJ-2024-0142\nCustomer: [Customer Name]\nProject Title: E-commerce Platform Migration to AWS\n\nDESIGN DOCUMENT DETAILS\n- Document Name: CustomerX_AWS_Migration_HLD_v1.2.pdf\n- Document Date: 2024-01-15\n- Design Author: John Smith (AWS SAA-C03)\n\nREVIEWER INFORMATION\n- Reviewer Name: Sarah Johnson\n- Certification: AWS Solutions Architect - Professional (SAP-C02)\n- Certification ID: AWS-SAP-12345\n- Certification Expiry: 2025-06-30\n- Review Date: 2024-01-18\n\nREVIEW SCOPE\n☑ Architecture alignment with requirements\n☑ Well-Architected Framework pillars assessment\n☑ Security controls adequacy\n☑ Cost optimization opportunities\n☑ Operational excellence considerations\n\nFINDINGS & RECOMMENDATIONS\n1. [HIGH] Missing encryption at rest for RDS - Recommend enabling KMS\n2. [MEDIUM] Single NAT Gateway creates AZ dependency - Add redundancy\n3. [LOW] Consider Reserved Instances for predictable workloads\n\nREMEDIATION STATUS\n- Finding 1: Addressed in HLD v1.3 (2024-01-20)\n- Finding 2: Addressed in HLD v1.3 (2024-01-20)\n- Finding 3: Deferred to optimization phase (customer approved)\n\nAPPROVAL\nDesign Approved: ☑ Yes\nReviewer Signature: [Digital Signature]\nApproval Date: 2024-01-22\n─────────────────────────────────────────\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Build Certification Inventory (Week 1)\n**⏱️ Time: 2-3 days | 👤 Owner: HR/Training Manager**\n\n```bash\nAction Items:\n1. Export all team members' AWS certifications from Credly\n2. Create tracking spreadsheet with:\n   - Name | Certification | Level | Cert ID | Issue Date | Expiry Date | Credly URL\n3. Identify gaps: Ensure you have at least:\n   - 2+ Solutions Architect Professional certified individuals\n   - 1+ relevant Specialty certification (Security, Database, or Networking)\n4. Set calendar reminders 60 days before any expiration\n```\n\n**🔧 Tool**: Use Credly's organization dashboard if available, or manually collect badge URLs\n\n### Step 2: Draft Tiered Review Policy (Week 1-2)\n**⏱️ Time: 3-4 days | 👤 Owner: Technical Lead + Compliance Manager**\n\n```\nCreate decision matrix:\n\nProject Characteristics → Required Reviewer Level\n─────────────────────────────────────────────────\nMonthly AWS spend <$10K, single region, non-prod → SAA (Associate)\nMonthly AWS spend $10K-$50K, production workload → SAA (Associate) + SAP review\nMonthly AWS spend >$50K OR multi-region → SAP (Professional) required\nHealthcare/Financial/Government data → SAP + Security Specialty\nMachine Learning workloads → SAP + ML Specialty\nAdvanced networking (Direct Connect, Transit Gateway) → SAP + Networking Specialty\n```\n\n### Step 3: Create Review Templates (Week 2)\n**⏱️ Time: 2 days | 👤 Owner: Solutions Architect Team**\n\nDevelop standardized templates using AWS Well-Architected Framework pillars:\n\n```\nTemplate Structure:\n├── Architecture_Review_Checklist.xlsx\n│   ├── Tab 1: Operational Excellence (15 checkpoints)\n│   ├── Tab 2: Security (20 checkpoints)\n│   ├── Tab 3: Reliability (15 checkpoints)\n│   ├── Tab 4: Performance Efficiency (12 checkpoints)\n│   ├── Tab 5: Cost Optimization (10 checkpoints)\n│   └── Tab 6: Sustainability (8 checkpoints)\n├── Review_Record_Template.docx\n└── Finding_Remediation_Tracker.xlsx\n```\n\n### Step 4: Implement Review Workflow in Project Management Tool (Week 2-3)\n**⏱️ Time: 3 days | 👤 Owner: PMO/Operations**\n\n```\nConfigure in Jira/ServiceNow/Monday.com:\n\nWorkflow States:\n[Design Submitted] → [Reviewer Assigned] → [Under Review] → \n[Findings Documented] → [Remediation Required] → [Re-review] → \n[Approved] → [Implementation Authorized]\n\nAutomation Rules:\n- Auto-assign based on project tags (e.g., \"security-sensitive\" → Security Specialty holder)\n- Block transition to \"Implementation\" without \"Approved\" status\n- Notify if review pending >3 business days\n```\n\n### Step 5: Conduct Pilot Reviews (Week 3-4)\n**⏱️ Time: 1-2 weeks | 👤 Owner: Solutions Architects**\n\n```\nSelect 2-3 recent/ongoing projects:\n1. One simple project (Associate-level review)\n2. One complex project (Professional-level review)\n3. One specialized project (Specialty certification review)\n\nExecute full review process and document:\n- Time taken for each review\n- Issues found in the process\n- Template improvements needed\n```\n\n### Step 6: Compile Audit Evidence Package (Week 4)\n**⏱️ Time: 2-3 days | 👤 Owner: Compliance Manager**\n\n```\nFinal Package Structure:\n📁 PLATP-001_Expert_Design_Review/\n├── 📄 1_Policy/\n│   ├── MSP-POL-007_Expert_Design_Review_Policy_v2.3.pdf\n│   └── Policy_Approval_Record.pdf (signed by leadership)\n├── 📄 2_Certification_Evidence/\n│   ├── Reviewer_Certification_Matrix.xlsx\n│   └── Credly_Badge_Screenshots/ (for each reviewer)\n├── 📄 3_Customer_Project_Evidence/\n│   ├── Project_A/\n│   │   ├── Original_Architecture_Design.pdf\n│   │   ├── Review_Record_Signed.pdf\n│   │   └── Remediation_Evidence.pdf\n│   └── Project_B/\n│       └── [Same structure]\n└── 📄 4_Process_Evidence/\n    ├── Workflow_Screenshot.png\n    └── Review_Templates.zip\n```\n\n### Step 7: Internal Audit Simulation (Week 5)\n**⏱️ Time: 1 day | 👤 Owner: Quality Assurance**\n\nHave someone NOT involved in preparation review the evidence package and verify:\n- Can they trace from policy → actual project review → certification validity?\n- Are all signatures and dates present?\n- Do certification dates cover the review dates?\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Certification Expired at Time of Review\n```\nFAIL SCENARIO:\n- Review conducted: March 15, 2024\n- Reviewer's SAP certification expired: February 28, 2024\n- Auditor checks Credly → IMMEDIATE FAILURE\n\nPREVENTION:\n- Maintain certification expiry dashboard\n- Require certification verification BEFORE assigning reviews\n- Include \"Certification Valid Until\" field in review record\n```\n\n### ❌ Mistake 2: Same Person Designs and Reviews\n```\nFAIL SCENARIO:\nPolicy says \"certified individual reviews all designs\"\nEvidence shows: John Smith (SAP) authored design AND reviewed it\n\nAUDITOR INTERPRETATION: No independent quality check occurred\n\nPREVENTION:\n- Policy must explicitly state \"reviewer must be different from design author\"\n- Small team? Partner with another MSP for cross-reviews\n- Document the independence requirement in workflow\n```\n\n### ❌ Mistake 3: Policy Lacks Specialty Certification Triggers\n```\nFAIL SCENARIO:\nPolicy only mentions \"Associate or Professional reviews all projects\"\nNo guidance on WHEN Specialty certifications are required\n\nAUDITOR QUESTION: \"How do you determine when Security Specialty \ncertified reviewer is needed?\"\n\nPREVENTION:\n- Create explicit decision matrix with Specialty triggers\n- Examples: PCI-DSS scope → Security Specialty\n            ML inference workloads → ML Specialty\n            Hybrid connectivity → Networking Specialty\n```\n\n### ❌ Mistake 4: Review Record Without Actionable Findings\n```\nFAIL SCENARIO:\nReview record shows: \"Architecture reviewed. Looks good. Approved.\"\n\nAUDITOR INTERPRETATION: Rubber-stamp process, not genuine review\n\nPREVENTION:\n- Require minimum documentation even for \"clean\" reviews\n- Template should include: \"Positive observations\" and \"Recommendations \n  for future consideration\" sections\n- Show at least 2-3 specific observations per pillar reviewed\n```\n\n### ❌ Mistake 5: No Evidence of Remediation\n```\nFAIL SCENARIO:\nReview record shows 3 HIGH findings\nNo evidence that findings were addressed before implementation\n\nAUDITOR QUESTION: \"Show me the updated design addressing these findings\"\n\nPREVENTION:\n- Include \"Remediation Evidence\" section in every review record\n- Reference specific document versions (v1.2 → v1.3)\n- For deferred items, require customer sign-off documentation\n```\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | Policy includes certification tier escalation matrix | Read Section 2 of policy | Clear table showing Associate/Professional/Specialty triggers with specific criteria (spend, compliance, technical complexity) |\n| 2 | Policy specifies reviewer independence requirement | Search for \"independence\" or \"different from author\" | Explicit statement that reviewer cannot be design author |\n| 3 | Customer project evidence shows different author vs. reviewer | Compare names on design document vs. review record | Two different individuals with documented certifications |\n| 4 | Reviewer certification was valid on review date | Cross-reference review date with Credly badge validity | Certification issue date < Review date < Certification expiry date |\n| 5 | Review record includes specific findings (not just \"approved\") | Read findings section | Minimum 3 specific observations with severity ratings |\n| 6 | Evidence of finding remediation exists | Check for updated design version or remediation notes | Either updated document version OR documented customer acceptance of risk |\n| 7 | Professional/Specialty review evidence exists | Verify at least one project has Pro/Specialty reviewer | At least one customer project reviewed by SAP/Specialty certified individual |\n\n### 📊 Quality Scoring (Self-Assessment)\n\n```\nScore your evidence package:\n\nPolicy Document:\n[ ] Comprehensive (covers all scenarios) = 3 points\n[ ] Adequate (covers most scenarios) = 2 points\n[ ] Basic (minimum coverage) = 1 point\n\nCustomer Evidence:\n[ ] Multiple projects with varied complexity = 3 points\n[ ] Two projects (simple + complex) = 2 points\n[ ] Single project only = 1 point\n\nCertification Traceability:\n[ ] Credly links + screenshots + matrix = 3 points\n[ ] Certification IDs + expiry dates = 2 points\n[ ] Names only without verification = 1 point\n\nMINIMUM TO PROCEED: 6 points\nRECOMMENDED: 8+ points\n```\n\n### ✅ Final Verification Questions\n\nBefore submitting, answer these questions auditors will ask:\n\n1. **\"Show me how you determine which certification level reviews a project\"**\n   → Point to: Policy Section 2 (Decision Matrix)\n\n2. **\"Prove this reviewer was certified when they conducted this review\"**\n   → Point to: Certification Matrix + Credly screenshot with dates\n\n3. **\"What happens when a review finds critical issues?\"**\n   → Point to: Policy Section 4 (Remediation Process) + Project evidence showing remediation\n\n4. **\"How do you ensure the reviewer is independent?\"**\n   → Point to: Policy Section 3 (Independence Requirement) + Different names on design vs. review\n\n5. **\"Show me a project that required Specialty certification review\"**\n   → Point to: Specific project folder with Security/ML/Networking Specialty reviewer\n\n---\n\n## 🎯 Quick Reference Card\n\n```\nPLATP-001 SUCCESS FORMULA:\n─────────────────────────────────────────\n✓ Policy with TIERED certification requirements\n✓ DIFFERENT person reviews vs. designs\n✓ Certification VALID at review time (prove it!)\n✓ SPECIFIC findings documented (not rubber-stamp)\n✓ REMEDIATION evidence for findings\n✓ At least ONE Professional/Specialty review example\n─────────────────────────────────────────\n```",
      "language": "en",
      "createdAt": "2026-01-07T02:32:52.665Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-001",
      "category": "Security",
      "title": "Security Policies and Procedures",
      "advice": "# SEC-001: Security Policies and Procedures - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\n\nSEC-001 serves as the **foundation of the entire security domain** in the AWS MSP audit. AWS views this as a \"gate\" requirement—without proper security governance, your organization cannot be trusted to manage customer AWS environments. This is mandatory because MSP Partners have privileged access to customer accounts, making your internal security posture directly relevant to customer risk.\n\n### 🔎 What Auditors Specifically Look For\n\n1. **Management Endorsement Evidence**: Auditors verify that security policies aren't just IT department documents—they need C-level or executive signatures with dates within the last 12 months\n\n2. **Scope Alignment with MSP Practice**: Your security policies must explicitly cover the AWS MSP operations, not just general corporate IT. Auditors will check if \"cloud services management\" or \"managed services delivery\" is mentioned in the scope statement\n\n3. **Policy-to-Procedure Linkage**: High-level policies must connect to operational procedures. Auditors trace from policy statements (e.g., \"access must be controlled\") to specific procedures (e.g., \"IAM user provisioning procedure\")\n\n4. **Review Cadence Documentation**: Evidence of annual (minimum) policy review cycles with documented meeting minutes or approval records\n\n5. **Coverage of AWS-Specific Risks**: Policies should address cloud-specific concerns like shared responsibility model, API key management, and multi-tenant environment security\n\n### Relevant AWS Services & Features\n- **AWS Artifact**: Download AWS compliance reports to understand AWS's security posture\n- **AWS Security Hub**: Demonstrates your operational security monitoring capability\n- **AWS Organizations SCPs**: Shows policy enforcement at scale\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Option A: Industry Certification Route (Faster Path)\n\n| Evidence Type | Specific Requirements | File Name Example |\n|--------------|----------------------|-------------------|\n| ISO 27001 Certificate | Must show MSP/cloud services in scope, valid date | `ISO27001_Certificate_2024_CloudServices.pdf` |\n| Statement of Applicability (SoA) | Controls A.9 (Access), A.12 (Operations), A.14 (Development) highlighted | `ISO27001_SoA_v3.2_MSP_Scope.xlsx` |\n| SOC 2 Type II Report | Trust Service Criteria covering Security, Availability; MSP services in scope | `SOC2_TypeII_Report_2023-2024.pdf` |\n| Scope Letter from Auditor | Explicitly stating MSP practice inclusion | `CertificationScopeLetter_MSP_2024.pdf` |\n\n**⚠️ Critical**: If your ISO 27001 or SOC 2 scope says \"Corporate IT Operations\" but doesn't mention \"Managed Services\" or \"Cloud Operations,\" auditors will reject it.\n\n### Option B: Policy Documentation Route\n\n| Document | Required Content | File Name Example |\n|----------|-----------------|-------------------|\n| Information Security Policy | Purpose, scope (must mention MSP), roles, management approval signature block | `InfoSec_Policy_v2.1_Approved_20240115.pdf` |\n| Access Control Policy | Least privilege principle, MFA requirements, privileged access management | `AccessControl_Policy_v1.8.pdf` |\n| Incident Response Policy | Detection, containment, eradication, recovery phases; AWS-specific scenarios | `IncidentResponse_Policy_v2.0.pdf` |\n| Data Classification Policy | Classification levels, handling requirements per level, AWS service mapping | `DataClassification_Policy_v1.5.pdf` |\n| Policy Review Meeting Minutes | Attendees, review items, approval decisions, action items | `SecurityPolicyReview_Minutes_20240110.pdf` |\n| Management Approval Record | Signed approval form or email chain from CISO/CTO/CEO | `PolicyApproval_CISO_Signature_20240115.pdf` |\n\n### Key Content Requirements for Each Policy\n\n**Information Security Policy Must Include:**\n```\n✓ Explicit statement: \"This policy applies to all managed services operations including AWS cloud management activities\"\n✓ Reference to AWS Shared Responsibility Model\n✓ Annual review commitment with specific month\n✓ Signature block: Name, Title, Date, Signature\n```\n\n**Access Control Policy Must Include:**\n```\n✓ MFA requirement for all AWS console and CLI access\n✓ IAM user/role lifecycle management process\n✓ Privileged access (root account, admin roles) handling\n✓ Customer environment access controls\n✓ Access review frequency (quarterly minimum)\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Conduct Policy Scope Gap Analysis (Week 1)\n**Action**: Review existing security policies for MSP-specific coverage\n\n```\n□ Search all policy documents for keywords: \"AWS,\" \"cloud,\" \"managed services,\" \"MSP\"\n□ Create gap matrix showing which policies mention MSP operations\n□ Identify policies that need scope expansion\n```\n\n**Tool**: Use document search + create spreadsheet tracker\n**Owner**: Security/Compliance Manager\n**Time**: 2-3 days\n\n### Step 2: Develop MSP-Specific Policy Addendum (Week 1-2)\n**Action**: If existing policies lack MSP scope, create addendum rather than full rewrite\n\n```\n□ Draft \"Cloud Services Security Addendum\" document\n□ Include sections: AWS account management, customer data handling, \n   cross-account access controls, API credential management\n□ Map to existing policy sections\n```\n\n**Template Structure**:\n```markdown\n# Cloud Services Security Addendum\n## 1. Scope Extension\nThis addendum extends [Policy Name] to cover AWS managed services operations...\n\n## 2. AWS-Specific Controls\n2.1 Account Security\n- Root account credentials stored in [approved password manager]\n- MFA enforced via [AWS IAM Identity Center/hardware tokens]\n...\n```\n\n**Owner**: Security Architect + MSP Operations Lead\n**Time**: 3-5 days\n\n### Step 3: Establish Policy Governance Structure (Week 2)\n**Action**: Create or document the policy review and approval workflow\n\n```\n□ Define Policy Review Committee (minimum: CISO/Security Lead, MSP Operations Director, Compliance)\n□ Set annual review calendar (specific month, not just \"annually\")\n□ Create policy approval form template with signature blocks\n□ Document escalation path for policy exceptions\n```\n\n**Evidence Output**: `Policy_Governance_Framework_v1.0.pdf`\n**Owner**: CISO or Security Manager\n**Time**: 2 days\n\n### Step 4: Execute Management Approval Cycle (Week 2-3)\n**Action**: Obtain formal management sign-off on all security policies\n\n```\n□ Schedule 1-hour policy review meeting with executives\n□ Prepare executive summary of policy changes/updates\n□ Collect physical or digital signatures (DocuSign acceptable)\n□ Record meeting minutes with attendance and decisions\n```\n\n**Critical Detail**: Signatures must include:\n- Full name and title\n- Date (within last 12 months of audit)\n- \"Approved\" statement\n\n**Owner**: CISO presenting to CTO/CEO\n**Time**: 1 week (scheduling dependent)\n\n### Step 5: Create Policy-to-Procedure Traceability Matrix (Week 3)\n**Action**: Document how policies connect to operational procedures\n\n```\n□ List each policy statement requiring operational implementation\n□ Map to specific procedure documents\n□ Identify gaps where procedures don't exist\n□ Prioritize procedure development for gaps\n```\n\n**Example Matrix**:\n| Policy Statement | Procedure Document | Status |\n|-----------------|-------------------|--------|\n| \"Access reviews conducted quarterly\" | `AccessReview_Procedure_v1.2.pdf` | ✅ Complete |\n| \"Incidents reported within 24 hours\" | `IncidentNotification_Procedure.pdf` | ✅ Complete |\n| \"API keys rotated every 90 days\" | *Gap identified* | 🔴 Need to create |\n\n**Owner**: Compliance Analyst\n**Time**: 2-3 days\n\n### Step 6: Compile Evidence Package (Week 4)\n**Action**: Organize all documents in audit-ready format\n\n```\n□ Create folder structure: /SEC-001/Policies/, /SEC-001/Approvals/, /SEC-001/Governance/\n□ Ensure all PDFs are searchable (not scanned images)\n□ Add document control information (version, date, owner)\n□ Create evidence index spreadsheet\n```\n\n**Folder Structure**:\n```\nSEC-001_Security_Policies/\n├── 01_Policies/\n│   ├── InfoSec_Policy_v2.1_Approved_20240115.pdf\n│   ├── AccessControl_Policy_v1.8.pdf\n│   └── IncidentResponse_Policy_v2.0.pdf\n├── 02_Approvals/\n│   ├── PolicyApproval_Form_Signed_20240115.pdf\n│   └── ReviewMeeting_Minutes_20240110.pdf\n├── 03_Governance/\n│   ├── Policy_Governance_Framework_v1.0.pdf\n│   └── PolicyProcedure_TraceabilityMatrix.xlsx\n└── Evidence_Index_SEC001.xlsx\n```\n\n**Owner**: Compliance/Audit Coordinator\n**Time**: 1-2 days\n\n### Step 7: Conduct Internal Pre-Audit Review (Week 4)\n**Action**: Have someone unfamiliar with the policies review evidence\n\n```\n□ Assign reviewer outside the policy creation team\n□ Use AWS MSP audit checklist for SEC-001\n□ Document findings and remediate before submission\n□ Verify all dates are current (within 12 months)\n```\n\n**Owner**: Internal Audit or QA team\n**Time**: 2 days\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Generic Corporate Policies Without MSP Scope\n**Problem**: Submitting standard corporate IT security policies that don't mention AWS, cloud services, or managed services operations.\n\n**What Happens**: Auditor asks \"Where does this policy cover your MSP practice?\" and you cannot point to specific language.\n\n**Fix**: Add explicit scope statement: *\"This policy applies to all information systems and services operated by [Company], including AWS managed services delivered to customers under the MSP program.\"*\n\n---\n\n### ❌ Mistake 2: Expired or Undated Approval Signatures\n**Problem**: Policy shows approval from 2+ years ago, or approval date is missing entirely.\n\n**What Happens**: Auditor marks as non-compliant due to lack of evidence of current management oversight.\n\n**Fix**: \n- Implement annual re-approval process (even if policy content unchanged)\n- Use format: \"Reviewed and approved by [Name], [Title], on [Date]\"\n- Set calendar reminder 30 days before anniversary\n\n---\n\n### ❌ Mistake 3: ISO 27001/SOC 2 Certificate Without Scope Verification\n**Problem**: Partner submits certification assuming it covers MSP operations, but the scope statement excludes cloud services or managed services.\n\n**What Happens**: Auditor reviews the Statement of Applicability or SOC 2 scope description and finds MSP operations are not included.\n\n**Fix**:\n- Request scope letter from your certification body explicitly stating MSP coverage\n- If scope doesn't include MSP, either expand certification scope (6+ month process) or prepare Option B documentation\n- Check SOC 2 report \"System Description\" section for service coverage\n\n---\n\n### ❌ Mistake 4: Policies Without Corresponding Procedures\n**Problem**: High-level policy states \"access must be reviewed quarterly\" but no procedure document explains how to actually do this.\n\n**What Happens**: Auditor asks for evidence of policy implementation and finds no operational guidance exists.\n\n**Fix**: Create traceability matrix (Step 5) and develop procedures for each policy requirement. Minimum procedures needed:\n- Access provisioning/deprovisioning procedure\n- Security incident handling procedure\n- Vulnerability management procedure\n\n---\n\n### ❌ Mistake 5: Missing AWS Shared Responsibility Model Reference\n**Problem**: Security policies don't acknowledge the unique security model of cloud environments.\n\n**What Happens**: Auditor questions whether the organization understands cloud security fundamentals.\n\n**Fix**: Include statement in Information Security Policy:\n*\"[Company] acknowledges and operates according to the AWS Shared Responsibility Model, where AWS is responsible for security OF the cloud, and [Company] is responsible for security IN the cloud for customer managed services.\"*\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **MSP scope explicitly stated in policies** | Search documents for \"managed services,\" \"MSP,\" \"AWS,\" \"cloud\" | At least one explicit reference in scope section of main security policy |\n| 2 | **Management approval dated within 12 months** | Check signature dates on approval forms | All approval dates after [current date - 12 months] |\n| 3 | **Approval includes appropriate authority level** | Verify signer titles | CISO, CTO, CEO, VP of Security, or equivalent executive |\n| 4 | **Policy review meeting documented** | Review meeting minutes | Minutes show attendees, date, agenda items, decisions made |\n| 5 | **All core policy areas covered** | Cross-reference against checklist | ✅ Information Security, ✅ Access Control, ✅ Incident Response, ✅ Data Classification |\n| 6 | **Certification scope includes MSP (if using Option A)** | Read certificate scope statement and SoA/SOC2 system description | Explicit mention of \"managed services,\" \"cloud operations,\" or \"MSP\" in scope |\n| 7 | **Documents are version-controlled** | Check for version numbers, dates, document owners | Each document shows: Version #, Effective Date, Document Owner, Next Review Date |\n\n### 📊 Quality Criteria Summary\n\n**Minimum Pass Requirements:**\n- [ ] At least one policy explicitly scoped to MSP operations\n- [ ] Executive approval within last 12 months\n- [ ] Evidence of annual review process\n- [ ] Coverage of access control, incident response, and data protection\n\n**Strong Pass Indicators:**\n- [ ] ISO 27001 or SOC 2 Type II with MSP in scope\n- [ ] Traceability matrix linking policies to procedures\n- [ ] AWS-specific controls documented (IAM, encryption, logging)\n- [ ] Policy governance framework with defined review committee\n\n---\n\n## 💡 Pro Tips from Audit Experience\n\n1. **If you have ISO 27001/SOC 2**: Lead with the certificate but also prepare a 1-page summary showing how your MSP operations map to the certification scope. Auditors appreciate this clarity.\n\n2. **Quick Win**: If policies exist but lack MSP scope, create a \"Cloud Services Security Addendum\" (2-3 pages) rather than rewriting entire policies. This is faster and equally acceptable.\n\n3. **Evidence Naming Convention**: Use format `[PolicyType]_[Version]_[ApprovalStatus]_[Date].pdf` for instant auditor comprehension.\n\n4. **Red Flag Phrases to Remove**: Avoid \"TBD,\" \"draft,\" \"pending approval,\" or future-tense language (\"will be implemented\") in submitted evidence.",
      "language": "en",
      "createdAt": "2026-01-07T03:01:29.283Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-002",
      "category": "Security",
      "title": "Security Awareness Training and testing",
      "advice": "# SEC-002: Security Awareness Training and Testing - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item Matters in AWS MSP Program\nSecurity awareness training is the **first line of defense** for MSP partners who manage customer AWS environments. AWS requires this because MSP employees have privileged access to customer accounts, and a single phishing incident or social engineering attack could compromise multiple customer environments simultaneously. This isn't just a checkbox—it's AWS's way of ensuring partners understand their responsibility in the shared security model.\n\n### 🔍 Key Points Auditors Specifically Look For\n\n1. **100% Coverage Verification**: Auditors will cross-reference your training completion list against your HR employee roster. They specifically check if *all* MSP practice employees (including contractors, part-timers, and recent hires) completed training—not just technical staff.\n\n2. **Training Recency**: Completion dates must fall within the **12 months preceding the audit date**. Training from 13 months ago will be flagged as non-compliant.\n\n3. **Content Relevance to Cloud/AWS**: Generic \"don't click phishing links\" training may be questioned. Auditors prefer seeing cloud-specific security topics (credential management, API key protection, MFA awareness).\n\n4. **Testing/Assessment Component**: The word \"testing\" in the requirement title is intentional. Auditors look for evidence that employees were *assessed*, not just that they watched videos.\n\n5. **New Hire Onboarding Timeline**: Auditors often ask about your policy for new employees—they expect training completion within 30-60 days of hire date.\n\n### Relevant AWS Resources\n- **Amazon Security Awareness Training**: https://learnsecurity.amazon.com/ (AWS's recommended free option)\n- **AWS Skill Builder**: Security-focused learning paths\n- **AWS Well-Architected Security Pillar**: Reference material for training content validation\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Key Contents |\n|--------------|--------|--------------|\n| **Training Completion Report** | PDF/Excel export | Employee name, email, completion date, score (if applicable) |\n| **MSP Employee Roster** | Excel/CSV | All MSP practice employees as of audit date |\n| **Training Program Description** | PDF/Word | Course syllabus, topics covered, assessment methodology |\n| **Training Policy Document** | PDF | Annual requirement, new hire timeline, non-compliance consequences |\n\n### 📄 Specific Evidence Examples\n\n**File Name Examples:**\n- `SEC-002_SecurityAwarenessTraining_CompletionReport_2024.pdf`\n- `SEC-002_MSP_EmployeeRoster_AsOf_20241115.xlsx`\n- `SEC-002_AmazonSecurityAwareness_CourseSyllabus.pdf`\n- `SEC-002_SecurityTrainingPolicy_v2.1.pdf`\n\n### Key Content Requirements for Each Evidence\n\n**Training Completion Report Must Include:**\n```\n✓ Full legal name (matching HR records)\n✓ Corporate email address\n✓ Training program name (e.g., \"Amazon Security Awareness\")\n✓ Completion date (MM/DD/YYYY format)\n✓ Pass/Fail status or score percentage\n✓ Certificate ID or unique completion identifier\n```\n\n**Employee Roster Must Include:**\n```\n✓ Employee ID\n✓ Full name\n✓ Department/Team (clearly identifying MSP practice)\n✓ Hire date\n✓ Employment status (FTE/Contractor/Part-time)\n✓ Role title\n```\n\n**Training Program Description Should Cover:**\n```\n✓ Phishing and social engineering recognition\n✓ Password/credential management\n✓ MFA importance and usage\n✓ Data classification and handling\n✓ Incident reporting procedures\n✓ Cloud-specific security (API keys, access keys, IAM)\n✓ Physical security awareness\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Define Your MSP Practice Employee Scope (Week 1)\n**Action**: Work with HR to create a definitive list of who constitutes \"MSP Practice employees\"\n\n```\nInclude:\n- Cloud engineers/architects working on customer AWS accounts\n- DevOps/SRE team members\n- Support/helpdesk staff with AWS console access\n- Project managers on MSP engagements\n- Sales engineers with demo account access\n- Contractors and consultants (if >30 days engagement)\n\nExclude:\n- Pure sales staff without technical access\n- Corporate functions (HR, Finance) not touching AWS\n- Employees in non-MSP business units\n```\n\n**Tool**: Export from HRIS (Workday, BambooHR, etc.)\n**Time**: 2-3 hours\n**Owner**: HR Business Partner + MSP Practice Lead\n\n---\n\n### Step 2: Select and Validate Training Program (Week 1-2)\n**Action**: Choose between Amazon Security Awareness or equivalent\n\n**If using Amazon Security Awareness (https://learnsecurity.amazon.com/):**\n- Register your organization\n- Verify all required topics are covered in current curriculum\n- Confirm assessment/quiz component exists\n- Test the completion certificate export functionality\n\n**If using alternative (KnowBe4, Proofpoint, SANS, etc.):**\n- Document topic coverage mapping to AWS expectations\n- Ensure cloud/AWS-specific modules are included\n- Verify reporting capabilities for completion tracking\n\n**Time**: 4-6 hours\n**Owner**: Security Team Lead\n\n---\n\n### Step 3: Establish Training Policy and Timeline (Week 2)\n**Action**: Create or update formal security training policy\n\n**Policy Must Define:**\n```yaml\nAnnual Requirement:\n  - All MSP employees complete training by December 31 each year\n  - Training valid for 12 months from completion date\n\nNew Hire Requirement:\n  - Complete within 30 days of start date\n  - No AWS console access until training completed\n\nNon-Compliance:\n  - Automated reminders at 7, 3, 1 days before deadline\n  - Manager escalation for overdue employees\n  - Access suspension for 14+ days overdue\n\nTracking:\n  - Security team maintains completion records\n  - Quarterly compliance reports to leadership\n```\n\n**Time**: 3-4 hours\n**Owner**: CISO/Security Manager\n\n---\n\n### Step 4: Execute Training Campaign (Week 3-6)\n**Action**: Roll out training to all MSP employees\n\n**Execution Checklist:**\n```\n□ Send announcement email explaining requirement and deadline\n□ Provide direct enrollment links\n□ Set calendar reminders for employees\n□ Configure LMS automated reminder emails\n□ Establish Slack/Teams channel for questions\n□ Track daily/weekly completion progress\n□ Escalate non-completers to managers at 50% timeline\n```\n\n**Pro Tip**: Schedule training during a slower business period. Avoid month-end, quarter-end, or major project deadlines.\n\n**Time**: 4-6 weeks for full completion\n**Owner**: Training Coordinator + Department Managers\n\n---\n\n### Step 5: Generate Completion Evidence (Week 7)\n**Action**: Export and format completion records\n\n**From Amazon Security Awareness:**\n1. Log into admin console\n2. Navigate to Reports > Completion Reports\n3. Export as CSV/PDF\n4. Include: Name, Email, Completion Date, Score\n\n**From other LMS platforms:**\n- Generate similar completion report\n- Ensure date format is consistent\n- Include pass/fail or score data\n\n**Time**: 1-2 hours\n**Owner**: Training Administrator\n\n---\n\n### Step 6: Cross-Reference and Gap Analysis (Week 7)\n**Action**: Match training completions against employee roster\n\n**Create Reconciliation Spreadsheet:**\n```\nColumn A: Employee Name (from HR)\nColumn B: Training Completion Date\nColumn C: Status (Complete/Incomplete/N/A)\nColumn D: Notes (e.g., \"On leave - due date extended\")\n```\n\n**Handle Edge Cases:**\n- Employees on extended leave: Document approved extension\n- Recent hires (<30 days): Note \"within onboarding window\"\n- Terminated employees: Remove from scope with termination date\n\n**Time**: 2-3 hours\n**Owner**: Security Team + HR\n\n---\n\n### Step 7: Package Evidence for Submission (Week 8)\n**Action**: Compile final evidence package\n\n**Folder Structure:**\n```\nSEC-002_SecurityAwarenessTraining/\n├── 01_CompletionReport_2024.pdf\n├── 02_EmployeeRoster_20241115.xlsx\n├── 03_Reconciliation_Matrix.xlsx\n├── 04_TrainingPolicy_v2.1.pdf\n├── 05_CourseSyllabus_AmazonSecurityAwareness.pdf\n└── 06_SampleCertificates/ (3-5 examples)\n```\n\n**Time**: 2 hours\n**Owner**: MSP Program Manager\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Incomplete Employee Coverage\n**What Goes Wrong**: Submitting training records for 45 employees when HR roster shows 52 MSP practice employees.\n\n**Why It Fails**: Auditors *will* count heads. Even one missing employee triggers a finding.\n\n**Solution**: \n- Get HR sign-off on final roster before audit\n- Include written explanation for any discrepancies (terminations, new hires in onboarding window)\n\n---\n\n### ❌ Mistake 2: Expired Training Records\n**What Goes Wrong**: Submitting training completed in January 2023 for an October 2024 audit.\n\n**Why It Fails**: Training must be within 12 months. Auditors check dates carefully.\n\n**Solution**:\n- Implement rolling annual renewal (each employee's anniversary)\n- OR company-wide annual refresh (everyone completes by specific date each year)\n- Run compliance report 60 days before audit to catch expirations\n\n---\n\n### ❌ Mistake 3: No Assessment/Testing Component\n**What Goes Wrong**: Using a training program that's video-only with no quiz or assessment.\n\n**Why It Fails**: The requirement explicitly says \"Training and **testing**\"—passive viewing isn't sufficient.\n\n**Solution**:\n- Verify your training includes knowledge checks or final assessment\n- Minimum: 70% passing score requirement\n- Document assessment methodology in training description\n\n---\n\n### ❌ Mistake 4: Generic Training Without Cloud Security Topics\n**What Goes Wrong**: Using basic corporate security training that covers only phishing and password hygiene.\n\n**Why It Fails**: Auditors expect MSP employees to understand cloud-specific security risks.\n\n**Solution**:\n- Ensure training covers: API key management, IAM best practices, shared responsibility model\n- If using generic training, supplement with AWS-specific module\n- Amazon Security Awareness includes cloud topics—document this coverage\n\n---\n\n### ❌ Mistake 5: Missing New Hire Documentation\n**What Goes Wrong**: An employee hired 45 days ago hasn't completed training, with no policy explaining the grace period.\n\n**Why It Fails**: Without documented policy, auditors assume non-compliance.\n\n**Solution**:\n- Document 30-day new hire completion requirement in policy\n- For employees within window, include hire date and expected completion date\n- Show automated tracking/reminder system for new hires\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Employee count matches** | Compare training report rows to HR roster rows | 100% match (with documented exceptions) |\n| 2 | **All completion dates within 12 months** | Sort by date, check oldest entry | No completion date >12 months from audit date |\n| 3 | **Training includes assessment** | Review course syllabus or platform settings | Quiz/test component documented with passing threshold |\n| 4 | **Cloud security topics covered** | Map syllabus to required topics | Minimum 3 cloud-specific topics included |\n| 5 | **New hires accounted for** | Filter roster by hire date <60 days | Either completed OR within documented grace period |\n| 6 | **Policy document current** | Check policy version date and review cycle | Policy dated within 12 months, signed by CISO/executive |\n| 7 | **Evidence files properly named** | Review file naming convention | Clear, consistent naming with SEC-002 prefix |\n\n### 🎯 Quality Criteria for Passing\n\n```\n✓ 100% of MSP practice employees completed training (or documented exception)\n✓ Training completion dates all within 12-month window\n✓ Assessment scores recorded (if applicable) with passing threshold met\n✓ Training content demonstrably covers security awareness fundamentals + cloud topics\n✓ Formal policy exists requiring annual completion\n✓ Evidence package is complete, organized, and cross-referenced\n```\n\n### Final Sanity Check Questions\n1. \"If an auditor randomly picks 5 names from our HR roster, can I show completion records for all 5?\"\n2. \"Can I explain our new hire training process if asked?\"\n3. \"If asked 'what cloud security topics does your training cover?', can I answer specifically?\"\n4. \"Is there anyone who might have AWS access who isn't on this training list?\"\n\n---\n\n## 💡 Pro Tips from Audit Experience\n\n**Timing Tip**: Schedule your annual training refresh to complete 2-3 months *before* your expected audit window. This gives buffer for stragglers and avoids last-minute scrambles.\n\n**Documentation Tip**: Include 3-5 sample completion certificates in your evidence package. This shows auditors what the actual training output looks like without them having to request it.\n\n**Automation Tip**: If using AWS Organizations, consider tagging IAM users with training completion status. This creates a technical control linking training to access—auditors love seeing this integration.",
      "language": "en",
      "createdAt": "2026-01-07T03:02:32.833Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-003_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-003",
      "category": "Security",
      "title": "AWS Account Configuration",
      "advice": "# SEC-003: AWS Account Configuration - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nSEC-003 is the **cornerstone of MSP security capability verification**. AWS wants to confirm that partners can consistently apply security baselines across all managed customer accounts, not just individual account management. This requirement directly validates whether you can implement \"Security at Scale\" - a core MSP competency.\n\n### 🎯 5 Key Points Auditors Focus On\n\n1. **Appendix A Full Coverage Verification**\n   - Auditors check item-by-item against the Appendix A checklist (approximately 15-20 security controls)\n   - Partial implementation is NOT acceptable - 100% coverage required\n\n2. **Organization-wide Visibility**\n   - Must demonstrate centralized security posture view across ALL accounts in at least one AWS Organization\n   - Individual account screenshots are insufficient - need aggregated dashboard view\n\n3. **High/Critical Finding Response Documentation**\n   - Zero tolerance for unexplained high/critical findings\n   - Each finding needs either: remediation evidence OR documented exception with timeline\n\n4. **Automation Evidence**\n   - Manual configuration screenshots are weak evidence\n   - Preference for AWS Config Rules, Security Hub standards, or IaC-based enforcement\n\n5. **Continuous Monitoring Proof**\n   - Point-in-time compliance is insufficient\n   - Need to show ongoing monitoring and drift detection capability\n\n### 🔧 Relevant AWS Services\n- **AWS Security Hub** (Primary - aggregates findings across Organization)\n- **AWS Config** (Configuration compliance rules)\n- **AWS Organizations** (Multi-account management)\n- **AWS Control Tower** (Guardrails and landing zone)\n- **AWS CloudTrail** (API activity logging)\n- **Amazon GuardDuty** (Threat detection)\n- **AWS IAM Access Analyzer** (Permission analysis)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|---------------------------|\n| Security Hub Dashboard Export | PDF + CSV | Organization-wide security score, findings by severity |\n| Appendix A Mapping Document | Excel/PDF | Each Appendix A item → AWS control → compliance status |\n| High/Critical Findings Report | PDF | Finding details + mitigation plan + owner + timeline |\n| Config Rules Compliance Report | PDF | All managed accounts showing rule compliance % |\n| Security Standards Document | PDF/Word | Your defined security baseline with Appendix A mapping |\n\n### 📄 Evidence Examples with File Names\n\n**1. Security Hub Organization Dashboard**\n```\nFilename: SEC-003_SecurityHub_OrgDashboard_[OrgID]_[Date].pdf\n```\nMust include:\n- Security Hub home page showing aggregated score\n- Findings by severity breakdown (Critical/High/Medium/Low)\n- Account coverage showing all member accounts\n- Standards enabled (AWS Foundational Security Best Practices, CIS)\n\n**2. Appendix A Compliance Matrix**\n```\nFilename: SEC-003_AppendixA_ComplianceMatrix_v[X.X].xlsx\n```\nStructure:\n| Appendix A Item | AWS Service/Control | Implementation Method | Evidence Location | Status |\n|-----------------|--------------------|-----------------------|-------------------|--------|\n| Root account MFA | IAM | Hardware MFA | Security Hub IAM.6 | ✅ |\n| CloudTrail enabled | CloudTrail | Org Trail | Config Rule | ✅ |\n| S3 public access blocked | S3 | Account-level block | Security Hub S3.1 | ✅ |\n\n**3. High/Critical Findings Mitigation Document**\n```\nFilename: SEC-003_HighCritical_Findings_Mitigation_[Date].pdf\n```\nFor each finding:\n- Finding ID and title\n- Affected account(s)\n- Root cause analysis\n- Remediation action taken OR exception justification\n- Timeline (if not yet remediated)\n- Owner name and role\n\n**4. Security Baseline Standard Document**\n```\nFilename: SEC-003_MSP_Security_Baseline_Standard_v[X.X].pdf\n```\nContents:\n- Scope and applicability\n- Each security control with implementation details\n- Exception process\n- Review and update schedule\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Enable Security Hub with Organization Integration (Day 1-2)\n**Responsible:** Cloud Security Engineer  \n**Time:** 4-8 hours\n\n```bash\n# In Management Account\naws securityhub enable-organization-admin-account \\\n    --admin-account-id <delegated-admin-account-id>\n\n# In Delegated Admin Account\naws securityhub update-organization-configuration \\\n    --auto-enable \\\n    --auto-enable-standards\n```\n\nEnable these standards:\n- ✅ AWS Foundational Security Best Practices v1.0.0\n- ✅ CIS AWS Foundations Benchmark v1.4.0\n\n### Step 2: Create Appendix A to AWS Control Mapping (Day 2-3)\n**Responsible:** Security Architect  \n**Time:** 6-8 hours\n\nDownload Appendix A from AWS Partner Central and map each item:\n\n| Appendix A Requirement | Security Hub Control ID | Config Rule |\n|------------------------|------------------------|-------------|\n| MFA on root account | IAM.6 | root-account-mfa-enabled |\n| No root access keys | IAM.4 | iam-root-access-key-check |\n| CloudTrail enabled all regions | CloudTrail.1 | cloudtrail-enabled |\n| S3 bucket logging | S3.9 | s3-bucket-logging-enabled |\n| EBS encryption default | EC2.7 | ec2-ebs-encryption-by-default |\n| RDS encryption | RDS.3 | rds-storage-encrypted |\n| VPC Flow Logs | EC2.6 | vpc-flow-logs-enabled |\n\n### Step 3: Deploy Config Conformance Packs (Day 3-4)\n**Responsible:** DevOps Engineer  \n**Time:** 4-6 hours\n\n```yaml\n# conformance-pack-msp-baseline.yaml\nResources:\n  RootAccountMFAEnabled:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      ConfigRuleName: root-account-mfa-enabled\n      Source:\n        Owner: AWS\n        SourceIdentifier: ROOT_ACCOUNT_MFA_ENABLED\n        \n  IAMRootAccessKeyCheck:\n    Type: AWS::Config::ConfigRule\n    Properties:\n      ConfigRuleName: iam-root-access-key-check\n      Source:\n        Owner: AWS\n        SourceIdentifier: IAM_ROOT_ACCESS_KEY_CHECK\n```\n\nDeploy across Organization:\n```bash\naws configservice put-organization-conformance-pack \\\n    --organization-conformance-pack-name MSP-Security-Baseline \\\n    --template-body file://conformance-pack-msp-baseline.yaml\n```\n\n### Step 4: Remediate High/Critical Findings (Day 4-7)\n**Responsible:** Security Operations Team  \n**Time:** 8-16 hours (varies by finding count)\n\nPriority remediation order:\n1. **Critical** - Root account issues (MFA, access keys)\n2. **Critical** - Public S3 buckets, open security groups\n3. **High** - Unencrypted storage (EBS, RDS, S3)\n4. **High** - Missing logging (CloudTrail, VPC Flow Logs)\n\nFor each unremediated finding, document:\n```markdown\n## Finding: [Security Hub Finding ID]\n**Severity:** High\n**Account:** 123456789012\n**Resource:** arn:aws:s3:::legacy-data-bucket\n\n### Root Cause\nLegacy application requires public read access for CDN origin.\n\n### Mitigation Plan\n- Migrate to CloudFront with OAI by Q2 2024\n- Interim: Bucket policy restricts to known IP ranges\n- Weekly access log review implemented\n\n### Owner: John Smith, Security Lead\n### Target Remediation Date: 2024-06-30\n```\n\n### Step 5: Generate Dashboard Evidence (Day 7-8)\n**Responsible:** Security Analyst  \n**Time:** 2-4 hours\n\n**Security Hub Screenshots Required:**\n1. Summary page showing organization security score\n2. Findings page filtered by CRITICAL severity\n3. Findings page filtered by HIGH severity\n4. Standards page showing enabled standards and compliance %\n5. Accounts page showing all integrated accounts\n\n**Export Process:**\n```bash\n# Export findings to S3 for CSV evidence\naws securityhub get-findings \\\n    --filters '{\"SeverityLabel\":[{\"Value\":\"CRITICAL\",\"Comparison\":\"EQUALS\"}]}' \\\n    --max-items 100 > critical_findings.json\n```\n\n### Step 6: Create Final Evidence Package (Day 8-9)\n**Responsible:** MSP Program Manager  \n**Time:** 4-6 hours\n\nCompile into single PDF with sections:\n1. Executive Summary (1 page)\n2. Security Hub Dashboard Screenshots (5-10 pages)\n3. Appendix A Compliance Matrix (2-3 pages)\n4. High/Critical Findings with Mitigation (variable)\n5. Security Baseline Standard Document (10-15 pages)\n\n### Step 7: Internal Review and Gap Closure (Day 9-10)\n**Responsible:** Security Lead + MSP Program Manager  \n**Time:** 4 hours\n\nRun final validation checklist (see Section 5).\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Showing Only One Account's Dashboard\n**Problem:** Submitting Security Hub screenshots from a single account instead of Organization-aggregated view.\n\n**Why It Fails:** Auditors specifically look for \"across all AWS accounts in at least one AWS Organization\" - single account evidence proves nothing about multi-account management capability.\n\n**Solution:** Enable Security Hub delegated administrator and ensure all member accounts are integrated. Dashboard must show account selector with multiple accounts visible.\n\n### ❌ Mistake 2: Unexplained High/Critical Findings in Screenshots\n**Problem:** Dashboard shows 15 Critical findings but evidence package only addresses 3.\n\n**Why It Fails:** Auditors will flag EVERY visible high/critical finding. If your screenshot shows findings, you must document ALL of them.\n\n**Solution:** Either:\n- Remediate all findings before taking screenshots\n- Document every single finding with mitigation plan\n- Use Security Hub filters to show \"RESOLVED\" status for remediated items\n\n### ❌ Mistake 3: Missing Appendix A Items\n**Problem:** Security baseline covers 12 of 18 Appendix A requirements.\n\n**Why It Fails:** Appendix A is a **minimum** requirement - partial coverage is automatic failure.\n\n**Common Missing Items:**\n- AWS account alternate contacts configured\n- S3 Block Public Access at account level\n- EBS default encryption enabled\n- IMDSv2 required for EC2\n\n**Solution:** Create explicit mapping document and verify each Appendix A item has corresponding control.\n\n### ❌ Mistake 4: Point-in-Time Screenshots Without Timestamps\n**Problem:** Screenshots don't show dates, or dates are months old.\n\n**Why It Fails:** Auditors need evidence of current state, not historical compliance.\n\n**Solution:** \n- Include browser URL bar showing date/time\n- Take screenshots within 2 weeks of submission\n- Add timestamp watermark to evidence documents\n\n### ❌ Mistake 5: Generic Security Policy Without AWS Specifics\n**Problem:** Security baseline document is generic IT security policy without AWS service-specific controls.\n\n**Why It Fails:** Auditors want to see AWS-native controls (Security Hub, Config Rules, GuardDuty) not generic statements like \"encryption shall be used.\"\n\n**Solution:** Each policy item must reference:\n- Specific AWS service\n- Implementation method (Console/CLI/IaC)\n- Monitoring mechanism (Config Rule ID, Security Hub control)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| 1 | Security Hub shows Organization-wide view | Screenshot shows multiple accounts in account selector | ≥2 accounts visible, ideally all managed accounts |\n| 2 | All Appendix A items mapped | Cross-reference Appendix A document with compliance matrix | 100% coverage - no gaps |\n| 3 | AWS Foundational Security Best Practices enabled | Security Hub → Standards page | Standard shows \"Enabled\" with compliance score |\n| 4 | CIS Benchmark enabled | Security Hub → Standards page | Standard shows \"Enabled\" with compliance score |\n| 5 | Zero unexplained Critical findings | Count Critical findings in dashboard vs. documented | Every Critical finding has mitigation document |\n| 6 | Zero unexplained High findings | Count High findings in dashboard vs. documented | Every High finding has mitigation document |\n| 7 | Evidence timestamps current | Check dates on all screenshots | Within 30 days of submission (preferably 14 days) |\n| 8 | Config Rules deployed org-wide | AWS Config → Conformance Packs | Conformance pack shows deployed to all accounts |\n| 9 | Security baseline document complete | Review against Appendix A | All 18+ items documented with AWS implementation |\n| 10 | Mitigation timelines reasonable | Review remediation dates | No timeline >90 days without executive justification |\n\n### 📊 Quality Scoring Guide\n\n**Ready to Submit (Score 9-10):**\n- ✅ Zero Critical findings OR all documented with <30 day remediation\n- ✅ <5 High findings, all documented\n- ✅ 100% Appendix A coverage\n- ✅ Organization-wide Security Hub enabled\n- ✅ Automated compliance monitoring in place\n\n**Needs Work (Score 6-8):**\n- ⚠️ Some High findings without documentation\n- ⚠️ Missing 1-2 Appendix A items\n- ⚠️ Security Hub enabled but not all accounts integrated\n\n**Not Ready (Score <6):**\n- ❌ Critical findings without mitigation plans\n- ❌ Missing >3 Appendix A items\n- ❌ Single account evidence only\n- ❌ No automated compliance monitoring\n\n---\n\n## 💡 Pro Tips from Passed Audits\n\n1. **Use Security Hub Insights** to create custom views that exactly match Appendix A requirements - auditors appreciate organized evidence\n\n2. **Enable AWS Config Aggregator** in addition to Security Hub for redundant compliance evidence\n\n3. **Document your exception process** - auditors accept that not all findings can be immediately remediated, but want to see governance around exceptions\n\n4. **Include architecture diagram** showing how Security Hub, Config, and Organizations work together in your MSP setup\n\n5. **Show trend data** if available - Security Hub security score improvement over time demonstrates operational maturity",
      "language": "en",
      "createdAt": "2026-01-07T03:03:35.489Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-004_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-004",
      "category": "Security",
      "title": "Identity and Access Management",
      "advice": "# SEC-004: Identity and Access Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nIdentity and Access Management (IAM) is the **foundational security control** for MSP operations. AWS requires MSPs to demonstrate that they can securely manage access across potentially hundreds of customer AWS accounts without creating security vulnerabilities. This isn't just about having an IdP—it's about proving you have **zero standing access** to customer environments and can trace every authentication event.\n\n### 🔎 Key Points Auditors Specifically Look For\n\n1. **Single Sign-On (SSO) Federation to ALL Customer Accounts**\n   - Auditors will ask: \"Show me how an engineer accesses Customer X's production account right now\"\n   - They verify there are NO local IAM users in customer accounts (except break-glass)\n   - They check that your IdP is the ONLY authentication path\n\n2. **Centralized Identity Provider Integration**\n   - Must be enterprise-grade IdP (Okta, Azure AD, Ping Identity, AWS IAM Identity Center)\n   - NOT acceptable: Separate credentials per customer, shared accounts, or local IAM users\n\n3. **Just-In-Time (JIT) Access Provisioning**\n   - Engineers should NOT have permanent access to customer accounts\n   - Access should be requested, approved, and time-limited\n\n4. **MFA Enforcement at IdP Level**\n   - Hardware tokens or phishing-resistant MFA (FIDO2) preferred\n   - SMS-based MFA may receive scrutiny\n\n5. **Access to Non-AWS Systems Containing Customer Data**\n   - Ticketing systems (ServiceNow, Jira)\n   - Monitoring platforms (Datadog, Splunk)\n   - Documentation systems with customer architecture\n\n### Relevant AWS Services\n- **AWS IAM Identity Center** (formerly AWS SSO) - Primary recommendation\n- **AWS Organizations** - Multi-account management\n- **AWS CloudTrail** - Authentication logging\n- **AWS Control Tower** - Guardrails for identity\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence List\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|---------------------------|\n| Live Demo Recording | MP4/WebM (10-15 min) | End-to-end authentication flow |\n| IdP Configuration Screenshots | PDF with annotations | SAML/OIDC trust relationships |\n| Permission Set Documentation | Excel/PDF | Role mappings per customer |\n| Access Request Workflow | Screen recording + SOP | Approval chain demonstration |\n| MFA Policy Configuration | Screenshots | Enforcement settings in IdP |\n\n### 📁 Specific Evidence Examples\n\n**Evidence 1: Live Authentication Demo (MANDATORY)**\n```\nFilename: SEC-004_Authentication_Demo_[Date].mp4\nDuration: 10-15 minutes\n```\nMust include:\n- Engineer opening browser with no cached sessions\n- Navigating to IdP login portal (show URL)\n- Entering credentials + MFA challenge\n- Selecting customer account from account picker\n- Landing in AWS Console with federated role\n- Showing CloudTrail event for the login\n- Demonstrating session timeout/logout\n\n**Evidence 2: IdP Trust Configuration**\n```\nFilename: SEC-004_IdP_SAML_Trust_Configuration.pdf\n```\nMust show:\n- SAML metadata exchange between IdP and AWS\n- Attribute mappings (groups → AWS roles)\n- Session duration settings (max 12 hours recommended)\n- List of all integrated applications (AWS + other systems)\n\n**Evidence 3: Permission Set Inventory**\n```\nFilename: SEC-004_Permission_Sets_Matrix.xlsx\n```\nColumns required:\n- Permission Set Name\n- AWS Managed Policies attached\n- Custom Policy ARNs\n- Customer accounts assigned\n- User groups with access\n- Maximum session duration\n\n**Evidence 4: Non-AWS Systems Access Proof**\n```\nFilename: SEC-004_Integrated_Systems_SSO.pdf\n```\nMust document:\n- ServiceNow/Jira SSO configuration\n- Monitoring tool (Datadog/Splunk) SAML setup\n- Any system containing customer IP addresses, credentials, or architecture\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current Identity Architecture (Week 1)\n**Action:** Map every path an engineer can use to access customer accounts\n\n```bash\n# Run this in each customer account to find local IAM users\naws iam list-users --query 'Users[?PasswordLastUsed!=`null`].[UserName,PasswordLastUsed]' --output table\n\n# Check for access keys that bypass SSO\naws iam list-access-keys --user-name [each-user]\n```\n\n**Tool:** AWS IAM Access Analyzer, AWS Config rule `iam-user-no-policies-check`\n**Owner:** Security Engineer\n**Time:** 3-5 days\n\n### Step 2: Implement/Validate AWS IAM Identity Center (Week 2)\n**Action:** Configure centralized identity with your IdP\n\nFor **Okta** integration:\n1. In Okta Admin → Applications → Add Application → AWS IAM Identity Center\n2. Download SAML metadata\n3. In AWS IAM Identity Center → Settings → Identity Source → External IdP\n4. Upload Okta metadata, configure attribute mappings:\n   ```\n   Subject: ${user.email}\n   https://aws.amazon.com/SAML/Attributes/SessionDuration: 43200\n   ```\n\n**Tool:** AWS IAM Identity Center, Okta/Azure AD\n**Owner:** Identity Administrator\n**Time:** 2-3 days\n\n### Step 3: Create Permission Sets with Least Privilege (Week 2-3)\n**Action:** Design role-based permission sets\n\nExample Permission Sets for MSP:\n```\nMSP-ReadOnly          → ViewOnlyAccess (AWS Managed)\nMSP-L1-Support        → Custom: CloudWatch, Support, EC2:Describe*\nMSP-L2-Operations     → Custom: Above + EC2, RDS stop/start\nMSP-L3-Admin          → PowerUserAccess (time-limited, approval required)\nMSP-Security-Audit    → SecurityAudit + custom Config/GuardDuty\nMSP-BreakGlass        → AdministratorAccess (emergency only, alerts triggered)\n```\n\n**Tool:** AWS IAM Identity Center Permission Sets\n**Owner:** Security Architect\n**Time:** 5-7 days\n\n### Step 4: Implement Access Request Workflow (Week 3)\n**Action:** Set up JIT access provisioning\n\n**Option A - ServiceNow Integration:**\n- Create catalog item \"AWS Elevated Access Request\"\n- Workflow: Request → Manager Approval → Security Approval → Auto-provision via API\n- Auto-revoke after 4/8/12 hours\n\n**Option B - AWS IAM Identity Center + Slack:**\n- Use AWS Chatbot for approval workflows\n- Integrate with Lambda for provisioning\n\n**Owner:** IT Operations + Security\n**Time:** 5-7 days\n\n### Step 5: Enforce MFA Across All Paths (Week 3)\n**Action:** Verify MFA is mandatory, not optional\n\nIn Okta:\n```\nSecurity → Authentication → Sign-on Policies\nRule: AWS Access → MFA Required → Every sign-in\nFactor: Okta Verify (Push) or FIDO2 WebAuthn\n```\n\nVerify in AWS:\n```bash\n# Check IAM Identity Center MFA settings\naws sso-admin describe-instance-access-control-attribute-configuration \\\n  --instance-arn arn:aws:sso:::instance/ssoins-xxxxx\n```\n\n**Owner:** Security Engineer\n**Time:** 1-2 days\n\n### Step 6: Integrate Non-AWS Systems (Week 4)\n**Action:** Connect all customer-data-containing systems to IdP\n\nPriority systems:\n1. **Ticketing:** ServiceNow, Jira Service Management\n2. **Monitoring:** Datadog, Splunk, CloudWatch cross-account\n3. **Documentation:** Confluence, SharePoint\n4. **Communication:** Slack (if customer channels exist)\n\n**Owner:** IT Operations\n**Time:** 3-5 days\n\n### Step 7: Record Demo and Collect Evidence (Week 4)\n**Action:** Create audit-ready demonstration\n\n**Demo Script:**\n```\n00:00 - Show IdP login page (Okta/Azure AD)\n01:00 - Enter credentials, complete MFA\n02:00 - Show AWS account picker with customer accounts\n03:00 - Select customer account, show role assumption\n04:00 - In AWS Console, show whoami (top right corner)\n05:00 - Navigate to CloudTrail → Event History\n06:00 - Filter by username, show login event\n07:00 - Show session expiration settings\n08:00 - Demonstrate access request workflow (if JIT)\n10:00 - Show non-AWS system login (Jira/Datadog)\n12:00 - Demonstrate logout and session termination\n```\n\n**Tool:** OBS Studio, Loom\n**Owner:** Security Engineer + Audit Lead\n**Time:** 2-3 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Local IAM Users Still Exist in Customer Accounts\n**Problem:** Auditors run `aws iam list-users` and find active users with console access\n**Solution:** \n- Delete all IAM users except service accounts\n- For service accounts, use IAM roles with external ID instead\n- Document any exceptions with business justification\n\n### ❌ Mistake 2: \"We Use SSO\" But MFA is Optional\n**Problem:** IdP configured but MFA policy allows \"remember device for 30 days\" or skip option\n**Solution:**\n- Set MFA to \"Every sign-in\" for AWS access\n- Disable \"remember this device\" for sensitive applications\n- Show MFA policy screenshot in evidence\n\n### ❌ Mistake 3: Break-Glass Accounts Without Monitoring\n**Problem:** Emergency admin accounts exist but no alerts when used\n**Solution:**\n```bash\n# Create CloudWatch alarm for root/break-glass usage\naws cloudwatch put-metric-alarm \\\n  --alarm-name \"BreakGlass-Account-Used\" \\\n  --metric-name \"ConsoleSignInCount\" \\\n  --namespace \"CloudTrailMetrics\" \\\n  --statistic Sum \\\n  --period 300 \\\n  --threshold 1 \\\n  --comparison-operator GreaterThanOrEqualToThreshold\n```\n\n### ❌ Mistake 4: Demo Shows Only AWS, Ignores Other Systems\n**Problem:** Perfect AWS SSO setup, but Jira/Datadog use separate passwords\n**Solution:**\n- The requirement explicitly says \"other systems containing customer data\"\n- Add SAML/OIDC integration for ALL tools\n- Include these in your demo\n\n### ❌ Mistake 5: Permission Sets Are Too Broad\n**Problem:** Everyone has `AdministratorAccess` because \"it's easier\"\n**Solution:**\n- Implement tiered access (L1/L2/L3)\n- Use AWS managed policies as baseline\n- Add custom deny policies for sensitive actions:\n```json\n{\n  \"Effect\": \"Deny\",\n  \"Action\": [\n    \"organizations:*\",\n    \"account:*\",\n    \"iam:CreateUser\",\n    \"iam:CreateAccessKey\"\n  ],\n  \"Resource\": \"*\"\n}\n```\n\n### 🚫 Primary Audit Failure Reasons\n1. Cannot demonstrate live authentication (only screenshots)\n2. Found IAM users with console passwords in customer accounts\n3. No evidence of MFA enforcement\n4. Access to monitoring/ticketing systems not federated\n5. No access logging or audit trail shown\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ | **IdP is single source of truth** | Attempt login to AWS without IdP | Login should fail; no direct IAM user access possible |\n| ✅ | **MFA enforced on every login** | Login to IdP, verify MFA prompt | MFA challenge appears every time, no skip option |\n| ✅ | **No local IAM users in customer accounts** | Run `aws iam list-users` in 3+ customer accounts | Zero users with console access (service accounts OK if documented) |\n| ✅ | **Permission sets follow least privilege** | Review permission set policies | No `*:*` permissions; tiered access model documented |\n| ✅ | **CloudTrail captures federation events** | Search CloudTrail for `AssumeRoleWithSAML` | Events show user identity, source IP, timestamp |\n| ✅ | **Non-AWS systems integrated** | Login to Jira/Datadog via IdP | SSO works; no separate password entry |\n| ✅ | **Demo recording is complete** | Watch full demo, check against script | All 7 demo steps visible; no cuts or edits in auth flow |\n| ✅ | **Break-glass procedure documented** | Review emergency access SOP | Procedure exists; alerts configured; tested within 90 days |\n\n### Quality Criteria for Passing\n- **Demo Quality:** 1080p minimum, audio narration explaining each step, no sensitive data visible (blur customer names if needed)\n- **Documentation:** Dated within 30 days of audit, signed by Security Officer\n- **Coverage:** 100% of customer accounts accessible only via federated identity\n- **Exceptions:** Any exceptions (legacy accounts, specific customer requirements) documented with compensating controls\n\n---\n\n## 📌 Pro Tips from Passed Audits\n\n> 💡 **Tip 1:** Auditors often ask \"What happens if Okta goes down?\" Have a documented break-glass procedure with hardware MFA tokens stored securely.\n\n> 💡 **Tip 2:** Show your IdP dashboard with the list of integrated applications. This visual proves centralization better than any document.\n\n> 💡 **Tip 3:** If you use AWS Control Tower, show the SCP that denies IAM user creation. This proves enforcement, not just policy.\n\n> 💡 **Tip 4:** Include a \"negative test\" in your demo—show what happens when someone tries to access without going through the IdP (access denied).",
      "language": "en",
      "createdAt": "2026-01-07T03:04:40.146Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-005_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-005",
      "category": "Security",
      "title": "Policy Management",
      "advice": "# SEC-005: Policy Management - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nPolicy Management is a **core security competency** that demonstrates your MSP's ability to maintain least-privilege access across customer environments. AWS auditors specifically want to see that you're not just setting up IAM policies once and forgetting them—they want evidence of **continuous governance** over identity permissions.\n\nThis requirement exists because IAM policy drift is one of the most common security risks in AWS environments. Permissions accumulate over time (permission creep), unused roles persist, and overly permissive policies go unnoticed without systematic review.\n\n### 🎯 Key Points Auditors Look For\n\n1. **Recurring Review Cadence**: Evidence of at least 2 distinct reviews within 12 months—not just a one-time setup. Auditors will check timestamps carefully.\n\n2. **Use of IAM Access Analyzer Findings**: They want to see actual findings from Access Analyzer (external access, unused access) and documented remediation actions—not just \"no findings\" screenshots.\n\n3. **Scope Coverage**: Reviews must cover both your internal MSP AWS accounts AND customer managed accounts. Single-account evidence is insufficient.\n\n4. **Actionable Outcomes**: Each review must show what was discovered, what decisions were made, and what changes were implemented. A review with no documented outcomes raises red flags.\n\n5. **Baseline Comparison**: Evidence that you're comparing current state against an established permission baseline, not just running ad-hoc scans.\n\n### 🔧 Relevant AWS Services & Features\n\n| Service/Feature | Purpose in This Requirement |\n|----------------|----------------------------|\n| **IAM Access Analyzer** | Primary tool for policy analysis (external access + unused access analyzers) |\n| **IAM Access Advisor** | Last accessed information for services |\n| **AWS Organizations** | Delegated administrator for org-wide Access Analyzer |\n| **AWS Config Rules** | `iam-policy-no-statements-with-admin-access`, `iam-user-unused-credentials-check` |\n| **AWS Security Hub** | Aggregated IAM-related findings |\n| **Amazon Athena** | Query CloudTrail for permission usage patterns |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### 📄 Document 1: IAM Policy Review Procedure Document\n**Filename**: `SEC-005_IAM_Policy_Review_Procedure_v2.1.pdf`\n\n**Must Include**:\n- Review frequency (quarterly recommended, minimum semi-annual)\n- Scope definition (which accounts, which identity types)\n- Tools used (IAM Access Analyzer configuration details)\n- Roles and responsibilities (who runs reviews, who approves remediations)\n- Escalation path for high-risk findings\n- Baseline definition methodology\n\n#### 📄 Document 2: Review Execution Records (Minimum 2 instances)\n\n**Review Instance 1**:\n- `SEC-005_IAM_Review_Q1_2024_Report.pdf`\n- `SEC-005_AccessAnalyzer_Findings_Export_20240315.csv`\n- `SEC-005_Remediation_Tracker_Q1_2024.xlsx`\n\n**Review Instance 2**:\n- `SEC-005_IAM_Review_Q3_2024_Report.pdf`\n- `SEC-005_AccessAnalyzer_Findings_Export_20240918.csv`\n- `SEC-005_Remediation_Tracker_Q3_2024.xlsx`\n\n#### 📄 Document 3: Permission Baseline Documentation\n**Filename**: `SEC-005_IAM_Permission_Baseline_CustomerTemplate.xlsx`\n\n**Must Include**:\n- Standard role definitions per customer tier\n- Approved policy templates\n- Deviation approval process\n- Baseline update history\n\n#### 📄 Document 4: Tool Configuration Evidence\n**Filename**: `SEC-005_AccessAnalyzer_Configuration_Screenshots.pdf`\n\n**Must Include**:\n- Access Analyzer analyzer creation (showing organization scope)\n- Unused access analyzer configuration (90-day tracking period)\n- Archive rules configuration (showing intentional exclusions are documented)\n\n### 📸 Screenshot Evidence Examples\n\n```\nScreenshots to capture:\n├── AccessAnalyzer_Dashboard_OrgView.png\n├── AccessAnalyzer_UnusedAccess_Findings.png\n├── AccessAnalyzer_ExternalAccess_Findings.png\n├── AccessAnalyzer_ArchiveRules_Config.png\n├── IAM_AccessAdvisor_ServiceLastAccessed.png\n├── SecurityHub_IAM_Findings_Summary.png\n└── Config_IAM_Rules_Compliance.png\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Configure Organization-Wide IAM Access Analyzer (Day 1-2)\n**Responsible**: Cloud Security Engineer\n**Time**: 4-6 hours\n\n```bash\n# Create organization-level analyzer via AWS CLI\naws accessanalyzer create-analyzer \\\n    --analyzer-name \"MSP-Org-PolicyAnalyzer\" \\\n    --type ORGANIZATION \\\n    --tags Purpose=MSP-Compliance,Requirement=SEC-005\n\n# Create unused access analyzer (requires IAM Access Analyzer unused access feature)\naws accessanalyzer create-analyzer \\\n    --analyzer-name \"MSP-UnusedAccess-Analyzer\" \\\n    --type ORGANIZATION_UNUSED_ACCESS \\\n    --configuration '{\"unusedAccess\": {\"unusedAccessAge\": 90}}'\n```\n\n**Document**: Screenshot the analyzer configuration in console showing organization scope and creation date.\n\n### Step 2: Establish Permission Baseline Template (Day 3-5)\n**Responsible**: Security Architect + MSP Operations Lead\n**Time**: 8-12 hours\n\nCreate a baseline spreadsheet with these tabs:\n- **Standard Roles**: Define 5-7 standard roles (e.g., ReadOnly, PowerUser, SecurityAudit, BillingAdmin, NetworkAdmin)\n- **Policy Boundaries**: Document permission boundaries applied to each role\n- **Customer Mapping**: Which customers use which role templates\n- **Exceptions Register**: Documented deviations with approval evidence\n\n### Step 3: Execute First Formal Review (Day 6-8)\n**Responsible**: Security Analyst\n**Time**: 6-8 hours per review\n\n**Review Execution Checklist**:\n```markdown\n□ Export Access Analyzer findings (external access)\n□ Export Access Analyzer findings (unused access)\n□ Run IAM Access Advisor report for all roles\n□ Query AWS Config for IAM rule compliance\n□ Compare current roles against baseline\n□ Document new roles created since last review\n□ Identify permissions not used in 90+ days\n□ Flag cross-account trust relationships\n```\n\n**Export Command**:\n```bash\n# Export findings to S3 for audit trail\naws accessanalyzer list-findings \\\n    --analyzer-arn arn:aws:access-analyzer:us-east-1:123456789012:analyzer/MSP-Org-PolicyAnalyzer \\\n    --output json > findings_$(date +%Y%m%d).json\n```\n\n### Step 4: Document Findings and Remediation Actions (Day 9-10)\n**Responsible**: Security Analyst + Account Manager\n**Time**: 4-6 hours\n\nCreate a findings report with this structure:\n\n| Finding ID | Account | Resource | Finding Type | Risk Level | Decision | Action Taken | Date Completed |\n|------------|---------|----------|--------------|------------|----------|--------------|----------------|\n| F-001 | 111122223333 | role/LegacyAdmin | Unused role (180 days) | High | Remediate | Role deleted | 2024-03-20 |\n| F-002 | 444455556666 | policy/S3FullAccess | Overly permissive | Medium | Accept | Customer approved, documented | 2024-03-22 |\n\n**Critical**: Every finding must have a documented decision (Remediate, Accept with justification, or Archive with reason).\n\n### Step 5: Schedule and Execute Second Review (Month 4-6)\n**Responsible**: Security Team Lead\n**Time**: 6-8 hours\n\n- Set calendar reminder for 90-120 days after first review\n- Use identical review process for consistency\n- Compare findings against previous review\n- Document trend analysis (improving, stable, degrading)\n\n### Step 6: Create Audit-Ready Summary Report (Day before submission)\n**Responsible**: Compliance Manager\n**Time**: 3-4 hours\n\n**Report Structure**:\n```\n1. Executive Summary\n   - Review dates: [Date 1], [Date 2]\n   - Accounts in scope: [X] accounts\n   - Total findings: [N] findings across both reviews\n   \n2. Tools Used\n   - IAM Access Analyzer (Organization scope)\n   - IAM Access Advisor\n   - AWS Config IAM rules\n   \n3. Review 1 Summary (Date)\n   - Findings by category\n   - Remediation summary\n   - Exceptions approved\n   \n4. Review 2 Summary (Date)\n   - Findings by category\n   - Remediation summary\n   - Trend comparison\n   \n5. Appendices\n   - Raw findings exports\n   - Remediation tickets\n   - Approval emails for exceptions\n```\n\n### Step 7: Validate Evidence Timestamps (Final check)\n**Responsible**: Audit Coordinator\n**Time**: 2 hours\n\nVerify all evidence shows dates within the 12-month window and reviews are clearly separated by at least 60 days.\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Single Point-in-Time Evidence\n**What Goes Wrong**: Submitting one Access Analyzer export and claiming it represents \"ongoing\" review.\n\n**Why Auditors Reject This**: The requirement explicitly states \"more than once during the last 12 months.\" A single export, even with comprehensive findings, fails the frequency requirement.\n\n**Fix**: Ensure you have clearly dated evidence from at least 2 separate review cycles, ideally 3-4 months apart.\n\n---\n\n### ❌ Mistake 2: Findings Without Outcomes\n**What Goes Wrong**: Showing Access Analyzer findings but no documentation of what was done about them.\n\n**Why Auditors Reject This**: Running a tool isn't policy management—acting on the results is. Auditors specifically look for the decision-making process.\n\n**Fix**: Every finding must have a corresponding entry showing:\n- Decision made (remediate/accept/archive)\n- Who made the decision\n- When action was completed\n- Evidence of completion (ticket closed, policy modified, etc.)\n\n---\n\n### ❌ Mistake 3: Ignoring Unused Access Analyzer\n**What Goes Wrong**: Only using the external access analyzer, missing the unused access feature.\n\n**Why Auditors Question This**: The requirement mentions \"baselining group and role membership\" and \"evaluating specific permissions granted\"—unused access analysis is essential for permission creep detection.\n\n**Fix**: Configure both analyzer types:\n- External access analyzer (default)\n- Unused access analyzer (requires explicit setup with tracking period)\n\n---\n\n### ❌ Mistake 4: MSP Account Only, No Customer Coverage\n**What Goes Wrong**: Showing reviews only for your internal MSP AWS accounts, not customer managed accounts.\n\n**Why Auditors Reject This**: MSP program is about managing customer environments. Evidence must demonstrate you apply these practices to customer accounts.\n\n**Fix**: Include at least 2-3 customer accounts in your review scope (with customer names redacted if needed). Show organization-level analyzer deployment.\n\n---\n\n### ❌ Mistake 5: No Baseline to Compare Against\n**What Goes Wrong**: Running Access Analyzer without having documented what \"good\" looks like for your environment.\n\n**Why Auditors Question This**: Without a baseline, you can't demonstrate that you're evaluating against standards—you're just generating findings randomly.\n\n**Fix**: Create and maintain a permission baseline document that defines:\n- Standard roles and their intended permissions\n- Acceptable cross-account trust patterns\n- Maximum permission boundaries per customer tier\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ 1 | **Two distinct review dates visible** | Check timestamps on all reports and exports | Dates are 60+ days apart, both within last 12 months |\n| ✅ 2 | **IAM Access Analyzer explicitly mentioned** | Search evidence documents for \"Access Analyzer\" | Tool name appears in procedure doc AND execution evidence |\n| ✅ 3 | **Organization scope configured** | Screenshot shows analyzer type = \"ORGANIZATION\" | Not account-level analyzer only |\n| ✅ 4 | **Unused access analysis included** | Evidence shows unused permissions/roles findings | 90-day unused access tracking demonstrated |\n| ✅ 5 | **Findings have documented outcomes** | Cross-reference findings export with remediation tracker | 100% of findings have decision + action documented |\n| ✅ 6 | **Customer accounts in scope** | Review scope section lists multiple account IDs | Minimum 3 accounts shown (MSP + 2 customers) |\n| ✅ 7 | **Baseline document exists** | Separate baseline document with version history | Baseline predates first review date |\n\n### 📊 Quality Scoring Guide\n\n**Strong Evidence (Audit Pass)**:\n- 3+ reviews documented in 12 months\n- Trend analysis showing improvement\n- Automated scheduling evidence (calendar invites, ticketing system)\n- Integration with change management process\n\n**Acceptable Evidence (Likely Pass)**:\n- 2 reviews documented with clear dates\n- All findings have outcomes documented\n- Access Analyzer organization-level deployment\n- Customer account coverage demonstrated\n\n**Weak Evidence (Risk of Failure)**:\n- Only 2 reviews but dates are unclear\n- Findings exist but outcomes are vague\n- Account-level analyzer only\n- No baseline comparison\n\n**Insufficient Evidence (Will Fail)**:\n- Single review only\n- No Access Analyzer usage (manual review only)\n- No documented outcomes\n- MSP account only, no customer coverage\n\n---\n\n### 🎯 Quick Reference: Evidence Package Checklist\n\n```\nSEC-005 Evidence Folder Structure:\n├── 01_Procedure/\n│   └── SEC-005_IAM_Policy_Review_Procedure_v2.1.pdf\n├── 02_Baseline/\n│   └── SEC-005_IAM_Permission_Baseline.xlsx\n├── 03_Review_Q1_2024/\n│   ├── SEC-005_IAM_Review_Q1_2024_Report.pdf\n│   ├── SEC-005_AccessAnalyzer_Findings_20240315.csv\n│   └── SEC-005_Remediation_Tracker_Q1_2024.xlsx\n├── 04_Review_Q3_2024/\n│   ├── SEC-005_IAM_Review_Q3_2024_Report.pdf\n│   ├── SEC-005_AccessAnalyzer_Findings_20240918.csv\n│   └── SEC-005_Remediation_Tracker_Q3_2024.xlsx\n└── 05_Configuration/\n    └── SEC-005_AccessAnalyzer_Config_Screenshots.pdf\n```",
      "language": "en",
      "createdAt": "2026-01-07T03:05:54.906Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-006_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-006",
      "category": "Security",
      "title": "Role-Based Access",
      "advice": "# SEC-006: Role-Based Access - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nRole-Based Access (RBAC) is the **cornerstone of AWS MSP security posture**. AWS requires MSPs to demonstrate they can securely manage not just their own infrastructure, but dozens or hundreds of customer accounts. If an MSP uses long-lived credentials or overly permissive IAM policies, a single compromise could cascade across all managed customer environments. This requirement validates that your organization has mature identity governance that scales with your MSP operations.\n\n### 🎯 What Auditors Specifically Look For\n\n1. **Zero long-term access keys for human users** - Auditors will run IAM Credential Reports and immediately flag any access keys older than 90 days attached to human identities. They expect to see IAM Identity Center (SSO) or federated access for all human operators.\n\n2. **Functional role segregation** - They want to see distinct IAM roles like `MSP-NetworkAdmin`, `MSP-SecurityAuditor`, `MSP-BillingReadOnly` rather than a single `MSP-Admin` role. Each role must map to actual job functions in your organization.\n\n3. **Cross-account access architecture** - Auditors examine how your NOC/SOC teams access customer accounts. They expect to see a hub-and-spoke model using `sts:AssumeRole` from a central identity account, not IAM users created in each customer account.\n\n4. **Machine identity justification** - For any service accounts with static credentials (e.g., legacy applications requiring access keys), auditors require documented exceptions with compensating controls like IP restrictions and mandatory rotation schedules.\n\n5. **Policy scope validation** - They will inspect actual IAM policies for wildcards. Seeing `\"Resource\": \"*\"` on actions like `ec2:*` or `s3:*` is an immediate red flag requiring justification.\n\n### 🔧 Relevant AWS Services\n\n- **IAM Identity Center (AWS SSO)** - Primary mechanism for human access\n- **AWS IAM Access Analyzer** - Policy validation and unused access detection\n- **AWS Organizations** - SCPs for guardrails across accounts\n- **AWS CloudTrail** - Evidence of temporary credential usage\n- **IAM Credential Report** - Audit artifact showing credential status\n- **AWS Config Rules** - `iam-user-no-policies-check`, `access-keys-rotated`\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|--------------------------|\n| IAM Role Inventory | Excel/CSV | All MSP-created roles across managed accounts with policy attachments |\n| Role-to-Function Mapping | PDF Document | Organizational chart showing which teams use which roles |\n| Live Demo Recording | MP4 (15-20 min) | Screen recording of actual role assumption workflow |\n| IAM Credential Reports | CSV exports | From identity account + 3 representative customer accounts |\n| Policy Documents | JSON exports | Actual IAM policies showing least privilege implementation |\n| Exception Register | PDF/Excel | Documented static credential exceptions with compensating controls |\n\n### 📄 Specific Evidence Examples\n\n**Evidence File 1: `MSP_IAM_Role_Architecture_Diagram.pdf`**\n- Must show: Identity Provider → IAM Identity Center → Permission Sets → Cross-account roles\n- Include: Session duration limits (e.g., 1 hour for privileged roles, 8 hours for read-only)\n- Show: MFA enforcement points\n\n**Evidence File 2: `Functional_Role_Matrix_v2.3.xlsx`**\n```\n| Role Name | AWS Permission Set | Job Function | Team | Max Session | MFA Required |\n|-----------|-------------------|--------------|------|-------------|--------------|\n| MSP-L1-Support | ViewOnlyAccess + CloudWatch:GetMetricData | NOC Analyst | Operations | 8 hours | Yes |\n| MSP-NetworkAdmin | NetworkAdministrator (custom) | Network Engineer | Infrastructure | 2 hours | Yes |\n| MSP-SecurityAudit | SecurityAudit + GuardDuty:Get* | Security Analyst | SecOps | 4 hours | Yes |\n| MSP-EmergencyBreakGlass | AdministratorAccess | Incident Commander | Leadership | 1 hour | Yes + Approval |\n```\n\n**Evidence File 3: `Demo_RoleBasedAccess_Walkthrough.mp4`**\nMust demonstrate:\n- Login via IAM Identity Center (not IAM user)\n- Role selection based on task (show multiple available roles)\n- Temporary credential generation (show STS token expiration)\n- Permission denial when attempting out-of-scope action\n- CloudTrail event showing `AssumeRole` API call\n\n**Evidence File 4: `Static_Credential_Exception_Register.pdf`**\n```\nException ID: CRED-EXC-2024-003\nService: Legacy monitoring agent (Nagios)\nJustification: Agent does not support IRSA or instance profiles\nCompensating Controls:\n  - IAM policy restricted to CloudWatch:GetMetricData only\n  - Source IP condition limiting to monitoring subnet (10.0.50.0/24)\n  - 30-day mandatory rotation via AWS Secrets Manager\n  - Alert on any API call from unexpected IP\nApproval: CISO signature, reviewed quarterly\nNext Review Date: 2024-06-15\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current IAM State (Week 1)\n**Tool:** AWS IAM Access Analyzer + Custom Script\n\n```bash\n# Generate credential report for all accounts in Organization\nfor account_id in $(aws organizations list-accounts --query 'Accounts[].Id' --output text); do\n  aws iam generate-credential-report --profile $account_id\n  aws iam get-credential-report --profile $account_id --output text --query 'Content' | base64 -d > credential_report_${account_id}.csv\ndone\n```\n\n**Action Items:**\n- Identify all IAM users with console access (should be zero in customer accounts)\n- List all access keys older than 90 days\n- Flag any access keys that have never been rotated\n\n**Responsible:** Cloud Security Engineer | **Time:** 3-4 hours\n\n### Step 2: Design Functional Role Taxonomy (Week 1-2)\n**Tool:** Spreadsheet + AWS IAM Policy Simulator\n\nCreate role definitions based on actual job functions:\n\n| Level | Role Pattern | Typical Permissions | Use Case |\n|-------|-------------|---------------------|----------|\n| L1 | `MSP-{Customer}-ReadOnly` | ViewOnlyAccess | Monitoring, initial triage |\n| L2 | `MSP-{Customer}-Operator` | PowerUserAccess minus IAM | Remediation, deployments |\n| L3 | `MSP-{Customer}-Admin` | Full admin minus Organizations | Architecture changes |\n| Break Glass | `MSP-{Customer}-Emergency` | AdministratorAccess | Incident response only |\n\n**Responsible:** IAM Architect + Team Leads | **Time:** 8-12 hours\n\n### Step 3: Implement IAM Identity Center Structure (Week 2-3)\n**Tool:** AWS IAM Identity Center + Terraform/CloudFormation\n\n```hcl\n# Example Permission Set for L1 Support\nresource \"aws_ssoadmin_permission_set\" \"msp_l1_support\" {\n  name             = \"MSP-L1-Support\"\n  instance_arn     = aws_ssoadmin_instances.main.arns[0]\n  session_duration = \"PT8H\"\n  \n  inline_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Effect = \"Allow\"\n        Action = [\n          \"cloudwatch:GetMetricData\",\n          \"cloudwatch:ListMetrics\",\n          \"cloudwatch:DescribeAlarms\",\n          \"logs:GetLogEvents\",\n          \"logs:FilterLogEvents\",\n          \"ec2:Describe*\",\n          \"rds:Describe*\",\n          \"ecs:Describe*\",\n          \"ecs:List*\"\n        ]\n        Resource = \"*\"\n      }\n    ]\n  })\n}\n```\n\n**Responsible:** IAM Engineer | **Time:** 16-24 hours\n\n### Step 4: Eliminate Static Credentials (Week 3-4)\n**Tool:** AWS Secrets Manager + IAM Roles Anywhere\n\nFor each identified static credential:\n1. Determine if workload can use IAM roles (EC2 instance profile, ECS task role, Lambda execution role)\n2. If external system, evaluate IAM Roles Anywhere with X.509 certificates\n3. If truly unavoidable, implement Secrets Manager rotation:\n\n```python\n# Secrets Manager rotation Lambda snippet\ndef rotate_iam_access_key(secret_arn, user_name):\n    iam = boto3.client('iam')\n    # Create new key\n    new_key = iam.create_access_key(UserName=user_name)\n    # Store in Secrets Manager\n    secrets.put_secret_value(SecretId=secret_arn, SecretString=json.dumps(new_key))\n    # Delete old key after 24h grace period (handled by separate Lambda)\n```\n\n**Responsible:** DevOps Engineer | **Time:** 20-40 hours (varies by legacy system count)\n\n### Step 5: Deploy Guardrails via SCPs (Week 4)\n**Tool:** AWS Organizations SCPs\n\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyLongTermCredentialCreation\",\n      \"Effect\": \"Deny\",\n      \"Action\": [\n        \"iam:CreateAccessKey\",\n        \"iam:CreateUser\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringNotLike\": {\n          \"aws:PrincipalArn\": \"arn:aws:iam::*:role/MSP-Automation-*\"\n        }\n      }\n    }\n  ]\n}\n```\n\n**Responsible:** Cloud Architect | **Time:** 4-6 hours\n\n### Step 6: Record Demonstration Video (Week 5)\n**Tool:** Screen recording software (OBS/Loom)\n\n**Script for 15-minute demo:**\n1. (0:00-2:00) Show IAM Identity Center portal, explain permission sets\n2. (2:00-5:00) Demonstrate L1 analyst logging in, accessing CloudWatch, being denied EC2 modification\n3. (5:00-8:00) Show L2 operator assuming elevated role, performing allowed remediation\n4. (8:00-11:00) Display CloudTrail logs showing `AssumeRole` events with temporary credentials\n5. (11:00-14:00) Show IAM Access Analyzer findings (should be clean)\n6. (14:00-15:00) Show credential report proving no long-term access keys for humans\n\n**Responsible:** Security Lead | **Time:** 2-3 hours\n\n### Step 7: Compile Exception Documentation (Week 5)\n**Tool:** Document template + Approval workflow\n\nFor each static credential exception, document:\n- Business justification (why temporary credentials impossible)\n- Technical constraints (specific service limitations)\n- Compensating controls (rotation, IP restrictions, monitoring)\n- Approval chain (CISO or equivalent)\n- Review schedule (quarterly minimum)\n\n**Responsible:** GRC Analyst | **Time:** 4-8 hours\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: \"Admin\" Role for All MSP Staff\n**Problem:** Creating a single `MSP-Administrator` role used by everyone from L1 support to architects.\n\n**Why Auditors Fail This:** Violates least privilege fundamentally. If your L1 NOC analyst can delete production databases, you haven't implemented RBAC.\n\n**Solution:** Minimum 4 distinct permission tiers with clear escalation path. L1 should only have read + specific remediation actions.\n\n### ❌ Mistake 2: Forgetting Service Account Credentials\n**Problem:** Focus on human access while ignoring CI/CD pipelines, monitoring agents, and backup solutions using static access keys.\n\n**Why Auditors Fail This:** Auditors run `aws iam list-access-keys` across all users. Finding 50+ access keys for \"service accounts\" with `AdministratorAccess` is an instant fail.\n\n**Solution:** Inventory ALL machine identities. Migrate to:\n- GitHub Actions → OIDC federation\n- Jenkins → EC2 instance profile or ECS task role\n- External monitoring → IAM Roles Anywhere\n\n### ❌ Mistake 3: Wildcard Resources on Sensitive Actions\n**Problem:** Policies like `\"Action\": \"s3:*\", \"Resource\": \"*\"` even for legitimate admin roles.\n\n**Why Auditors Fail This:** IAM Access Analyzer will flag these. Auditors expect resource-level restrictions or at minimum condition keys.\n\n**Solution:** \n```json\n{\n  \"Effect\": \"Allow\",\n  \"Action\": \"s3:*\",\n  \"Resource\": [\n    \"arn:aws:s3:::${aws:PrincipalTag/Team}-*\",\n    \"arn:aws:s3:::${aws:PrincipalTag/Team}-*/*\"\n  ]\n}\n```\n\n### ❌ Mistake 4: No Evidence of Actual Usage\n**Problem:** Showing beautiful IAM architecture diagrams but no proof that staff actually use these roles.\n\n**Why Auditors Fail This:** They want CloudTrail evidence showing real `AssumeRole` events, not theoretical designs.\n\n**Solution:** Pull 30 days of CloudTrail showing:\n- `AssumeRoleWithSAML` events (IAM Identity Center)\n- Distribution across different roles (not everyone using admin)\n- Session durations matching policy limits\n\n### ❌ Mistake 5: Break Glass Without Controls\n**Problem:** Having emergency admin access without approval workflow or audit trail.\n\n**Why Auditors Fail This:** Emergency access is expected, but uncontrolled emergency access is a security gap.\n\n**Solution:** Implement break glass with:\n- Separate approval (PagerDuty/ServiceNow integration)\n- Automatic alerting when role is assumed\n- 1-hour maximum session\n- Mandatory incident ticket linkage\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Zero IAM users with console passwords in customer accounts** | Run `aws iam get-credential-report` for each managed account | `password_enabled` = false for all entries except break-glass (if applicable) |\n| 2 | **All human access via IAM Identity Center** | Screenshot of IAM Identity Center showing all MSP staff | 100% of operations team members visible with appropriate permission sets |\n| 3 | **Access keys < 90 days old** | Credential report column `access_key_1_last_rotated` | No access keys older than 90 days; ideally zero access keys for humans |\n| 4 | **Minimum 3 distinct permission tiers** | Permission set inventory | Clear differentiation: ReadOnly, Operator, Admin (minimum) |\n| 5 | **IAM Access Analyzer clean** | Access Analyzer console screenshot | Zero critical/high findings on MSP-created policies |\n| 6 | **CloudTrail shows temporary credential usage** | 30-day CloudTrail export filtered for `AssumeRole*` | >95% of MSP access events use `AssumeRole`, not direct IAM user authentication |\n| 7 | **Static credential exceptions documented** | Exception register with signatures | Each exception has: justification, compensating controls, CISO approval, review date |\n\n### 🎬 Demo Readiness Check\n\nBefore recording demonstration:\n- [ ] Test login flow works smoothly (no password resets mid-demo)\n- [ ] Prepare \"negative test\" showing permission denial\n- [ ] Have CloudTrail console open to show real-time events\n- [ ] Clear browser history/bookmarks that might show sensitive info\n- [ ] Verify IAM Access Analyzer has completed recent analysis\n\n### 📊 Quality Criteria for Passing\n\n| Aspect | Minimum Standard | Ideal State |\n|--------|-----------------|-------------|\n| Human access method | IAM Identity Center or SAML federation | IAM Identity Center with Okta/Azure AD integration |\n| Permission granularity | 3+ distinct roles | 5+ roles with clear job function mapping |\n| Static credentials | Documented exceptions only | Zero static credentials (all workloads use roles) |\n| Session duration | ≤8 hours standard, ≤1 hour privileged | Dynamic based on sensitivity + step-up auth for privileged |\n| Policy wildcards | Justified and documented | Zero wildcards; all resource-scoped |",
      "language": "en",
      "createdAt": "2026-01-07T03:07:08.466Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-007_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-007",
      "category": "Security",
      "title": "Multi-Factor Authentication",
      "advice": "# SEC-007: Multi-Factor Authentication (MFA) - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical for AWS MSP Program\nMFA is the **first line of defense** against credential compromise in AWS environments. AWS considers this a non-negotiable baseline security control because MSP partners manage multiple customer AWS accounts, making them high-value targets. A single compromised credential without MFA could expose dozens of customer environments.\n\n### 🎯 Key Points Auditors Specifically Look For\n\n1. **Enforcement, Not Just Enablement** - Auditors verify MFA is *required* (cannot be bypassed), not merely *available*. They will test if a user can authenticate without MFA.\n\n2. **Coverage of ALL Human Access Paths** - This includes:\n   - AWS Console access\n   - AWS CLI/API access via IAM Identity Center or federated roles\n   - Programmatic access that involves human interaction (not service accounts)\n\n3. **IdP-Level Enforcement** - For federated access, MFA must be enforced at the Identity Provider (Okta, Azure AD, Ping Identity, etc.), not just AWS-side\n\n4. **Root Account MFA** - Special attention to root account MFA using hardware tokens (Virtual MFA is acceptable but hardware is preferred)\n\n5. **No Exceptions or Workarounds** - Auditors check for \"break glass\" accounts or test accounts that might bypass MFA\n\n### Relevant AWS Services & Features\n- **AWS IAM Identity Center** (formerly AWS SSO) - Centralized MFA enforcement\n- **AWS IAM** - MFA device management, IAM policies with `aws:MultiFactorAuthPresent` condition\n- **AWS Organizations SCPs** - Organization-wide MFA enforcement\n- **AWS CloudTrail** - Evidence of MFA usage in authentication events\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|---------------------------|\n| **Live Demo Recording** | MP4/WebM (5-10 min) | Screen recording showing MFA enforcement in action |\n| **IdP MFA Policy Screenshot** | PNG/PDF | Configuration showing MFA is mandatory, not optional |\n| **AWS IAM Identity Center Config** | Screenshot + Export | MFA settings showing \"Required\" status |\n| **SCP Policy Document** | JSON + Console Screenshot | Policy denying actions without MFA |\n| **Root Account MFA Evidence** | Screenshot | Each account's root MFA device configuration |\n\n### 📄 Specific Evidence Examples\n\n**Evidence File 1: `SEC-007_MFA_Demo_Recording.mp4`**\n- Show login attempt → MFA prompt appears → Cannot proceed without MFA\n- Demonstrate with 2-3 different user accounts\n- Show what happens if MFA is skipped (access denied)\n\n**Evidence File 2: `SEC-007_Okta_MFA_Policy.pdf`** (or your IdP)\n```\nMust show:\n- Policy name: \"AWS Access MFA Requirement\"\n- Scope: All users accessing AWS applications\n- MFA Factor: Required (not \"Optional\" or \"Prompt\")\n- Allowed factors: TOTP, FIDO2, Push notification\n```\n\n**Evidence File 3: `SEC-007_IAM_Identity_Center_MFA_Config.png`**\nScreenshot showing:\n- Settings → Authentication → MFA\n- \"Require MFA\" = Enabled\n- \"If user does not have MFA device\" = \"Block sign-in\"\n\n**Evidence File 4: `SEC-007_MFA_Enforcement_SCP.json`**\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyAllWithoutMFA\",\n      \"Effect\": \"Deny\",\n      \"Action\": \"*\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"BoolIfExists\": {\n          \"aws:MultiFactorAuthPresent\": \"false\"\n        },\n        \"StringNotLike\": {\n          \"aws:PrincipalARN\": [\n            \"arn:aws:iam::*:role/AWSServiceRole*\",\n            \"arn:aws:iam::*:role/aws-service-role/*\"\n          ]\n        }\n      }\n    }\n  ]\n}\n```\n\n**Evidence File 5: `SEC-007_Root_Account_MFA_Status.xlsx`**\n| Account ID | Account Name | MFA Type | Device Serial | Last Verified |\n|------------|--------------|----------|---------------|---------------|\n| 123456789012 | MSP-Master | Hardware YubiKey | GAHT12345678 | 2024-01-15 |\n| 234567890123 | MSP-Security | Virtual (Authenticator) | arn:aws:iam::234567890123:mfa/root | 2024-01-15 |\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current MFA Coverage (Day 1-2)\n**Tool:** AWS CLI + Custom Script\n\n```bash\n# Check all IAM users for MFA status across all accounts\naws iam generate-credential-report\naws iam get-credential-report --query 'Content' --output text | base64 -d > mfa_report.csv\n\n# Look for users where mfa_active = false\n```\n\n**Responsible:** Security Engineer\n**Output:** Gap analysis spreadsheet identifying users without MFA\n\n---\n\n### Step 2: Configure IdP MFA Enforcement (Day 3-5)\n**For Okta:**\n1. Navigate to Security → Authentication Policies\n2. Create new policy: \"AWS-MFA-Required\"\n3. Add rule: IF accessing AWS apps → THEN require MFA\n4. Set \"Factor Lifetime\" to maximum 12 hours\n5. Assign policy to all AWS-related applications\n\n**For Azure AD:**\n1. Azure Portal → Azure AD → Security → Conditional Access\n2. New Policy → Name: \"Require MFA for AWS\"\n3. Assignments → Cloud apps → Select AWS SSO/IAM Identity Center\n4. Access controls → Grant → Require MFA\n5. Enable policy\n\n**Responsible:** Identity Team Lead\n**Time:** 4-6 hours including testing\n\n---\n\n### Step 3: Configure AWS IAM Identity Center MFA (Day 5-6)\n1. AWS Console → IAM Identity Center → Settings\n2. Authentication tab → Configure\n3. Set the following:\n   - **MFA types:** Authenticator apps, Security keys (FIDO2)\n   - **If user doesn't have MFA:** Block sign-in\n   - **Users can add/manage MFA devices:** Yes (or No if managed centrally)\n   - **Require MFA:** Every time they sign in\n\n**Screenshot this configuration for evidence**\n\n**Responsible:** AWS Administrator\n**Time:** 1-2 hours\n\n---\n\n### Step 4: Deploy MFA Enforcement SCP (Day 6-7)\n1. AWS Organizations → Policies → Service Control Policies\n2. Create policy named `RequireMFAForHumanAccess`\n3. Apply to all OUs except service account OUs\n4. Test with a pilot user before organization-wide deployment\n\n```bash\n# Verify SCP is attached\naws organizations list-policies-for-target \\\n  --target-id ou-xxxx-xxxxxxxx \\\n  --filter SERVICE_CONTROL_POLICY\n```\n\n**Responsible:** Cloud Platform Team\n**Time:** 3-4 hours including testing\n\n---\n\n### Step 5: Secure All Root Accounts (Day 7-8)\nFor each AWS account:\n1. Sign in as root (use secure workstation)\n2. Navigate to IAM → Security credentials\n3. Assign MFA device (hardware preferred for management accounts)\n4. Store recovery codes in secure vault (HashiCorp Vault, AWS Secrets Manager)\n5. Document device serial numbers\n\n**Responsible:** Security Team Lead (with witness for root access)\n**Time:** 30 minutes per account\n\n---\n\n### Step 6: Create Demo Recording (Day 9)\n**Recording Script:**\n```\n1. [00:00-00:30] Introduction - \"Demonstrating MFA enforcement for AWS access\"\n2. [00:30-02:00] Show IdP configuration (Okta/Azure AD policy settings)\n3. [02:00-04:00] Attempt login without MFA - show it's blocked\n4. [04:00-06:00] Complete login with MFA - show successful access\n5. [06:00-08:00] Show AWS IAM Identity Center MFA settings\n6. [08:00-10:00] Show SCP policy in Organizations console\n```\n\n**Tool:** OBS Studio, Loom, or similar\n**Responsible:** Security Engineer\n**Time:** 2-3 hours including retakes\n\n---\n\n### Step 7: Compile Evidence Package (Day 10)\nCreate folder structure:\n```\nSEC-007_MFA_Evidence/\n├── 01_Demo_Recording/\n│   └── SEC-007_MFA_Enforcement_Demo.mp4\n├── 02_IdP_Configuration/\n│   ├── Okta_MFA_Policy_Screenshot.png\n│   └── Okta_MFA_Policy_Export.pdf\n├── 03_AWS_Configuration/\n│   ├── IAM_Identity_Center_MFA_Settings.png\n│   └── SCP_RequireMFA_Policy.json\n├── 04_Root_Account_MFA/\n│   └── Root_MFA_Status_All_Accounts.xlsx\n└── 05_Supporting_Documentation/\n    └── MFA_Coverage_Report.pdf\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: MFA \"Enabled\" but Not \"Enforced\"\n**Problem:** IdP shows MFA is available, but users can choose to skip it\n**Solution:** Set MFA to \"Required\" or \"Always\" - never \"Optional\" or \"When prompted\"\n**Audit Failure Rate:** 35% of first-time submissions\n\n### ❌ Mistake 2: Forgetting CLI/API Access\n**Problem:** MFA enforced for Console but CLI access works without MFA\n**Solution:** \n- Use IAM Identity Center with MFA for CLI (`aws sso login`)\n- Or implement `GetSessionToken` with MFA for IAM users\n- Add `aws:MultiFactorAuthPresent` condition to all human-used roles\n\n### ❌ Mistake 3: Service Account Exemptions Too Broad\n**Problem:** SCP exempts too many roles, creating bypass opportunities\n**Anti-pattern:**\n```json\n\"StringNotLike\": {\n  \"aws:PrincipalARN\": \"arn:aws:iam::*:role/*\"  // TOO BROAD!\n}\n```\n**Correct approach:** Explicitly list only AWS service-linked roles\n\n### ❌ Mistake 4: Root Account MFA Not Documented\n**Problem:** Root accounts have MFA but no evidence prepared\n**Solution:** Screenshot each account's root MFA status, create tracking spreadsheet with device serial numbers\n\n### ❌ Mistake 5: Demo Shows Configuration, Not Enforcement\n**Problem:** Recording shows MFA settings exist but doesn't prove enforcement\n**What Auditors Want:** Actual login attempt showing MFA is mandatory\n**Solution:** Record a login flow where MFA prompt cannot be skipped\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ☐ | **IdP MFA Policy is \"Required\"** | Login to IdP admin console, check policy settings | Policy shows \"Required\" not \"Optional\" |\n| ☐ | **IAM Identity Center MFA = Block if no device** | AWS Console → IAM Identity Center → Settings → Authentication | \"Block sign-in\" is selected |\n| ☐ | **SCP deployed to all human-access OUs** | `aws organizations list-policies-for-target` for each OU | SCP attached to all relevant OUs |\n| ☐ | **100% of root accounts have MFA** | Check each account's IAM → Security credentials | MFA device assigned with serial number visible |\n| ☐ | **Demo shows enforcement, not just configuration** | Watch recording - verify login is blocked without MFA | User cannot proceed past MFA prompt |\n| ☐ | **CLI access requires MFA** | Test: `aws sts get-caller-identity` without MFA session | Access denied OR requires `aws sso login` with MFA |\n| ☐ | **No \"break glass\" accounts bypass MFA** | Review all IAM users and roles for exceptions | Zero accounts can access without MFA |\n\n### 🏁 Quality Gate Criteria\nYour evidence passes when:\n1. ✅ Live demo clearly shows authentication **fails** without MFA\n2. ✅ IdP configuration screenshot shows MFA is **mandatory** (not optional)\n3. ✅ All root accounts have MFA devices with documented serial numbers\n4. ✅ SCP is deployed and excludes only AWS service-linked roles\n5. ✅ Evidence covers Console AND CLI/API access paths\n\n### 📞 Pre-Submission Test\nBefore submitting, have a colleague attempt to:\n1. Sign into AWS Console without completing MFA → Should fail\n2. Use AWS CLI without MFA session → Should fail or require `aws sso login`\n3. Access any account as root without MFA → Should fail\n\nIf any test succeeds without MFA, your evidence will not pass audit.",
      "language": "en",
      "createdAt": "2026-01-07T03:08:16.053Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-008_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-008",
      "category": "Security",
      "title": "Vulnerability Management",
      "advice": "# SEC-008: Vulnerability Management - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nVulnerability Management is a **core security capability** that AWS expects all MSPs to demonstrate. This isn't just about having a scanning tool—it's about proving you can **proactively identify, assess, and remediate security weaknesses** across customer AWS environments before they become incidents. AWS wants assurance that MSP partners won't become a security liability for their shared customers.\n\n### 🔍 Key Points Auditors Evaluate\n\n1. **Coverage Scope**: Does your scanning cover EC2 instances, containers (ECS/EKS), Lambda functions, AND infrastructure configurations? Auditors reject solutions that only scan one layer.\n\n2. **Scanning Frequency & Automation**: Manual monthly scans won't pass. Auditors expect continuous or at minimum weekly automated scanning with evidence of scheduled jobs.\n\n3. **Remediation Workflow Integration**: Having scan results isn't enough—auditors want to see how findings flow into ticketing systems (ServiceNow, Jira) and get resolved.\n\n4. **Multi-Account Capability**: Since MSPs manage multiple customer accounts, your solution must demonstrate scanning across AWS Organizations or multiple standalone accounts.\n\n5. **Severity Classification & SLA Alignment**: Auditors verify you have defined response timeframes (Critical: 24hrs, High: 7 days, etc.) and track compliance against these SLAs.\n\n### 🛠️ Relevant AWS Services\n\n| Service | Purpose |\n|---------|---------|\n| **Amazon Inspector** | Primary AWS-native vulnerability scanning for EC2, ECR, Lambda |\n| **AWS Security Hub** | Aggregation point for findings with ASFF format |\n| **AWS Systems Manager Patch Manager** | Remediation automation for OS vulnerabilities |\n| **Amazon ECR Image Scanning** | Container image vulnerability detection |\n| **AWS Config Rules** | Infrastructure misconfiguration detection |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### 📄 Primary Evidence: Live Demonstration Recording (MANDATORY)\n\n**File Name Example**: `SEC-008_VulnMgmt_Demo_[CompanyName]_2024.mp4`\n\n**Must Include in Demo** (15-20 minutes):\n- Login to vulnerability management console (Inspector dashboard or third-party tool)\n- Show active scanning schedules configured\n- Navigate through findings by severity (Critical/High/Medium/Low)\n- Demonstrate drill-down into specific CVE with affected resources\n- Show integration with ticketing system (ticket creation from finding)\n- Display remediation tracking dashboard\n- Show multi-account view if using AWS Organizations\n\n#### 📊 Supporting Documentation\n\n| Document | Format | Key Contents |\n|----------|--------|--------------|\n| `Vulnerability_Management_Policy_v2.1.pdf` | PDF | Scanning frequency requirements, severity definitions, SLA matrix, roles & responsibilities |\n| `VulnScan_Architecture_Diagram.png` | PNG/Visio | Data flow from scanning → aggregation → ticketing → remediation |\n| `Monthly_Vulnerability_Report_Sample.pdf` | PDF | Executive summary, trend analysis, remediation metrics, aging report |\n| `Inspector_Coverage_Screenshot.png` | PNG | Screenshot showing % of resources covered by Inspector |\n| `Remediation_SLA_Tracking.xlsx` | Excel | Last 3 months of SLA compliance data with ticket IDs |\n\n#### 📸 Screenshot Evidence Package\n\n```\n/SEC-008_Screenshots/\n├── 01_Inspector_Dashboard_Overview.png\n├── 02_Scanning_Schedule_Config.png\n├── 03_Critical_Findings_List.png\n├── 04_CVE_Detail_Example.png\n├── 05_SecurityHub_Integration.png\n├── 06_Jira_Ticket_FromFinding.png\n├── 07_MultiAccount_Coverage.png\n└── 08_Remediation_Metrics_Dashboard.png\n```\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Enable Amazon Inspector Across All Managed Accounts (Day 1-2)\n**⏱️ Time: 4-6 hours | 👤 Role: Security Engineer**\n\n```bash\n# Enable Inspector via AWS CLI for delegated administrator\naws inspector2 enable --resource-types EC2 ECR LAMBDA \\\n  --account-ids \"111111111111\" \"222222222222\" \"333333333333\"\n\n# Verify activation status\naws inspector2 batch-get-account-status\n```\n\n**Key Actions**:\n- Designate a delegated administrator account in AWS Organizations\n- Enable EC2 scanning (requires SSM agent), ECR scanning, and Lambda scanning\n- Verify SSM agent is running on all EC2 instances (common gap!)\n\n### Step 2: Configure Security Hub as Aggregation Point (Day 2-3)\n**⏱️ Time: 3-4 hours | 👤 Role: Security Engineer**\n\n- Enable Security Hub in aggregation region\n- Set up cross-region finding aggregation\n- Enable Inspector integration (automatic with Inspector v2)\n- Create custom insights for vulnerability tracking:\n\n```\nInsight Name: \"Critical Vulnerabilities Aging > 7 Days\"\nFilter: ProductName = \"Inspector\" AND Severity = CRITICAL AND CreatedAt < now-7d\n```\n\n### Step 3: Build Remediation Workflow Integration (Day 3-5)\n**⏱️ Time: 8-12 hours | 👤 Role: DevOps/Security Engineer**\n\n**Option A: EventBridge → Lambda → Jira**\n```python\n# Lambda function snippet for Jira ticket creation\ndef create_jira_ticket(finding):\n    ticket = {\n        \"project\": {\"key\": \"SECOPS\"},\n        \"summary\": f\"[{finding['Severity']}] {finding['Title']}\",\n        \"description\": f\"CVE: {finding['Vulnerabilities'][0]['Id']}\\n\"\n                      f\"Resource: {finding['Resources'][0]['Id']}\\n\"\n                      f\"Remediation: {finding['Remediation']['Recommendation']['Text']}\",\n        \"issuetype\": {\"name\": \"Security Vulnerability\"},\n        \"priority\": severity_to_priority_map[finding['Severity']]\n    }\n    return jira_client.create_issue(fields=ticket)\n```\n\n**Option B: Security Hub → AWS Service Catalog → ServiceNow**\n- Use AWS Service Management Connector for ServiceNow\n- Configure bi-directional sync for finding status updates\n\n### Step 4: Establish Scanning Schedules and Coverage Monitoring (Day 5-6)\n**⏱️ Time: 4 hours | 👤 Role: Security Engineer**\n\n- Inspector v2 scans continuously (event-driven), but verify:\n  - ECR: Scan on push AND rescan frequency (30 days default)\n  - EC2: SSM inventory collection schedule\n  - Lambda: Automatic on deployment\n\n**Create Coverage Dashboard in CloudWatch**:\n```\nMetric: Inspector/CoveragePercentage\nDimension: ResourceType = EC2_INSTANCE\nAlarm: < 95% coverage triggers SNS notification\n```\n\n### Step 5: Define and Document SLA Matrix (Day 6-7)\n**⏱️ Time: 4 hours | 👤 Role: Security Manager**\n\n| Severity | CVSS Score | Response SLA | Remediation SLA | Escalation Path |\n|----------|------------|--------------|-----------------|-----------------|\n| Critical | 9.0-10.0 | 4 hours | 24 hours | → CISO |\n| High | 7.0-8.9 | 24 hours | 7 days | → Security Lead |\n| Medium | 4.0-6.9 | 72 hours | 30 days | → Team Lead |\n| Low | 0.1-3.9 | 7 days | 90 days | Standard queue |\n\n### Step 6: Generate Sample Reports and Metrics (Day 7-8)\n**⏱️ Time: 6 hours | 👤 Role: Security Analyst**\n\nCreate monthly report template including:\n- Total findings by severity (trend over 3 months)\n- Mean Time to Remediate (MTTR) by severity\n- Top 10 recurring CVEs\n- Coverage gaps identified\n- SLA compliance percentage\n\n### Step 7: Record Demonstration Video (Day 8-9)\n**⏱️ Time: 3-4 hours | 👤 Role: Security Engineer + Manager**\n\n**Demo Script Outline**:\n1. (0:00-2:00) Introduction to vulnerability management program\n2. (2:00-5:00) Inspector dashboard walkthrough - show active scanning\n3. (5:00-8:00) Findings deep-dive - pick a real Critical CVE\n4. (8:00-12:00) Ticketing integration - show Jira ticket creation\n5. (12:00-15:00) Remediation workflow - show patch deployment via SSM\n6. (15:00-18:00) Reporting and metrics dashboard\n7. (18:00-20:00) Multi-account management view\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: SSM Agent Not Running on EC2 Instances\n**Problem**: Inspector can't scan EC2 instances without SSM agent, leading to 40-60% coverage gaps.\n\n**Solution**: \n```bash\n# Check SSM managed instances\naws ssm describe-instance-information --query 'InstanceInformationList[*].[InstanceId,PingStatus]'\n\n# Deploy SSM agent via State Manager\naws ssm create-association --name \"AWS-ConfigureAWSPackage\" \\\n  --targets \"Key=tag:Environment,Values=Production\" \\\n  --parameters \"action=Install,name=AmazonSSMAgent\"\n```\n\n### ❌ Mistake 2: Showing Only Scanning Without Remediation Workflow\n**Problem**: Auditors frequently reject demos that show \"we can find vulnerabilities\" but not \"we fix them systematically.\"\n\n**Solution**: Always demonstrate the full lifecycle:\n`Scan → Detect → Ticket → Assign → Patch → Verify → Close`\n\n### ❌ Mistake 3: Using Only Third-Party Tool Without AWS Integration\n**Problem**: Using Qualys/Tenable/Rapid7 alone without showing AWS-native integration fails to demonstrate AWS expertise.\n\n**Solution**: Even if using third-party tools, show:\n- Integration with Security Hub (send findings via ASFF)\n- Use of AWS Systems Manager for remediation\n- CloudWatch metrics for vulnerability trends\n\n### ❌ Mistake 4: No Evidence of Historical Remediation\n**Problem**: Showing a clean dashboard with zero findings looks suspicious—auditors want to see you've actually processed vulnerabilities.\n\n**Solution**: Keep 3-6 months of:\n- Closed tickets with resolution notes\n- Before/after scan comparisons\n- MTTR metrics showing improvement trends\n\n### ❌ Mistake 5: Container/Lambda Scanning Gaps\n**Problem**: Many MSPs only scan EC2, missing modern workloads.\n\n**Solution**: Explicitly show in demo:\n- ECR image scanning results\n- Lambda function code scanning\n- EKS/ECS vulnerability findings (if applicable)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ | Inspector enabled across all managed accounts | `aws inspector2 batch-get-account-status` | All accounts show \"ENABLED\" status |\n| ✅ | EC2 coverage ≥ 95% | Inspector Dashboard → Coverage tab | Coverage percentage displayed ≥ 95% |\n| ✅ | Container scanning active | ECR Console → Scan on push setting | \"Scan on push\" enabled for all repositories |\n| ✅ | Lambda scanning enabled | Inspector Dashboard → Lambda coverage | Lambda functions showing in findings |\n| ✅ | Ticketing integration functional | Create test finding → verify ticket created | Ticket appears in Jira/ServiceNow within 5 minutes |\n| ✅ | SLA definitions documented | Review policy document | All 4 severity levels have defined response/remediation SLAs |\n| ✅ | Demo video covers full lifecycle | Watch recording end-to-end | Scan → Detect → Ticket → Remediate → Verify shown |\n| ✅ | Multi-account view demonstrated | Demo video timestamp check | At least 2 different AWS accounts shown in aggregated view |\n| ✅ | Historical remediation evidence | Jira/ServiceNow export | Minimum 10 closed vulnerability tickets from past 90 days |\n| ✅ | Monthly report sample complete | Review PDF | Contains trends, MTTR, SLA compliance, top CVEs sections |\n\n### 🎯 Quality Criteria for Passing\n\n**Minimum Requirements**:\n- Live demo showing real customer environment (sanitized data OK)\n- Automated scanning (not manual/on-demand only)\n- Integration with operational ticketing system\n- Defined SLAs with evidence of tracking\n\n**Excellence Indicators** (strengthen your submission):\n- Custom Security Hub insights for vulnerability tracking\n- Automated remediation via SSM Patch Manager\n- Risk-based prioritization beyond just CVSS scores\n- Integration with CI/CD pipeline for shift-left scanning\n\n---\n\n## 💡 Pro Tips from Passed Audits\n\n1. **Narrate your demo**: Don't just click through—explain WHY each step matters for customer security outcomes.\n\n2. **Show a real Critical finding**: Sanitize customer names, but showing an actual CVE-2024-XXXXX with your remediation response is powerful evidence.\n\n3. **Prepare for follow-up questions**: Auditors may ask \"What happens if a Critical isn't fixed in 24 hours?\" Have your escalation process ready.\n\n4. **Include exception handling**: Show how you handle false positives or accepted risks (risk acceptance documentation).",
      "language": "en",
      "createdAt": "2026-01-07T03:09:17.143Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-009_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-009",
      "category": "Security",
      "title": "Security Event Logging",
      "advice": "# SEC-009: Security Event Logging - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nSecurity Event Logging is the **foundation of incident response and compliance**. AWS views this as a core MSP capability because without proper logging, you cannot detect breaches, investigate incidents, or prove compliance to regulators. This requirement validates that you're not just deploying infrastructure, but actively protecting customer environments through comprehensive audit trails.\n\n### 🔍 Key Points Auditors Evaluate\n\n1. **Documented Agreement with Customer** - Auditors specifically look for a signed document (SOW, Security Addendum, or Service Agreement) that explicitly lists which log types will be captured and for how long. Verbal agreements or internal-only documents will fail.\n\n2. **Log Source Completeness** - They verify you're capturing security-relevant events across multiple layers: CloudTrail (API calls), VPC Flow Logs (network), GuardDuty findings, ALB/NLB access logs, S3 access logs, and application-level authentication logs.\n\n3. **Retention Period Enforcement** - Auditors check for **technical controls** (S3 Lifecycle policies, CloudWatch Logs retention settings) that automatically enforce retention—not just documentation saying \"we keep logs for 1 year.\"\n\n4. **Immutability & Integrity** - They look for evidence that logs cannot be tampered with (S3 Object Lock, CloudTrail Log File Validation, cross-account log aggregation).\n\n5. **Accessibility for Investigation** - Logs must be queryable. Having logs in Glacier without Athena tables or a SIEM integration suggests you're storing but not actually using them.\n\n### 🛠️ Relevant AWS Services\n\n| Service | Purpose in SEC-009 |\n|---------|-------------------|\n| AWS CloudTrail | API activity logging (mandatory) |\n| Amazon CloudWatch Logs | Application/system logs with retention settings |\n| VPC Flow Logs | Network traffic metadata |\n| Amazon S3 | Log storage with Lifecycle policies & Object Lock |\n| AWS Config | Configuration change logging |\n| Amazon GuardDuty | Security finding logs |\n| Amazon Athena | Log querying capability |\n| AWS Security Lake | Centralized security log aggregation (OCSF format) |\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n#### Evidence A: Customer Agreement Document\n**File Name Example:** `CustomerABC_Security_Logging_Agreement_v2.1.pdf`\n\n**Must Include:**\n- Customer company name and signature/approval\n- Explicit list of log sources to be captured:\n  ```\n  Example clause: \"MSP shall capture and retain the following security events:\n  - AWS CloudTrail logs (all regions, management & data events)\n  - VPC Flow Logs (all VPCs, ACCEPT and REJECT)\n  - GuardDuty findings\n  - ALB access logs\n  - S3 server access logs for buckets containing PII\n  - RDS audit logs for production databases\"\n  ```\n- Retention periods per log type:\n  ```\n  Example: \"CloudTrail: 365 days hot storage, 7 years archive\n           VPC Flow Logs: 90 days\n           GuardDuty findings: 365 days\"\n  ```\n- Date of agreement (must be current/active)\n\n#### Evidence B: Log Capture Implementation Screenshots\n**File Names:**\n- `CustomerABC_CloudTrail_Config_Screenshot.png`\n- `CustomerABC_VPCFlowLogs_Config_Screenshot.png`\n- `CustomerABC_GuardDuty_Enabled_Screenshot.png`\n- `CustomerABC_S3_AccessLogs_Config_Screenshot.png`\n\n**Must Show:**\n- AWS Console or CLI output showing enabled logging\n- Customer account ID visible in screenshot\n- Timestamp of screenshot\n- Configuration details matching the agreement\n\n#### Evidence C: Retention Implementation Proof\n**File Names:**\n- `CustomerABC_S3_Lifecycle_Policy.json`\n- `CustomerABC_CloudWatch_Retention_Settings.png`\n- `CustomerABC_S3_ObjectLock_Config.png`\n\n**Must Include:**\n- S3 Lifecycle policy JSON showing transition rules:\n  ```json\n  {\n    \"Rules\": [\n      {\n        \"ID\": \"CloudTrail-Retention-365days\",\n        \"Status\": \"Enabled\",\n        \"Transitions\": [\n          {\"Days\": 90, \"StorageClass\": \"STANDARD_IA\"},\n          {\"Days\": 180, \"StorageClass\": \"GLACIER\"}\n        ],\n        \"Expiration\": {\"Days\": 365}\n      }\n    ]\n  }\n  ```\n- CloudWatch Logs retention setting screenshot (showing specific day values)\n- Object Lock configuration for immutability (if claimed)\n\n#### Evidence D: Log Verification Report\n**File Name:** `CustomerABC_Security_Log_Verification_Report_2024Q4.pdf`\n\n**Must Include:**\n- Sample log entries from each source (redacted if needed)\n- Athena query results showing logs exist for required retention period\n- Oldest log entry date vs. retention requirement comparison\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Audit Current Customer Logging State (Day 1-2)\n**Responsible:** Security Engineer  \n**Time:** 4-6 hours per customer\n\nRun this AWS CLI script to inventory logging status:\n```bash\n# Check CloudTrail status\naws cloudtrail describe-trails --query 'trailList[*].[Name,IsMultiRegionTrail,IsLogging]'\n\n# Check VPC Flow Logs\naws ec2 describe-flow-logs --query 'FlowLogs[*].[FlowLogId,ResourceId,LogDestination,TrafficType]'\n\n# Check GuardDuty\naws guardduty list-detectors\n\n# Check CloudWatch Log Groups retention\naws logs describe-log-groups --query 'logGroups[*].[logGroupName,retentionInDays]'\n```\n\nCreate a gap analysis spreadsheet comparing current state vs. what's needed.\n\n### Step 2: Draft Security Logging Agreement (Day 3-4)\n**Responsible:** Service Delivery Manager + Security Architect  \n**Time:** 2-3 hours\n\nCreate agreement using this structure:\n1. **Scope** - Which AWS accounts are covered\n2. **Log Sources Table** - Log type, source, destination, retention\n3. **Responsibilities** - Who enables, who monitors, who responds\n4. **Review Cadence** - Annual review of requirements\n5. **Signature Block** - Customer authorized representative\n\n**Pro Tip:** Use your MSA/SOW amendment process rather than creating a standalone document—auditors prefer seeing this integrated into your commercial relationship.\n\n### Step 3: Implement Centralized Logging Architecture (Day 5-10)\n**Responsible:** Cloud Engineer  \n**Time:** 8-16 hours\n\nDeploy this architecture using CloudFormation/Terraform:\n```\nCustomer Account(s)\n    └── CloudTrail → S3 (Log Archive Account)\n    └── VPC Flow Logs → CloudWatch Logs → Kinesis Firehose → S3\n    └── GuardDuty → EventBridge → S3\n    \nLog Archive Account (Centralized)\n    └── S3 Bucket with:\n        - Bucket Policy (deny delete)\n        - Object Lock (Governance mode)\n        - Lifecycle Policy\n        - Server-side encryption (SSE-S3 or SSE-KMS)\n```\n\n### Step 4: Configure Retention Policies (Day 11-12)\n**Responsible:** Cloud Engineer  \n**Time:** 2-4 hours\n\nApply S3 Lifecycle policy matching customer agreement:\n```bash\naws s3api put-bucket-lifecycle-configuration \\\n  --bucket customer-abc-security-logs \\\n  --lifecycle-configuration file://lifecycle-policy.json\n```\n\nSet CloudWatch Logs retention:\n```bash\naws logs put-retention-policy \\\n  --log-group-name /aws/vpc/flowlogs/customer-abc \\\n  --retention-in-days 90\n```\n\n### Step 5: Enable Log Integrity Verification (Day 13)\n**Responsible:** Security Engineer  \n**Time:** 2 hours\n\nEnable CloudTrail log file validation:\n```bash\naws cloudtrail update-trail \\\n  --name customer-abc-trail \\\n  --enable-log-file-validation\n```\n\nEnable S3 Object Lock (must be done at bucket creation or with support):\n```bash\naws s3api put-object-lock-configuration \\\n  --bucket customer-abc-security-logs \\\n  --object-lock-configuration '{\"ObjectLockEnabled\":\"Enabled\",\"Rule\":{\"DefaultRetention\":{\"Mode\":\"GOVERNANCE\",\"Days\":365}}}'\n```\n\n### Step 6: Create Verification Queries (Day 14)\n**Responsible:** Security Engineer  \n**Time:** 3-4 hours\n\nSet up Athena table for CloudTrail:\n```sql\nCREATE EXTERNAL TABLE cloudtrail_logs (\n  eventVersion STRING,\n  eventTime STRING,\n  eventSource STRING,\n  eventName STRING,\n  awsRegion STRING,\n  sourceIPAddress STRING,\n  userAgent STRING,\n  userIdentity STRUCT<...>\n)\nPARTITIONED BY (region STRING, year STRING, month STRING, day STRING)\nSTORED AS PARQUET\nLOCATION 's3://customer-abc-security-logs/AWSLogs/';\n```\n\nRun verification query:\n```sql\nSELECT MIN(eventTime) as oldest_log, MAX(eventTime) as newest_log\nFROM cloudtrail_logs\nWHERE year = '2024';\n```\n\n### Step 7: Compile Evidence Package (Day 15)\n**Responsible:** Compliance Analyst  \n**Time:** 4-6 hours\n\n- Export signed agreement as PDF\n- Take timestamped screenshots with customer account ID visible\n- Export Lifecycle policy JSON\n- Generate log verification report with Athena query results\n- Create evidence index document mapping each piece to requirement\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Agreement Missing Specific Retention Periods\n**What Goes Wrong:** Customer agreement says \"logs will be retained per compliance requirements\" without specifying actual days/years.\n\n**Fix:** Always include a table like:\n| Log Type | Hot Storage | Archive | Total Retention |\n|----------|-------------|---------|-----------------|\n| CloudTrail | 90 days | 275 days | 365 days |\n| VPC Flow Logs | 90 days | N/A | 90 days |\n\n### ❌ Mistake 2: Showing Internal Policy Instead of Customer Agreement\n**What Goes Wrong:** Partners submit their internal \"Security Logging Standard\" document instead of a customer-specific agreement.\n\n**Fix:** Evidence must show customer acknowledgment. Use SOW exhibit, signed security addendum, or email approval from customer's authorized representative (with their title visible).\n\n### ❌ Mistake 3: Lifecycle Policy Doesn't Match Agreement\n**What Goes Wrong:** Agreement says 365 days, but S3 Lifecycle shows 90-day expiration.\n\n**Fix:** Before submitting, run this verification:\n```bash\naws s3api get-bucket-lifecycle-configuration --bucket customer-logs | jq '.Rules[].Expiration'\n```\nCompare output against agreement. They must match exactly.\n\n### ❌ Mistake 4: Logs Exist But Can't Prove Retention Period\n**What Goes Wrong:** Partner shows CloudTrail is enabled but cannot demonstrate logs actually exist for the full retention period.\n\n**Fix:** Run Athena query showing oldest log entry date:\n```sql\nSELECT MIN(eventtime) FROM cloudtrail_logs;\n```\nIf result shows logs only go back 45 days but you claim 365-day retention, you'll fail. For new implementations, document the start date and show Lifecycle policy will enforce retention going forward.\n\n### ❌ Mistake 5: Missing Data Event Logging for S3/Lambda\n**What Goes Wrong:** CloudTrail captures management events only, missing S3 object-level access or Lambda invocations that are security-relevant.\n\n**Fix:** If agreement includes S3 data events, verify configuration:\n```bash\naws cloudtrail get-event-selectors --trail-name customer-trail\n```\nMust show `\"ReadWriteType\": \"All\"` for S3 data events if required.\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|------------|---------------------|---------------|\n| ✅ 1 | Customer agreement explicitly lists all log types | Read document section-by-section | Each log source (CloudTrail, VPC Flow Logs, GuardDuty, etc.) is named with retention period |\n| ✅ 2 | Agreement is signed/approved by customer | Check for signature, email approval, or DocuSign completion | Customer representative name, title, and date visible |\n| ✅ 3 | CloudTrail is multi-region and logging | Run `aws cloudtrail get-trail-status` | `IsLogging: true` for all regions |\n| ✅ 4 | S3 Lifecycle policy matches retention requirement | Export policy JSON and compare to agreement | Expiration days ≥ agreed retention period |\n| ✅ 5 | CloudWatch Logs retention is set (not \"Never expire\") | Screenshot showing retention dropdown | Specific day value matching agreement |\n| ✅ 6 | Log integrity controls are enabled | Check CloudTrail validation + S3 Object Lock | `LogFileValidationEnabled: true` + Object Lock configured |\n| ✅ 7 | Can query logs for full retention period | Run Athena query for oldest log entry | `MIN(eventtime)` is older than (today - retention period) OR implementation date documented |\n\n### 🎯 Quality Criteria for Passing\n\n**Minimum Passing Evidence:**\n1. One customer agreement with specific log types AND retention periods\n2. Screenshots showing logging enabled in that customer's account\n3. Technical proof (Lifecycle policy, retention settings) showing retention enforcement\n4. Demonstration that logs are actually being captured (sample entries or query results)\n\n**Strong Evidence (Recommended):**\n- All of the above PLUS\n- Cross-account log aggregation architecture diagram\n- S3 Object Lock or CloudTrail log validation enabled\n- Athena/Security Lake integration showing logs are queryable\n- Monthly log verification report as part of operational process\n\n---\n\n## 📌 Quick Reference: Evidence Mapping\n\n| Requirement Component | Evidence Type | AWS Service Proof |\n|-----------------------|---------------|-------------------|\n| \"Defines requirements with customers\" | Signed agreement/SOW | N/A (document) |\n| \"Captures required security events\" | Console screenshots + CLI output | CloudTrail, VPC Flow Logs, GuardDuty, CloudWatch |\n| \"Implements controls for retention\" | Policy exports + configuration screenshots | S3 Lifecycle, CloudWatch retention, Object Lock |\n| \"Retention periods are honored\" | Query results showing log age | Athena, CloudWatch Logs Insights |",
      "language": "en",
      "createdAt": "2026-01-07T03:10:18.176Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SEC-010_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SEC-010",
      "category": "Security",
      "title": "SaaS Tooling Account Access",
      "advice": "# SEC-010: SaaS Tooling Account Access - Practical Advice Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Requirement Matters in AWS MSP Program\n\nThis requirement exists because MSP partners typically deploy monitoring, backup, security scanning, and cost optimization tools across multiple customer AWS accounts. Without proper cross-account access controls using IAM Roles with External IDs, customers face significant security risks including:\n\n- **Confused Deputy Problem**: Without External IDs, a malicious actor could trick your SaaS tool into accessing the wrong customer's account\n- **Credential Exposure**: Long-term access keys are far more vulnerable than temporary credentials from AssumeRole\n- **Audit Trail Gaps**: Direct access without role assumption doesn't create clear CloudTrail attribution\n\n### 🔎 What Auditors Specifically Look For\n\n1. **Complete SaaS Tool Inventory**: Auditors verify you've identified ALL third-party and internally-developed tools accessing customer accounts—not just the obvious ones like Datadog or CloudHealth, but also smaller utilities, scripts, and internal automation platforms\n\n2. **External ID Implementation Pattern**: They check that External IDs are:\n   - Unique per customer (not a single shared External ID across all customers)\n   - Cryptographically random or unpredictable (not customer names or sequential numbers)\n   - Stored securely and not exposed in documentation\n\n3. **Trust Policy Structure**: Auditors examine actual IAM role trust policies for correct `sts:ExternalId` condition syntax\n\n4. **Consistency Across Customer Base**: They may ask for evidence from multiple customers to verify the pattern is consistently applied\n\n5. **No Access Key Usage**: Verification that tools aren't using IAM user access keys as an alternative to role assumption\n\n### Relevant AWS Services & Features\n- **AWS IAM**: Cross-account roles, trust policies, External ID condition\n- **AWS STS**: AssumeRole API with ExternalId parameter\n- **AWS CloudTrail**: Logging of AssumeRole events showing External ID usage\n- **AWS Organizations**: SCPs that can enforce External ID requirements\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Format | Specific Content Required |\n|--------------|--------|---------------------------|\n| SaaS Tool Inventory | Excel/CSV | Tool name, vendor, purpose, AWS services accessed, customer accounts using it |\n| IAM Trust Policy Examples | JSON files | Actual trust policies from 2-3 customer accounts per tool |\n| External ID Management Documentation | PDF/Word | How External IDs are generated, stored, and rotated |\n| Architecture Diagram | Visio/Draw.io | Cross-account access flow showing role assumption |\n\n### 📄 Detailed Evidence Specifications\n\n**Evidence 1: SaaS Tool Inventory Spreadsheet**\n```\nFilename: SEC-010_SaaS_Tool_Inventory_v1.2.xlsx\n\nRequired Columns:\n- Tool Name (e.g., \"Datadog\", \"Veeam Backup for AWS\", \"CloudHealth\")\n- Tool Category (Monitoring/Backup/Security/Cost Management/Custom)\n- Vendor Name & Contact\n- AWS Services Accessed (EC2, S3, CloudWatch, etc.)\n- Access Method (Must be \"IAM Role with External ID\")\n- Number of Customer Accounts Using Tool\n- Role Name Pattern (e.g., \"DatadogIntegrationRole\")\n- Last Security Review Date\n```\n\n**Evidence 2: IAM Trust Policy Examples**\n```\nFilename: SEC-010_TrustPolicy_[ToolName]_[CustomerCode].json\n\nExample for Datadog:\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"AWS\": \"arn:aws:iam::464622532012:root\"\n      },\n      \"Action\": \"sts:AssumeRole\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"sts:ExternalId\": \"a1b2c3d4e5f6789012345678901234567890abcd\"\n        }\n      }\n    }\n  ]\n}\n```\n\n**Evidence 3: External ID Management Procedure**\n```\nFilename: SEC-010_ExternalID_Management_Procedure.pdf\n\nMust Include:\n- External ID generation method (UUID v4, cryptographic random, etc.)\n- Storage location (secrets manager, encrypted database)\n- Access controls for External ID retrieval\n- Rotation procedure and frequency\n- Customer communication process for External ID changes\n```\n\n### Example Evidence File Names\n- `SEC-010_SaaS_Tool_Inventory_2024Q4.xlsx`\n- `SEC-010_TrustPolicy_Datadog_CUST001.json`\n- `SEC-010_TrustPolicy_Datadog_CUST002.json`\n- `SEC-010_TrustPolicy_CloudHealth_CUST001.json`\n- `SEC-010_TrustPolicy_VeeamBackup_CUST003.json`\n- `SEC-010_ExternalID_Generation_Screenshot.png`\n- `SEC-010_CrossAccount_Access_Architecture.pdf`\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Discover All Cross-Account Access Tools (2-3 days)\n**Responsible**: Security Team + DevOps Lead\n\n🔧 **Specific Actions**:\n```bash\n# Run this AWS CLI command against your MSP management account\n# to find all roles that assume into customer accounts\naws iam list-roles --query \"Roles[?contains(AssumeRolePolicyDocument.Statement[].Principal.AWS, 'arn:aws:iam::')]\"\n```\n\n- Interview each team: \"What tools do you use that connect to customer AWS accounts?\"\n- Check CI/CD pipelines for AWS credentials or role assumptions\n- Review your internal ticketing system for tool deployment requests\n- Audit your SaaS vendor contracts for AWS integration mentions\n- Check AWS Marketplace subscriptions that require cross-account access\n\n**Common tools to verify**:\n| Category | Examples to Check |\n|----------|------------------|\n| Monitoring | Datadog, New Relic, Dynatrace, Splunk, Sumo Logic |\n| Backup | Veeam, Druva, Commvault, Clumio |\n| Security | Prisma Cloud, Lacework, Wiz, Orca Security, Qualys |\n| Cost | CloudHealth, CloudCheckr, Spot.io, Apptio |\n| Custom | Internal automation tools, deployment scripts |\n\n---\n\n### Step 2: Audit Existing IAM Role Configurations (2-3 days)\n**Responsible**: Cloud Security Engineer\n\n🔧 **Specific Actions**:\n\nFor each customer account, extract trust policies:\n```bash\n# Script to audit trust policies in customer account\nROLE_NAME=\"DatadogIntegrationRole\"\naws iam get-role --role-name $ROLE_NAME --query 'Role.AssumeRolePolicyDocument' --output json\n```\n\n**Create audit checklist per role**:\n- [ ] Trust policy contains `sts:ExternalId` condition\n- [ ] External ID is unique (not shared across customers)\n- [ ] External ID is not predictable (not \"customer-name-123\")\n- [ ] Principal is specific (not `\"AWS\": \"*\"`)\n- [ ] Role has appropriate permission boundaries\n\n---\n\n### Step 3: Remediate Non-Compliant Configurations (3-5 days)\n**Responsible**: DevOps Team + Customer Success\n\n🔧 **Specific Actions**:\n\nFor roles missing External IDs, create remediation tickets:\n```\nTemplate: JIRA Ticket for External ID Remediation\n\nTitle: [SEC-010] Add External ID to {ToolName} role in {CustomerName} account\nPriority: High\nLabels: security, msp-audit, compliance\n\nDescription:\n- Current State: Role {RoleName} lacks External ID condition\n- Required State: Add External ID condition with unique value\n- External ID to Use: [Generate from secrets manager]\n- Tool Configuration Update: [Link to vendor documentation]\n```\n\n**Generate External IDs properly**:\n```python\n# Python script for generating compliant External IDs\nimport secrets\nimport string\n\ndef generate_external_id():\n    # 40-character alphanumeric External ID\n    alphabet = string.ascii_letters + string.digits\n    return ''.join(secrets.choice(alphabet) for _ in range(40))\n\n# Generate and store in AWS Secrets Manager\nexternal_id = generate_external_id()\n# Output: \"a7Bk9mNp2xQr5tYw8zAc3dFg6hJk1LmN4oPq0RsT\"\n```\n\n---\n\n### Step 4: Document External ID Management Process (1-2 days)\n**Responsible**: Security Architect\n\n🔧 **Specific Actions**:\n\nCreate procedure document with these sections:\n1. **Generation**: \"External IDs are generated using Python secrets module, producing 40-character alphanumeric strings\"\n2. **Storage**: \"External IDs are stored in AWS Secrets Manager under path `/msp/customers/{customer-id}/external-ids/{tool-name}`\"\n3. **Access Control**: \"Only the MSP-ToolIntegration IAM role can retrieve External IDs\"\n4. **Rotation**: \"External IDs are rotated annually or upon customer request\"\n\n---\n\n### Step 5: Collect Trust Policy Evidence (1 day)\n**Responsible**: Compliance Analyst\n\n🔧 **Specific Actions**:\n\n```bash\n# Automated evidence collection script\n#!/bin/bash\nTOOLS=(\"Datadog\" \"CloudHealth\" \"VeeamBackup\")\nCUSTOMERS=(\"CUST001\" \"CUST002\" \"CUST003\")\n\nfor tool in \"${TOOLS[@]}\"; do\n  for customer in \"${CUSTOMERS[@]}\"; do\n    ROLE_NAME=\"${tool}IntegrationRole\"\n    aws iam get-role --role-name $ROLE_NAME \\\n      --query 'Role.AssumeRolePolicyDocument' \\\n      --output json > \"SEC-010_TrustPolicy_${tool}_${customer}.json\"\n  done\ndone\n```\n\n**Screenshot requirements**:\n- AWS Console showing IAM role trust relationship tab\n- Tool vendor console showing External ID configuration\n- Secrets Manager showing External ID storage (values redacted)\n\n---\n\n### Step 6: Create Architecture Diagram (0.5 days)\n**Responsible**: Solutions Architect\n\n🔧 **Specific Actions**:\n\nCreate diagram showing:\n```\n[SaaS Tool Account] \n    │\n    │ AssumeRole with External ID\n    ▼\n[Customer AWS Account]\n    │\n    ├── IAM Role: DatadogIntegrationRole\n    │   └── Trust Policy with External ID condition\n    │\n    └── CloudTrail logs AssumeRole event\n```\n\nInclude in diagram:\n- SaaS vendor's AWS account ID\n- Your MSP management account\n- Customer account(s)\n- Role names and External ID flow\n- CloudTrail logging\n\n---\n\n### Step 7: Compile Final Evidence Package (0.5 days)\n**Responsible**: MSP Program Manager\n\nCreate folder structure:\n```\nSEC-010_SaaS_Tooling_Access/\n├── 01_Tool_Inventory/\n│   └── SEC-010_SaaS_Tool_Inventory_2024Q4.xlsx\n├── 02_Trust_Policies/\n│   ├── Datadog/\n│   │   ├── SEC-010_TrustPolicy_Datadog_CUST001.json\n│   │   └── SEC-010_TrustPolicy_Datadog_CUST002.json\n│   ├── CloudHealth/\n│   │   └── SEC-010_TrustPolicy_CloudHealth_CUST001.json\n│   └── VeeamBackup/\n│       └── SEC-010_TrustPolicy_VeeamBackup_CUST003.json\n├── 03_Procedures/\n│   └── SEC-010_ExternalID_Management_Procedure.pdf\n├── 04_Architecture/\n│   └── SEC-010_CrossAccount_Access_Diagram.pdf\n└── 05_Screenshots/\n    ├── SEC-010_IAM_Console_TrustPolicy.png\n    └── SEC-010_SecretsManager_ExternalID_Storage.png\n```\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Using Shared External IDs Across Customers\n**Problem**: Using the same External ID (like your company name) for all customers\n```json\n// WRONG - Same External ID for everyone\n\"Condition\": {\n  \"StringEquals\": {\n    \"sts:ExternalId\": \"MyMSPCompany2024\"\n  }\n}\n```\n**Why it fails audit**: Defeats the purpose of External IDs—if one customer's ID is compromised, all customers are at risk\n\n**Solution**: Generate unique External ID per customer-tool combination\n\n---\n\n### ❌ Mistake 2: Forgetting Internal/Custom Tools\n**Problem**: Only listing commercial SaaS tools, omitting internal automation scripts\n**Why it fails audit**: Auditors specifically ask \"Do you have ANY internal tools that access customer accounts?\"\n\n**Solution**: Include in inventory:\n- Custom Python/Bash scripts for automation\n- Internal monitoring dashboards\n- Deployment pipelines that assume customer roles\n- Support team troubleshooting tools\n\n---\n\n### ❌ Mistake 3: Incomplete Trust Policy Evidence\n**Problem**: Showing only the trust policy without demonstrating the External ID is actually used\n```json\n// Shows External ID in policy, but is the tool actually sending it?\n```\n**Why it fails audit**: Auditors want proof the External ID is configured on BOTH sides\n\n**Solution**: Provide:\n- IAM role trust policy (AWS side)\n- Screenshot of tool configuration showing External ID entry (tool side)\n- CloudTrail log showing successful AssumeRole with External ID\n\n---\n\n### ❌ Mistake 4: Predictable External ID Patterns\n**Problem**: Using patterns like `{customer-name}-{date}` or sequential numbers\n```\n\"ExternalId\": \"acme-corp-2024\"  // Predictable!\n\"ExternalId\": \"customer-001\"    // Sequential!\n```\n**Why it fails audit**: Predictable IDs can be guessed by attackers\n\n**Solution**: Use cryptographically random strings (minimum 32 characters)\n\n---\n\n### ❌ Mistake 5: Missing Tool from Inventory\n**Problem**: Auditor discovers a cross-account role during review that wasn't in your inventory\n**Why it fails audit**: Suggests incomplete security oversight\n\n**Solution**: Before submission, run discovery:\n```bash\n# In each customer account, find all roles with cross-account trust\naws iam list-roles --query \"Roles[?AssumeRolePolicyDocument.Statement[?Principal.AWS!=null]]\" --output table\n```\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n### Pre-Submission Verification\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | **Tool inventory is complete** | Cross-reference with vendor contracts, team interviews, and IAM role discovery scan | Every cross-account role has corresponding tool entry |\n| 2 | **All trust policies include External ID condition** | JSON validation: `grep -l \"sts:ExternalId\" *.json` | 100% of policy files contain the condition key |\n| 3 | **External IDs are unique per customer** | Extract all External IDs to spreadsheet, check for duplicates | Zero duplicate External IDs across customers |\n| 4 | **External IDs are cryptographically random** | Verify generation method documentation; IDs should be 32+ chars, alphanumeric | No patterns, no customer names, no sequential values |\n| 5 | **Both sides configured** | For each tool, have evidence of IAM policy AND tool-side configuration | Matching External ID visible in both AWS and tool console |\n| 6 | **No IAM access keys in use** | Check tool configurations for access key fields | All tools use \"IAM Role\" or \"AssumeRole\" method, not access keys |\n| 7 | **Evidence from multiple customers** | Collect trust policies from at least 3 different customers per tool | Demonstrates consistent implementation, not one-off |\n\n### 🎯 Quality Criteria for Passing\n\n**Inventory Spreadsheet**:\n- [ ] Minimum 3 tools listed (most MSPs have 5-10)\n- [ ] All columns populated with specific data\n- [ ] Includes at least one internal/custom tool\n\n**Trust Policy JSON Files**:\n- [ ] Valid JSON syntax (use `jq . filename.json` to validate)\n- [ ] Contains `sts:ExternalId` in Condition block\n- [ ] Principal specifies exact AWS account ARN (not wildcard)\n- [ ] External ID is ",
      "language": "en",
      "createdAt": "2026-01-07T03:11:23.973Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SECP-001_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SECP-001",
      "category": "Security",
      "title": "Access Key Exposure Detection",
      "advice": "# SECP-001: Access Key Exposure Detection - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\n\nAccess Key Exposure Detection is a **core security capability** that AWS MSP Partners must demonstrate. When customer access keys are exposed on public repositories like GitHub, attackers can exploit them within minutes for cryptocurrency mining or data breaches. AWS considers this a \"RISK\" event because compromised credentials directly threaten customer infrastructure and AWS's ecosystem reputation.\n\nThis requirement validates that MSP Partners can **protect customers proactively** rather than reactively responding after damage occurs.\n\n### 🔎 Key Points Auditors Evaluate\n\n1. **Automation Verification**: Auditors check if AWS Health events with `eventTypeCategory: \"RISK\"` and `eventTypeCode: \"AWS_RISK_CREDENTIALS_EXPOSED\"` trigger automatic ticket creation - manual monitoring fails this requirement\n\n2. **Multi-Account Coverage**: Evidence must show the mechanism covers ALL managed customer accounts, not just a subset - auditors specifically ask \"How do you ensure new customer accounts are automatically included?\"\n\n3. **Severity Mapping**: Tickets must be created at **highest severity/P1** level - creating medium or low priority tickets is a common failure point\n\n4. **Response Procedure Completeness**: The documented procedure must include specific steps for credential deletion/rotation, not just \"investigate and remediate\"\n\n5. **Integration Proof**: Auditors want to see actual ITSM integration (ServiceNow, Jira, PagerDuty) not just email notifications\n\n### 🛠️ Relevant AWS Services\n\n- **AWS Health API** (specifically `DescribeEvents` with `eventTypeCategory: \"RISK\"`)\n- **Amazon EventBridge** (for event routing)\n- **AWS Organizations** (for multi-account aggregation)\n- **AWS Lambda** (for ticket creation automation)\n- **AWS Security Hub** (optional but recommended for centralized findings)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Package\n\n| Evidence Type | Document Name Example | Format |\n|--------------|----------------------|--------|\n| Response Procedure | `SEC-PROC-001_Exposed_Credential_Response_Procedure_v2.1.pdf` | PDF/Word |\n| Architecture Diagram | `AWS_Health_RISK_Event_Integration_Architecture.png` | Visio/Draw.io |\n| Automation Code/Config | `exposed-key-detection-lambda.py` + `eventbridge-rule.json` | Code files |\n| ITSM Integration Proof | `ServiceNow_Integration_Screenshots.pdf` | Screenshots |\n| Test Execution Record | `RISK_Event_Simulation_Test_Report_2024Q4.pdf` | PDF |\n\n### 📄 Key Content for Response Procedure Document\n\nYour documented procedure **must include** these specific sections:\n\n```markdown\n1. SCOPE\n   - List of customer accounts covered (or reference to account inventory)\n   - Statement: \"This procedure applies to all AWS Health RISK events \n     related to exposed credentials\"\n\n2. DETECTION MECHANISM\n   - EventBridge rule configuration details\n   - Lambda function logic summary\n   - ITSM ticket creation parameters (severity: Critical/P1)\n\n3. RESPONSE STEPS (with specific timeframes)\n   Step 1: Acknowledge ticket within 15 minutes\n   Step 2: Identify exposed IAM user/access key from event details\n   Step 3: Disable the exposed access key (NOT delete immediately)\n   Step 4: Contact customer within 30 minutes\n   Step 5: Investigate CloudTrail for unauthorized usage\n   Step 6: Rotate credential or delete based on customer decision\n   Step 7: Document remediation in ticket\n   Step 8: Conduct post-incident review\n\n4. ESCALATION MATRIX\n   - Who to contact if customer unreachable\n   - Executive escalation after X hours\n\n5. CREDENTIAL ROTATION PROCEDURE\n   - Specific AWS CLI/Console steps for key rotation\n   - Application credential update process\n```\n\n### 📸 Screenshot Evidence Examples\n\n**ITSM Ticket Screenshot Must Show:**\n- Ticket created with \"Critical\" or \"P1\" severity\n- Source showing \"AWS Health\" or automation name\n- Customer account ID in ticket details\n- Timestamp proving automated creation (not manual)\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Enable AWS Health Organizational View (Day 1-2)\n**Responsible**: Cloud Platform Engineer\n\n```bash\n# In Management Account\naws organizations enable-aws-service-access \\\n    --service-principal health.amazonaws.com\n\n# Verify\naws health describe-events-for-organization \\\n    --filter \"eventTypeCategories=accountNotification\"\n```\n\n⚠️ **Requirement**: AWS Business or Enterprise Support plan needed for Health API access\n\n---\n\n### Step 2: Create EventBridge Rule for RISK Events (Day 2-3)\n**Responsible**: Security Engineer\n\nCreate rule in **management account** with this exact pattern:\n\n```json\n{\n  \"source\": [\"aws.health\"],\n  \"detail-type\": [\"AWS Health Event\"],\n  \"detail\": {\n    \"eventTypeCategory\": [\"accountNotification\"],\n    \"eventTypeCode\": [\"AWS_RISK_CREDENTIALS_EXPOSED\"]\n  }\n}\n```\n\n**Critical**: Also include pattern for `AWS_RISK_CREDENTIALS_COMPROMISED` variant\n\n---\n\n### Step 3: Develop Lambda for ITSM Integration (Day 3-5)\n**Responsible**: DevOps Engineer\n\nLambda function must extract and pass:\n- `affectedAccount` (customer account ID)\n- `eventArn` (for reference)\n- `eventDescription` (contains exposed key ID)\n- `startTime` (for SLA tracking)\n\n**ServiceNow API Example Payload:**\n```python\nticket_payload = {\n    \"short_description\": f\"[P1] AWS Exposed Credential - Account {account_id}\",\n    \"urgency\": \"1\",\n    \"impact\": \"1\",\n    \"category\": \"Security Incident\",\n    \"description\": event_description,\n    \"assignment_group\": \"Cloud Security Team\"\n}\n```\n\n---\n\n### Step 4: Document Response Procedure (Day 5-7)\n**Responsible**: Security Manager\n\nUse the template structure from Section 2. Include:\n- Actual AWS CLI commands for key rotation\n- Screenshots of your ITSM workflow\n- Contact information for escalation\n\n---\n\n### Step 5: Conduct Integration Test (Day 7-8)\n**Responsible**: QA/Security Team\n\n**Testing Method** (since you can't trigger real RISK events):\n```bash\n# Create test event via EventBridge\naws events put-events --entries '[{\n  \"Source\": \"aws.health.test\",\n  \"DetailType\": \"AWS Health Event\",\n  \"Detail\": \"{\\\"eventTypeCategory\\\":\\\"accountNotification\\\",\\\"eventTypeCode\\\":\\\"AWS_RISK_CREDENTIALS_EXPOSED\\\",\\\"affectedAccount\\\":\\\"123456789012\\\"}\"\n}]'\n```\n\nDocument the test with:\n- Timestamp of test event\n- Screenshot of created ticket\n- Time elapsed from event to ticket creation\n\n---\n\n### Step 6: Create Architecture Diagram (Day 8-9)\n**Responsible**: Solutions Architect\n\nInclude these components:\n```\n[Customer Accounts] → [AWS Health (Org View)] → [EventBridge Rule] \n    → [Lambda Function] → [ITSM/ServiceNow] → [Security Team Alert]\n```\n\n---\n\n### Step 7: Compile Evidence Package (Day 9-10)\n**Responsible**: MSP Program Manager\n\nCreate single PDF combining:\n1. Response procedure document\n2. Architecture diagram\n3. EventBridge rule configuration export\n4. Lambda code snippet (key sections)\n5. Test execution screenshots with timestamps\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Email-Only Notification\n**Problem**: Setting up SNS email alerts without ITSM ticket creation\n\n**Why It Fails**: AWS explicitly requires \"automated system to create new tickets in an ITSM or security ticketing system\" - email is not a ticketing system\n\n**Solution**: Integrate with ServiceNow, Jira Service Management, PagerDuty, or similar ITSM tool\n\n---\n\n### ❌ Mistake 2: Missing Multi-Account Coverage Proof\n**Problem**: Showing automation only for one account\n\n**Why It Fails**: Auditors ask \"How do you onboard new customer accounts?\" - if answer is \"manually add EventBridge rule,\" this fails\n\n**Solution**: Use AWS Organizations + delegated administrator pattern so new accounts automatically inherit monitoring\n\n---\n\n### ❌ Mistake 3: Procedure Missing Rotation Steps\n**Problem**: Document says \"rotate or delete credentials\" without specific steps\n\n**Why It Fails**: AWS requirement explicitly states \"documented procedure...that includes deleting or rotating the exposed credentials\"\n\n**Solution**: Include actual AWS CLI commands:\n```bash\n# Disable key immediately\naws iam update-access-key --access-key-id AKIAEXAMPLE --status Inactive --user-name compromised-user\n\n# Create new key\naws iam create-access-key --user-name compromised-user\n\n# Delete old key after application update\naws iam delete-access-key --access-key-id AKIAEXAMPLE --user-name compromised-user\n```\n\n---\n\n### ❌ Mistake 4: Non-Critical Ticket Severity\n**Problem**: Tickets created as \"Medium\" or \"P3\" priority\n\n**Why It Fails**: Requirement states \"highest severity\" - auditors check actual ticket screenshots\n\n**Solution**: Configure ITSM integration to always create P1/Critical tickets for this event type\n\n---\n\n### ❌ Mistake 5: No Test Evidence\n**Problem**: Submitting procedure document without proof of execution\n\n**Why It Fails**: Auditors want evidence the automation actually works, not just documentation\n\n**Solution**: Conduct quarterly tests and maintain test records with timestamps showing end-to-end flow\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| 1 | EventBridge rule captures RISK events | Export rule JSON, verify `eventTypeCode` pattern includes `AWS_RISK_CREDENTIALS_EXPOSED` | Pattern matches exactly |\n| 2 | Multi-account coverage enabled | Run `aws health describe-events-for-organization` from management account | Returns events from multiple accounts |\n| 3 | ITSM ticket auto-creation works | Review test execution screenshots | Ticket created <5 minutes from event |\n| 4 | Ticket severity is highest | Check ticket screenshot | Shows \"Critical\", \"P1\", or \"Severity 1\" |\n| 5 | Response procedure includes rotation commands | Search document for \"aws iam\" commands | Contains disable, create, delete key commands |\n| 6 | Procedure has timeframes | Review SLA section | Specific times (e.g., \"acknowledge within 15 minutes\") |\n| 7 | Architecture diagram shows complete flow | Visual review | Shows: Health API → EventBridge → Lambda → ITSM |\n\n### 📋 Pre-Submission Quality Check\n\n**Ask yourself these questions:**\n\n1. \"If an auditor asks 'Show me a ticket created by this automation,' can I provide one?\" ✓\n2. \"Does my procedure tell a new team member exactly what AWS commands to run?\" ✓\n3. \"If we onboard a new customer tomorrow, will they automatically be protected?\" ✓\n4. \"Is the ticket severity explicitly set to Critical/P1 in my Lambda code?\" ✓\n\n### 🎯 Evidence Quality Indicators\n\n| Quality Level | Characteristics |\n|--------------|-----------------|\n| **Pass** | Procedure + architecture + test evidence with P1 tickets |\n| **Strong Pass** | Above + quarterly test records + runbook with screenshots |\n| **Fail** | Email-only alerts, or procedure without specific rotation steps |\n\n---\n\n## 💡 Pro Tip for Audit Day\n\nWhen auditors ask about this control, be prepared to **demonstrate live**:\n1. Show the EventBridge rule in console\n2. Show a historical ticket created by automation\n3. Walk through the response procedure step-by-step\n\nHaving a \"demo account\" with test evidence ready significantly increases auditor confidence.",
      "language": "en",
      "createdAt": "2026-01-07T02:33:46.037Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    },
    {
      "id": "SECP-002_en_20260107_102612_bedrock_anthropic-claude-opus-4-5-2025",
      "itemId": "SECP-002",
      "category": "Security",
      "title": "Public Resources",
      "advice": "# SECP-002: Public Resources - Practical Preparation Guide\n\n## 1. 📋 Understanding Requirements\n\n### Why This Item is Critical in AWS MSP Program\nPublic exposure incidents are the most common and impactful security failures in AWS environments. A single misconfigured S3 bucket can lead to massive data breaches affecting your customers. AWS requires MSP Partners to demonstrate **proactive prevention capabilities**, not just reactive detection. This requirement validates that you have systematic controls preventing \"accidental public\" scenarios that have caused numerous high-profile breaches.\n\n### 🔍 Key Points Auditors Evaluate\n\n1. **Coverage Completeness**: Auditors verify your tooling covers ALL 7 specified resource types (S3, RDS instances, EC2, Security Groups, EBS snapshots, RDS snapshots, AMIs) - partial coverage fails\n\n2. **Prevention vs Detection Balance**: They look for preventive controls (SCPs, S3 Block Public Access) alongside detective controls (Config Rules) - detection-only approaches receive pushback\n\n3. **Automated Remediation Evidence**: Manual review processes alone are insufficient; auditors want to see automated alerting and ideally auto-remediation workflows\n\n4. **Multi-Account Strategy**: Your procedure must address how you handle public resource detection across ALL customer accounts in your management scope\n\n5. **Response Time SLAs**: Documented maximum time from detection to remediation (typically expecting <4 hours for critical exposures)\n\n### Relevant AWS Services\n- **AWS Config** (Config Rules for each resource type)\n- **AWS Security Hub** (aggregated findings)\n- **S3 Block Public Access** (account and bucket level)\n- **AWS Organizations SCPs** (preventive guardrails)\n- **Amazon Macie** (S3-specific sensitive data exposure)\n- **IAM Access Analyzer** (external access detection)\n- **AWS Trusted Advisor** (public resource checks)\n\n---\n\n## 2. ✅ Evidence to Prepare\n\n### Required Evidence Documents\n\n| Evidence Type | Document Name Example | Format |\n|--------------|----------------------|--------|\n| Master Procedure | `MSP-SEC-002_Public_Resource_Prevention_Procedure_v2.1.pdf` | PDF (signed) |\n| Technical Implementation Guide | `Public_Exposure_Detection_Technical_Runbook.docx` | Word/PDF |\n| Config Rules Inventory | `AWS_Config_Rules_Public_Resource_Matrix.xlsx` | Excel |\n| Alert/Response Workflow | `Public_Exposure_Incident_Response_Workflow.vsdx` | Visio/Lucidchart |\n| Evidence of Active Monitoring | `SecurityHub_Public_Resource_Findings_Dashboard_Screenshot.png` | Screenshots |\n| Remediation Log Sample | `Public_Exposure_Remediation_Log_Q4_2024.xlsx` | Excel |\n\n### 📄 Key Content for Master Procedure Document\n\n**Section 1: Scope & Coverage Matrix**\n```\n| Resource Type      | Prevention Control        | Detection Control           | Remediation Method    |\n|--------------------|---------------------------|-----------------------------|-----------------------|\n| S3 Buckets         | S3 Block Public Access    | Config: s3-bucket-public-*  | Auto-remediate via Lambda |\n| RDS Instances      | SCP deny public           | Config: rds-instance-public-access-check | Alert + Manual |\n| EC2 Instances      | SCP restrict EIP          | Config: ec2-instance-no-public-ip | Alert + Manual |\n| Security Groups    | SCP deny 0.0.0.0/0        | Config: restricted-ssh, restricted-common-ports | Auto-remediate |\n| EBS Snapshots      | Default encryption SCP    | Config: ebs-snapshot-public-restorable-check | Auto-remediate |\n| RDS Snapshots      | SCP deny public share     | Config: rds-snapshots-public-prohibited | Auto-remediate |\n| AMIs               | SCP deny public AMI       | Custom Config Rule          | Alert + Manual |\n```\n\n**Section 2: Response SLAs**\n- Critical (S3 with sensitive data, RDS public): 1 hour detection, 4 hour remediation\n- High (Public Security Groups on production): 4 hour detection, 24 hour remediation\n- Medium (Public AMI, EBS snapshot): 24 hour detection, 72 hour remediation\n\n**Section 3: Escalation Path**\n- L1: SOC Analyst → L2: Cloud Security Engineer → L3: Security Manager → Customer CISO\n\n---\n\n## 3. 📝 Step-by-Step Preparation Guide\n\n### Step 1: Deploy S3 Block Public Access at Organization Level (Day 1-2)\n**Responsible**: Cloud Security Engineer  \n**Time**: 4 hours\n\n```bash\n# Enable S3 Block Public Access for all accounts via AWS Organizations\naws s3control put-public-access-block \\\n    --account-id <management-account-id> \\\n    --public-access-block-configuration \\\n    \"BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\"\n```\n\n**Screenshot Evidence**: Capture S3 console showing \"Block Public Access settings for this account: On\" for 3+ customer accounts\n\n---\n\n### Step 2: Create Preventive SCPs for All 7 Resource Types (Day 2-4)\n**Responsible**: Cloud Architect  \n**Time**: 8 hours\n\n**SCP Example - Prevent Public RDS:**\n```json\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"DenyPublicRDS\",\n      \"Effect\": \"Deny\",\n      \"Action\": [\n        \"rds:CreateDBInstance\",\n        \"rds:ModifyDBInstance\"\n      ],\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"Bool\": {\n          \"rds:PubliclyAccessible\": \"true\"\n        }\n      }\n    }\n  ]\n}\n```\n\n**Evidence**: Export all SCPs with naming convention `SCP-PublicResource-{ResourceType}`\n\n---\n\n### Step 3: Deploy AWS Config Conformance Pack (Day 4-5)\n**Responsible**: DevOps Engineer  \n**Time**: 6 hours\n\nDeploy the **Operational Best Practices for Public Resources** conformance pack containing:\n- `s3-bucket-public-read-prohibited`\n- `s3-bucket-public-write-prohibited`\n- `rds-instance-public-access-check`\n- `ec2-instance-no-public-ip`\n- `restricted-ssh`\n- `restricted-common-ports`\n- `ebs-snapshot-public-restorable-check`\n- `rds-snapshots-public-prohibited`\n\n**Custom Rule Required for AMIs:**\n```python\n# Lambda function for custom Config rule\ndef evaluate_compliance(configuration_item):\n    ami_id = configuration_item['configuration']['imageId']\n    ec2 = boto3.client('ec2')\n    response = ec2.describe_image_attribute(\n        ImageId=ami_id,\n        Attribute='launchPermission'\n    )\n    if any(perm.get('Group') == 'all' for perm in response['LaunchPermissions']):\n        return 'NON_COMPLIANT'\n    return 'COMPLIANT'\n```\n\n---\n\n### Step 4: Configure Security Hub Aggregation (Day 5-6)\n**Responsible**: Security Operations  \n**Time**: 4 hours\n\n1. Enable Security Hub in all regions across all managed accounts\n2. Configure cross-account aggregation to central security account\n3. Create custom insight for public resources:\n\n```\nInsight Name: \"Public Resource Exposure - All Customers\"\nFilters:\n- Type STARTS_WITH \"Software and Configuration Checks/AWS Security Best Practices\"\n- RecordState = ACTIVE\n- Compliance.Status = FAILED\n- ResourceType IN [AwsS3Bucket, AwsRdsDbInstance, AwsEc2Instance, AwsEc2SecurityGroup, AwsEc2Snapshot]\n```\n\n**Evidence**: Screenshot of Security Hub dashboard showing aggregated findings\n\n---\n\n### Step 5: Build Auto-Remediation Workflows (Day 6-8)\n**Responsible**: Automation Engineer  \n**Time**: 12 hours\n\n**EventBridge Rule + Lambda for S3 Auto-Remediation:**\n```yaml\n# CloudFormation snippet\nPublicS3RemediationRule:\n  Type: AWS::Events::Rule\n  Properties:\n    EventPattern:\n      source:\n        - aws.config\n      detail-type:\n        - Config Rules Compliance Change\n      detail:\n        configRuleName:\n          - s3-bucket-public-read-prohibited\n          - s3-bucket-public-write-prohibited\n        newEvaluationResult:\n          complianceType:\n            - NON_COMPLIANT\n    Targets:\n      - Arn: !GetAtt RemediationLambda.Arn\n        Id: RemediatePublicS3\n```\n\n---\n\n### Step 6: Document Procedure and Create Runbook (Day 8-9)\n**Responsible**: Security Manager  \n**Time**: 8 hours\n\nCreate procedure document with:\n- Flowchart showing detection → alert → triage → remediate → verify → close\n- RACI matrix for each resource type\n- Customer notification templates\n- Exception request process (some customers legitimately need public resources)\n\n---\n\n### Step 7: Conduct Tabletop Exercise and Collect Evidence (Day 10)\n**Responsible**: Security Team Lead  \n**Time**: 4 hours\n\n1. Intentionally create a public S3 bucket in test account\n2. Document detection time (should be <15 minutes)\n3. Execute remediation procedure\n4. Capture timestamps at each stage\n5. Create evidence package showing end-to-end workflow\n\n---\n\n## 4. ⚠️ Precautions and Common Mistakes\n\n### ❌ Mistake 1: Covering Only S3 and Security Groups\n**Problem**: Many MSPs focus heavily on S3 (most publicized) but neglect EBS snapshots and AMIs  \n**Solution**: Create explicit Config rules and SCPs for ALL 7 resource types; auditors specifically check for AMI and snapshot coverage\n\n### ❌ Mistake 2: Detection-Only Architecture\n**Problem**: Procedure shows Config Rules detecting issues but remediation is \"manual review within 7 days\"  \n**Solution**: Implement at least 3 auto-remediation workflows (S3, Security Groups, Snapshots are easiest) and document SLAs under 24 hours for manual items\n\n### ❌ Mistake 3: No Evidence of Actual Findings/Remediations\n**Problem**: Perfect procedure document but no proof it's being used  \n**Solution**: Include 2-3 sanitized examples of actual public resource findings and their remediation (redact customer names but show timestamps, resource IDs, actions taken)\n\n### ❌ Mistake 4: Missing Multi-Account Coverage Explanation\n**Problem**: Procedure assumes single-account but MSPs manage hundreds of accounts  \n**Solution**: Explicitly document:\n- How Config rules are deployed via StackSets/Control Tower\n- How Security Hub aggregates across accounts\n- How SCPs are applied at OU level\n\n### ❌ Mistake 5: No Exception Handling Process\n**Problem**: Procedure says \"all public resources are blocked\" but some customers need public S3 for static websites  \n**Solution**: Include documented exception process with:\n- Business justification requirement\n- Security review checklist for exceptions\n- Time-limited approvals with review dates\n- Compensating controls (CloudFront, WAF)\n\n---\n\n## 5. 🔍 Final Review Checklist\n\n| # | Check Item | Verification Method | Pass Criteria |\n|---|-----------|---------------------|---------------|\n| ✅ 1 | All 7 resource types have documented prevention controls | Cross-reference procedure table with SCP inventory | Each resource type has at least 1 SCP or native AWS prevention feature enabled |\n| ✅ 2 | All 7 resource types have detection controls | Verify Config Rules list in AWS Console | Config rules active and evaluating in all customer accounts |\n| ✅ 3 | Auto-remediation exists for at least S3 and Security Groups | Trigger test violation, verify auto-fix | Remediation completes within 15 minutes without manual intervention |\n| ✅ 4 | Security Hub shows aggregated public resource findings | Login to central security account | Single dashboard view showing findings from 3+ customer accounts |\n| ✅ 5 | Procedure includes specific SLAs with timeframes | Review procedure Section 2 | Detection SLA ≤4 hours, Remediation SLA ≤24 hours for critical resources |\n| ✅ 6 | Evidence of real-world execution exists | Review remediation logs | At least 2 documented incidents showing full detection→remediation cycle |\n| ✅ 7 | Exception process is documented and includes compensating controls | Review procedure exception section | Form template exists, approval workflow defined, compensating controls listed |\n\n### 🎯 Quality Criteria for Passing\n\n**Minimum Viable Evidence Package:**\n1. ✅ Signed procedure document (PDF, 10+ pages)\n2. ✅ Config Rules deployment evidence (screenshots from 3 accounts)\n3. ✅ SCP JSON files for all 7 resource types\n4. ✅ Security Hub aggregation screenshot\n5. ✅ One complete remediation case study with timestamps\n6. ✅ Architecture diagram showing prevention + detection + remediation flow\n\n**Auditor Red Flags That Cause Failure:**\n- 🚩 Procedure mentions \"periodic manual review\" as primary detection method\n- 🚩 No evidence of cross-account deployment\n- 🚩 Missing any of the 7 required resource types\n- 🚩 No auto-remediation capability demonstrated\n- 🚩 Procedure dated >12 months ago without review signature",
      "language": "en",
      "createdAt": "2026-01-07T02:34:41.369Z",
      "version": "20260107_102612_bedrock_anthropic-claude-opus-4-5-2025"
    }
  ]
}